[["index.html", "Personality Predictors of Dementia Diagnosis and Neuropathic Burden: A Mega-Analysis Chapter 1 Workspace 1.1 Packages 1.2 Directory Path 1.3 Codebook 1.4 Tables", " Personality Predictors of Dementia Diagnosis and Neuropathic Burden: A Mega-Analysis Emorie D. Beck Feinberg School of Medicine Daniel K. Mroczek Feinberg School of Medicine, Northwestern University Eileen K. Graham Feinberg School of Medicine 25 October 2022 Abstract “INTRODUCTION: The extent to which the Big Five personality traits and subjective well-being (SWB) are discriminatory predictors of clinical manifestation of dementia versus dementia-related neuropathology is unclear.” “METHODS: Using data from eight independent studies (Ntotal=44,531; baseline Mage= years, % female), Bayesian multilevel models tested whether traits and SWB differentially predicted neuropsychological and neuropathological characteristics of dementia.” “RESULTS: Adjusting for sociodemographic and health covariates, synthesized and individual study results indicate that high neuroticism, low conscientiousness, and high negative affect were associated with increased risk of long-term dementia diagnosis.” “DISCUSSION: This multi-study project provides robust, conceptually replicated evidence that psychosocial factors are strong predictors of dementia diagnosis, but differentially associated with neuropathology at autopsy as a function of premorbid dementia diagnoses in some samples. These results suggest the possible importance of brain maintenance or test performance, while also highlighting the need for ongoing data collection efforts to disentangle these complex relationships.” Chapter 1 Workspace In this section, we’ll set up everything we need to clean data in the next section. This includes: Loading in all packages Loading in the codebook Setting up data frames for personality traits / well-being, outcomes, covariates, and moderators, so that we can more easily rename their short-hand names to production ready ones later Loading in and rendering html tables of some descriptives, measures, etc. 1.1 Packages First, let’s load in the packages. Note the descriptions for each commented next to them. library(knitr) # knit documents library(kableExtra) # formatted tables library(readxl) # read excel files library(haven) # read spss files library(broom.mixed) # summaries of models library(rstan) # bayes underpinnings library(tidybayes) # pretty bayes draws and plots library(cowplot) # piece plots together library(plyr) # data wrangling library(tidyverse) # data wrangling library(brms) # bayesian models library(furrr) # parallel purrr mapping library(psych) # psychometrics 1.2 Directory Path We have three different directories: 1. data_path stores the raw that that cannot be shared per data use agreements 2. res_path includes the GitHub link where shareable objects can be found 3. local_path is mostly used to save files as they render, or in some limited cases of objects that hold raw data, to access those objects that can’t be shared data_path &lt;- &quot;/Volumes/Emorie/data&quot; # res_path &lt;- &quot;/Volumes/Emorie/projects/dementia/prediction&quot; res_path &lt;- &quot;https://github.com/emoriebeck/personality-dementia-neuropath/raw/master&quot; local_path &lt;- &quot;/Volumes/Emorie/projects/dementia/prediction&quot; 1.3 Codebook Each study has a separate codebook indexing covariate, moderator, personality, and outcome variables. Moreover, these codebooks contain information about the original scale of the variable, any recoding of the variable (including binarizing outcomes, changing the scale, and removing missing data), reverse coding of scale variables, categories, etc. # list of all codebook sheets url &lt;- &quot;https://github.com/emoriebeck/personality-dementia-neuropath/raw/master/codebooks/master_codebook_09.04.20.xlsx?raw=true&quot; destfile &lt;- &quot;master_codebook_09.04.20.xlsx&quot; curl::curl_download(url, destfile) sheets &lt;- excel_sheets(destfile) # function for reading in sheets read_fun &lt;- function(x){ read_xlsx(destfile, sheet = x) } # read in sheets and index source codebook &lt;- tibble( study = sheets, codebook = map(study, read_fun) ) ## short and long versions of names of all categories for later use studies &lt;- c(&quot;ROS&quot;, &quot;RADC-MAP&quot;, &quot;EAS&quot;, &quot;ADRC&quot; , &quot;SATSA&quot;, &quot;HRS&quot;, &quot;LISS&quot;, &quot;GSOEP&quot;) studies_long &lt;- c(&quot;ROS&quot;, &quot;Rush-MAP&quot;, &quot;EAS&quot;, &quot;WUSM-MAP&quot;, &quot;SATSA&quot;, &quot;HRS&quot;, &quot;LISS&quot;, &quot;GSOEP&quot;) stdcolors &lt;- tibble( studies = c(&quot;Overall&quot;, studies) , studies_long = c(&quot;Overall&quot;, studies_long) , std_text = str_remove_all(studies, &quot;[-]&quot;) , colors = c(&quot;black&quot;, &quot;#332288&quot;, &quot;#88ccee&quot;, &quot;#44aa99&quot;, &quot;#117733&quot;, &quot;#999933&quot;, #&quot;#ddcc77&quot;, &quot;#cc6677&quot;, &quot;#332288&quot;, &quot;#88ccee&quot;, &quot;#44aa99&quot;)#, &quot;#117733&quot;, &quot;#999933&quot;, &quot;#ddcc77&quot;) , lt = c(rep(&quot;solid&quot;, 6), rep(&quot;dotted&quot;, 3))) traits &lt;- codebook$codebook[[2]] %&gt;% filter(category == &quot;pers&quot;) %&gt;% select(long_name = Construct, short_name = name); traits ## # A tibble: 8 × 2 ## long_name short_name ## &lt;chr&gt; &lt;chr&gt; ## 1 Extraversion E ## 2 Agreeableness A ## 3 Conscientiousness C ## 4 Neuroticism N ## 5 Openness to Experience O ## 6 Positive Affect PA ## 7 Negative Affect NA ## 8 Satisfaction with Life SWL outcomes &lt;- codebook$codebook[[2]] %&gt;% filter(category == &quot;out&quot;) %&gt;% select(long_name = Construct, short_name = name, link, colnm); outcomes ## # A tibble: 11 × 4 ## long_name short_name link colnm ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Incident Dementia Diagnosis dementia factor OR [CI] ## 2 Braak Stage braak continuous b [CI] ## 3 CERAD cerad continuous b [CI] ## 4 Lewy Body Disease lewyBodyDis factor OR [CI] ## 5 Gross Cerebral Infarcts vsclrInfrcts factor OR [CI] ## 6 Gross Cerebral Microinfarcts vsclrMcrInfrcts factor OR [CI] ## 7 Cerebral Atherosclerosis atherosclerosis continuous b [CI] ## 8 Cerebral Amyloid Angiopathy angiopathy continuous b [CI] ## 9 Arteriolosclerosis arteriolosclerosis continuous b [CI] ## 10 Hippocampal Sclerosis hipSclerosis factor OR [CI] ## 11 TDP-43 tdp43 factor OR [CI] moders &lt;- codebook$codebook[[2]] %&gt;% filter(category == &quot;mod&quot;) %&gt;% select(long_name = Construct, short_name = name, short_term = old_term, long_term = new_term); moders ## # A tibble: 6 × 4 ## long_name short_name short_term long_term ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 None none p_value Personality ## 2 Age age age Age ## 3 Gender gender gender1 Gender (Male v Female) ## 4 Education education education Education (Years) ## 5 Cognition cognition cognition Cognition ## 6 Dementia Diagnosis dementia dementia Dementia Diagnosis (No v Yes) covars &lt;- codebook$codebook[[2]] %&gt;% filter(category == &quot;covariates&quot;) %&gt;% select(long_name = Construct, short_name = name, desc = new_term); # used personality waves url &lt;- &quot;https://github.com/emoriebeck/personality-dementia-neuropath/raw/master/codebooks/tables.xlsx?raw=true&quot; destfile &lt;- &quot;tables.xlsx&quot; curl::curl_download(url, destfile) p_waves &lt;- read_xlsx(destfile, sheet = &quot;Table 2&quot;) 1.4 Tables 1.4.1 Table S1 Below, I create Table S1, which includes information the personality and well-being scales used in each study: p_tab &lt;- p_waves %&gt;% select(Study, everything(), -p_item, -Used) %&gt;% filter(Study != &quot;BLSA&quot;) %&gt;% mutate(Measure = factor(Measure, traits$long_name)) %&gt;% arrange(Study, Measure) rs &lt;- p_tab %&gt;% group_by(Study) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) p_tab &lt;- p_tab %&gt;% select(-Study) %&gt;% kable(. , &quot;html&quot; , caption = &quot;&lt;strong&gt;Table S1&lt;/strong&gt;&lt;br&gt;&lt;em&gt;Personality Trait and Subjective Well-Being Measurement Inventories, Scales, and Assessments Across Samples&lt;/em&gt;&quot; , escape = F , col.names = paste0(&quot;&lt;strong&gt;&quot;, colnames(p_tab)[-1], &quot;&lt;/strong&gt;&quot;) , align = c(&quot;r&quot;, &quot;l&quot;, &quot;l&quot;, &quot;c&quot;) ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) for (i in 1:nrow(rs)){ p_tab &lt;- p_tab %&gt;% kableExtra::group_rows(rs$Study[i], rs$start[i], rs$end[i]) } p_tab Table 1.1: Table S1Personality Trait and Subjective Well-Being Measurement Inventories, Scales, and Assessments Across Samples Measure Source Scale Used (Available) ADRC-MAP Extraversion 12 items from the NEO Five-Factor Inventory (NEO-FFI; Costa &amp; McCrae, 1992) 1 “strongly disagree” to 5 “strongly agree” Baseline (Clinical Follow-ups) Agreeableness 12 items from the NEO Five-Factor Inventory (NEO-FFI; Costa &amp; McCrae, 1992) 1 “strongly disagree” to 5 “strongly agree” Baseline (Clinical Follow-ups) Conscientiousness 12 items from the NEO Five-Factor Inventory (NEO-FFI; Costa &amp; McCrae, 1992) 1 “strongly disagree” to 5 “strongly agree” Baseline (Clinical Follow-ups) Neuroticism 12 items from the NEO Five-Factor Inventory (NEO-FFI; Costa &amp; McCrae, 1992) 1 “strongly disagree” to 5 “strongly agree” Baseline (Clinical Follow-ups) Positive Affect — — — Negative Affect — — — Satisfaction with Life — — — 12 items from the NEO Five-Factor Inventory (NEO-FFI; Costa &amp; McCrae, 1992) 1 “strongly disagree” to 5 “strongly agree” Baseline (Clinical Follow-ups) EAS Extraversion 24 items from the IPIP NEO 1 “strongly disagree” to 5 “strongly agree” 2004 (Annual Follow-ups) Agreeableness 24 items from the IPIP NEO 1 “strongly disagree” to 5 “strongly agree” 2004 (Annual Follow-ups) Conscientiousness 24 items from the IPIP NEO 1 “strongly disagree” to 5 “strongly agree” 2004 (Annual Follow-ups) Neuroticism 24 items from the IPIP NEO 1 “strongly disagree” to 5 “strongly agree” 2004 (Annual Follow-ups) Positive Affect — — — Negative Affect — — — Satisfaction with Life — — — 24 items from the IPIP NEO 1 “strongly disagree” to 5 “strongly agree” 2004 (Annual Follow-ups) GSOEP Extraversion 3 items from the 15 item BFI-S (John, Naumann, &amp; Soto, 2008, and Lang, Lüdtke, &amp; Asendorpf, 2001) 1 “does not apply at all” to 7 ” applies perfectly” 2005 (2005, 2009, 2013, 2017) Agreeableness 3 items from the 15 item BFI-S (John, Naumann, &amp; Soto, 2008, and Lang, Lüdtke, &amp; Asendorpf, 2001) 1 “does not apply at all” to 7 ” applies perfectly” 2005 (2005, 2009, 2013, 2017) Conscientiousness 3 items from the 15 item BFI-S (John, Naumann, &amp; Soto, 2008, and Lang, Lüdtke, &amp; Asendorpf, 2001) 1 “does not apply at all” to 7 ” applies perfectly” 2005 (2005, 2009, 2013, 2017) Neuroticism 3 items from the 15 item BFI-S (John, Naumann, &amp; Soto, 2008, and Lang, Lüdtke, &amp; Asendorpf, 2001) 1 “does not apply at all” to 7 ” applies perfectly” 2005 (2005, 2009, 2013, 2017) Positive Affect 1 item (“Frequency of being happy in the last 4 weeks”) 1 “very seldom” to 5 “very often” 2007 (2007-2017) Negative Affect 3 items (angry, sad, worried) 1 “very seldom” to 5 “very often” 2007 (2007-2017) Satisfaction with Life SWLS (Diener, Emmons, Larsen, &amp; Griffin, 1985) 0 “low” to 10 “high” 2005 (1984-2017) 3 items from the 15 item BFI-S (John, Naumann, &amp; Soto, 2008, and Lang, Lüdtke, &amp; Asendorpf, 2001) 1 “does not apply at all” to 7 ” applies perfectly” 2005 (2005, 2009, 2013, 2017) HRS Extraversion 5 adjectives from a 25 adjective checklist (Lachman &amp; Weaver, 1997) **1 “a lot” to 4 “not at all” 2006/8 (2006/8, 2010/12, 2014/16) Agreeableness 5 adjectives from a 25 adjective checklist (Lachman &amp; Weaver, 1997) **1 “a lot” to 4 “not at all” 2006/8 (2006/8, 2010/12, 2014/16) Conscientiousness 5 adjectives from a 25 adjective checklist (Lachman &amp; Weaver, 1997) **1 “a lot” to 4 “not at all” 2006/8 (2006/8, 2010/12, 2014/16) Neuroticism 5 adjectives from a 25 adjective checklist (Lachman &amp; Weaver, 1997) **1 “a lot” to 4 “not at all” 2006/8 (2006/8, 2010/12, 2014/16) Positive Affect PANAS-X (Watson &amp; Clark, 1994) *1 “very much” to 5 “not at all” 2006-2016 Negative Affect PANAS-X (Watson &amp; Clark, 1994) *1 “very much” to 5 “not at all” 2006-2016 Satisfaction with Life SWLS (Diener, Emmons, Larsen, &amp; Griffin, 1985) 1 “strongly disagree” to 7 “strongly agree” 2006/8 (2006/8, 2010/12, 2014/16) 5 adjectives from a 25 adjective checklist (Lachman &amp; Weaver, 1997) **1 “a lot” to 4 “not at all” 2006/8 (2006/8, 2010/12, 2014/16) LISS Extraversion 10 items from the 50 item IPIP-50 (Goldberg, 1992) 1 “very inaccurate” to 5 “very accurate” 2008 (2008-2018) Agreeableness 10 items from the 50 item IPIP-50 (Goldberg, 1992) 1 “very inaccurate” to 5 “very accurate” 2008 (2008-2018) Conscientiousness 10 items from the 50 item IPIP-50 (Goldberg, 1992) 1 “very inaccurate” to 5 “very accurate” 2008 (2008-2018) Neuroticism 10 items from the 50 item IPIP-50 (Goldberg, 1992) 1 “very inaccurate” to 5 “very accurate” 2008 (2008-2018) Positive Affect 10 items (e.g. “interested”) 1 “not at all” to 7 “extremely” 2008 (2008-2018) Negative Affect 10 items (e.g. “distressed”) 1 “not at all” to 7 “extremely” 2008 (2008-2018) Satisfaction with Life SWLS (Diener, Emmons, Larsen, &amp; Griffin, 1985) 1 “strongly disagree” to 7 “strongly agree” 2008 (2008-2018) 10 items from the 50 item IPIP-50 (Goldberg, 1992) 1 “very inaccurate” to 5 “very accurate” 2008 (2008-2018) RUSH-MAP Extraversion 6 items from the NEO Five Factor Inventory 1 “strongly disagree” to 5 “strongly agree” Baseline (Baseline) Agreeableness — — — Conscientiousness 12 items from the NEO Five-Factor Inventory (NEO-FFI; Costa &amp; McCrae, 1992) 1 “strongly disagree” to 5 “strongly agree” Baseline (Baseline) Neuroticism 12 items from the NEO Five-Factor Inventory (NEO-FFI; Costa &amp; McCrae, 1992) 1 “strongly disagree” to 5 “strongly agree” Baseline (Baseline) Positive Affect 1 item “Overall, how happy are you?” *1 “Very happy” to 4 “Not happy at all” Baseline (Annual Clinical Followups) Negative Affect PANAS-X (Watson &amp; Clark, 1994) 1 “Very slightly or not at al” to 5 “Extremely” Baseline (Annual Clinical Followups) Satisfaction with Life SWLS (Diener, Emmons, Larsen, &amp; Griffin, 1985) *1 “Strongly agree” to 7 “Strongly Disagree” Baseline (Annual Clinical Followups) — — — RUSH-ROS Extraversion 6 items from the NEO Five Factor Inventory 1 “strongly disagree” to 5 “strongly agree” Baseline (Baseline) Agreeableness 12 items from the NEO Five-Factor Inventory (NEO-FFI; Costa &amp; McCrae, 1992) 1 “strongly disagree” to 5 “strongly agree” Baseline (Baseline) Conscientiousness 12 items from the NEO Five-Factor Inventory (NEO-FFI; Costa &amp; McCrae, 1992) 1 “strongly disagree” to 5 “strongly agree” Baseline (Baseline) Neuroticism 12 items from the NEO Five-Factor Inventory (NEO-FFI; Costa &amp; McCrae, 1992) 1 “strongly disagree” to 5 “strongly agree” Baseline (Baseline) Positive Affect 1 item “Overall, how happy are you?” *1 “Very happy” to 4 “Not happy at all” Baseline (Annual Clinical Followups) Negative Affect — — — Satisfaction with Life SWLS (Diener, Emmons, Larsen, &amp; Griffin, 1985) *1 “Strongly agree” to 7 “Strongly Disagree” Baseline (Annual Clinical Followups) 12 items from the NEO Five-Factor Inventory (NEO-FFI; Costa &amp; McCrae, 1992) 1 “strongly disagree” to 5 “strongly agree” Baseline (Baseline) SATSA Extraversion 9 items from the Eysenck Personality Inventory **1 “exactly right” to 5 “not right at all” 1984 (1984, 1987, 1989, 1990, 1992, 1993, 1999, 2002, 2004, 2005, 2007) Agreeableness 10 items **1 “exactly right” to 5 “not right at all” 1984 (1984) Conscientiousness 10 items **1 “exactly right” to 5 “not right at all” 1984 (1984) Neuroticism 9 items from the Eysenck Personality Inventory **1 “exactly right” to 5 “not right at all” 1984 (1984, 1987, 1989, 1990, 1992, 1993, 1999, 2002, 2004, 2005, 2007) Positive Affect 5 items (e.g., “calm”, “harmonious”) **1 “exactly right” to 5 “not right at all” 1984 (1984, 1987, 1989, 1990, 1992, 1993, 1995) Positive Affect 6 items (e.g., “worried”, “tense”) **1 “exactly right” to 5 “not right at all” 1984 (1984, 1987, 1989, 1990, 1992, 1993, 1995) Satisfaction with Life 13 items **1 “exactly right” to 5 “not right at all” 1984 (1984, 1987, 1989, 1990, 1993, 2004, 2007) 25 items from the NEO Personality Inventory **1 “exactly right” to 5 “not right at all” 1984 (1984) save_kable(p_tab, file = sprintf(&quot;%s/results/tables/tab-s1.html&quot;, local_path)) 1.4.2 Table S2 Next, I create table S2, which indicates which measures were in each study, including which cognitive measures were in each sample. meas &lt;- read_xlsx(destfile, sheet = &quot;Table 1&quot;) %&gt;% select(-BLSA) rs &lt;- meas %&gt;% group_by(Category) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) meas &lt;- meas %&gt;% select(-Category) %&gt;% kable(. , &quot;html&quot; , caption = &quot;&lt;strong&gt;Table S2&lt;/strong&gt;&lt;br&gt;&lt;em&gt;List of Measures Across Samples&lt;/em&gt;&quot; , escape = F , col.names = paste0(&quot;&lt;strong&gt;&quot;, colnames(meas)[-1], &quot;&lt;/strong&gt;&quot;) , align = c(&quot;l&quot;, rep(&quot;c&quot;, 8)) ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) for (i in 1:nrow(rs)){ meas &lt;- meas %&gt;% kableExtra::group_rows(rs$Category[i], rs$start[i], rs$end[i]) } meas Table 1.2: Table S2List of Measures Across Samples Measure GSOEP HRS LISS SATSA RUSH-MAP RUSH-ROS ADRC-MAP EAS Cognitive Extraversion X X X X X X X X Covariates Agreeableness X X X X X X X Outcomes Conscientiousness X X X X X X X Personality Neuroticim X X X X X X X X NA Openness to Experience X X X X X X X X Satisfaction with Life X X X X X X X Positive Affect X X X X X Negative Affect X X X X X Self-Reported Dementia X X X X X X X X Braak Stage X X X X CERAD X X X X Lewy Body Disease X X X X Gross Cerebral Infarcts X X X X Gross Cerebral Microinfarcts X X X X Cerebral Atherosclerosis X X X X Cerebral Amyloid Angiopathy X X X X Arteriolosclerosis X X X X Hippocampal Sclerosis X X X X Block Design X X X Digits Forward X X X X X Digits Backward X X X X X X Information X X X Digit Symbol X X X X X Cued Recall X X X Free Recall X X X X X Category Fluency X X X X X Picture Memory X Figure Logic X Vocabulary X X Boston Naming Test X X Progressive Matrices X Serial 7’s X Trail-Making Task X X Card Rotation Age X X X X X X X X Gender X X X X X X X X Education X X X X X X X X Race X X X X Ethnicity X X X X Marital Status X X X X X X X X Self-Rated Health X X X X X X Heart Problems X X X X X X X X Stroke X X X X X X X X Diabetes X X X X X X X X Cancer X X X X X X X X Respiratory Problems X X X X X X X X Smoking X X X X X X X Alcohol X X X X X X X save_kable(meas, file = sprintf(&quot;%s/results/tables/tab-s2.html&quot;, local_path)) "],["cleaning.html", "Chapter 2 Data Cleaning 2.1 Health and Retirement Study (HRS) 2.2 RUSH Memory and and Aging Project (RUSH-MAP) 2.3 RUSH Religious Orders Study (ROS) 2.4 Swedish Adoption Twin Study of Aging (SATSA) 2.5 ADRC Memory and Aging Project (ADRC-MAP) 2.6 Einstein Aging Study 2.7 German Socioeconomic Panel Study (GSOEP) 2.8 The Longitudinal Studies for the Social sciences (LISS)", " Chapter 2 Data Cleaning In this section, we will clean the data for each study. Raw data cannot be shared directly, but for each study, we include instrucitons on how to access the data. Mode &lt;- function(x) { ux &lt;- unique(x) ux &lt;- ux[!is.na(ux)] ux[which.max(tabulate(match(x, ux)))] } pomp &lt;- function(x) (x - min(x, na.rm = T))/(max(x, na.rm = T) - min(x, na.rm = T))*10 2.1 Health and Retirement Study (HRS) The Health and Retirement Study [HRS; (juster1995overview?)] is an ongoing longitudinal study of households in the United States. These data are available at https://hrs.isr.umich.edu by creating a free account. Participants were recruited from more than 35,000 individuals from the financial households of individuals born between 1931 and 1941 in the US. Data have been collected biannually since 1992. The latest data release includes data up to 2016. On average, 10,000 individuals are sampled each wave More information on the HRS can be found at https://hrs.isr.umich.edu/documentation/survey-design, but, in short, the HRS is a nationally representative sample of adults over 50 in the US. It is critical to note that the HRS samples households of the original cohort and follows individuals and their spouses or partners until their death. Sample size varies by year, ranging from approximately 7,500 (2014) to 15,500 (1992). (https://hrs.isr.umich.edu/sites/default/files/biblio/ResponseRates_2017.pdf). This provides 99% power to detect a zero-order correlation effect size of ~.04, two-tailed at alpha .05. 2.1.1 Load Data hrs_read_fun &lt;- function(year) { read_da &lt;- function(da, dct, Year){ print(paste(da, dct, year, sep = &quot; &quot;)) data.file &lt;- sprintf(&quot;%s/hrs/%s/%s&quot;, data_path, Year, da) # Set path to the dictionary file &quot;*.DCT&quot; dict.file &lt;- sprintf(&quot;%s/hrs/%s/%s&quot;, data_path, Year, dct) # Read the dictionary file df.dict &lt;- read.table(dict.file, skip = 1, fill = TRUE, stringsAsFactors = FALSE) # Set column names for dictionary dataframe colnames(df.dict) &lt;- c(&quot;col.num&quot;,&quot;col.type&quot;,&quot;col.name&quot;,&quot;col.width&quot;,&quot;col.lbl&quot;) # Remove last row which only contains a closing } row &lt;- which(df.dict$col.name == &quot;HHID&quot;) df.dict &lt;- df.dict[-nrow(df.dict),] if(row == 2){df.dict &lt;- df.dict[-1,]} # Extract numeric value from column width field df.dict$col.width &lt;- as.integer(sapply(df.dict$col.width, gsub, pattern = &quot;[^0-9\\\\.]&quot;, replacement = &quot;&quot;)) # Convert column types to format to be used with read_fwf function df.dict$col.type &lt;- sapply(df.dict$col.type, function(x) ifelse(x %in% c(&quot;int&quot;,&quot;byte&quot;,&quot;long&quot;), &quot;i&quot;, ifelse(x == &quot;float&quot;, &quot;n&quot;, ifelse(x == &quot;double&quot;, &quot;d&quot;, &quot;c&quot;)))) # Read the data file into a dataframe df &lt;- read_fwf(file = data.file, fwf_widths(widths = df.dict$col.width, col_names = df.dict$col.name), col_types = paste(df.dict$col.type, collapse = &quot;&quot;)) # Add column labels to headers attributes(df)$variable.labels &lt;- df.dict$col.lbl old.names &lt;- (hrs_codebook %&gt;% filter(year == Year))$orig_itemname if(any(c(&quot;PN&quot;, &quot;HHID&quot;) %in% colnames(df)) &amp; any(old.names %in% colnames(df))){ # if(any(c(&quot;PN&quot;, &quot;HHID&quot;) %in% colnames(df))){ df &lt;- df %&gt;% mutate(hhidpn = 1000*as.numeric(HHID) + as.numeric(PN)) %&gt;% select(one_of(c(&quot;PN&quot;, &quot;HHID&quot;)), one_of(old.names)) %&gt;% distinct() # gather(key = item, value = value, -hhidpn) } else {df &lt;- NA} return(df) } # Set path to the data file &quot;*.DA&quot; files &lt;- list.files(sprintf(&quot;%s/hrs/%s&quot;, data_path, year)) df2 &lt;- tibble( da = files[grepl(&quot;.da&quot;, files) | grepl(&quot;.DA&quot;, files)], dct = files[grepl(&quot;.dct&quot;, files) | grepl(&quot;.DCT&quot;, files)] ) %&gt;% mutate(data = map2(da, dct, possibly(~read_da(.x, .y, year), NA_real_))) %&gt;% filter(!is.na(data)) %&gt;% select(-da, -dct) if(nrow(df2) != 0){df2$data %&gt;% reduce(full_join) %&gt;% distinct()} else {NA} } hrs_codebook &lt;- (codebook %&gt;% filter(study == &quot;HRS&quot;))$codebook[[1]] %&gt;% mutate(orig_itemname = str_to_upper(orig_itemname)) %&gt;% mutate_at(vars(orig_itemname, name, itemname), ~str_remove_all(., &quot;[[:space:]]&quot;)) hrs_codebook ## # A tibble: 702 × 17 ## study dataset category name itemname wave waveletter year orig_itemname descrip…¹ scale rever…² recode mini maxi comp_…³ long_…⁴ ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 hrs Rand cognition cognition digitsBckwd 3 &lt;NA&gt; 1996 R3BWC20 BACKWARD… &quot;0.I… no ifels… NA NA sum select ## 2 hrs Rand cognition cognition digitsBckwd 4 &lt;NA&gt; 1998 R4BWC20 BACKWARD… &quot;0.I… no ifels… NA NA sum select ## 3 hrs Rand cognition cognition digitsBckwd 5 &lt;NA&gt; 2000 R5BWC20 BACKWARD… &quot;0.I… no ifels… NA NA sum select ## 4 hrs Rand cognition cognition digitsBckwd 6 &lt;NA&gt; 2002 R6BWC20 BACKWARD… &quot;0.I… no ifels… NA NA sum select ## 5 hrs Rand cognition cognition digitsBckwd 7 &lt;NA&gt; 2004 R7BWC20 BACKWARD… &quot;0.I… no ifels… NA NA sum select ## 6 hrs Rand cognition cognition digitsBckwd 8 &lt;NA&gt; 2006 R8BWC20 BACKWARD… &quot;0.I… no ifels… NA NA sum select ## 7 hrs Rand cognition cognition digitsBckwd 9 &lt;NA&gt; 2008 R9BWC20 BACKWARD… &quot;0.I… no ifels… NA NA sum select ## 8 hrs Rand cognition cognition digitsBckwd 10 &lt;NA&gt; 2010 R10BWC20 BACKWARD… &quot;0.I… no ifels… NA NA sum select ## 9 hrs Rand cognition cognition digitsBckwd 11 &lt;NA&gt; 2012 R11BWC20 BACKWARD… &quot;0.I… no ifels… NA NA sum select ## 10 hrs Rand cognition cognition digitsBckwd 12 &lt;NA&gt; 2014 R12BWC20 BACKWARD… &quot;0.I… no ifels… NA NA sum select ## # … with 692 more rows, and abbreviated variable names ¹​description, ²​reverse_code, ³​comp_rule, ⁴​long_rule old.names &lt;- unique(hrs_codebook$orig_itemname) hrs.paq &lt;- tibble( year = sprintf(&quot;%s/hrs&quot;, data_path) %&gt;% list.files(., pattern = &quot;^[0-9]&quot;) , data = map(year, hrs_read_fun) , names = map(data, colnames) ) %&gt;% filter(!is.na(data)) old.names &lt;- unique((hrs_codebook %&gt;% filter(dataset == &quot;Rand&quot;))$orig_itemname) hrs.rand &lt;- sprintf(&quot;%s/hrs/randhrs1992_2016v1.sav&quot;, data_path) %&gt;% haven::read_sav(.) %&gt;% haven::zap_labels(.) %&gt;% select(SID = HHIDPN, one_of(old.names)) %&gt;% gather(key = orig_itemname, value = value, -SID, na.rm = T) hrs_long &lt;- hrs.paq %&gt;% mutate(data = map(data, ~(.) %&gt;% pivot_longer(cols = c(-HHID, -PN) , names_to = &quot;orig_itemname&quot; , values_to = &quot;value&quot; , values_drop_na = TRUE))) %&gt;% select(-names, -year) %&gt;% unnest(data) %&gt;% mutate(SID = 1000*as.numeric(HHID) + as.numeric(PN)) %&gt;% select(-PN, -HHID) hrs_dem &lt;- sprintf(&quot;%s/hrs/pdem_withvarnames.sas7bdat&quot;, data_path) %&gt;% haven::read_sas(.) %&gt;% select(SID = hhidpn, year = prediction_year, value = prob_dementia) %&gt;% mutate(orig_itemname = &quot;PROB_DEMENTIA&quot;) hrs.subs &lt;- unique(hrs_long$SID)[unique(hrs_long$SID) %in% unique(hrs.rand$SID)] hrs_long &lt;- hrs_long %&gt;% bind_rows(hrs.rand %&gt;% select(orig_itemname, value, SID)) %&gt;% filter(SID %in% hrs.subs) save(hrs.rand, hrs.paq, file = sprintf(&quot;%s/data/clean/hrs_raw.RData&quot;, load_path)) rm(list = c(&quot;hrs.paq&quot;, &quot;hrs.rand&quot;)) 2.1.2 Recoding &amp; Reverse Scoring hrs_waves &lt;- p_waves %&gt;% filter(Study == &quot;HRS&quot;) %&gt;% select(Used) %&gt;% distinct() # join data with recoding info hrs_recode &lt;- hrs_codebook %&gt;% filter(category %in% c(&quot;pers&quot;, &quot;outcome&quot;, &quot;covariates&quot;, &quot;cognition&quot;) &amp; orig_itemname != &quot;prob_dementia&quot;) %&gt;% select(category, name, itemname, wave, year, orig_itemname, reverse_code:long_rule) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% left_join(hrs_long))) hrs_recode &lt;- hrs_dem %&gt;% left_join( hrs_codebook %&gt;% select(category, name, itemname, orig_itemname, reverse_code:long_rule) ) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() %&gt;% bind_rows(hrs_recode) # recode recode_fun &lt;- function(rule, y, year, p_year){ x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } hrs_recode &lt;- hrs_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(year = mapvalues(year, seq(2006, 2016, 2), rep(c(2006, 2010, 2014), each = 2)), p_year = 2006) %&gt;% group_by(recode, year, p_year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(recode, data, year, p_year), recode_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(value &lt; 0 | is.nan(value) | is.infinite(value), NA, value)))) # reverse code hrs_recode &lt;- hrs_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(value = ifelse(reverse_code == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))))) fun_call &lt;- function(x, rule){ switch(rule, average = mean(x, na.rm = T), mode = Mode(x)[1], sum = sum(x, na.rm = T), skip = unique(x)[1], select = unique(x)[1], max = max(x, na.rm = T), min = min(x, na.rm = T)) } 2.1.3 Covariates # compositing within years year_comp_fun &lt;- function(df, rule){ df %&gt;% # group by person and item (collapse across age) group_by(SID, name, year, p_year, long_rule) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } # composite WITHIN years hrs_cov &lt;- hrs_recode %&gt;% filter(category == &quot;covariates&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule), &quot;skip&quot;, comp_rule)) %&gt;% group_by(comp_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, year_comp_fun)) %&gt;% unnest(data) comp_fun &lt;- function(d, rule, p_year){ d %&gt;% filter(year &lt;= p_year) %&gt;% group_by(SID, name) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% distinct() } # composite ACROSS years hrs_cov &lt;- hrs_cov %&gt;% mutate(long_rule = ifelse(is.na(long_rule), &quot;skip&quot;, long_rule)) %&gt;% group_by(p_year, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(data, long_rule, p_year), comp_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %&gt;% select(-long_rule) %&gt;% spread(name, value) %&gt;% filter(!is.na(SID)) hrs_cov ## # A tibble: 28,726 × 19 ## p_year SID alcohol BMI cancer diabe…¹ educa…² exerc…³ gender heart…⁴ height married race respDis smokes SRhea…⁵ stroke weight yearB…⁶ ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2006 3010 1 28.8 0 0 12 2.02 0 1 165. 1 0 0 0 2 0 73.4 1936 ## 2 2006 3020 1 28.8 1 0 16 1.77 1 0 165. 1 0 0 0 3 0 83.6 1938 ## 3 2006 10001010 0 23.5 0 0 12 1.88 0 0 183. 0 0 0 0 5 0 78.6 1939 ## 4 2006 10003030 0 28.5 0 0 16 1.25 1 1 157. 1 0 1 0 3 1 76.8 1956 ## 5 2006 10004010 1 27.0 1 0 16 1.75 0 0 185. 1 0 0 1 5 0 99.7 1939 ## 6 2006 10004040 1 27.0 0 0 12 2 1 0 165. 1 0 0 1 5 0 68.4 1946 ## 7 2006 10013010 0 28.2 0 1 12 1.57 0 1 177. 1 0 0 1 5 0 89.0 1938 ## 8 2006 10013040 1 24.5 0 0 13 1.5 1 0 160. 1 0 0 1 3 0 62.2 1947 ## 9 2006 10038010 1 23.3 0 0 16 1.75 0 1 177. 1 0 0 0 5 0 76.7 1936 ## 10 2006 10038040 1 23.3 0 0 16 1.78 1 0 170. 1 0 0 1 5 0 64.1 1943 ## # … with 28,716 more rows, and abbreviated variable names ¹​diabetes, ²​education, ³​exercise, ⁴​heartProb, ⁵​SRhealth, ⁶​yearBrth 2.1.4 Personality Variables hrs_pers &lt;- hrs_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% filter(year == &quot;2006&quot; &amp; !is.na(value)) %&gt;% group_by(SID, p_year, year, name, itemname, comp_rule) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() # alpha&#39;s hrs_alpha &lt;- hrs_pers %&gt;% filter(!is.na(value)) %&gt;% select(name, itemname, year, SID, value) %&gt;% group_by(name, year) %&gt;% nest() %&gt;% mutate(data = map(data, ~(.) %&gt;% distinct() %&gt;% pivot_wider(names_from = itemname, values_from = value, values_fn = list(mean))), alpha = map(data, possibly(~psych::alpha((.) %&gt;% select(-SID)), NA_real_))) comp_fun &lt;- function(df, rule){ df %&gt;% group_by(SID) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } # create composites hrs_pers &lt;- hrs_pers %&gt;% group_by(name, comp_rule, year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, comp_fun)) %&gt;% unnest(data) %&gt;% select(-comp_rule) hrs_pers ## # A tibble: 116,915 × 4 ## year name SID value ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2006 A 3010 3 ## 2 2006 A 3020 3 ## 3 2006 A 10001010 4 ## 4 2006 A 10003030 3.4 ## 5 2006 A 10004010 3.4 ## 6 2006 A 10004040 3.6 ## 7 2006 A 10013010 2 ## 8 2006 A 10013040 2.6 ## 9 2006 A 10038010 3.4 ## 10 2006 A 10038040 2.6 ## # … with 116,905 more rows 2.1.5 Cognition Variables hrs_cog &lt;- hrs_recode %&gt;% filter(category == &quot;cognition&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% filter(year == p_year) %&gt;% filter(!is.na(value)) %&gt;% group_by(name, itemname, year) %&gt;% mutate(value = pomp(value)) %&gt;% group_by(SID, name) %&gt;% summarize(value = mean(value)) %&gt;% ungroup() %&gt;% pivot_wider(names_from = &quot;name&quot;, values_from = &quot;value&quot;) hrs_cog ## # A tibble: 16,778 × 2 ## SID cognition ## &lt;dbl&gt; &lt;dbl&gt; ## 1 3010 7.5 ## 2 3020 8.08 ## 3 10001010 8.75 ## 4 10003030 6 ## 5 10004010 7.92 ## 6 10004040 8.83 ## 7 10013010 7.25 ## 8 10013040 8.67 ## 9 10038010 8.58 ## 10 10038040 8.25 ## # … with 16,768 more rows 2.1.6 Outcome Variables # composite within years # compositing within years hrs_out &lt;- hrs_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% unnest(data) %&gt;% group_by(SID, name, year, p_year) %&gt;% summarize(value = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.nan(value) | is.infinite(value), NA, value), group = ifelse(year &gt; p_year, &quot;future&quot;, &quot;past&quot;)) %&gt;% filter(!is.na(value)) %&gt;% group_by(SID, p_year, year, name, group) %&gt;% mutate(value = ifelse(value &lt; .5, 0, 1)) %&gt;% group_by(SID, p_year, name, group) %&gt;% summarize(value = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value), NA, value)) %&gt;% pivot_wider(names_from = group, values_from = value) %&gt;% group_by(SID, name) %&gt;% mutate(value = ifelse(is.na(past) | (past == 0 &amp; !is.na(future)), future, ifelse(past == 0 &amp; is.na(future), past, ifelse(past == 1, NA, NA)))) %&gt;% ungroup() hrs_out ## # A tibble: 27,187 × 6 ## SID p_year name future past value ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 3010 2006 dementia 1 NA 1 ## 2 3020 2006 dementia 0 NA 0 ## 3 10001010 2006 dementia 0 NA 0 ## 4 10003030 2006 dementia 0 NA 0 ## 5 10004010 2006 dementia 0 NA 0 ## 6 10004040 2006 dementia 0 NA 0 ## 7 10013010 2006 dementia 1 NA 1 ## 8 10013040 2006 dementia 0 NA 0 ## 9 10038010 2006 dementia 0 NA 0 ## 10 10038040 2006 dementia 0 NA 0 ## # … with 27,177 more rows 2.1.7 Combine Data hrs_combined &lt;- hrs_pers %&gt;% rename(Trait = name, p_value = value, p_year = year) %&gt;% full_join(hrs_out %&gt;% select(SID, Outcome = name, o_value = value)) %&gt;% full_join(hrs_cov) %&gt;% left_join( hrs_out %&gt;% filter(name == &quot;dementia&quot;) %&gt;% mutate(value = ifelse(rowSums(cbind(future, past), na.rm = T) &gt;= 1, 1, 0)) %&gt;% select(-future, -past) %&gt;% pivot_wider(names_from = &quot;name&quot;, values_from = &quot;value&quot;) ) %&gt;% full_join(hrs_cog) %&gt;% filter(!is.na(p_value) &amp; !is.na(o_value)) %&gt;% mutate(age = p_year - yearBrth , o_year = 2014) hrs_combined ## # A tibble: 110,816 × 27 ## p_year Trait SID p_value Outcome o_value alcohol BMI cancer diabe…¹ educa…² exerc…³ gender heart…⁴ height married race respDis smokes ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2006 A 3010 3 dement… 1 1 28.8 0 0 12 2.02 0 1 165. 1 0 0 0 ## 2 2006 A 3020 3 dement… 0 1 28.8 1 0 16 1.77 1 0 165. 1 0 0 0 ## 3 2006 A 10001010 4 dement… 0 0 23.5 0 0 12 1.88 0 0 183. 0 0 0 0 ## 4 2006 A 10003030 3.4 dement… 0 0 28.5 0 0 16 1.25 1 1 157. 1 0 1 0 ## 5 2006 A 10004010 3.4 dement… 0 1 27.0 1 0 16 1.75 0 0 185. 1 0 0 1 ## 6 2006 A 10004040 3.6 dement… 0 1 27.0 0 0 12 2 1 0 165. 1 0 0 1 ## 7 2006 A 10013010 2 dement… 1 0 28.2 0 1 12 1.57 0 1 177. 1 0 0 1 ## 8 2006 A 10013040 2.6 dement… 0 1 24.5 0 0 13 1.5 1 0 160. 1 0 0 1 ## 9 2006 A 10038010 3.4 dement… 0 1 23.3 0 0 16 1.75 0 1 177. 1 0 0 0 ## 10 2006 A 10038040 2.6 dement… 0 1 23.3 0 0 16 1.78 1 0 170. 1 0 0 1 ## # … with 110,806 more rows, 8 more variables: SRhealth &lt;dbl&gt;, stroke &lt;dbl&gt;, weight &lt;dbl&gt;, yearBrth &lt;dbl&gt;, dementia &lt;dbl&gt;, cognition &lt;dbl&gt;, ## # age &lt;dbl&gt;, o_year &lt;dbl&gt;, and abbreviated variable names ¹​diabetes, ²​education, ³​exercise, ⁴​heartProb save(hrs_cov, hrs_alpha, hrs_pers, hrs_out, hrs_combined, hrs_cog, file = sprintf(&quot;%s/data/clean/hrs_cleaned.RData&quot;, load_path)) rm(list =ls()[grepl(&quot;hrs&quot;, ls())]) 2.2 RUSH Memory and and Aging Project (RUSH-MAP) The RUSH Memory and Aging Project (RUSH-MAP) is an ongoing longitudinal study that began in 1997 (a2012overview?). These data are available, through application from https://www.radc.rush.edu/requests.htm. Participants who were 65 and older were recruited from retirement communities and subsidized senior housing facilities throughout Chicagoland and northeastern Illinois beginning in 1997. Data are collected annually, and all participants are organ donors. Additional participants are recuited each year. Additional information and documentation on the data can be found at https://www.radc.rush.edu/docs/var/variables.htm. Sample sizes vary by year, ranging from 52 (1997) to 2205 participants including 884 deceased participants with autopsy data (2019, 2020). This provides 99% power to detect a zero-order correlation effect size of ~.10, two-tailed at alpha .05. 2.2.1 Load Data (map_codebook &lt;- (codebook %&gt;% filter(study == &quot;RADC-MAP&quot;))$codebook[[1]] %&gt;% mutate(orig_itemname = str_to_lower(orig_itemname))) ## # A tibble: 44 × 15 ## study dataset category name itemname year orig_itemname description scale rever…¹ recode mini maxi comp_…² long_…³ ## &lt;chr&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 RADC-MAP NA cognition cognition freeRecall longitudinal cts_wlii word list reca… &lt;NA&gt; no ifels… NA NA sum select ## 2 RADC-MAP NA cognition cognition cuedRecall longitudinal cts_wliii word list reco… &lt;NA&gt; no ifels… NA NA sum select ## 3 RADC-MAP NA cognition cognition digitsFrwd longitudinal cts_df digits backward &lt;NA&gt; no ifels… NA NA sum select ## 4 RADC-MAP NA cognition cognition digitsBckwd longitudinal cts_db digits forward &lt;NA&gt; no ifels… NA NA sum select ## 5 RADC-MAP NA cognition cognition catFluency longitudinal cts_catflu category fluen… &lt;NA&gt; no ifels… NA NA sum select ## 6 RADC-MAP NA cognition cognition bosNaming longitudinal cts_bname Boston naming … &lt;NA&gt; no ifels… NA NA sum select ## 7 RADC-MAP NA cognition cognition progMat longitudinal cts_pmat progressive ma… &lt;NA&gt; no ifels… NA NA sum select ## 8 RADC-MAP NA cognition cognition digitSymbol longitudinal cts_sdmt symbol digits … &lt;NA&gt; no ifels… NA NA sum select ## 9 RADC-MAP NA covariates age ageBaseline baseline age_bl The age at bas… &lt;NA&gt; no ifels… NA NA skip select ## 10 RADC-MAP NA covariates alcohol alcohol baseline alcohol_g_bl Grams of alcoh… &quot;\\r\\… no ifels… NA NA skip average ## # … with 34 more rows, and abbreviated variable names ¹​reverse_code, ²​comp_rule, ³​long_rule map &lt;- sprintf(&quot;%s/rush-radc/dataset_1033_long_03-24-2021.xlsx&quot;, data_path) %&gt;% read_excel() %&gt;% full_join(sprintf(&quot;%s/rush-radc/dataset_1033_basic_03-24-2021.xlsx&quot;, data_path) %&gt;% read_excel()) %&gt;% full_join(sprintf(&quot;%s/rush-radc/dataset_1034_long_03-25-2021.xlsx&quot;, data_path) %&gt;% read_excel()) %&gt;% full_join(sprintf(&quot;%s/rush-radc/dataset_1034_basic_03-25-2021.xlsx&quot;, data_path) %&gt;% read_excel()) %&gt;% filter(study == &quot;MAP&quot;) 2.2.2 Recoding &amp; Reverse Scoring rename_fun &lt;- function(cb, var){ print(var) old.names &lt;- unique((map_codebook %&gt;% filter(name == var))$orig_itemname) df &lt;- map %&gt;% select(SID = projid, wave = fu_year, one_of(old.names)) %&gt;% gather(key = orig_itemname, value = value, -SID, -wave, na.rm = T) %&gt;% left_join(cb %&gt;% select(itemname, orig_itemname, reverse_code:long_rule)) } # join data with recoding info map_recode &lt;- map_codebook %&gt;% select(category, name, itemname, year, orig_itemname, reverse_code:long_rule) %&gt;% filter(category %in% c(&quot;pers&quot;, &quot;outcome&quot;, &quot;covariates&quot;, &quot;cognition&quot;)) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, name, rename_fun)) # recode recode_fun &lt;- function(rule, y, year){ x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } map_recode &lt;- map_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(wave = as.numeric(wave)) %&gt;% group_by(recode, wave) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(recode, data, wave), recode_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(value &lt; 0 | is.nan(value) | is.infinite(value), NA, value)))) # reverse code map_recode &lt;- map_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(value = as.numeric(value), value = ifelse(reverse_code == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))))) fun_call &lt;- function(x, rule){ switch(rule, average = mean(x, na.rm = T), mode = Mode(x)[1], sum = sum(x, na.rm = T), skip = unique(x)[1], select = unique(x)[1], max = max(x, na.rm = T), min = min(x, na.rm = T)) } 2.2.3 Covariates # composite WITHIN years map_cov &lt;- map_recode %&gt;% filter(category == &quot;covariates&quot;) %&gt;% select(-category) %&gt;% mutate(data = map(data, ~(.) %&gt;% filter(!is.na(value)) %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule), &quot;skip&quot;, comp_rule)) %&gt;% group_by(comp_rule, SID, wave, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %&gt;% unnest(data) %&gt;% filter(wave == 0) )) comp_fun &lt;- function(d, rule){ d %&gt;% group_by(SID, name) %&gt;% summarize(value = fun_call(data, rule)) %&gt;% ungroup() %&gt;% distinct() } # composite ACROSS years map_cov &lt;- map_cov %&gt;% unnest(data) %&gt;% mutate(long_rule = ifelse(is.na(long_rule), &quot;skip&quot;, long_rule)) %&gt;% group_by(long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(data, long_rule), comp_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %&gt;% select(-long_rule) %&gt;% spread(name, value) %&gt;% filter(!is.na(SID)) map_cov ## # A tibble: 2,192 × 16 ## SID age alcohol BMI cancer diabetes education exercise gender heartProb married mmse parkinsons race smokes stroke ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 00009121 80.0 1 26.8 0 0 12 1 0 0 1 29 0 0 1 NA ## 2 00033027 81.0 0 32.6 0 1 14 0 0 0 1 29 0 0 0 0 ## 3 00045071 87.5 1 28.2 0 1 16 1 1 1 1 18 0 0 1 0 ## 4 00130005 89.8 0 27.8 0 0 15 1 0 1 1 29 0 2 0 0 ## 5 00204228 65.2 0 36.6 0 1 8 1 1 0 1 27 0 2 0 0 ## 6 00228190 73.5 1 23.0 1 0 22 1 0 0 1 29 0 0 0 0 ## 7 00246264 90.0 0 24.0 0 0 16 1 0 0 1 27 0 0 0 0 ## 8 00285563 84.7 0 27.0 0 0 12 1 0 0 1 28 0 0 0 0 ## 9 00402800 78.7 0 17.2 0 0 16 1 0 0 1 17 0 0 0 1 ## 10 00482428 81.4 1 NA 1 0 12 1 0 0 1 30 0 0 0 1 ## # … with 2,182 more rows 2.2.4 Personality Variables map_pers &lt;- map_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% distinct() %&gt;% group_by(SID, name) %&gt;% filter(wave == min(wave)) %&gt;% ungroup() %&gt;% select(SID, name, wave, value) map_pers ## # A tibble: 9,115 × 4 ## SID name wave value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 00009121 C 0 35 ## 2 00045071 C 0 38 ## 3 00130005 C 0 31 ## 4 00246264 C 0 33 ## 5 00402800 C 0 24 ## 6 00582981 C 0 37 ## 7 00617643 C 0 34 ## 8 00696418 C 0 27 ## 9 00701662 C 0 31 ## 10 00709354 C 0 40 ## # … with 9,105 more rows 2.2.5 Outcome Variables map_out_waves &lt;- map_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% unnest(data) %&gt;% group_by(SID, name) %&gt;% summarize(o_year = max(wave)) %&gt;% ungroup() map_out &lt;- map_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% select(-category) %&gt;% unnest(data) map_dem &lt;- map_out %&gt;% filter(name == &quot;dementia&quot;) %&gt;% group_by(SID, name, wave) %&gt;% summarize(value = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.nan(value) | is.infinite(value), NA, value), group = ifelse(wave &gt; 0, &quot;future&quot;, &quot;past&quot;)) %&gt;% group_by(SID, name, group) %&gt;% summarize(value = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value), NA, value)) %&gt;% pivot_wider(names_from = group, values_from = value) %&gt;% group_by(SID, name) %&gt;% mutate(value = ifelse(is.na(past) | (past == 0 &amp; !is.na(future)), future, ifelse(past == 0 &amp; is.na(future), past, ifelse(past == 1, NA, NA)))) %&gt;% ungroup() comp_fun &lt;- function(df, rule){ df %&gt;% group_by(SID) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } # create composites map_out &lt;- map_out %&gt;% filter(wave &gt; 0 &amp; name != &quot;dementia&quot;) %&gt;% group_by(name, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, long_rule, comp_fun)) %&gt;% unnest(data) %&gt;% select(-long_rule) %&gt;% full_join(map_dem) %&gt;% left_join(map_out_waves) map_out ## # A tibble: 11,128 × 6 ## name SID value future past o_year ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ageDementia 00045071 88.5 NA NA 1 ## 2 ageDementia 00285563 90.5 NA NA 13 ## 3 ageDementia 00668310 88.6 NA NA 5 ## 4 ageDementia 01243685 89.7 NA NA 3 ## 5 ageDementia 01797756 86.4 NA NA 11 ## 6 ageDementia 02108769 90.9 NA NA 8 ## 7 ageDementia 03227207 97.8 NA NA 17 ## 8 ageDementia 03380931 85.7 NA NA 7 ## 9 ageDementia 03806878 92.4 NA NA 5 ## 10 ageDementia 04330337 101. NA NA 15 ## # … with 11,118 more rows 2.2.6 Cognition Variables # composite within years map_cog &lt;- map_recode %&gt;% filter(category == &quot;cognition&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% filter(wave == 0) %&gt;% filter(!is.na(value)) %&gt;% group_by(name, itemname, wave) %&gt;% mutate(value = pomp(value)) %&gt;% group_by(name, SID) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() %&gt;% pivot_wider(names_from = &quot;name&quot; , values_from = &quot;value&quot;) map_cog ## # A tibble: 2,189 × 2 ## SID cognition ## &lt;chr&gt; &lt;dbl&gt; ## 1 00009121 7.55 ## 2 00033027 6.17 ## 3 00045071 4.84 ## 4 00130005 6.59 ## 5 00204228 5.81 ## 6 00228190 7.38 ## 7 00246264 6.16 ## 8 00285563 5.79 ## 9 00402800 4.14 ## 10 00482428 6.58 ## # … with 2,179 more rows 2.2.7 Combine Data map_combined &lt;- map_pers %&gt;% rename(Trait = name, p_value = value, p_year = wave) %&gt;% full_join( map_out %&gt;% select(Outcome = name, SID, o_value = value, o_year) ) %&gt;% full_join(map_cov) %&gt;% left_join( map_out %&gt;% filter(name == &quot;dementia&quot;) %&gt;% mutate(value = ifelse(rowSums(cbind(future, past), na.rm = T) &gt;= 1, 1, 0)) %&gt;% select(-future, -past) %&gt;% pivot_wider(names_from = &quot;name&quot;, values_from = &quot;value&quot;) ) %&gt;% full_join(map_cog) %&gt;% filter(!is.na(p_value) &amp; !is.na(o_value)) map_combined ## # A tibble: 42,999 × 24 ## SID Trait p_year p_value Outcome o_value o_year age alcohol BMI cancer diabe…¹ educa…² exerc…³ gender heart…⁴ married mmse parki…⁵ ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 00009121 C 0 35 dementia 0 10 80.0 1 26.8 0 0 12 1 0 0 1 29 0 ## 2 00045071 C 0 38 ageDeme… 88.5 1 87.5 1 28.2 0 1 16 1 1 1 1 18 0 ## 3 00045071 C 0 38 dementia 1 1 87.5 1 28.2 0 1 16 1 1 1 1 18 0 ## 4 00130005 C 0 31 dementia 0 4 89.8 0 27.8 0 0 15 1 0 1 1 29 0 ## 5 00246264 C 0 33 angiopa… 2 8 90.0 0 24.0 0 0 16 1 0 0 1 27 0 ## 6 00246264 C 0 33 arterio… 2 8 90.0 0 24.0 0 0 16 1 0 0 1 27 0 ## 7 00246264 C 0 33 atheros… 1 8 90.0 0 24.0 0 0 16 1 0 0 1 27 0 ## 8 00246264 C 0 33 braak 3 8 90.0 0 24.0 0 0 16 1 0 0 1 27 0 ## 9 00246264 C 0 33 cerad 2 8 90.0 0 24.0 0 0 16 1 0 0 1 27 0 ## 10 00246264 C 0 33 hipScle… 0 8 90.0 0 24.0 0 0 16 1 0 0 1 27 0 ## # … with 42,989 more rows, 5 more variables: race &lt;dbl&gt;, smokes &lt;dbl&gt;, stroke &lt;dbl&gt;, dementia &lt;dbl&gt;, cognition &lt;dbl&gt;, and abbreviated variable ## # names ¹​diabetes, ²​education, ³​exercise, ⁴​heartProb, ⁵​parkinsons save(map_cov, map_pers, map_out, map_combined, map_cog, file = sprintf(&quot;%s/data/clean/radc-map_cleaned.RData&quot;, load_path)) rm(list =ls()[grepl(&quot;map&quot;, ls())]) 2.3 RUSH Religious Orders Study (ROS) The RUSH Religious Orders Study (ROS) is an ongoing longitudinal study that began in 1994 (a2012overview?). These data are available, through application from https://www.radc.rush.edu/requests.htm. Older (65 and above) Catholic nuns, priests, and brothers with no prior dementia diagnosis and who agreed to annual evaluations and eventual organ donation were recruited from more than 40 groups across the United States. Additional participants are recuited each year. Additional information and documentation on the data can be found at https://www.radc.rush.edu/docs/var/variables.htm. Sample sizes vary bt year from 353 participants (1994) to 1487 participants, including 797 deceased participants with autopsy data (2019, 2020). This provides 99% power to detect a zero-order correlation effect size of ~.11, two-tailed at alpha .05. (ros_codebook &lt;- (codebook %&gt;% filter(study == &quot;ROS&quot;))$codebook[[1]] %&gt;% mutate(orig_itemname = str_to_lower(orig_itemname))) ## # A tibble: 42 × 15 ## study dataset category name itemname year orig_itemname description scale rever…¹ recode mini maxi comp_…² long_…³ ## &lt;chr&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 ROS NA cognition cognition freeRecall longitudinal cts_wlii word list recall &lt;NA&gt; no ifels… NA NA sum select ## 2 ROS NA cognition cognition cuedRecall longitudinal cts_wliii word list recogni… &lt;NA&gt; no ifels… NA NA sum select ## 3 ROS NA cognition cognition digitsFrwd longitudinal cts_df digits backward &lt;NA&gt; no ifels… NA NA sum select ## 4 ROS NA cognition cognition digitsBckwd longitudinal cts_db digits forward &lt;NA&gt; no ifels… NA NA sum select ## 5 ROS NA cognition cognition catFluency longitudinal cts_catflu category fluency … &lt;NA&gt; no ifels… NA NA sum select ## 6 ROS NA cognition cognition bosNaming longitudinal cts_bname Boston naming (15… &lt;NA&gt; no ifels… NA NA sum select ## 7 ROS NA cognition cognition progMat longitudinal cts_pmat progressive matri… &lt;NA&gt; no ifels… NA NA sum select ## 8 ROS NA cognition cognition digitSymbol longitudinal cts_sdmt symbol digits mod… &lt;NA&gt; no ifels… NA NA sum select ## 9 ROS NA covariates age ageBaseline baseline age_bl The age at baseli… &lt;NA&gt; no ifels… NA NA skip select ## 10 ROS NA covariates alcohol alcohol baseline alcohol_g_bl Grams of alcohol … &quot;\\r\\… no ifels… NA NA skip average ## # … with 32 more rows, and abbreviated variable names ¹​reverse_code, ²​comp_rule, ³​long_rule ros &lt;- sprintf(&quot;%s/rush-radc/dataset_1033_long_03-24-2021.xlsx&quot;, data_path) %&gt;% read_excel() %&gt;% full_join(sprintf(&quot;%s/rush-radc/dataset_1033_basic_03-24-2021.xlsx&quot;, data_path) %&gt;% read_excel()) %&gt;% full_join(sprintf(&quot;%s/rush-radc/dataset_1034_long_03-25-2021.xlsx&quot;, data_path) %&gt;% read_excel()) %&gt;% full_join(sprintf(&quot;%s/rush-radc/dataset_1034_basic_03-25-2021.xlsx&quot;, data_path) %&gt;% read_excel()) %&gt;% filter(study == &quot;ROS&quot;) 2.3.1 Recoding &amp; Reverse Scoring rename_fun &lt;- function(cb, var){ print(var) old.names &lt;- unique((ros_codebook %&gt;% filter(name == var))$orig_itemname) df &lt;- ros %&gt;% select(SID = projid, wave = fu_year, one_of(old.names)) %&gt;% gather(key = orig_itemname, value = value, -SID, -wave, na.rm = T) %&gt;% left_join(cb %&gt;% select(itemname, orig_itemname, reverse_code:long_rule)) } # join data with recoding info ros_recode &lt;- ros_codebook %&gt;% select(category, name, itemname, year, orig_itemname, reverse_code:long_rule) %&gt;% filter(category %in% c(&quot;pers&quot;, &quot;outcome&quot;, &quot;covariates&quot;, &quot;cognition&quot;)) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, name, rename_fun)) # recode recode_fun &lt;- function(rule, y, year){ x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } ros_recode &lt;- ros_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(wave = as.numeric(wave)) %&gt;% group_by(recode, wave) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(recode, data, wave), recode_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(value &lt; 0 | is.nan(value) | is.infinite(value), NA, value)))) # reverse code ros_recode &lt;- ros_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(value = as.numeric(value), value = ifelse(reverse_code == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))))) fun_call &lt;- function(x, rule){ switch(rule, average = mean(x, na.rm = T), mode = Mode(x)[1], sum = sum(x, na.rm = T), skip = unique(x)[1], select = unique(x)[1], max = max(x, na.rm = T), min = min(x, na.rm = T)) } 2.3.2 Covariates # composite WITHIN years ros_cov &lt;- ros_recode %&gt;% filter(category == &quot;covariates&quot;) %&gt;% select(-category) %&gt;% mutate(data = map(data, ~(.) %&gt;% filter(!is.na(value)) %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule), &quot;skip&quot;, comp_rule)) %&gt;% group_by(comp_rule, SID, wave, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %&gt;% unnest(data) %&gt;% filter(wave == 0) )) comp_fun &lt;- function(d, rule){ d %&gt;% group_by(SID, name) %&gt;% summarize(value = fun_call(data, rule)) %&gt;% ungroup() %&gt;% distinct() } # composite ACROSS years ros_cov &lt;- ros_cov %&gt;% unnest(data) %&gt;% mutate(long_rule = ifelse(is.na(long_rule), &quot;skip&quot;, long_rule)) %&gt;% group_by(long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(data, long_rule), comp_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %&gt;% select(-long_rule) %&gt;% spread(name, value) %&gt;% filter(!is.na(SID)) ros_cov ## # A tibble: 1,485 × 14 ## SID age alcohol BMI cancer diabetes education exercise gender heartProb mmse race smokes stroke ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 00021073 80.0 0 19.9 0 0 22 1 0 1 18 0 0 0 ## 2 00337708 82.2 0 42.8 0 0 22 1 1 0 27 0 0 0 ## 3 00381112 70.3 0 29.7 0 0 20 0 0 0 30 0 0 NA ## 4 00470212 72.6 1 20.0 1 0 18 1 0 0 30 0 0 0 ## 5 00756793 87.3 0 33.2 0 1 20 0 1 0 23 1 1 0 ## 6 00985084 78.6 0 23.7 1 0 21 1 0 0 28 0 0 0 ## 7 01211411 85.2 0 25.1 0 0 12 0 1 0 24 0 1 0 ## 8 01237015 72.0 0 18.8 0 0 16 1 0 0 29 0 0 0 ## 9 01679543 65.2 1 36.4 0 0 22 1 0 0 30 0 0 0 ## 10 02105734 85.2 1 21.5 0 0 18 1 0 0 29 0 0 0 ## # … with 1,475 more rows 2.3.3 Personality Variables ros_pers &lt;- ros_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% distinct() %&gt;% group_by(SID, name) %&gt;% filter(wave == min(wave)) %&gt;% ungroup() %&gt;% select(SID, name, wave, value) ros_pers ## # A tibble: 7,569 × 4 ## SID name wave value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 00021073 A 0 32 ## 2 00337708 A 0 30 ## 3 00381112 A 0 36 ## 4 00470212 A 0 41 ## 5 00756793 A 0 27 ## 6 00985084 A 0 33 ## 7 01211411 A 0 27 ## 8 01237015 A 0 34 ## 9 01679543 A 0 43 ## 10 02105734 A 0 36 ## # … with 7,559 more rows 2.3.4 Outcome Variables ros_out_waves &lt;- ros_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% unnest(data) %&gt;% group_by(SID, name) %&gt;% summarize(o_year = max(wave)) %&gt;% ungroup() ros_out &lt;- ros_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% select(-category) %&gt;% unnest(data) ros_dem &lt;- ros_out %&gt;% filter(name == &quot;dementia&quot;) %&gt;% group_by(SID, name, wave) %&gt;% summarize(value = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.nan(value) | is.infinite(value), NA, value), group = ifelse(wave &gt; 0, &quot;future&quot;, &quot;past&quot;)) %&gt;% group_by(SID, name, group) %&gt;% summarize(value = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value), NA, value)) %&gt;% pivot_wider(names_from = group, values_from = value) %&gt;% group_by(SID, name) %&gt;% mutate(value = ifelse(is.na(past) | (past == 0 &amp; !is.na(future)), future, ifelse(past == 0 &amp; is.na(future), past, ifelse(past == 1, NA, NA)))) %&gt;% ungroup() comp_fun &lt;- function(df, rule){ df %&gt;% group_by(SID) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } # create composites ros_out &lt;- ros_out %&gt;% filter(wave &gt; 0 &amp; name != &quot;dementia&quot;) %&gt;% group_by(name, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, long_rule, comp_fun)) %&gt;% unnest(data) %&gt;% select(-long_rule) %&gt;% full_join(ros_dem) %&gt;% left_join(ros_out_waves) ros_out ## # A tibble: 9,581 × 6 ## name SID value future past o_year ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ageDementia 02495739 92.5 NA NA 13 ## 2 ageDementia 07299965 80.0 NA NA 13 ## 3 ageDementia 07660182 83.7 NA NA 4 ## 4 ageDementia 10100150 84.5 NA NA 12 ## 5 ageDementia 10100286 80.7 NA NA 18 ## 6 ageDementia 10101039 90.4 NA NA 8 ## 7 ageDementia 10101589 107. NA NA 6 ## 8 ageDementia 10101741 92.4 NA NA 12 ## 9 ageDementia 10116694 82.2 NA NA 5 ## 10 ageDementia 10200901 96.2 NA NA 23 ## # … with 9,571 more rows 2.3.5 Cognition Variables # composite within years ros_cog &lt;- ros_recode %&gt;% filter(category == &quot;cognition&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% filter(wave == 0) %&gt;% filter(!is.na(value)) %&gt;% group_by(name, itemname, wave) %&gt;% mutate(value = pomp(value)) %&gt;% group_by(name, SID) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() %&gt;% pivot_wider(names_from = &quot;name&quot; , values_from = &quot;value&quot;) ros_cog ## # A tibble: 1,485 × 2 ## SID cognition ## &lt;chr&gt; &lt;dbl&gt; ## 1 00021073 4.19 ## 2 00337708 5.89 ## 3 00381112 7.02 ## 4 00470212 6.68 ## 5 00756793 4.35 ## 6 00985084 6.83 ## 7 01211411 3.83 ## 8 01237015 5.64 ## 9 01679543 7.23 ## 10 02105734 6.64 ## # … with 1,475 more rows 2.3.6 Combine Data ros_combined &lt;- ros_pers %&gt;% rename(Trait = name, p_value = value, p_year = wave) %&gt;% full_join( ros_out %&gt;% select(Outcome = name, SID, o_value = value, o_year) ) %&gt;% full_join(ros_cov) %&gt;% left_join( ros_out %&gt;% filter(name == &quot;dementia&quot;) %&gt;% mutate(value = ifelse(rowSums(cbind(future, past), na.rm = T) &gt;= 1, 1, 0)) %&gt;% select(-future, -past) %&gt;% pivot_wider(names_from = &quot;name&quot;, values_from = &quot;value&quot;) ) %&gt;% full_join(ros_cog) %&gt;% filter(!is.na(p_value) &amp; !is.na(o_value)) ros_combined ## # A tibble: 48,074 × 22 ## SID Trait p_year p_value Outcome o_value o_year age alcohol BMI cancer diabe…¹ educa…² exerc…³ gender heart…⁴ mmse race smokes stroke ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0002… A 0 32 angiop… 3 2 80.0 0 19.9 0 0 22 1 0 1 18 0 0 0 ## 2 0002… A 0 32 arteri… 0 2 80.0 0 19.9 0 0 22 1 0 1 18 0 0 0 ## 3 0002… A 0 32 athero… 2 2 80.0 0 19.9 0 0 22 1 0 1 18 0 0 0 ## 4 0002… A 0 32 braak 6 2 80.0 0 19.9 0 0 22 1 0 1 18 0 0 0 ## 5 0002… A 0 32 cerad 1 2 80.0 0 19.9 0 0 22 1 0 1 18 0 0 0 ## 6 0002… A 0 32 hipScl… 0 2 80.0 0 19.9 0 0 22 1 0 1 18 0 0 0 ## 7 0002… A 0 32 lewyBo… 0 2 80.0 0 19.9 0 0 22 1 0 1 18 0 0 0 ## 8 0002… A 0 32 vsclrI… 0 2 80.0 0 19.9 0 0 22 1 0 1 18 0 0 0 ## 9 0002… A 0 32 vsclrM… 1 2 80.0 0 19.9 0 0 22 1 0 1 18 0 0 0 ## 10 0002… A 0 32 tdp43 1 2 80.0 0 19.9 0 0 22 1 0 1 18 0 0 0 ## # … with 48,064 more rows, 2 more variables: dementia &lt;dbl&gt;, cognition &lt;dbl&gt;, and abbreviated variable names ¹​diabetes, ²​education, ³​exercise, ## # ⁴​heartProb save(ros_cov, ros_pers, ros_out, ros_combined, ros_cog, file = sprintf(&quot;%s/data/clean/ros_cleaned.RData&quot;, load_path)) rm(list =ls()[grepl(&quot;ros&quot;, ls())]) 2.4 Swedish Adoption Twin Study of Aging (SATSA) The Swedish Adoption Twin Study of Aging (SATSA) is a longitudinal study of twin pairs from the Swedish Twin Registry that began in 1984. Data are available through the ICPSR database at https://www.icpsr.umich.edu/web/ICPSR/studies/3843. All twin-pairs on the Swedish Twin Registry who were separated at an early age were invited to be a part of the study in 1984. A control sample of twins reared together were also included. Additional waves of all participants were collected in 1987, 1990, 1993, 2004, 2007, 2010, 2012, and 2014. More information, including codebooks, scales, and variable search functions can be found at https://www.maelstrom-research.org/mica/individual-study/satsa/#. Sample sizes vary by wave, ranging from 2018 participants at baseline (1984) to 379 participants (IPT7). Given that the target measures were collected at baseline, this provides 99% power to detect a zero-order correlation effect size of ~.10, two-tailed at alpha .05. 2.4.1 Load Data satsa_read_fun &lt;- function(x){ prob_vars &lt;- c(&quot;FHEART&quot;, &quot;FPARKIN&quot;, &quot;FSTROKE&quot;) y &lt;- sprintf(&quot;%s/satsa/%s&quot;, data_path, x) %&gt;% haven::read_sav(.) %&gt;% select(SID = TWINNR, one_of(old.names)) %&gt;% as_tibble() %&gt;% haven::zap_labels(.) if(any(prob_vars %in% colnames(y))){ y &lt;- y %&gt;% mutate_at(vars(one_of(prob_vars)), ~as.numeric(as.character(.))) } return(y) } satsa_codebook &lt;- (codebook %&gt;% filter(study == &quot;SATSA&quot;))$codebook[[1]] %&gt;% mutate_at(vars(orig_itemname), str_to_upper) satsa_codebook ## # A tibble: 840 × 17 ## study dataset category name itemname wave_letter year item_stem orig_…¹ descr…² scale rever…³ recode mini maxi comp_…⁴ long_…⁵ ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 satsa SATSA_IPT1 cognition cognition blockDesign &lt;NA&gt; 1985 &lt;NA&gt; IBLOC_… Block … inte… no ifels… NA NA sum select ## 2 satsa SATSA_IPT2 cognition cognition blockDesign &lt;NA&gt; 1989 &lt;NA&gt; IBLOC_… Block … inte… no ifels… NA NA sum select ## 3 satsa SATSA_IPT3 cognition cognition blockDesign &lt;NA&gt; 1992 &lt;NA&gt; IBLOC_… Block … inte… no ifels… NA NA sum select ## 4 satsa SATSA_IPT4 cognition cognition blockDesign &lt;NA&gt; 1995 &lt;NA&gt; IBLOC_… Block … inte… no ifels… NA NA sum select ## 5 satsa SATSA_IPT5 cognition cognition blockDesign &lt;NA&gt; 1999 &lt;NA&gt; IBLOC_… Block … inte… no ifels… NA NA sum select ## 6 satsa SATSA_IPT6 cognition cognition blockDesign &lt;NA&gt; 2002 &lt;NA&gt; IBLOC_… Block … inte… no ifels… NA NA sum select ## 7 satsa SATSA_IPT7 cognition cognition blockDesign &lt;NA&gt; 2005 &lt;NA&gt; IBLOC_… Block … inte… no ifels… NA NA sum select ## 8 satsa SATSA_IPT1 cognition cognition digitSpan &lt;NA&gt; 1985 &lt;NA&gt; IDGSP_… Digit … inte… no ifels… NA NA sum select ## 9 satsa SATSA_IPT2 cognition cognition digitSpan &lt;NA&gt; 1989 &lt;NA&gt; IDGSP_… Digit … inte… no ifels… NA NA sum select ## 10 satsa SATSA_IPT3 cognition cognition digitSpan &lt;NA&gt; 1992 &lt;NA&gt; IDGSP_… Digit … inte… no ifels… NA NA sum select ## # … with 830 more rows, and abbreviated variable names ¹​orig_itemname, ²​description, ³​reverse_code, ⁴​comp_rule, ⁵​long_rule old.names &lt;- unique(satsa_codebook$orig_itemname) %&gt;% str_to_upper datasets &lt;- sprintf(&quot;%s/satsa&quot;, data_path) %&gt;% list.files(., pattern = &quot;.sav&quot;) satsa &lt;- tibble(datasets = datasets) %&gt;% mutate(data = map(datasets, satsa_read_fun), ncol = map_dbl(data, ncol)) %&gt;% filter(ncol != 0) satsa &lt;- reduce(satsa$data, full_join) satsa &lt;- satsa %&gt;% mutate_if(is.factor, ~as.numeric(sub(&quot;^\\\\(0*([0-9]+)\\\\).+$&quot;, &quot;\\\\1&quot;, .))) satsa_long &lt;- satsa %&gt;% pivot_longer( names_to = &quot;orig_itemname&quot; , values_to = &quot;value&quot; , cols = -SID # , values_drop_na = T ) save(satsa, file = sprintf(&quot;%s/data/clean/satsa_raw.RData&quot;, load_path)) rm(satsa) 2.4.2 Recoding &amp; Reverse Scoring satsa_waves &lt;- p_waves %&gt;% filter(Study == &quot;SATSA&quot;) %&gt;% select(Used) %&gt;% distinct() # join data with recoding info satsa_recode &lt;- satsa_codebook %&gt;% select(category, name, itemname, year, orig_itemname, reverse_code:long_rule) %&gt;% filter(category %in% c(&quot;pers&quot;, &quot;outcome&quot;, &quot;covariates&quot;, &quot;cognition&quot;)) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% left_join(satsa_long))) # recode recode_fun &lt;- function(rule, y, year){ x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } satsa_recode &lt;- satsa_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% group_by(recode, year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(recode, data, year), recode_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(value &lt; 0 | is.nan(value) | is.infinite(value), NA, value)) %&gt;% filter(!is.na(value)))) # reverse code satsa_recode &lt;- satsa_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(value = ifelse(reverse_code == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))))) fun_call &lt;- function(x, rule){ switch(rule, average = mean(x, na.rm = T), mode = Mode(x)[1], sum = sum(x, na.rm = T), skip = unique(x)[1], select = unique(x)[1], max = max(x, na.rm = T), min = min(x, na.rm = T)) } 2.4.3 Covariates load(sprintf(&quot;%s/data/clean/satsa_cleaned.RData&quot;, local_path)) satsa_cov &lt;- satsa_recode %&gt;% filter(category == &quot;covariates&quot;) # bring in year or birth for cleaning yrBrth &lt;- satsa_cov %&gt;% filter(name == &quot;yearBrth&quot;) %&gt;% unnest(data) %&gt;% group_by(SID) %&gt;% summarize(yearBrth = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(yearBrth = ifelse(is.infinite(yearBrth), NA, yearBrth)) # compositing within years year_comp_fun &lt;- function(df, rule){ df %&gt;% # group by person and item (collapse across age) group_by(SID, name, year, long_rule) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } satsa_waves &lt;- p_waves %&gt;% filter(Study == &quot;SATSA&quot;) %&gt;% select(Used) %&gt;% distinct() satsa_cov &lt;- satsa_cov %&gt;% unnest(data) %&gt;% filter(year &lt;= max(satsa_waves$Used) + 1) %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule) | comp_rule == &quot;none&quot;, &quot;skip&quot;, comp_rule)) %&gt;% group_by(comp_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, year_comp_fun)) %&gt;% unnest(data) comp_fun &lt;- function(d, rule){ d %&gt;% group_by(SID) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() } satsa_cov &lt;- satsa_cov %&gt;% group_by(name, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, long_rule, comp_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %&gt;% select(-long_rule) %&gt;% pivot_wider(names_from = name, values_from = value, values_fn = list(value = max)) %&gt;% mutate(BMI = weight/((height/100)^2)) satsa_cov ## # A tibble: 3,840 × 18 ## SID smokes alcohol cancer diabetes heartProb married parkinsons respProb stroke gender education mmse yearBrth SRhea…¹ height weight BMI ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 181 0 NA NA NA NA NA NA NA NA 0 NA NA 1900 NA NA NA NA ## 2 182 0 NA NA NA NA NA NA NA NA 0 NA NA 1900 NA NA NA NA ## 3 1101 0 NA NA NA NA NA NA NA NA 0 NA NA 1900 NA NA NA NA ## 4 1102 0 NA NA NA NA NA NA NA NA 0 NA NA 1900 NA NA NA NA ## 5 1121 0 NA NA NA NA NA NA NA NA 1 NA NA 1900 NA NA NA NA ## 6 1122 0 NA NA NA NA NA NA NA NA 1 NA NA 1900 NA NA NA NA ## 7 1151 0 NA NA NA NA NA NA NA NA 1 NA NA 1900 NA NA NA NA ## 8 1152 0 NA NA NA NA NA NA NA NA 1 NA NA 1900 NA NA NA NA ## 9 1211 0 NA NA NA NA NA NA NA NA 1 NA NA 1900 NA NA NA NA ## 10 1212 0 NA NA NA NA NA NA NA NA 1 NA NA 1900 NA NA NA NA ## # … with 3,830 more rows, and abbreviated variable name ¹​SRhealth 2.4.4 Personality Variables satsa_pers &lt;- satsa_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% unnest(data) %&gt;% left_join(p_waves %&gt;% filter(Study == &quot;SATSA&quot;) %&gt;% select(name = p_item, Used)) %&gt;% filter(year %in% Used &amp; !is.na(value)) %&gt;% distinct() # alpha&#39;s satsa_alpha &lt;- satsa_pers %&gt;% select(name, itemname, year, SID, value) %&gt;% group_by(name, year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% spread(itemname, value)), alpha = map(data, possibly(~psych::alpha((.) %&gt;% select(-SID)), NA_real_))) # create composites satsa_pers &lt;- satsa_pers %&gt;% group_by(SID, name, year) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() satsa_pers ## # A tibble: 14,109 × 4 ## SID name year value ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1292 A 1984 4 ## 2 1292 C 1984 4 ## 3 1292 E 1984 3.67 ## 4 1292 N 1984 4.33 ## 5 1292 O 1984 3.5 ## 6 1292 SWL 1984 2.54 ## 7 1701 C 1984 5 ## 8 1701 E 1984 3.89 ## 9 1701 N 1984 4 ## 10 1701 O 1984 1 ## # … with 14,099 more rows 2.4.5 Outcome Variables satsa_out &lt;- satsa_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% unnest(data) %&gt;% distinct() %&gt;% full_join(crossing(p_year = satsa_waves$Used, name = unique((.)$name))) satsa_out_waves &lt;- satsa_out %&gt;% group_by(SID, name) %&gt;% summarize(o_year = max(year)) %&gt;% ungroup() satsa_waves &lt;- p_waves %&gt;% filter(Study == &quot;SATSA&quot;) %&gt;% select(Used) %&gt;% distinct() satsa_out &lt;- satsa_out %&gt;% filter(year &gt; p_year) %&gt;% group_by(SID, name, year, p_year) %&gt;% summarize(value = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.nan(value)|is.infinite(value), NA, value)) %&gt;% group_by(SID, p_year, name) %&gt;% summarize(value = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value), NA, value), o_year = 2005) satsa_out ## # A tibble: 3,840 × 5 ## SID p_year name value o_year ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 181 1984 dementia 0 2005 ## 2 182 1984 dementia 0 2005 ## 3 1101 1984 dementia 0 2005 ## 4 1102 1984 dementia 0 2005 ## 5 1121 1984 dementia 0 2005 ## 6 1122 1984 dementia 0 2005 ## 7 1151 1984 dementia 0 2005 ## 8 1152 1984 dementia 0 2005 ## 9 1211 1984 dementia 0 2005 ## 10 1212 1984 dementia 0 2005 ## # … with 3,830 more rows 2.4.6 Cognition Variables # composite within years satsa_cog &lt;- satsa_recode %&gt;% filter(category == &quot;cognition&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% filter(year == 1985) %&gt;% filter(!is.na(value)) %&gt;% group_by(name, itemname, year) %&gt;% mutate(value = pomp(value)) %&gt;% group_by(name, SID) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() %&gt;% pivot_wider(names_from = &quot;name&quot; , values_from = &quot;value&quot;) 2.4.7 Combine Data satsa_combined &lt;- satsa_pers %&gt;% rename(Trait = name, p_value = value, p_year = year) %&gt;% full_join(satsa_out %&gt;% rename(Outcome = name, o_value = value)) %&gt;% full_join(satsa_cov) %&gt;% left_join( satsa_out %&gt;% filter(name == &quot;dementia&quot;) %&gt;% pivot_wider(names_from = &quot;name&quot;, values_from = &quot;value&quot;) ) %&gt;% full_join(satsa_cog) %&gt;% filter(!is.na(p_value) &amp; !is.na(o_value)) %&gt;% mutate(age = p_year - yearBrth , o_year = 2005) satsa_combined ## # A tibble: 14,109 × 27 ## SID Trait p_year p_value Outcome o_value o_year smokes alcohol cancer diabetes heart…¹ married parki…² respP…³ stroke gender educa…⁴ mmse ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1292 A 1984 4 dementia 0 2005 0 0 1 0 1 1 0 0 0 1 9 NA ## 2 1292 C 1984 4 dementia 0 2005 0 0 1 0 1 1 0 0 0 1 9 NA ## 3 1292 E 1984 3.67 dementia 0 2005 0 0 1 0 1 1 0 0 0 1 9 NA ## 4 1292 N 1984 4.33 dementia 0 2005 0 0 1 0 1 1 0 0 0 1 9 NA ## 5 1292 O 1984 3.5 dementia 0 2005 0 0 1 0 1 1 0 0 0 1 9 NA ## 6 1292 SWL 1984 2.54 dementia 0 2005 0 0 1 0 1 1 0 0 0 1 9 NA ## 7 1701 C 1984 5 dementia 0 2005 0 0 0 0 1 NA 0 0 0 1 12 NA ## 8 1701 E 1984 3.89 dementia 0 2005 0 0 0 0 1 NA 0 0 0 1 12 NA ## 9 1701 N 1984 4 dementia 0 2005 0 0 0 0 1 NA 0 0 0 1 12 NA ## 10 1701 O 1984 1 dementia 0 2005 0 0 0 0 1 NA 0 0 0 1 12 NA ## # … with 14,099 more rows, 8 more variables: yearBrth &lt;dbl&gt;, SRhealth &lt;dbl&gt;, height &lt;dbl&gt;, weight &lt;dbl&gt;, BMI &lt;dbl&gt;, dementia &lt;dbl&gt;, ## # cognition &lt;dbl&gt;, age &lt;dbl&gt;, and abbreviated variable names ¹​heartProb, ²​parkinsons, ³​respProb, ⁴​education save(satsa_cov, satsa_alpha, satsa_pers, satsa_out, satsa_combined, satsa_cog, file = sprintf(&quot;%s/data/clean/satsa_cleaned.RData&quot;, load_path)) rm(list =ls()[grepl(&quot;satsa&quot;, ls())]) 2.5 ADRC Memory and Aging Project (ADRC-MAP) The Alzheimer Disease Research Center Memory and Aging Project (ADRC-MAP) is an ongoing longitudinal study of memory and Alzheimer’s Disease that began in 1979. Data are available on a study-by-study basis through application from https://knightadrc.wustl.edu/Research/ResourceRequest.htm. Participants were recruited from the Charles and Joanne F. Knight Alzheimer’s Disease Research Center at Washington University in St. Louis as part of an ongoing study of disease progression. The current study uses a subset of approximately 1200 of these participants who completed personality surveys as part of a substudy (see Duchek et al., 2019). More information on the study can be found at https://knightadrc.wustl.edu/Research/PDFs/Clinical%20Core%20list%20of%20measures.pdf. Sample sizes vary over time, from approximately 400 to 1200. This provides 99% power to detect a zero-order correlation effect size of ~.15, two-tailed at alpha .05. 2.5.1 Load Data (adrc_codebook &lt;- (codebook %&gt;% filter(study == &quot;ADRC&quot;))$codebook[[1]]) ## # A tibble: 106 × 15 ## study dataset category name itemname year orig_itemname description scale rever…¹ recode mini maxi comp_…² long_…³ ## &lt;chr&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 ADRC NA cognition cognition waisBlckDes longitudinal PSY021 &quot;WAIS BLOCK DESIG… Rang… no ifels… NA NA sum select ## 2 ADRC NA cognition cognition waisInfo longitudinal PSY019 &quot;WAIS INFORMATION… Rang… no ifels… NA NA sum select ## 3 ADRC NA cognition cognition waisRDigSym longitudinal DIGSYM &quot;WAIS-R DIGIT SYM… Rang… no ifels… NA NA sum select ## 4 ADRC NA cognition cognition digFrwdCor longitudinal DIGFORCT &quot;NUMBER SPAN TEST… Rang… no ifels… NA NA sum select ## 5 ADRC NA cognition cognition digBckwdCor longitudinal DIGBACCT &quot;NUMBER SPAN TEST… Rang… no ifels… NA NA sum select ## 6 ADRC NA cognition cognition trailMakingA longitudinal TRAILA &quot;The score is the… Rang… no ifels… NA NA sum select ## 7 ADRC NA cognition cognition trailMakingB longitudinal TRAILB &quot;The score is the… Rang… no ifels… NA NA sum select ## 8 ADRC NA cognition cognition cuedRecallT1 longitudinal SRT1C &quot;Free &amp; Cued SRT:… Rang… no ifels… NA NA sum select ## 9 ADRC NA cognition cognition cuedRecallT2 longitudinal SRT2C &quot;Free &amp; Cued SRT:… Rang… no ifels… NA NA sum select ## 10 ADRC NA cognition cognition cuedRecallT3 longitudinal SRT3C &quot;Free &amp; Cued SRT:… Rang… no ifels… NA NA sum select ## # … with 96 more rows, and abbreviated variable names ¹​reverse_code, ²​comp_rule, ³​long_rule adrc_read_fun &lt;- function(file){ print(file) d &lt;- sprintf(&quot;%s/adrc-map/%s&quot;, data_path, file) %&gt;% read_excel(.) %&gt;% select(SID = id, one_of(c(&quot;TESTDATE&quot;, old.names)), contains(&quot;NEO Date&quot;)) if(&quot;TESTDATE&quot; %in% colnames(d)){ if(any(class(d$TESTDATE) != &quot;numeric&quot;)){d$TESTDATE &lt;- lubridate::year(d$TESTDATE)}} d } old.names &lt;- unique(adrc_codebook$orig_itemname) adrc &lt;- tibble(file = list.files(sprintf(&quot;%s/adrc-map&quot;, data_path), pattern = &quot;.xlsx&quot;)) %&gt;% filter(!grepl(&quot;NEO&quot;, file)) %&gt;% mutate(data = map(file, adrc_read_fun)) %&gt;% filter(map_dbl(data, ncol) &gt; 1) waves &lt;- adrc %&gt;% mutate(data = map(data, ~(.) %&gt;% select(SID, one_of(&quot;TESTDATE&quot;)))) %&gt;% select(-file) %&gt;% unnest(data) %&gt;% filter(complete.cases(.)) %&gt;% # mutate(year = lubridate::year(TESTDATE)) %&gt;% distinct() %&gt;% arrange(SID, TESTDATE) %&gt;% group_by(SID) %&gt;% mutate(frstyear = min(TESTDATE)) %&gt;% ungroup() %&gt;% mutate(year = TESTDATE, wave = year - frstyear + 1) adrc_long &lt;- reduce(adrc$data, full_join) %&gt;% distinct() %&gt;% select(SID, year = TESTDATE, everything()) %&gt;% mutate(BIRTH = lubridate::year(BIRTH)) %&gt;% pivot_longer(cols = c(-SID, -year) , names_to = &quot;orig_itemname&quot; , values_to = &quot;value&quot;) # load personality data separately old.names &lt;- (adrc_codebook %&gt;% filter(category == &quot;pers&quot;))$orig_itemname adrc_pers &lt;- sprintf(&quot;%s/adrc-map/NEO - Raw Scores_FINAL.xlsx&quot;, data_path) %&gt;% read_xlsx() %&gt;% select(SID = id, date = `NEO Date 1`, one_of(old.names)) %&gt;% mutate(date = ifelse(grepl(&quot;[//]&quot;, date), as.numeric(as.Date(date, format = &quot;%m/%d/%Y&quot;)), date), date = as.Date(as.numeric(date), origin=&quot;1899-12-30&quot;)) %&gt;% filter(!is.na(date)) # get waves for participants adrc_pers_waves &lt;- adrc_pers %&gt;% select(SID, p_year = date) %&gt;% distinct() %&gt;% mutate(p_year = lubridate::year(p_year)) 2.5.2 Recode &amp; Reverse-Scoring adrc_recode &lt;- adrc_codebook %&gt;% filter(category %in% c(&quot;covariates&quot;, &quot;outcome&quot;, &quot;cognition&quot;) &amp; !is.na(orig_itemname)) %&gt;% select(category, name, itemname, orig_itemname, reverse_code:long_rule) %&gt;% right_join(adrc_long) %&gt;% left_join(adrc_pers_waves) # recode recode_fun &lt;- function(rule, y, year){ # print(rule) x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } adrc_recode &lt;- adrc_recode %&gt;% group_by(recode, year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(recode, data, year), recode_fun)) %&gt;% unnest(data) # reverse code adrc_recode &lt;- adrc_recode %&gt;% mutate(value = ifelse(reverse_code == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() fun_call &lt;- function(x, rule){ switch(rule, average = mean(x, na.rm = T), mode = Mode(x)[1], sum = sum(x, na.rm = T), skip = unique(x)[1], select = unique(x)[1], max = max(x, na.rm = T), min = min(x, na.rm = T)) } 2.5.3 Covariates load(sprintf(&quot;%s/data/clean/adrc_cleaned.RData&quot;, local_path)) # compositing within years year_comp_fun &lt;- function(df, rule){ df %&gt;% # group by person and item (collapse across age) group_by(SID, name, year, p_year, long_rule) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } adrc_cov &lt;- adrc_recode %&gt;% filter(category == &quot;covariates&quot;) %&gt;% unnest(data) %&gt;% filter(year &lt;= p_year) %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule) | comp_rule == &quot;none&quot;, &quot;skip&quot;, comp_rule)) %&gt;% group_by(comp_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, year_comp_fun)) %&gt;% unnest(data) %&gt;% select(-comp_rule) comp_fun &lt;- function(d, rule){ d %&gt;% group_by(SID, name) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() } adrc_cov &lt;- adrc_cov %&gt;% filter(!is.na(value) &amp; !is.na(name)) %&gt;% group_by(long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, long_rule, comp_fun)) %&gt;% unnest(data) %&gt;% select(-long_rule) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %&gt;% pivot_wider(names_from = name, values_from = value, values_fn = list(value = max)) %&gt;% right_join(adrc_pers_waves) %&gt;% mutate(age = p_year - yearBrth) adrc_cov ## # A tibble: 1,162 × 15 ## SID gender yearBrth alcohol cancer diabetes education heartProb married race smokes stroke weight p_year age ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1070 0 1918 1 1 0 17 1 1 0 0 0 187 2003 85 ## 2 1088 0 1916 1 1 0 16 1 1 0 0 0 217 2005 89 ## 3 1380 1 1913 1 1 0 16 1 0 0 0 0 129 2003 90 ## 4 10018 0 1929 0 0 0 14 1 1 0 1 0 156 2005 76 ## 5 10034 0 1930 0 1 0 16 0 1 0 0 0 193 2004 74 ## 6 10037 1 1923 1 1 0 13 1 1 0 1 0 179 2006 83 ## 7 10038 0 1927 1 0 0 18 0 1 0 0 0 205 2003 76 ## 8 10045 1 1931 1 1 0 16 0 1 0 1 0 160 2003 72 ## 9 10054 1 1930 0 1 0 13 1 1 0 1 0 173 2008 78 ## 10 10064 0 1928 1 1 0 20 1 1 0 1 0 199 2003 75 ## # … with 1,152 more rows 2.5.4 Personality Variables # bring in codebook info adrc_pers &lt;- adrc_pers %&gt;% pivot_longer(`1S1`:`1S60` , names_to = &quot;orig_itemname&quot; , values_to = &quot;value&quot; , values_drop_na = T) %&gt;% left_join(adrc_codebook %&gt;% select(name:orig_itemname, reverse_code:maxi)) recode_fun &lt;- function(rule, y){ x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } # recode adrc_pers &lt;- adrc_pers %&gt;% group_by(recode) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(recode, data, recode_fun)) %&gt;% unnest(data) # reverse code adrc_pers &lt;- adrc_pers %&gt;% mutate(value = ifelse(tolower(reverse_code) == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))) # alpha&#39;s adrc_alpha &lt;- adrc_pers %&gt;% select(name, itemname, date, SID, value) %&gt;% group_by(name) %&gt;% nest() %&gt;% mutate(data = map(data, ~(.) %&gt;% pivot_wider(names_from = itemname, values_from = value)), alpha = map(data, possibly(~psych::alpha((.) %&gt;% select(-SID, -date)), NA_real_))) # create composites adrc_pers &lt;- adrc_pers %&gt;% group_by(SID, name, date) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() %&gt;% left_join(adrc_pers_waves) adrc_pers ## # A tibble: 5,730 × 5 ## SID name date value p_year ## &lt;dbl&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1070 A 2003-10-28 4.08 2003 ## 2 1070 C 2003-10-28 4.83 2003 ## 3 1070 E 2003-10-28 4.08 2003 ## 4 1070 N 2003-10-28 1.08 2003 ## 5 1070 O 2003-10-28 3.17 2003 ## 6 1088 A 2005-04-18 4.5 2005 ## 7 1088 C 2005-04-18 3.42 2005 ## 8 1088 E 2005-04-18 3.08 2005 ## 9 1088 N 2005-04-18 1.25 2005 ## 10 1088 O 2005-04-18 3.08 2005 ## # … with 5,720 more rows 2.5.5 Outcome Variables adrc_out &lt;- adrc_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% unnest(data) adrc_out_waves &lt;- adrc_out %&gt;% select(year, SID, name) %&gt;% group_by(SID, name) %&gt;% summarize(o_year = max(year)) %&gt;% ungroup() # compositing within years year_comp_fun &lt;- function(df, rule){ df %&gt;% # group by person and item (collapse across age) group_by(SID, name, year, long_rule, p_year) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } adrc_out &lt;- adrc_out %&gt;% filter(!is.na(value)) %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule) | comp_rule == &quot;none&quot;, &quot;skip&quot;, comp_rule)) %&gt;% group_by(comp_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, year_comp_fun)) %&gt;% unnest(data) comp_fun &lt;- function(d, rule){ d %&gt;% group_by(SID, name) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() } adrc_out &lt;- adrc_out %&gt;% filter(name == &quot;dementia&quot;) %&gt;% mutate(group = ifelse(year &lt;= p_year, &quot;past&quot;, &quot;future&quot;)) %&gt;% group_by(SID, name, group, p_year) %&gt;% summarize(value = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value), NA, value)) %&gt;% pivot_wider(names_from = group, values_from = value) %&gt;% group_by(SID, name) %&gt;% mutate(value = ifelse(is.na(past) | (past == 0 &amp; !is.na(future)), future, ifelse(past == 0 &amp; is.na(future), past, ifelse(past == 1, NA, NA)))) %&gt;% ungroup() %&gt;% full_join( adrc_out %&gt;% filter(name != &quot;dementia&quot; &amp; !is.na(value) &amp; year &gt;= p_year) %&gt;% group_by(long_rule, p_year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, long_rule, comp_fun)) %&gt;% select(-long_rule) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) ) %&gt;% left_join(adrc_out_waves) adrc_out ## # A tibble: 2,575 × 8 ## SID name p_year future past `NA` value o_year ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1070 dementia 2003 1 0 NA 1 2019 ## 2 1088 dementia 2005 1 1 NA NA 2015 ## 3 1380 dementia 2003 1 0 NA 1 2013 ## 4 10018 dementia 2005 0 0 NA 0 2018 ## 5 10034 dementia 2004 0 0 NA 0 2020 ## 6 10037 dementia 2006 1 0 NA 1 2019 ## 7 10038 dementia 2003 1 0 NA 1 2016 ## 8 10045 dementia 2003 1 1 NA NA 2018 ## 9 10054 dementia 2008 0 0 NA 0 2012 ## 10 10064 dementia 2003 1 0 NA 1 2018 ## # … with 2,565 more rows 2.5.6 Cognition Variables # composite within years adrc_cog &lt;- adrc_recode %&gt;% filter(category == &quot;cognition&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% filter(!is.na(p_year)) %&gt;% filter(!is.na(value)) %&gt;% group_by(name, itemname, year) %&gt;% mutate(value = pomp(value)) %&gt;% group_by(SID, name, itemname) %&gt;% filter(year %in% (p_year - 1):(p_year + 1)) %&gt;% group_by(name, SID) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() %&gt;% pivot_wider(names_from = &quot;name&quot; , values_from = &quot;value&quot;) adrc_cog ## # A tibble: 1,023 × 2 ## SID cognition ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1070 4.62 ## 2 1088 3.40 ## 3 1380 2.36 ## 4 10018 5.59 ## 5 10034 5.30 ## 6 10037 4.64 ## 7 10038 6.60 ## 8 10045 8.52 ## 9 10054 2.41 ## 10 10064 7.36 ## # … with 1,013 more rows 2.5.7 Combine Data adrc_combined &lt;- adrc_pers %&gt;% select(SID, Trait = name, p_value = value, p_year) %&gt;% full_join( adrc_out %&gt;% select(SID, o_year, Outcome = name, o_value = value) ) %&gt;% filter(!is.na(o_value) &amp; !is.na(p_value)) %&gt;% distinct() %&gt;% left_join(adrc_cov) %&gt;% left_join( adrc_out %&gt;% filter(name == &quot;dementia&quot;) %&gt;% mutate(value = ifelse(rowSums(cbind(future, past), na.rm = T) &gt;= 1, 1, 0)) %&gt;% select(-future, -past) %&gt;% pivot_wider(names_from = &quot;name&quot;, values_from = &quot;value&quot;) ) %&gt;% left_join(adrc_cog) %&gt;% left_join(adrc_out_waves %&gt;% select(SID, Outcome = name, o_year)) adrc_combined ## # A tibble: 11,145 × 23 ## SID Trait p_value p_year o_year Outcome o_value gender yearB…¹ alcohol cancer diabe…² educa…³ heart…⁴ married race smokes stroke weight ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1070 A 4.08 2003 2019 dementia 1 0 1918 1 1 0 17 1 1 0 0 0 187 ## 2 1070 C 4.83 2003 2019 dementia 1 0 1918 1 1 0 17 1 1 0 0 0 187 ## 3 1070 E 4.08 2003 2019 dementia 1 0 1918 1 1 0 17 1 1 0 0 0 187 ## 4 1070 N 1.08 2003 2019 dementia 1 0 1918 1 1 0 17 1 1 0 0 0 187 ## 5 1070 O 3.17 2003 2019 dementia 1 0 1918 1 1 0 17 1 1 0 0 0 187 ## 6 1088 A 4.5 2005 2015 angiopathy 0 0 1916 1 1 0 16 1 1 0 0 0 217 ## 7 1088 A 4.5 2005 2015 arteriolo… 1 0 1916 1 1 0 16 1 1 0 0 0 217 ## 8 1088 A 4.5 2005 2015 atheroscl… 2 0 1916 1 1 0 16 1 1 0 0 0 217 ## 9 1088 A 4.5 2005 2015 braak 3 0 1916 1 1 0 16 1 1 0 0 0 217 ## 10 1088 A 4.5 2005 2015 hipSclero… 0 0 1916 1 1 0 16 1 1 0 0 0 217 ## # … with 11,135 more rows, 4 more variables: age &lt;dbl&gt;, `NA` &lt;dbl&gt;, dementia &lt;dbl&gt;, cognition &lt;dbl&gt;, and abbreviated variable names ¹​yearBrth, ## # ²​diabetes, ³​education, ⁴​heartProb save(adrc_cov, adrc_alpha, adrc_pers, adrc_out, adrc_combined, adrc_cog, file = sprintf(&quot;%s/data/clean/adrc_cleaned.RData&quot;, load_path)) rm(list =ls()[grepl(&quot;adrc&quot;, ls())]) 2.6 Einstein Aging Study The Einstein Aging Study (EAS) is an ongoing longitudinal study of the aging brain. The EAS began in 1980 and has enrolled more than 2,600 participants since then. Data are available through application at http://www.einstein.yu.edu/departments/neurology/clinical-research-program/eas/data-sharing.aspx. Since 1993, the EAS has systematically recruited a representative aging sample in the Bronx, New York, As of 2017, 2,600 participants were enrolled in the study. As of 2010, approximately 200 of the enrolled participants had autopsy data. More information on the study can be found at http://www.einstein.yu.edu/departments/neurology/clinical-research-program/EAS/. Sample sizes vary over time, with ranges across waves not publically available. However, we suspect approximately 2,000 participants to have basic personality and dementia diagnoses, with between 150 and 300 participants having full autopsy data collected after personality was introduced into the study. This yields 99% power to detect a zero-order correlation effect size of .10 and .24, respectively, two-tailed at alpha .05. 2.6.1 Load Data (eas_codebook &lt;- (codebook %&gt;% filter(study == &quot;EAS&quot;))$codebook[[1]]) ## # A tibble: 78 × 15 ## study dataset category name itemname year orig_itemname description scale rever…¹ recode mini maxi comp_…² long_…³ ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 EAS behavior cognition cognition waisBlkDsgn longitudinal Blockraw &quot;WAIS III: Bl… &quot;int… &lt;NA&gt; ifels… NA NA sum select ## 2 EAS behavior cognition cognition trailmakingA longitudinal Tr-A1 &quot;Other Workin… &quot;int… &lt;NA&gt; ifels… NA NA sum select ## 3 EAS behavior cognition cognition trailmakingB longitudinal Tr-B1 &quot;Other Workin… &quot;int… &lt;NA&gt; ifels… NA NA sum select ## 4 EAS behavior cognition cognition digitSym longitudinal Symraw &quot;Digit Symbol&quot; &quot;int… &lt;NA&gt; ifels… NA NA sum select ## 5 EAS behavior cognition cognition recall longitudinal TotRecall &quot;total Recall&quot; &quot;int… &lt;NA&gt; ifels… NA NA sum select ## 6 EAS behavior cognition cognition SPN longitudinal Spnraw &quot;Digit Span?&quot; &quot;int… &lt;NA&gt; ifels… NA NA sum select ## 7 EAS behavior cognition cognition CAT longitudinal CAT &lt;NA&gt; &quot;int… &lt;NA&gt; ifels… NA NA sum select ## 8 EAS behavior cognition cognition FAS longitudinal FAS &lt;NA&gt; &quot;int… &lt;NA&gt; ifels… NA NA sum select ## 9 EAS behavior covariates alcohol alcoholPrev50 baseline SAB262 &quot;What was the… &quot;1=N… no ifels… NA NA max max ## 10 EAS behavior covariates alcohol alcoholPrev50p baseline SAB263 &quot;What was the… &quot;1=N… no ifels… NA NA max max ## # … with 68 more rows, and abbreviated variable names ¹​reverse_code, ²​comp_rule, ³​long_rule old.names1 &lt;- unique((eas_codebook %&gt;% filter(dataset == &quot;behavior&quot;))$orig_itemname) old.names2 &lt;- unique((eas_codebook %&gt;% filter(dataset == &quot;neuropath&quot;))$orig_itemname) old.names3 &lt;- unique((eas_codebook %&gt;% filter(dataset == &quot;activity&quot;))$orig_itemname) eas &lt;- sprintf(&quot;%s/eas/Behavior_with_Master_Data_2021_10_25.xlsx&quot;, data_path) %&gt;% read_excel(., sheet = 1) %&gt;% mutate(year = lubridate::year(BehaviorDate)) %&gt;% select(SID = Id, wave = Wave, year, one_of(old.names1)) %&gt;% full_join( sprintf(&quot;%s/eas/Neuropath_and_Behavior_Data_2021_09_26 (3).xlsx&quot;, data_path) %&gt;% read_excel(.) %&gt;% select(SID = `Clin#`, year = DOD, wave = Wave, one_of(old.names2)) %&gt;% mutate(comb_dx = ifelse(c(&quot;VaD&quot;, &quot;AD&quot;, &quot;AGD&quot;) %in% Dx1 | c(&quot;VaD&quot;, &quot;AD&quot;, &quot;AGD&quot;) %in% Dx2 | c(&quot;VaD&quot;, &quot;AD&quot;, &quot;AGD&quot;) %in% Dx3 | grepl(&quot;VaD&quot;, `OTHER Dx`) | grepl(&quot;AD&quot;, `OTHER Dx`) | grepl(&quot;AGD&quot;, `OTHER Dx`), 1, 0) , year = lubridate::year(year)) %&gt;% select(-(Dx1:`OTHER Dx`)) ) %&gt;% full_join( sprintf(&quot;%s/eas/Northwestern_supp_Physical_Activities_2021_10_25-1.xlsx&quot;, data_path) %&gt;% read_excel(.) %&gt;% select(SID = Id, wave = Wave, one_of(old.names3)) ) %&gt;% mutate(Gender = ifelse(Gender == &quot;F&quot;, 1, ifelse(Gender == &quot;M&quot;, 0, NA))) eas_waves &lt;- eas %&gt;% select(SID, wave, year) %&gt;% distinct() eas_long &lt;- eas %&gt;% pivot_longer(values_to = &quot;value&quot; , names_to = &quot;orig_itemname&quot; , cols = c(-SID, -wave, -year)) 2.6.2 Recode &amp; Reverse-Scoring eas_recode &lt;- eas_codebook %&gt;% filter(category %in% c(&quot;covariates&quot;, &quot;outcome&quot;, &quot;cognition&quot;, &quot;pers&quot;) &amp; !is.na(orig_itemname)) %&gt;% select(category, name, itemname, orig_itemname, reverse_code:long_rule) %&gt;% right_join(eas_long) # recode recode_fun &lt;- function(rule, y, year){ print(rule) x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } eas_recode &lt;- eas_recode %&gt;% group_by(recode, year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(recode, data, year), recode_fun)) %&gt;% unnest(data) # reverse code eas_recode &lt;- eas_recode %&gt;% mutate(value = ifelse(reverse_code == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() fun_call &lt;- function(x, rule){ switch(rule, average = mean(x, na.rm = T), mode = Mode(x)[1], sum = sum(x, na.rm = T), skip = unique(x)[1], select = unique(x)[1], max = max(x, na.rm = T), min = min(x, na.rm = T)) } eas_p_waves &lt;- eas_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% unnest(data) %&gt;% filter(!is.na(value)) %&gt;% group_by(SID) %&gt;% filter(year == min(year)) %&gt;% ungroup() %&gt;% select(SID, p_year = year) %&gt;% distinct() 2.6.3 Covariates # compositing within years year_comp_fun &lt;- function(df, rule){ df %&gt;% # group by person and item (collapse across age) group_by(SID, name, year, p_year, long_rule) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } eas_cov &lt;- eas_recode %&gt;% filter(category == &quot;covariates&quot;) %&gt;% unnest(data) %&gt;% left_join(eas_p_waves) %&gt;% filter(year &lt;= p_year) %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule) | comp_rule == &quot;none&quot;, &quot;skip&quot;, comp_rule)) %&gt;% group_by(comp_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, year_comp_fun)) %&gt;% unnest(data) %&gt;% select(-comp_rule) comp_fun &lt;- function(d, rule){ d %&gt;% group_by(SID, name) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() } eas_cov &lt;- eas_cov %&gt;% filter(!is.na(value) &amp; !is.na(name)) %&gt;% group_by(long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, long_rule, comp_fun)) %&gt;% unnest(data) %&gt;% select(-long_rule) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %&gt;% pivot_wider(names_from = name, values_from = value, values_fn = list(value = max)) %&gt;% right_join(eas_p_waves) eas_cov ## # A tibble: 799 × 17 ## SID alcohol cancer diabetes heartProb hypertension married race smokes stroke exercise BMI age education SRhealth gender p_year ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 6075 0 0 0 0 0 1 0 0 0 NA 21.1 73.4 17 2 1 2016 ## 2 8024 1 0 0 0 0 1 0 1 0 NA 28.8 94.8 10 2 0 2006 ## 3 8027 1 0 0 0 0 1 0 0 0 NA 20.4 93.0 12 3 0 2009 ## 4 8265 1 1 1 0 1 1 0 1 0 NA 28.5 77.3 12 3 0 2006 ## 5 8291 0 0 0 0 0 1 0 0 0 NA 24 81.7 16 1 0 2009 ## 6 8296 1 0 0 0 0 1 0 0 0 NA 23 88.9 14 1 0 2006 ## 7 8310 1 0 1 0 0 1 0 1 0 NA 29.4 86.0 16 3 0 2007 ## 8 8313 1 0 0 0 0 1 1 1 0 NA NA 87.3 16 3 1 2007 ## 9 8375 1 1 0 0 NA 1 0 0 0 NA 26.3 87.2 12 3 1 2006 ## 10 8512 1 0 0 0 1 1 1 1 0 NA NA 78.9 11 3 1 2010 ## # … with 789 more rows 2.6.4 Personality Variables # bring in codebook info eas_pers &lt;- eas_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% unnest(data) %&gt;% left_join(eas_p_waves) %&gt;% filter(year == p_year) # create composites eas_pers &lt;- eas_pers %&gt;% group_by(SID, name, p_year) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() eas_pers ## # A tibble: 3,995 × 4 ## SID name p_year value ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 6075 A 2016 3.6 ## 2 6075 C 2016 3.4 ## 3 6075 E 2016 2.5 ## 4 6075 N 2016 2.8 ## 5 6075 O 2016 3.1 ## 6 8024 A 2006 3.7 ## 7 8024 C 2006 4.1 ## 8 8024 E 2006 2.7 ## 9 8024 N 2006 2.7 ## 10 8024 O 2006 2.9 ## # … with 3,985 more rows 2.6.5 Outcome Variables eas_out &lt;- eas_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% unnest(data) eas_out_waves &lt;- eas_out %&gt;% filter(!is.na(value)) %&gt;% select(year, SID, name) %&gt;% group_by(SID, name) %&gt;% summarize(o_year = max(year)) %&gt;% ungroup() # compositing within years year_comp_fun &lt;- function(df, rule){ df %&gt;% # group by person and item (collapse across age) group_by(SID, name, year, long_rule, p_year) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } eas_out &lt;- eas_out %&gt;% left_join(eas_p_waves) %&gt;% filter(!is.na(value)) %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule) | comp_rule == &quot;none&quot;, &quot;skip&quot;, comp_rule)) %&gt;% group_by(comp_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, year_comp_fun)) %&gt;% unnest(data) eas_out &lt;- eas_out %&gt;% filter(name == &quot;dementia&quot;) %&gt;% mutate(group = ifelse(year &lt;= p_year, &quot;past&quot;, &quot;future&quot;)) %&gt;% group_by(SID, name, group, p_year) %&gt;% summarize(value = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value), NA, value)) %&gt;% pivot_wider(names_from = group, values_from = value) %&gt;% group_by(SID, name) %&gt;% mutate(value = ifelse(is.na(past) | (past == 0 &amp; !is.na(future)), future, ifelse(past == 0 &amp; is.na(future), past, ifelse(past == 1, NA, NA)))) %&gt;% ungroup() %&gt;% full_join(eas_out %&gt;% filter(name != &quot;dementia&quot;) %&gt;% group_by(SID, name, long_rule, p_year) %&gt;% summarize(value = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% select(-long_rule) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) ) %&gt;% left_join(eas_out_waves) %&gt;% filter(!is.na(value)) eas_out ## # A tibble: 878 × 8 ## SID name p_year past future `NA` value o_year ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 8024 dementia 2006 0 NA NA 0 2006 ## 2 8027 dementia 2009 0 1 NA 1 2017 ## 3 8265 dementia 2006 0 0 NA 0 2011 ## 4 8291 dementia 2009 0 0 NA 0 2012 ## 5 8296 dementia 2006 0 NA NA 0 2006 ## 6 8310 dementia 2007 0 NA NA 0 2007 ## 7 8313 dementia 2007 0 NA NA 0 2007 ## 8 8375 dementia 2006 0 0 NA 0 2010 ## 9 8512 dementia 2010 0 0 NA 0 2013 ## 10 8518 dementia 2011 0 NA NA 0 2011 ## # … with 868 more rows 2.6.6 Cognition Variables # composite within years eas_cog &lt;- eas_recode %&gt;% filter(category == &quot;cognition&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% left_join(eas_p_waves) %&gt;% filter(!is.na(p_year) &amp; !is.na(value)) %&gt;% group_by(name, itemname, year) %&gt;% mutate(value = pomp(value)) %&gt;% group_by(SID, name, itemname) %&gt;% filter(year %in% (p_year - 1):(p_year + 1)) %&gt;% group_by(name, SID) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() %&gt;% pivot_wider(names_from = &quot;name&quot; , values_from = &quot;value&quot;) eas_cog ## # A tibble: 799 × 2 ## SID cognition ## &lt;dbl&gt; &lt;dbl&gt; ## 1 6075 5.78 ## 2 8024 4.83 ## 3 8027 4.55 ## 4 8265 5.60 ## 5 8291 4.64 ## 6 8296 5.20 ## 7 8310 4.16 ## 8 8313 4.37 ## 9 8375 6.10 ## 10 8512 3.62 ## # … with 789 more rows 2.6.7 Combine Data eas_combined &lt;- eas_pers %&gt;% select(SID, Trait = name, p_value = value, p_year) %&gt;% full_join( eas_out %&gt;% select(SID, o_year, Outcome = name, o_value = value) ) %&gt;% filter(!is.na(o_value) &amp; !is.na(p_value)) %&gt;% distinct() %&gt;% left_join( eas_out %&gt;% filter(name == &quot;dementia&quot;) %&gt;% mutate(value = ifelse(rowSums(cbind(future, past), na.rm = T) &gt;= 1, 1, 0)) %&gt;% select(-future, -past) %&gt;% pivot_wider(names_from = &quot;name&quot;, values_from = &quot;value&quot;) ) %&gt;% left_join(eas_cov) %&gt;% left_join(eas_cog) eas_combined ## # A tibble: 4,320 × 25 ## SID Trait p_value p_year o_year Outcome o_value `NA` demen…¹ alcohol cancer diabe…² heart…³ hyper…⁴ married race smokes stroke exerc…⁵ ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 8024 A 3.7 2006 2006 dementia 0 NA 0 1 0 0 0 0 1 0 1 0 NA ## 2 8024 C 4.1 2006 2006 dementia 0 NA 0 1 0 0 0 0 1 0 1 0 NA ## 3 8024 E 2.7 2006 2006 dementia 0 NA 0 1 0 0 0 0 1 0 1 0 NA ## 4 8024 N 2.7 2006 2006 dementia 0 NA 0 1 0 0 0 0 1 0 1 0 NA ## 5 8024 O 2.9 2006 2006 dementia 0 NA 0 1 0 0 0 0 1 0 1 0 NA ## 6 8027 A 3.2 2009 2017 dementia 1 NA 1 1 0 0 0 0 1 0 0 0 NA ## 7 8027 A 3.2 2009 2017 braak 5.5 NA 1 1 0 0 0 0 1 0 0 0 NA ## 8 8027 A 3.2 2009 2017 hipSclero… 0 NA 1 1 0 0 0 0 1 0 0 0 NA ## 9 8027 A 3.2 2009 2017 lewyBodyD… 1 NA 1 1 0 0 0 0 1 0 0 0 NA ## 10 8027 C 3.4 2009 2017 dementia 1 NA 1 1 0 0 0 0 1 0 0 0 NA ## # … with 4,310 more rows, 6 more variables: BMI &lt;dbl&gt;, age &lt;dbl&gt;, education &lt;dbl&gt;, SRhealth &lt;dbl&gt;, gender &lt;dbl&gt;, cognition &lt;dbl&gt;, and ## # abbreviated variable names ¹​dementia, ²​diabetes, ³​heartProb, ⁴​hypertension, ⁵​exercise save(eas_cov, eas_pers, eas_out, eas_combined, eas_cog, file = sprintf(&quot;%s/data/clean/eas_cleaned.RData&quot;, load_path)) rm(list =ls()[grepl(&quot;eas&quot;, ls())]) 2.7 German Socioeconomic Panel Study (GSOEP) The German Socioeconomic Panel Study (GSOEP; Socio-Economic Panel, 2017) is an ongoing longitudinal study of German collected by the German Institute of Economic Research (DIW Berlin). The data are freely available at https://www.diw.de/soep by application. Data have been collected annually since 1984 (the latest data release includes data up to 2017). Participants have been recruited from more than 11,000 households, which are nationally representative of private German households. 20,000 individuals are sampled each year, on average. It is critical to note that the GSOEP samples households, not individuals, and the households consist of individuals living in both the “old” and “new” federal states (the former West and East Germany), foreigners, and recent immigrants to Germany. Sample size varies by year, ranging from approximately 10,000 (1989) to 31,000 (2013). This provides 99% power to detect a zero-order correlation effect size of ~.06, two-tailed at alpha &lt; .05. 2.7.1 Load Data gsoep_read_fun &lt;- function(Year, WL){ old.names &lt;- (gsoep_codebook %&gt;% filter(year == Year | category == &quot;proc&quot;))$orig_itemname p &lt;- sprintf(&quot;%s/gsoep/%sp.sav&quot;, data_path, WL) %&gt;% haven::read_sav(.) %&gt;% full_join(sprintf(&quot;%s/gsoep/%skind.sav&quot;, data_path, WL) %&gt;% haven::read_sav(.)) %&gt;% full_join(sprintf(&quot;%s/gsoep/%spequiv.sav&quot;, data_path, WL) %&gt;% haven::read_sav(.)) %&gt;% full_join(sprintf(&quot;%s/gsoep/%spgen.sav&quot;, data_path, WL) %&gt;% haven::read_sav(.)) %&gt;% full_join(sprintf(&quot;%s/gsoep/%spkal.sav&quot;, data_path, WL) %&gt;% haven::read_sav(.)) %&gt;% select(one_of(old.names)) %&gt;% gather(key = orig_itemname, value = value, -persnr, -hhnr, na.rm = T) sprintf(&quot;%s/gsoep/%shbrutto.sav&quot;, data_path, WL) %&gt;% haven::read_sav(.) %&gt;% full_join(sprintf(&quot;%s/gsoep/%sh.sav&quot;, data_path, WL) %&gt;% haven::read_sav(.)) %&gt;% select(one_of(old.names)) %&gt;% gather(key = orig_itemname, value = value, -hhnr, na.rm = T) %&gt;% full_join(p %&gt;% select(persnr, hhnr) %&gt;% distinct()) %&gt;% full_join(p) } gsoep_codebook &lt;- (codebook %&gt;% filter(study == &quot;GSOEP&quot;))$codebook[[1]] %&gt;% mutate(orig_itemname = str_to_lower(orig_itemname)) gsoep_codebook ## # A tibble: 594 × 17 ## study dataset category name itemname wave waveletter year orig_itemname description scale rever…¹ recode mini maxi comp_…² long_…³ ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 gosep cognit cognition cognition animals1 23 w 2006 f99z30r Symbol Digi… inte… no ifels… NA NA sum select ## 2 gosep cognit cognition cognition animals1 29 bc 2012 f99z30r Symbol Digi… inte… no ifels… NA NA sum select ## 3 gosep cognit cognition cognition animals2 23 w 2006 f99z60r Symbol Digi… inte… no ifels… NA NA sum select ## 4 gosep cognit cognition cognition animals2 29 bc 2012 f99z60r Symbol Digi… inte… no ifels… NA NA sum select ## 5 gosep cognit cognition cognition animals3 23 w 2006 f99z90r Symbol Digi… inte… no ifels… NA NA sum select ## 6 gosep cognit cognition cognition animals3 29 bc 2012 f99z90r Symbol Digi… inte… no ifels… NA NA sum select ## 7 gosep cognit cognition cognition symDig1 23 w 2006 f96t30g Symbol Digi… inte… no ifels… NA NA sum select ## 8 gosep cognit cognition cognition symDig1 29 bc 2012 f96t30g Symbol Digi… inte… no ifels… NA NA sum select ## 9 gosep cognit cognition cognition symDig2 23 w 2006 f96t60g Symbol Digi… inte… no ifels… NA NA sum select ## 10 gosep cognit cognition cognition symDig2 29 bc 2012 f96t60g Symbol Digi… inte… no ifels… NA NA sum select ## # … with 584 more rows, and abbreviated variable names ¹​reverse_code, ²​comp_rule, ³​long_rule gsoep &lt;- gsoep_codebook %&gt;% select(wave, waveletter, year) %&gt;% filter(complete.cases(.)) %&gt;% distinct() %&gt;% arrange(year) %&gt;% filter(year != &quot;2018&quot;) %&gt;% mutate(data = map2(year, waveletter, gsoep_read_fun)) old.names &lt;- unique(gsoep_codebook$orig_itemname) gsoep_cog &lt;- sprintf(&quot;%s/gsoep/cognit.sav&quot;, data_path) %&gt;% haven::read_sav(.) %&gt;% select(persnr, hhnr, one_of(old.names)) %&gt;% haven::zap_labels(.) %&gt;% select(-hhnr) %&gt;% gather(key = orig_itemname, value = value, -persnr, na.rm = T) gsoep_long &lt;- gsoep %&gt;% unnest(data) %&gt;% select(-hhnr, -wave, -waveletter, -year) %&gt;% # filter(persnr %in% gsoep_cog_subs) %&gt;% full_join(gsoep_cog) %&gt;% rename(SID = persnr) save(gsoep, file = sprintf(&quot;%s/data/clean/gsoep_raw.RData&quot;, load_path)) rm(gsoep) 2.7.2 Recoding &amp; Reverse Scoring gsoep_waves &lt;- p_waves %&gt;% filter(Study == &quot;GSOEP&quot;) %&gt;% select(Used) %&gt;% distinct() # join data with recoding info gsoep_recode &lt;- gsoep_codebook %&gt;% filter(category %in% c(&quot;pers&quot;, &quot;outcome&quot;, &quot;covariates&quot;, &quot;cognition&quot;)) %&gt;% select(category, name, itemname, wave, year, orig_itemname, reverse_code:long_rule) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% left_join(gsoep_long))) # recode recode_fun &lt;- function(rule, y, year){ x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } gsoep_recode &lt;- gsoep_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% group_by(recode, year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(recode, data, year), recode_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(value &lt; 0 | is.nan(value) | is.infinite(value), NA, value)))) # reverse code gsoep_recode &lt;- gsoep_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(value = ifelse(reverse_code == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))))) fun_call &lt;- function(x, rule){ switch(rule, average = mean(x, na.rm = T), mode = Mode(x)[1], sum = sum(x, na.rm = T), skip = unique(x)[1], select = unique(x)[1], max = max(x, na.rm = T), min = min(x, na.rm = T)) } 2.7.3 Covariates load(sprintf(&quot;%s/data/clean/gsoep_cleaned.RData&quot;, local_path)) yrBrth &lt;- gsoep_recode %&gt;% filter(name == &quot;yearBrth&quot;) %&gt;% unnest(data) %&gt;% group_by(SID) %&gt;% summarize(yearBrth = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(yearBrth = ifelse(is.infinite(yearBrth), NA, yearBrth), yearBrth = ifelse(yearBrth &lt; 1000, yearBrth + 1000, yearBrth)) # compositing within years year_comp_fun &lt;- function(df, rule, name){ print(paste(rule, name)) df %&gt;% group_by(SID, yearBrth, year, long_rule) %&gt;% # group by person and item (collapse across age) summarize(value = fun_call(value, rule)) %&gt;% ungroup() } gsoep_waves &lt;- p_waves %&gt;% filter(Study == &quot;GSOEP&quot;) %&gt;% select(Used) %&gt;% distinct() gsoep_cov &lt;- gsoep_recode %&gt;% filter(category == &quot;covariates&quot;) %&gt;% mutate(data = ifelse(name == &quot;alcohol&quot;, map(data, ~(.) %&gt;% mutate(year = ifelse(year == 2006, 2005, year))), data)) %&gt;% mutate(data = map(data, ~(.) %&gt;% left_join(yrBrth) %&gt;% filter(year &lt;= max(gsoep_waves$Used) &amp; !is.na(value)) %&gt;% group_by(comp_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule), &quot;skip&quot;, comp_rule)))) %&gt;% filter(map(data, nrow) &gt; 0) %&gt;% unnest(data) %&gt;% mutate(data = pmap(list(data, comp_rule, name), year_comp_fun)) %&gt;% unnest(data) comp_fun &lt;- function(rule, p_year){ gsoep_cov %&gt;% filter(year &lt;= p_year &amp; long_rule == rule) %&gt;% group_by(SID, yearBrth, name) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() } gsoep_cov &lt;- crossing( p_year = gsoep_waves$Used, long_rule = unique(gsoep_cov$long_rule) ) %&gt;% mutate(data = map2(long_rule, p_year, comp_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %&gt;% select(-long_rule, -yearBrth) %&gt;% pivot_wider(names_from = name, values_from = value) %&gt;% mutate(yearBrth = ifelse(yearBrth &lt; 1000, yearBrth + 1000, yearBrth)) gsoep_cov ## # A tibble: 114,106 × 16 ## p_year SID exercise height weight cancer diabetes married stroke alcohol education smokes gender yearBrth age SRhealth ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2005 101 1.67 NA NA 0 0 1 0 NA NA NA 0 1930 54 NA ## 2 2005 102 1 NA NA 0 0 1 0 NA NA NA 1 1940 44 NA ## 3 2005 103 2.67 NA NA 0 0 0 0 NA NA NA 0 1963 21 NA ## 4 2005 201 2 157 61 0 0 0 0 1 11 0 1 1926 58 3 ## 5 2005 202 3 NA NA 0 0 0 0 NA NA NA 1 1956 28 NA ## 6 2005 203 4 177 77 0 0 0 0 1 NA 0 0 1960 24 5 ## 7 2005 301 1 NA NA 0 0 1 0 NA NA NA 0 1960 24 4 ## 8 2005 302 1 NA NA 0 0 1 0 NA NA NA 1 1961 23 3 ## 9 2005 401 1 NA NA 0 0 0 0 NA NA NA 0 1920 64 NA ## 10 2005 501 1 NA NA 0 0 0 0 NA NA NA 1 1911 73 2 ## # … with 114,096 more rows 2.7.4 Personality Variables gsoep_pers &lt;- gsoep_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% unnest(data) %&gt;% filter(year %in% gsoep_waves$Used) %&gt;% distinct() # alpha&#39;s gsoep_alpha &lt;- gsoep_pers %&gt;% select(name, itemname, year, SID, value) %&gt;% group_by(name, year) %&gt;% nest() %&gt;% mutate(data = map(data, ~(.) %&gt;% pivot_wider(names_from = itemname, values_from = value)), alpha = map(data, possibly(~psych::alpha((.) %&gt;% select(-persnr)), NA_real_))) comp_fun &lt;- function(df, rule){ df %&gt;% group_by(SID) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() } # create composites gsoep_pers &lt;- gsoep_pers %&gt;% group_by(name, comp_rule, year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, comp_fun)) %&gt;% unnest(data) %&gt;% select(-comp_rule) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) gsoep_pers ## # A tibble: 191,511 × 4 ## name year SID value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 A 2005 201 7 ## 2 A 2005 203 4.67 ## 3 A 2005 602 4.33 ## 4 A 2005 901 4.67 ## 5 A 2005 1202 7 ## 6 A 2005 1501 4.67 ## 7 A 2005 1601 4 ## 8 A 2005 1602 6.67 ## 9 A 2005 1603 4.33 ## 10 A 2005 1701 7 ## # … with 191,501 more rows 2.7.5 Outcome Variables gsoep_pers_subs &lt;- unique(gsoep_pers$SID) gsoep_waves &lt;- p_waves %&gt;% filter(Study == &quot;GSOEP&quot;) %&gt;% select(Used) %&gt;% distinct() # composite within years # compositing within years year_comp_fun &lt;- function(df, rule){ df %&gt;% group_by(SID, name, year) %&gt;% # group by person and item (collapse across age) summarize(value = fun_call(value, rule)) %&gt;% ungroup() } gsoep_out &lt;- gsoep_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% unnest(data) %&gt;% # filter(year &lt;= max(gsoep_waves$Used)) %&gt;% group_by(comp_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(comp_rule = ifelse(comp_rule == &quot;select&quot;, &quot;skip&quot;, comp_rule), data = map2(data, comp_rule, year_comp_fun)) %&gt;% unnest(data) # composite across years comp_fun &lt;- function(p_year){ gsoep_out %&gt;% group_by(SID, name) %&gt;% summarize(value = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value), NA, value)) } gsoep_out &lt;- tibble(p_year = gsoep_waves$Used) %&gt;% mutate(data = map(p_year, comp_fun)) %&gt;% unnest(data) %&gt;% mutate(o_year = 2017) gsoep_out ## # A tibble: 109,214 × 5 ## p_year SID name value o_year ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2005 602 dementia 0 2017 ## 2 2005 604 dementia 0 2017 ## 3 2005 901 dementia 0 2017 ## 4 2005 1501 dementia 0 2017 ## 5 2005 1601 dementia 0 2017 ## 6 2005 1602 dementia 0 2017 ## 7 2005 2301 dementia 0 2017 ## 8 2005 2302 dementia 0 2017 ## 9 2005 4701 dementia 0 2017 ## 10 2005 4901 dementia 0 2017 ## # … with 109,204 more rows 2.7.6 Cognition Variables gsoep_cog &lt;- gsoep_recode %&gt;% filter(category == &quot;cognition&quot;) %&gt;% unnest(data) %&gt;% filter(!is.na(value)) gsoep_cog_waves &lt;- gsoep_cog %&gt;% select(itemname, SID, year) %&gt;% group_by(SID, itemname) %&gt;% summarize(o_year = max(year)) %&gt;% ungroup() gsoep_cog &lt;- gsoep_cog %&gt;% right_join(gsoep_cog_waves) %&gt;% filter(year == o_year) %&gt;% filter(!is.na(value)) %&gt;% group_by(name, itemname, year) %&gt;% mutate(value = pomp(value)) %&gt;% group_by(name, o_year, SID) %&gt;% summarize(value = mean(value)) %&gt;% ungroup() %&gt;% pivot_wider(names_from = &quot;name&quot;, values_from = &quot;value&quot;) gsoep_cog ## # A tibble: 22,445 × 3 ## o_year SID cognition ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2012 201 0 ## 2 2012 1501 3.81 ## 3 2012 5601 2.06 ## 4 2012 6002 2.46 ## 5 2012 7302 1.44 ## 6 2012 8603 3.75 ## 7 2012 9801 3.88 ## 8 2012 11301 3.45 ## 9 2012 12303 2.66 ## 10 2012 13401 1.98 ## # … with 22,435 more rows 2.7.7 Combine Data gsoep_combined &lt;- gsoep_pers %&gt;% rename(Trait = name, p_value = value, p_year = year) %&gt;% full_join(gsoep_out %&gt;% select(p_year, SID, Outcome = name, o_year, o_value = value)) %&gt;% full_join(gsoep_cov) %&gt;% left_join( gsoep_out %&gt;% filter(name == &quot;dementia&quot;) %&gt;% pivot_wider(names_from = &quot;name&quot;, values_from = &quot;value&quot;) ) %&gt;% full_join(gsoep_cog) %&gt;% filter(!is.na(p_value) &amp; !is.na(o_value)) %&gt;% mutate(age = p_year - yearBrth , BMI = weight/((height/100)^2)) gsoep_combined ## # A tibble: 136,465 × 24 ## Trait p_year SID p_value Outcome o_year o_value exercise height weight cancer diabe…¹ married stroke alcohol educa…² smokes gender yearB…³ ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 A 2005 602 4.33 dementia 2017 0 2.8 177 87 0 0 1 0 1 18 1 1 1958 ## 2 A 2005 901 4.67 dementia 2017 0 2.8 158 47 0 0 0 0 0 10.5 1 1 1951 ## 3 A 2005 1501 4.67 dementia 2017 0 1 168. 84 0 0 0 0 1 18 0 0 1958 ## 4 A 2005 1601 4 dementia 2017 0 2.67 174. 75 0 0 1 0 1 10.5 1 0 1940 ## 5 A 2005 1602 6.67 dementia 2017 0 2 160. 48 0 0 1 0 1 NA 1 1 1961 ## 6 A 2005 2301 5 dementia 2017 0 1.8 180 75 0 0 1 0 0 18 1 0 1946 ## 7 A 2005 2302 3.33 dementia 2017 0 3 157 46.5 0 0 1 0 1 18 1 1 1946 ## 8 A 2005 4701 6 dementia 2017 0 2.2 168 70 0 0 0 0 1 9 0 1 1919 ## 9 A 2005 4901 5.33 dementia 2017 0 1 162. 66.5 0 0 0 0 1 9 0 1 1925 ## 10 A 2005 5201 6.33 dementia 2017 0 1.07 183 83 0 0 1 0 0 10.5 1 0 1955 ## # … with 136,455 more rows, 5 more variables: age &lt;dbl&gt;, SRhealth &lt;dbl&gt;, dementia &lt;dbl&gt;, cognition &lt;dbl&gt;, BMI &lt;dbl&gt;, and abbreviated variable ## # names ¹​diabetes, ²​education, ³​yearBrth save(gsoep_cov, gsoep_alpha, gsoep_pers, gsoep_out, gsoep_combined, gsoep_cog, file = sprintf(&quot;%s/data/clean/gsoep_cleaned.RData&quot;, load_path)) rm(list =ls()[grepl(&quot;gsoep&quot;, ls())]) 2.8 The Longitudinal Studies for the Social sciences (LISS) The Longitudinal Studies for the Social sciences (LISS; Scherpenzeel, Das, Ester, &amp; Kaczmirek, 2010) is an ongoing longitudinal study of households in the Netherlands. These data are online, through application, from https://statements.centerdata.nl/liss-panel-data-statement. Participants were approximately 8,000 Dutch-speaking individuals permanently residing in the Netherlands from 5,000 households. Data have been collected annually since 2007. The latest data release includes 11 waves of data from 2008 to 2018. More documentation are available at https://www.dataarchive.lissdata.nl/study_units/view/1. Sample sizes vary by year, ranging from 5,021 (2018) to 6808 (2008). This provides 99/% power to detect a correlation effect size of ~.04, two-tailed at alpha .05. 2.8.1 Load Data liss_read_fun &lt;- function(x){ sprintf(&quot;%s/liss/%s&quot;, data_path, x) %&gt;% haven::read_sav(.) %&gt;% select(one_of(old.names)) } liss_codebook &lt;- (codebook %&gt;% filter(study == &quot;LISS&quot;))$codebook[[1]] liss_codebook ## # A tibble: 1,327 × 17 ## study dataset category name itemname wave wave_letter year orig_itemname descr…¹ scale rever…² recode mini maxi comp_…³ long_…⁴ ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 liss ai07a cognition cognition BSI 1 a 2008 ai07a031 BSI pr… &quot;1\\t… &lt;NA&gt; ifels… NA NA skip select ## 2 liss ai08b cognition cognition BSI 2 b 2009 ai08b031 BSI pr… &quot;1\\t… &lt;NA&gt; ifels… NA NA skip select ## 3 liss ai08c cognition cognition BSI 3 c 2010 ai08c031 BSI pr… &quot;1\\t… &lt;NA&gt; ifels… NA NA skip select ## 4 liss ai08d cognition cognition BSI 4 d 2011 ai08d031 BSI pr… &quot;1\\t… &lt;NA&gt; ifels… NA NA skip select ## 5 liss avars_2008 covariates yearBrth YOB1 1 a 2008 gebjaar Year o… &quot;num… &lt;NA&gt; ifels… NA NA mode select ## 6 liss avars_2009 covariates yearBrth YOB1 2 b 2009 gebjaar Year o… &quot;num… &lt;NA&gt; ifels… NA NA mode select ## 7 liss avars_2010 covariates yearBrth YOB1 3 c 2010 gebjaar Year o… &quot;num… &lt;NA&gt; ifels… NA NA mode select ## 8 liss avars_2011 covariates yearBrth YOB1 4 d 2011 gebjaar Year o… &quot;num… &lt;NA&gt; ifels… NA NA mode select ## 9 liss avars_2012 covariates yearBrth YOB1 5 e 2012 gebjaar Year o… &quot;num… &lt;NA&gt; ifels… NA NA mode select ## 10 liss avars_2013 covariates yearBrth YOB1 6 f 2013 gebjaar Year o… &quot;num… &lt;NA&gt; ifels… NA NA mode select ## # … with 1,317 more rows, and abbreviated variable names ¹​description, ²​reverse_code, ³​comp_rule, ⁴​long_rule old.names &lt;- unique(liss_codebook$orig_itemname) %&gt;% str_to_lower datasets &lt;- sprintf(&quot;%s/liss&quot;, data_path) %&gt;% list.files() liss &lt;- tibble(datasets = datasets) %&gt;% mutate(data = map(datasets, liss_read_fun)) liss &lt;- reduce(liss$data, full_join) %&gt;% haven::zap_labels(.) save(liss, file = sprintf(&quot;%s/data/clean/liss_raw.RData&quot;, load_path)) avars &lt;- tibble(ds = datasets[grepl(&quot;avar&quot;, datasets)]) %&gt;% mutate(data = map(ds, ~sprintf(&quot;%s/liss/%s&quot;, data_path, .) %&gt;% haven::read_sav(.) %&gt;% select(one_of(old.names)) %&gt;% haven::zap_labels(.))) %&gt;% separate(ds, c(&quot;ds&quot;, &quot;year&quot;, &quot;scrap1&quot;, &quot;scrap2&quot;), sep = &quot;_&quot;) %&gt;% separate(year, c(&quot;year&quot;, &quot;month&quot;), -2) %&gt;% select(year, month, data) %&gt;% unnest(data) 2.8.2 Recoding &amp; Reverse-Scoring rename_fun &lt;- function(cb, var){ print(var) old.names &lt;- unique((liss_codebook %&gt;% filter(name == var))$orig_itemname) df &lt;- liss %&gt;% select(SID = nomem_encr, HHID = nohouse_encr, one_of(old.names)) %&gt;% gather(key = orig_itemname, value = value, -SID, -HHID, na.rm=T) if(length(old.names) &gt; 1){ df &lt;- df %&gt;% left_join(cb %&gt;% select(itemname, year, orig_itemname, reverse_code:long_rule)) } else { df &lt;- df %&gt;% left_join(cb %&gt;% select(-(itemname:year)) %&gt;% distinct()) %&gt;% mutate(year = 0) } if(var %in% c(&quot;yearBrth&quot;, &quot;gender&quot;)) df &lt;- df %&gt;% left_join(avars %&gt;% select(-category, -name)) return(df) } avars &lt;- avars %&gt;% select(SID = nomem_encr, HHID = nohouse_encr, everything()) %&gt;% group_by(SID, HHID, year) %&gt;% summarize_at(vars(gebjaar, geslacht), Mode) %&gt;% ungroup() %&gt;% pivot_longer(cols = c(&quot;gebjaar&quot;, &quot;geslacht&quot;) , names_to = &quot;orig_itemname&quot; , values_to = &quot;value&quot;) %&gt;% mutate(year = as.numeric(year)) %&gt;% left_join( liss_codebook %&gt;% select(category, name, itemname, year, orig_itemname, reverse_code:long_rule) ) # rename variables liss_recode &lt;- liss_codebook %&gt;% filter(category %in% c(&quot;covariates&quot;, &quot;pers&quot;, &quot;outcome&quot;, &quot;cognition&quot;)) %&gt;% select(category, name:wave, year:orig_itemname, reverse_code:long_rule) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, name, rename_fun)) recode_fun &lt;- function(rule, y){ x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } liss_recode &lt;- liss_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% group_by(recode) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(recode, data), recode_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(value &lt; 0 | is.nan(value) | is.infinite(value), NA, value)))) # reverse code liss_recode &lt;- liss_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(value = ifelse(tolower(reverse_code) == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))))) fun_call &lt;- function(x, rule){ switch(rule, average = mean(x, na.rm = T), mode = Mode(x)[1], sum = sum(x, na.rm = T), skip = unique(x)[1], select = unique(x)[1], max = max(x, na.rm = T), min = min(x, na.rm = T)) } 2.8.3 Covariates load(sprintf(&quot;%s/data/clean/liss_cleaned.RData&quot;, local_path)) # bring in year or birth for cleaning liss_cov &lt;- liss_recode %&gt;% filter(category == &quot;covariates&quot;) %&gt;% unnest(data) %&gt;% distinct() # compositing within years year_comp_fun &lt;- function(df, rule){ df %&gt;% # group by person and item (collapse across age) group_by(SID, HHID, long_rule, name, year) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } liss_waves &lt;- p_waves %&gt;% filter(Study == &quot;LISS&quot;) %&gt;% select(Used) %&gt;% distinct() liss_cov &lt;- liss_cov %&gt;% filter(year &lt;= max(liss_waves$Used)) %&gt;% group_by(comp_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, year_comp_fun)) %&gt;% unnest(data) comp_fun &lt;- function(rule, p_year){ liss_cov %&gt;% filter(year &lt;= p_year &amp; long_rule == rule) %&gt;% group_by(SID, HHID, name) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() } liss_cov &lt;- crossing( p_year = liss_waves$Used, long_rule = unique(liss_cov$long_rule) ) %&gt;% mutate(data = map2(long_rule, p_year, comp_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %&gt;% select(-long_rule) %&gt;% pivot_wider(names_from = name, values_from = value, values_fn = list(value = max)) %&gt;% mutate(BMI = weight/((height/100)^2)) liss_cov ## # A tibble: 27,202 × 21 ## p_year SID HHID weight exercise alcohol cancer diabetes education ethnicity heartP…¹ height parki…² respDis smokes stroke married gender ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2008 800033 583404 58 NA 1 0 0 12 2 0 165 0 0 1 0 NA 0 ## 2 2008 800042 500277 74.5 0 1 0 0 16 NA 0 169 0 0 1 0 1 1 ## 3 2008 800045 548654 84 NA 1 0 0 NA NA 0 185 0 0 1 0 1 0 ## 4 2008 800057 580532 85 NA 1 0 0 18 NA 0 198 0 0 1 0 NA 0 ## 5 2008 800076 578048 57 0 1 0 0 NA NA 0 167 0 0 0 0 NA 1 ## 6 2008 800119 537783 84.5 NA 0 1 0 NA 2 0 174 0 0 0 0 1 1 ## 7 2008 800125 582101 61 NA 1 0 0 16 2 0 158 0 1 0 0 NA 1 ## 8 2008 800134 549826 66 NA 1 0 0 NA NA 0 162 0 0 1 0 1 1 ## 9 2008 800158 519049 87.5 NA 1 0 0 14 NA 0 180 0 0 0 0 1 0 ## 10 2008 800170 520571 56.5 0 1 0 0 14 NA 0 160 0 0 1 0 1 1 ## # … with 27,192 more rows, 3 more variables: yearBrth &lt;dbl&gt;, SRhealth &lt;dbl&gt;, BMI &lt;dbl&gt;, and abbreviated variable names ¹​heartProb, ²​parkinsons 2.8.4 Personality Variables liss_pers &lt;- liss_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% unnest(data) %&gt;% filter(year == liss_waves$Used) %&gt;% distinct() # alpha&#39;s liss_alpha &lt;- liss_pers %&gt;% select(name, itemname, year, SID, value) %&gt;% group_by(name, year) %&gt;% nest() %&gt;% mutate(data = map(data, ~(.) %&gt;% pivot_wider(names_from = itemname, values_from = value)), alpha = map(data, possibly(~psych::alpha((.) %&gt;% select(-SID)), NA_real_))) # create composites liss_pers &lt;- liss_pers %&gt;% group_by(SID, HHID, name, year) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() liss_pers ## # A tibble: 54,280 × 5 ## SID HHID name year value ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 800033 583404 A 2008 2.8 ## 2 800033 583404 C 2008 2.3 ## 3 800033 583404 E 2008 2.4 ## 4 800033 583404 N 2008 2.7 ## 5 800033 583404 NA 2008 3.3 ## 6 800033 583404 O 2008 3.4 ## 7 800033 583404 PA 2008 4.2 ## 8 800033 583404 SWL 2008 6 ## 9 800042 500277 A 2008 3.7 ## 10 800042 500277 C 2008 3.9 ## # … with 54,270 more rows 2.8.5 Cognition Variables liss_cog &lt;- liss_recode %&gt;% filter(category == &quot;cognition&quot;) %&gt;% unnest(data) %&gt;% filter(year == liss_waves$Used) %&gt;% filter(!is.na(value)) %&gt;% group_by(name, itemname, year) %&gt;% mutate(value = pomp(value)) %&gt;% distinct() %&gt;% group_by(name, SID) %&gt;% summarize(value = mean(value)) %&gt;% ungroup() %&gt;% pivot_wider(names_from = &quot;name&quot;, values_from = &quot;value&quot;) liss_cog ## # A tibble: 1,804 × 2 ## SID cognition ## &lt;dbl&gt; &lt;dbl&gt; ## 1 800076 2.5 ## 2 800170 0 ## 3 800186 7.5 ## 4 800231 2.5 ## 5 800326 0 ## 6 800354 2.5 ## 7 800424 7.5 ## 8 800540 5 ## 9 800601 5 ## 10 800790 5 ## # … with 1,794 more rows 2.8.6 Outcome Variables liss_out &lt;- liss_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% unnest(data) %&gt;% mutate(p_year = liss_waves$Used, group = ifelse(year &gt; p_year, &quot;future&quot;, &quot;past&quot;)) %&gt;% group_by(SID, name, group, p_year) %&gt;% summarize(value = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value), NA, value)) %&gt;% pivot_wider(names_from = group, values_from = value) %&gt;% group_by(SID, p_year, name) %&gt;% mutate(value = ifelse(is.na(past) | (past == 0 &amp; !is.na(future)), future, ifelse(past == 0 &amp; is.na(future), past, ifelse(past == 1, NA, NA)))) %&gt;% ungroup() %&gt;% filter(!is.na(value)) liss_out ## # A tibble: 13,452 × 6 ## SID name p_year future past value ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 800009 dementia 2008 0 NA 0 ## 2 800012 dementia 2008 0 NA 0 ## 3 800015 dementia 2008 0 NA 0 ## 4 800018 dementia 2008 0 NA 0 ## 5 800033 dementia 2008 0 0 0 ## 6 800042 dementia 2008 0 0 0 ## 7 800045 dementia 2008 NA 0 0 ## 8 800054 dementia 2008 0 NA 0 ## 9 800057 dementia 2008 0 0 0 ## 10 800073 dementia 2008 0 NA 0 ## # … with 13,442 more rows 2.8.7 Combine Data liss_combined &lt;- liss_pers %&gt;% rename(Trait = name, p_value = value, p_year = year) %&gt;% full_join(liss_out %&gt;% rename(Outcome = name, o_value = value)) %&gt;% full_join(liss_cov) %&gt;% left_join( liss_out %&gt;% filter(name == &quot;dementia&quot;) %&gt;% mutate(value = ifelse(rowSums(cbind(future, past), na.rm = T) &gt;= 1, 1, 0)) %&gt;% select(-future, -past) %&gt;% pivot_wider(names_from = &quot;name&quot;, values_from = &quot;value&quot;) ) %&gt;% full_join(liss_cog) %&gt;% filter(!is.na(p_value) &amp; !is.na(o_value)) %&gt;% mutate(age = p_year - yearBrth , o_year = 2018) liss_combined ## # A tibble: 52,267 × 31 ## SID HHID Trait p_year p_value Outcome future past o_value weight exerc…¹ alcohol cancer diabe…² educa…³ ethni…⁴ heart…⁵ height parki…⁶ ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 800033 583404 A 2008 2.8 dementia 0 0 0 58 NA 1 0 0 12 2 0 165 0 ## 2 800033 583404 C 2008 2.3 dementia 0 0 0 58 NA 1 0 0 12 2 0 165 0 ## 3 800033 583404 E 2008 2.4 dementia 0 0 0 58 NA 1 0 0 12 2 0 165 0 ## 4 800033 583404 N 2008 2.7 dementia 0 0 0 58 NA 1 0 0 12 2 0 165 0 ## 5 800033 583404 NA 2008 3.3 dementia 0 0 0 58 NA 1 0 0 12 2 0 165 0 ## 6 800033 583404 O 2008 3.4 dementia 0 0 0 58 NA 1 0 0 12 2 0 165 0 ## 7 800033 583404 PA 2008 4.2 dementia 0 0 0 58 NA 1 0 0 12 2 0 165 0 ## 8 800033 583404 SWL 2008 6 dementia 0 0 0 58 NA 1 0 0 12 2 0 165 0 ## 9 800042 500277 A 2008 3.7 dementia 0 0 0 74.5 0 1 0 0 16 NA 0 169 0 ## 10 800042 500277 C 2008 3.9 dementia 0 0 0 74.5 0 1 0 0 16 NA 0 169 0 ## # … with 52,257 more rows, 12 more variables: respDis &lt;dbl&gt;, smokes &lt;dbl&gt;, stroke &lt;dbl&gt;, married &lt;dbl&gt;, gender &lt;dbl&gt;, yearBrth &lt;dbl&gt;, ## # SRhealth &lt;dbl&gt;, BMI &lt;dbl&gt;, dementia &lt;dbl&gt;, cognition &lt;dbl&gt;, age &lt;dbl&gt;, o_year &lt;dbl&gt;, and abbreviated variable names ¹​exercise, ²​diabetes, ## # ³​education, ⁴​ethnicity, ⁵​heartProb, ⁶​parkinsons save(liss_cov, liss_alpha, liss_pers, liss_out, liss_combined, liss_cog, file = sprintf(&quot;%s/data/clean/liss_cleaned.RData&quot;, local_path)) rm(list =ls()[grepl(&quot;liss&quot;, ls())]) "],["runmodels.html", "Chapter 3 Models 3.1 Part 1: Combine Data 3.2 Part 2: Clean and Prepare Data Sets 3.3 Part 3: Models 3.4 Compile Results", " Chapter 3 Models In this section, we will: Combine the data across samples and create new data frames for each personality trait / well-being x covariate x outcome x moderator combination. As preregistered, we will then rescale variables in each sample to harmonize across samples Next, we will create a series of functions to: Run the model Extract sample-specific estimates from each sample Extract cross-sample heterogeneity estimates Extract fixed and and random simple slopes Run the models or export files to the computing cluster to speed up runtime. 3.1 Part 1: Combine Data First, we’ll just load in all the combined data frames for each sample and keep our core variables: loadRData &lt;- function(fileName, type){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/data/clean/%s_cleaned.RData&quot;, local_path, fileName) load(path) get(ls()[grepl(type, ls())]) } # which(apply(nested_data %&gt;% mutate(cols = map(data, colnames)) %&gt;% select(-data) %&gt;% unnest(cols) %&gt;% mutate(inc = &quot;yes&quot;) %&gt;% spread(study, inc), 1, function(x){sum(is.na(x))/7*100}) &lt; 25) nested_data &lt;- tibble( study = studies , data = map(str_to_lower(study), ~loadRData(., &quot;combined&quot;)) ) %&gt;% mutate( data = map(data, ~(.) %&gt;% ungroup() %&gt;% mutate(SID = as.character(SID)) %&gt;% select(SID, Trait, p_year, p_value, Outcome, o_year, o_value # core variables , one_of(c(&quot;age&quot;, &quot;gender&quot;, &quot;education&quot;, &quot;cognition&quot; , &quot;alcohol&quot;, &quot;smokes&quot;, &quot;BMI&quot;, &quot;race&quot;, &quot;SRhealth&quot; , &quot;stroke&quot;, &quot;cancer&quot;, &quot;diabetes&quot;, &quot;heartProb&quot;, &quot;dementia&quot;))) ) , study = mapvalues(study, studies, studies_long) ) %&gt;% unnest(data) %&gt;% # removing this outcome because there was no variance for WUSM MAP filter(!(Outcome == &quot;vsclrInfrcts&quot; &amp; study == &quot;ADRC&quot;)) nested_data ## # A tibble: 420,195 × 22 ## study SID Trait p_year p_value Outcome o_year o_value age gender educa…¹ cogni…² alcohol smokes BMI race stroke cancer diabe…³ heart…⁴ ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ROS 0002… A 0 32 angiop… 2 3 80.0 0 22 4.19 0 0 19.9 0 0 0 0 1 ## 2 ROS 0002… A 0 32 arteri… 2 0 80.0 0 22 4.19 0 0 19.9 0 0 0 0 1 ## 3 ROS 0002… A 0 32 athero… 2 2 80.0 0 22 4.19 0 0 19.9 0 0 0 0 1 ## 4 ROS 0002… A 0 32 braak 2 6 80.0 0 22 4.19 0 0 19.9 0 0 0 0 1 ## 5 ROS 0002… A 0 32 cerad 2 1 80.0 0 22 4.19 0 0 19.9 0 0 0 0 1 ## 6 ROS 0002… A 0 32 hipScl… 2 0 80.0 0 22 4.19 0 0 19.9 0 0 0 0 1 ## 7 ROS 0002… A 0 32 lewyBo… 2 0 80.0 0 22 4.19 0 0 19.9 0 0 0 0 1 ## 8 ROS 0002… A 0 32 vsclrI… 2 0 80.0 0 22 4.19 0 0 19.9 0 0 0 0 1 ## 9 ROS 0002… A 0 32 vsclrM… 2 1 80.0 0 22 4.19 0 0 19.9 0 0 0 0 1 ## 10 ROS 0002… A 0 32 tdp43 2 1 80.0 0 22 4.19 0 0 19.9 0 0 0 0 1 ## # … with 420,185 more rows, 2 more variables: dementia &lt;dbl&gt;, SRhealth &lt;dbl&gt;, and abbreviated variable names ¹​education, ²​cognition, ³​diabetes, ## # ⁴​heartProb 3.2 Part 2: Clean and Prepare Data Sets Next time to rescale or relevel variables. 3.2.1 POMP and Factor Levels The first thing we’ll do is get everything on the same scale. To do so, and as we preregistered, we will convert: - age to centered at 60 - education (in years) to centered at 12 years - personality characteristics and cognition to POMP - chronic conditions to 0 = no, 1 = yes - Dementia diagnosis to 0 = no, 1 = yes - Lewy Body Disease (binary; 0 = none, 1 = yes, collapsing across types) - Gross Cerebral Infarcts, Gross Cerebral Microinfarcts, Hippocampal Sclerosis (binary; 0 = No, 1 = Yes) All other indicators have scales that are already standardized across studies (e.g., BMI, Braak stage, CERAD) and will not be transformed. But first, we’ll make a table of descriptive values (M (SD) or percentage) for all variables for each sample. cln &lt;- c(&quot;Study&quot;, &quot;E&quot;, &quot;A&quot;, &quot;C&quot;, &quot;N&quot;, &quot;O&quot;, &quot;Crystallized / Knowledge&quot;, &quot;Age (Years)&quot;, &quot;Education (Years)&quot;, &quot;% Women&quot;) fctr_vars &lt;- c(&quot;dementia&quot;, &quot;hipSclerosis&quot;, &quot;lewyBodyDis&quot;, &quot;tdp43&quot;, &quot;vsclrInfrcts&quot;, &quot;vsclrMcrInfrcts&quot;, &quot;gender&quot; , &quot;smokes&quot;, &quot;alcohol&quot;, &quot;race&quot;, &quot;stroke&quot;, &quot;cancer&quot;, &quot;diabetes&quot;, &quot;heartProb&quot;) transpose_df &lt;- function(df) { t_df &lt;- data.table::transpose(df) colnames(t_df) &lt;- rownames(df) rownames(t_df) &lt;- colnames(df) t_df &lt;- t_df %&gt;% tibble::rownames_to_column(.data = .) %&gt;% tibble::as_tibble(.) %&gt;% filter(row_number() != 1) %&gt;% set_names(c(&quot;Variable&quot;, df$study)) return(t_df) } desc_tab &lt;- nested_data %&gt;% select(-p_year, -o_year, -one_of(fctr_vars)) %&gt;% group_by(study, Trait, Outcome) %&gt;% mutate_at(vars(p_value, SRhealth), ~((. - min(., na.rm = T))/(max(., na.rm = T) - min(., na.rm = T))*10)) %&gt;% mutate_at(vars(p_value, SRhealth), ~ifelse(is.infinite(.), NA, .)) %&gt;% ungroup() %&gt;% pivot_wider(names_from = Outcome, values_from = o_value, values_fn = mean) %&gt;% pivot_wider(names_from = Trait, values_from = p_value, values_fn = mean) %&gt;% group_by(study) %&gt;% mutate(n = n()) %&gt;% select(-one_of(fctr_vars)) %&gt;% distinct() %&gt;% pivot_longer(cols = c(-study, -SID, -n), values_to = &quot;value&quot;, names_to = &quot;item&quot;, values_drop_na = T) %&gt;% group_by(study, item, n) %&gt;% summarize(est = sprintf(&quot;%.2f (%.2f)&quot;, mean(value, na.rm = T), sd(value, na.rm = T))) %&gt;% ungroup() %&gt;% pivot_wider(names_from = item, values_from = est) %&gt;% full_join( nested_data %&gt;% group_by(Outcome, SID, study) %&gt;% filter(o_year == min(o_year)) %&gt;% ungroup() %&gt;% select(-o_year, -dementia) %&gt;% pivot_wider(names_from = Outcome, values_from = o_value, values_fn = mean) %&gt;% select(-Trait, -p_year, -p_value) %&gt;% distinct() %&gt;% select(study, SID, one_of(fctr_vars)) %&gt;% distinct() %&gt;% group_by(study) %&gt;% summarize_at(vars(-SID), ~mean(., na.rm = T)*100) %&gt;% mutate_at(vars(-study), ~ifelse(is.nan(.) | is.na(.), &quot;&quot;, sprintf(&quot;%.2f%%&quot;, .))) %&gt;% ungroup() ) %&gt;% select(study, n, E, A, C, N, O, PA, `NA`, SWL, one_of(outcomes$short_name), age, gender, education, cognition, BMI, SRhealth, smokes, alcohol, BMI, race, stroke, cancer, diabetes, heartProb) %&gt;% transpose_df() %&gt;% mutate(Variable = ifelse(Variable == &quot;n&quot;, &quot;Valid N&quot;, Variable)) %&gt;% mutate(Variable = mapvalues(Variable, c(traits$short_name, outcomes$short_name), str_wrap(c(traits$long_name, outcomes$long_name), 25))) %&gt;% select(Variable, `Rush-MAP`, ROS, `WUSM-MAP`, EAS, GSOEP, HRS, LISS, SATSA) %&gt;% kable(., &quot;html&quot; , digits = 2 # , col.names = cln , caption = &quot;&lt;strong&gt;Table 1&lt;/strong&gt;&lt;br&gt;&lt;em&gt;Descriptive Statistics of All Harmonized Measures Across Samples&quot; , align = c(&quot;l&quot;, rep(&quot;c&quot;,9))) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% kableExtra::group_rows(&quot;Big Five Personality&quot;, 2, 6) %&gt;% kableExtra::group_rows(&quot;Subjective Well-Being&quot;, 7, 9) %&gt;% kableExtra::group_rows(&quot;Dementia and Neuropathology&quot;, 10, 20) %&gt;% kableExtra::group_rows(&quot;Covariates&quot;, 21, 33) %&gt;% add_footnote(notation = &quot;none&quot;, label = &quot;&lt;em&gt;Note.&lt;/em&gt; E = Extraversion; A = Agreeableness; C = Conscientiousness; N = Neuroticism; O = Openness, PA = Positive Affect, NA = Negative Affect, SWL = Satisfaction with Life; Age, education, gender, smoking, alcohol, BMI, chronic conditions, and cognition were assessed at the first baseline personality assessment.&quot;, escape = F); desc_tab (#tab:tab 2)Table 1Descriptive Statistics of All Harmonized Measures Across Samples Variable Rush-MAP ROS WUSM-MAP EAS GSOEP HRS LISS SATSA Valid N 4283 3374 1478 813 31072 14001 6543 2002 Big Five Personality Extraversion 5.50 (1.69) 5.17 (1.65) 5.73 (1.67) 5.59 (1.75) 6.40 (1.88) 7.33 (1.85) 5.64 (1.62) 6.33 (0.74) Agreeableness 5.33 (1.40) 6.37 (1.62) 6.73 (1.87) 7.45 (1.63) 8.42 (1.59) 6.68 (1.48) 7.23 (1.17) Conscientiousness 6.25 (1.57) 6.27 (1.39) 6.31 (1.79) 6.95 (1.73) 8.21 (1.55) 7.85 (1.61) 6.34 (1.49) 7.05 (1.35) Neuroticism 3.65 (1.68) 4.59 (1.61) 3.94 (1.91) 3.56 (2.08) 4.92 (2.04) 3.51 (2.06) 3.97 (1.69) 6.53 (1.35) Openness to Experience 5.50 (1.51) 5.60 (1.59) 5.85 (2.03) 5.88 (2.01) 6.44 (1.87) 5.98 (1.34) 4.84 (1.34) Subjective Well-Being Positive Affect 8.46 (1.82) 8.20 (3.86) 6.22 (2.15) 6.56 (1.93) 5.94 (1.67) 7.47 (2.12) Negative Affect 1.06 (1.30) 3.63 (1.98) 1.92 (1.81) 1.75 (1.76) 2.14 (2.29) Satisfaction with Life 7.39 (1.78) 6.75 (2.20) 7.00 (1.76) 6.08 (2.34) 6.56 (1.46) 5.75 (2.87) Dementia and Neuropathology Incident Dementia Diagnosis 22.17% 30.77% 27.39% 5.67% 1.03% 7.19% 0.31% 8.14% Braak Stage 3.77 (1.20) 3.58 (1.25) 4.01 (1.66) 3.12 (1.06) CERAD 2.16 (1.12) 2.22 (1.13) 2.46 (0.81) Lewy Body Disease 23.14% 23.44% 38.67% 11.76% Gross Cerebral Infarcts 37.91% 34.70% 100.00% Gross Cerebral Microinfarcts 33.08% 31.37% 17.09% Cerebral Atherosclerosis 1.13 (0.77) 1.24 (0.78) 1.29 (0.76) Cerebral Amyloid Angiopathy 1.29 (0.95) 1.29 (0.97) 1.27 (0.88) Arteriolosclerosis 1.03 (0.91) 0.99 (0.96) 1.42 (0.70) Hippocampal Sclerosis 9.77% 7.64% 3.66% 11.76% TDP-43 54.31% 49.79% 31.40% Covariates age 81.12 (6.96) 76.53 (7.24) 71.37 (10.39) 79.57 (5.39) 48.51 (16.93) 67.93 (10.45) 46.54 (15.94) 59.76 (14.02) gender 25.93% 28.64% 56.63% 61.34% 52.48% 59.49% 54.53% 58.79% education 14.87 (3.15) 18.25 (3.48) 15.71 (2.95) 14.46 (3.39) 11.60 (2.52) 12.61 (3.08) 12.60 (4.19) 10.32 (1.82) cognition 6.55 (1.02) 6.43 (0.98) 3.92 (1.29) 4.98 (0.81) 7.18 (1.58) 3.08 (2.81) 5.49 (1.35) BMI 27.03 (5.02) 27.32 (5.39) 28.28 (5.09) 25.61 (4.35) 27.66 (4.42) 25.42 (7.82) 25.50 (3.80) SRhealth 3.93 (2.94) 6.75 (2.30) 6.36 (2.78) 5.39 (1.89) 2.16 (2.79) smokes 42.52% 19.57% 11.58% 54.51% 33.97% 56.08% 61.97% 49.85% alcohol 36.01% 27.57% 5.25% 92.01% 58.31% 53.43% 92.02% 67.89% race 17.59% 15.38% 15.05% 44.20% 35.44% stroke 9.26% 6.95% 2.03% 4.38% 0.00% 9.62% 0.81% 2.06% cancer 32.96% 30.49% 6.68% 17.62% 0.00% 17.51% 1.62% 3.98% diabetes 13.41% 13.26% 8.95% 18.24% 0.00% 23.77% 4.76% 6.38% heartProb 12.15% 10.10% 8.35% 21.91% 30.52% 3.93% 33.91% Note. E = Extraversion; A = Agreeableness; C = Conscientiousness; N = Neuroticism; O = Openness, PA = Positive Affect, NA = Negative Affect, SWL = Satisfaction with Life; Age, education, gender, smoking, alcohol, BMI, chronic conditions, and cognition were assessed at the first baseline personality assessment. save_kable(desc_tab, file = sprintf(&quot;%s/results/tables/tab-1-desc.html&quot;, local_path)) Now let’s: POMP personality / well-being and self-rated health Create a chronic conditions composite (sum of stroke, cancer, diabetes, heart problem) Turn binary indicators into factors Center age at 60 years and education at 12 years. nested_data &lt;- nested_data %&gt;% group_by(Trait, Outcome, study, p_year) %&gt;% mutate_at(vars(p_value, SRhealth), ~((. - min(., na.rm = T))/(max(., na.rm = T) - min(., na.rm = T))*10)) %&gt;% mutate_at(vars(p_value, SRhealth), ~ifelse(is.infinite(.), NA, .)) %&gt;% mutate(CC = rowSums(cbind(stroke, cancer, diabetes, heartProb), na.rm = T)) %&gt;% mutate_at(vars(alcohol, smokes, stroke, cancer, diabetes, heartProb, gender, dementia), factor) %&gt;% mutate(age = age - 60 , education = education - 12) %&gt;% ungroup() nested_data ## # A tibble: 420,195 × 23 ## study SID Trait p_year p_value Outcome o_year o_value age gender educa…¹ cogni…² alcohol smokes BMI race stroke cancer diabe…³ heart…⁴ ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; ## 1 ROS 0002… A 0 4.29 angiop… 2 3 20.0 0 10 4.19 0 0 19.9 0 0 0 0 1 ## 2 ROS 0002… A 0 4.29 arteri… 2 0 20.0 0 10 4.19 0 0 19.9 0 0 0 0 1 ## 3 ROS 0002… A 0 4.29 athero… 2 2 20.0 0 10 4.19 0 0 19.9 0 0 0 0 1 ## 4 ROS 0002… A 0 4.29 braak 2 6 20.0 0 10 4.19 0 0 19.9 0 0 0 0 1 ## 5 ROS 0002… A 0 4.29 cerad 2 1 20.0 0 10 4.19 0 0 19.9 0 0 0 0 1 ## 6 ROS 0002… A 0 4.29 hipScl… 2 0 20.0 0 10 4.19 0 0 19.9 0 0 0 0 1 ## 7 ROS 0002… A 0 4.29 lewyBo… 2 0 20.0 0 10 4.19 0 0 19.9 0 0 0 0 1 ## 8 ROS 0002… A 0 4.29 vsclrI… 2 0 20.0 0 10 4.19 0 0 19.9 0 0 0 0 1 ## 9 ROS 0002… A 0 4.29 vsclrM… 2 1 20.0 0 10 4.19 0 0 19.9 0 0 0 0 1 ## 10 ROS 0002… A 0 4.29 tdp43 2 1 20.0 0 10 4.19 0 0 19.9 0 0 0 0 1 ## # … with 420,185 more rows, 3 more variables: dementia &lt;fct&gt;, SRhealth &lt;dbl&gt;, CC &lt;dbl&gt;, and abbreviated variable names ¹​education, ²​cognition, ## # ³​diabetes, ⁴​heartProb 3.2.2 Rescale Outcomes Now that we’ve got personality and covariates scaled, we will group by personality characteristic and outcome to rescale outcomes, as needed. save_fun &lt;- function(d, trait, outcome){ if(outcome %in% c(&quot;dementia&quot;, &quot;hipSclerosis&quot;, &quot;lewyBodyDis&quot;, &quot;tdp43&quot;, &quot;vsclrInfrcts&quot;, &quot;vsclrMcrInfrcts&quot;)){ d &lt;- d %&gt;% mutate(o_value = factor(o_value)) } save(d, file = sprintf(&quot;%s/data/SCA/%s-%s.RData&quot;, local_path, trait, outcome)) return(d) } nested_data &lt;- nested_data %&gt;% group_by(Trait, Outcome) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(data, Trait, Outcome), save_fun)) nested_data ## # A tibble: 96 × 3 ## Trait Outcome data ## &lt;chr&gt; &lt;chr&gt; &lt;list&gt; ## 1 A angiopathy &lt;tibble [909 × 21]&gt; ## 2 A arteriolosclerosis &lt;tibble [926 × 21]&gt; ## 3 A atherosclerosis &lt;tibble [943 × 21]&gt; ## 4 A braak &lt;tibble [969 × 21]&gt; ## 5 A cerad &lt;tibble [889 × 21]&gt; ## 6 A hipSclerosis &lt;tibble [844 × 21]&gt; ## 7 A lewyBodyDis &lt;tibble [935 × 21]&gt; ## 8 A vsclrInfrcts &lt;tibble [934 × 21]&gt; ## 9 A vsclrMcrInfrcts &lt;tibble [934 × 21]&gt; ## 10 A tdp43 &lt;tibble [791 × 21]&gt; ## # … with 86 more rows 3.2.3 Bring in Moderators and Covariate Adjustments These full data sets will be used for sensitivity analyses and adjusted models, but we also want to set up our data for unadjusted models and moderator tests. For robusteness, we are using a few different sets of theoretically plausible covariates. The goal is to ensure that the pattern of results is not greatly impacted by the inclusion of different covariates. Not knowing the answer to this can be a threat to good science. mod_setup_fun &lt;- function(d, trait, outcome){ crossing(Covariates = c(&quot;fully&quot;, &quot;shared&quot;, &quot;standard&quot;, &quot;butOne&quot;, &quot;unadjusted&quot;, &quot;shareddx&quot;, &quot;standarddx&quot;) , Moderator = c(&quot;none&quot;, &quot;education&quot;, &quot;age&quot;, &quot;gender&quot;, &quot;cognition&quot;, &quot;dementia&quot;)) %&gt;% mutate(data = list(d)) %&gt;% mutate(data = pmap(list(data, trait, outcome, Moderator, Covariates), mod_save_fun)) return(NULL) } mod_save_fun &lt;- function(d, trait, outcome, mod, cov){ covs &lt;- if(cov == &quot;unadjusted&quot;){ mod } else if (cov %in% c(&quot;shared&quot;, &quot;shareddx&quot;)){ c(mod, &quot;age&quot;, &quot;gender&quot;, &quot;education&quot;, &quot;smokes&quot;, &quot;alcohol&quot;) } else if (cov %in% c(&quot;standard&quot;, &quot;standarddx&quot;)){ c(mod, &quot;age&quot;, &quot;gender&quot;, &quot;education&quot;) } else if(cov == &quot;butOne&quot;){ c(mod, &quot;age&quot;, &quot;gender&quot;, &quot;education&quot;, &quot;smokes&quot;, &quot;alcohol&quot;, &quot;cognition&quot;, &quot;CC&quot;) } else{ colnames(d) } if(grepl(&quot;dx&quot;, cov)) covs &lt;- c(covs, &quot;dementia&quot;) d2 &lt;- d %&gt;% select(study, SID, p_year, p_value, o_year, o_value, one_of(covs)) %&gt;% filter(complete.cases(.)) d2 &lt;- if(cov == &quot;unadjusted&quot;){ d %&gt;% select(study, SID, p_year, p_value, o_year, o_value, one_of(mod)) %&gt;% filter(complete.cases(.)) } else if (cov == &quot;shared&quot;){ d %&gt;% select(study, SID, p_year, p_value, o_year, o_value, one_of(mod), age, gender, education, smokes, alcohol) %&gt;% filter(complete.cases(.)) } else if (cov == &quot;standard&quot;){ d %&gt;% select(study, SID, p_year, p_value, o_year, o_value, one_of(mod), age, gender, education) %&gt;% filter(complete.cases(.)) } else if (cov == &quot;butOne&quot;) { d %&gt;% select(study, SID, p_year, p_value, o_year, o_value, one_of(mod), age, gender, education, smokes, alcohol, cognition, CC) %&gt;% filter(complete.cases(.)) } else { d %&gt;% filter(complete.cases(.)) } # if(mod != &quot;none&quot;) colnames(d2)[colnames(d2) == mod] &lt;- &quot;modvalue&quot; save(d2, file = sprintf(&quot;%s/data/mega-analysis/%s/%s-%s-%s.RData&quot; , local_path, cov, trait, outcome, mod)) return(NULL) } nested_data %&gt;% # filter(Outcome != &quot;dementia&quot;) %&gt;% mutate(data = pmap(list(data, Trait, Outcome), mod_setup_fun)) Here’s one example: load(&quot;/Volumes/Emorie/projects/dementia/prediction/data/mega-analysis/shared/A-angiopathy-gender.RData&quot;) d2 ## # A tibble: 817 × 11 ## study SID p_year p_value o_year o_value gender age education smokes alcohol ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; ## 1 ROS 00021073 0 4.29 2 3 0 20.0 10 0 0 ## 2 ROS 10100312 0 6.07 13 2 1 15.3 8 0 1 ## 3 ROS 10100448 0 5 15 0 1 12.4 11 1 1 ## 4 ROS 10100574 0 5.71 9 1 1 13.7 9 0 1 ## 5 ROS 10100736 0 6.07 9 0 1 20.8 2 1 1 ## 6 ROS 10101039 0 5.71 8 1 1 23.4 7 1 1 ## 7 ROS 10101291 0 4.29 1 0 1 21.5 3 1 0 ## 8 ROS 10101327 0 3.57 2 1 1 26.9 9 1 0 ## 9 ROS 10101589 0 6.07 6 1 1 42.1 8 0 0 ## 10 ROS 10101741 0 5 12 1 1 23.3 -2 0 0 ## # … with 807 more rows 3.3 Part 3: Models For these first models, we’ll be testing three sets of covariates. For a full test of how covariates impact our inferences, we’ll then follow up in a later step doing a specification curve / multiverse analysis. For these first models, we will run a series of Bayesian regressions. For binary outcomes, these will be multilevel logistic regressions, while for the others, these will be “regular” multilevel linear regressions. For each of these, we will also test age, gender, and education, and cognitive functioning as moderators. 3.3.1 Functions 3.3.1.1 Model Function ipd_mega_mod_fun &lt;- function(trait, outcome, mod, cov){ ## load the data load(sprintf(&quot;%s/data/mega-analysis/%s/%s-%s-%s.RData&quot;, local_path, cov, trait, outcome, mod)) ## compiled Bayesian model to speed up processing and avoid crashing if(outcome %in% c(&quot;dementia&quot;, &quot;hipSclerosis&quot;, &quot;lewyBodyDis&quot;, &quot;tdp43&quot;, &quot;vsclrInfrcts&quot;, &quot;vsclrMcrInfrcts&quot;)) load(sprintf(&quot;%s/results/bayes_sample_mod_binomial.RData&quot;, local_path)) else load(sprintf(&quot;%s/results/bayes_sample_mod_continuous.RData&quot;, local_path)) ## formula cv &lt;- c(&quot;age&quot;, &quot;gender&quot;, &quot;education&quot;, &quot;smokes&quot;, &quot;alcohol&quot;) #if (cov == &quot;shared&quot;) cv &lt;- cv if (cov == &quot;butOne&quot;) cv &lt;- c(cv, &quot;CC&quot;, &quot;cognition&quot;) if (cov == &quot;fully&quot;) cv &lt;- c(cv, &quot;CC&quot;, &quot;cognition&quot;, &quot;BMI&quot;, &quot;race&quot;, &quot;SRhealth&quot;) if (grepl(&quot;standard&quot;, cov)) cv &lt;- c(&quot;age&quot;, &quot;gender&quot;, &quot;education&quot;) if(grepl(&quot;dx&quot;, cov)) cv &lt;- c(cv, &quot;dementia&quot;) rhs &lt;- &quot;p_value&quot; rhs &lt;- if(cov != &quot;unadjusted&quot;) c(rhs, cv) else rhs if(mod != &quot;none&quot;) rhs &lt;- c(rhs, paste(&quot;p_value&quot;, mod, sep = &quot;*&quot;)) re &lt;- if(mod == &quot;none&quot;) &quot;(p_value | study)&quot; else paste(paste(&quot;(p_value&quot;, mod, sep = &quot; * &quot;), &quot;| study)&quot;) rhs &lt;- paste(c(rhs, re), collapse = &quot; + &quot;) f &lt;- paste(&quot;o_value ~ &quot;, rhs, collapse = &quot;&quot;) ## run the models &amp; save m &lt;- update(m , formula = f , newdata = d2 , iter = 2000 , warmup = 1000 , cores = 12 , threads = threading(3) , backend = &quot;cmdstanr&quot; , chains = 4 ) save(m, file = sprintf(&quot;%s/results/models/%s/%s_%s_%s.RData&quot; , local_path, cov, outcome, trait, mod)) ## extract model terms and confidence intervals &amp; save fx &lt;- tidy(m, conf.int = T) %&gt;% select(term, estimate, conf.low, conf.high) rx &lt;- std_eff_fun(m) save(fx, rx, file = sprintf(&quot;%s/results/summary/%s/%s_%s_%s.RData&quot; , local_path, cov, outcome, trait, mod)) ## extract heterogeneity estimates het &lt;- hetero_fun(m) save(het, file = sprintf(&quot;%s/results/heterogeneity/%s/%s_%s_%s.RData&quot; , local_path, cov, outcome, trait, mod)) if(mod != &quot;none&quot;){ # load(sprintf(&quot;%s/results/models/%s/%s_%s_%s.RData&quot;, local_path, cov, outcome, trait, mod)) pred.fx &lt;- fx_pred_fun(m, mod) pred.rx &lt;- rx_pred_fun(m, mod) save(pred.fx, pred.rx, file = sprintf(&quot;%s/results/predicted/%s/%s_%s_%s.RData&quot; , local_path, cov, outcome, trait, mod)) # rm(list = c(&quot;pred.fx&quot;, &quot;pred.rx&quot;, &quot;m&quot;)) # gc() # return(T) } ## clean up the local function environment rm(list = c(&quot;d&quot;, &quot;f&quot;, &quot;rhs&quot;, &quot;m&quot;, &quot;fx&quot;, &quot;rx&quot;, &quot;het&quot;)) gc() } 3.3.1.2 Study-Specific Effects Function As noted previously, once we run the model, we will have to use a second step to get the study-specific estimates for all studies. Unlike with dummy codes, doing so is much more straightforward. We just have to pull study-specific effects using the coef() for both Bayesian and Frequentist approaches. std_eff_fun &lt;- function(m){ coef(m, probs = c(0.025, 0.975))[[1]] %&gt;% array_tree(3) %&gt;% tibble(names = names(.), data = .) %&gt;% mutate(data = map(data, ~(.) %&gt;% data.frame %&gt;% rownames_to_column(&quot;study&quot;))) %&gt;% unnest(data) %&gt;% select(names, study, estimate = Estimate, conf.low = Q2.5, conf.high = Q97.5) } 3.3.1.3 Heterogeneity Estimates Function The Final pieces of information we need to extract from these models are estimates of the heterogeneity of effects across studies. hetero_fun &lt;- function(m){ args &lt;- list(x = m, effects = &quot;ran_pars&quot;, conf.int = T) do.call(tidy, args) %&gt;% select(group, term, estimate, conf.low, conf.high) %&gt;% separate(term, c(&quot;est&quot;, &quot;term&quot;), sep = &quot;__&quot;) %&gt;% mutate_at(vars(estimate:conf.high), ~ifelse(est == &quot;sd&quot;, .^2, .)) %&gt;% mutate(est = ifelse(est == &quot;sd&quot;, &quot;var&quot;, est)) } 3.3.1.4 Simple Effects Function 3.3.1.4.1 Fixed Effects fx_pred_fun &lt;-function(m, moder){ d &lt;- m$data d &lt;- d %&gt;% select(-o_value, -p_value, -study) cols &lt;- colnames(d) md_cl &lt;- class(d[,moder]) if(any(sapply(d, class) == &quot;numeric&quot;)){ msd &lt;- d %&gt;% select_if(is.numeric) %&gt;% pivot_longer(everything() , names_to = &quot;item&quot; , values_to = &quot;value&quot;) %&gt;% group_by(item) %&gt;% summarize_at(vars(value), lst(mean, sd)) %&gt;% ungroup() } if(any(sapply(d, class) == &quot;factor&quot;)){ fct_lev &lt;- d %&gt;% select_if(is.factor) %&gt;% summarize_all(~list(levels(.))) } d &lt;- d %&gt;% select(-one_of(moder)) md_levs &lt;- if(md_cl == &quot;numeric&quot;){ if(moder %in% c(&quot;age&quot;)) { c(-10, 0, 10) } else if (moder %in% c(&quot;education&quot;)) { c(-5, 0, 5) } else { with(msd, c(mean[item == moder] - sd[item == moder], mean[item == moder], mean[item == moder] + sd[item == moder])) } } else { sort(unique(fct_lev[,moder][[1]])) } md_fac &lt;- if(moder == &quot;age&quot;) c(&quot;-10 yrs&quot;, &quot;60&quot;, &quot;+10 yrs&quot;) else if (moder == &quot;education&quot;) c(&quot;-5 yrs&quot;, &quot;12 years&quot;, &quot;+5 yrs&quot;) else if(moder == &quot;gender&quot;) c(&quot;Male&quot;, &quot;Female&quot;) else if(moder == &quot;dementia&quot;) c(&quot;No&quot;, &quot;Yes&quot;) else c(&quot;-1 SD&quot;, &quot;M&quot;, &quot;+1 SD&quot;) mod_frame &lt;- expand.grid( p_value = seq(0,10,.1) , modvalue = md_levs , stringsAsFactors = F ) %&gt;% mutate(mod_fac = factor(modvalue, levels = unique(modvalue), labels = md_fac)) %&gt;% setNames(c(&quot;p_value&quot;, moder, &quot;mod_fac&quot;)) if(ncol(d) &gt; 0){ if(any(sapply(d, class) == &quot;numeric&quot;)){ mod_frame &lt;- tibble(mod_frame, d %&gt;% select_if(is.numeric) %&gt;% summarize_all(mean)) } if(any(sapply(d, class) == &quot;factor&quot;)){ fcts &lt;- colnames(d)[sapply(d, class) == &quot;factor&quot;] for(i in 1:length(fcts)){ fct &lt;- fcts[i] mod_frame &lt;- crossing( mod_frame , levels(d[,fct]) ) %&gt;% setNames(c(colnames(mod_frame), fct)) } } } pred.fx &lt;- bind_cols( mod_frame, fitted(m , newdata = mod_frame , re_formula = NA) %&gt;% data.frame ) %&gt;% select(one_of(colnames(m$data)), mod_fac, pred = Estimate, lower = Q2.5, upper = Q97.5) %&gt;% group_by(p_value, mod_fac) %&gt;% summarize_at(vars(pred, lower, upper), mean) %&gt;% ungroup() rm(list = c(&quot;m&quot;, &quot;mod_frame&quot;, &quot;d&quot;, &quot;md_levs&quot;)) gc() return(pred.fx) } 3.3.1.4.2 Study-Specific Effects rx_pred_fun &lt;- function(m, moder){ d &lt;- m$data d &lt;- d %&gt;% select(-o_value, -p_value) cols &lt;- colnames(d) md_cl &lt;- class(d[,moder]) if(any(sapply(d, class) == &quot;numeric&quot;)){ msd &lt;- d %&gt;% group_by(study) %&gt;% select_if(is.numeric) %&gt;% pivot_longer(-study , names_to = &quot;item&quot; , values_to = &quot;value&quot;) %&gt;% group_by(study, item) %&gt;% summarize_at(vars(value), lst(mean, sd), na.rm = T) %&gt;% ungroup() } if(any(sapply(d, class) == &quot;factor&quot;)){ fct_lev &lt;- d %&gt;% group_by(study) %&gt;% select_if(is.factor) %&gt;% summarize_all(~list((levels(.)))) %&gt;% ungroup() } d &lt;- d %&gt;% select(-one_of(moder)) md_fac &lt;- if(moder == &quot;age&quot;) c(&quot;-10 yrs&quot;, &quot;60&quot;, &quot;+10 yrs&quot;) else if (moder == &quot;education&quot;) c(&quot;-5 yrs&quot;, &quot;12 years&quot;, &quot;+5 yrs&quot;) else if(moder == &quot;gender&quot;) c(&quot;Male&quot;, &quot;Female&quot;) else if(moder == &quot;dementia&quot;) c(&quot;No&quot;, &quot;Yes&quot;) else c(&quot;-1 SD&quot;, &quot;M&quot;, &quot;+1 SD&quot;) md_levs &lt;- if(moder != &quot;cognition&quot;){ crossing( study = unique(d$study) , modvalue = if(moder == &quot;age&quot;) c(-10, 0, 10) else if (moder == &quot;education&quot;) c(-5,0,5) else c(0,1) ) %&gt;% mutate(mod_fac = factor(modvalue, levels = unique(modvalue), labels = md_fac)) %&gt;% setNames(c(&quot;study&quot;, moder, &quot;mod_fac&quot;)) } else { msd %&gt;% filter(item == moder) %&gt;% mutate(lower = mean - sd, upper = mean + sd) %&gt;% select(-sd) %&gt;% pivot_longer(cols = c(mean, lower, upper) , names_to = &quot;meas&quot; , values_to = &quot;modvalue&quot;) %&gt;% pivot_wider(names_from = &quot;item&quot;, values_from = &quot;modvalue&quot;) %&gt;% select(study, one_of(moder)) %&gt;% setNames(c(&quot;study&quot;, &quot;modvalue&quot;)) %&gt;% group_by(study) %&gt;% mutate(mod_fac = factor(modvalue, levels = unique(modvalue), labels = md_fac)) %&gt;% ungroup() %&gt;% setNames(c(&quot;study&quot;, moder, &quot;mod_fac&quot;)) } mod_frame &lt;- crossing( p_value = seq(0,10,.1) , md_levs ) if(ncol(d) &gt; 0){ if(any(sapply(d, class) == &quot;numeric&quot;)){ mod_frame &lt;- d %&gt;% group_by(study) %&gt;% select_if(is.numeric) %&gt;% summarize_all(mean, na.rm = T) %&gt;% ungroup() %&gt;% full_join(mod_frame) } if(any(sapply(d, class) == &quot;factor&quot;)){ fcts &lt;- colnames(d)[sapply(d, class) == &quot;factor&quot;] for(i in 1:length(fcts)){ fct &lt;- fcts[i] mod_frame &lt;- crossing( mod_frame , levels(d[,fct]) ) %&gt;% setNames(c(colnames(mod_frame), fct)) } } } pred.rx &lt;- bind_cols( mod_frame, fitted(m , newdata = mod_frame) %&gt;% data.frame ) %&gt;% select(one_of(colnames(m$data)), mod_fac, pred = Estimate, lower = Q2.5, upper = Q97.5) %&gt;% group_by(p_value, mod_fac, study) %&gt;% summarize_at(vars(pred, lower, upper), mean) %&gt;% ungroup() rm(list = c(&quot;m&quot;, &quot;mod_frame&quot;, &quot;d&quot;)) gc() return(pred.rx) } 3.3.2 Run Models and Summaries 3.3.2.1 Sample Bayesian Models Before we actually run the models, we will estimate two models on smaller subsets of data. The advantage to this is that it prevents the rstan model from having to recompile the model, which speeds up runtime and prevents random crashes. It’s going to fit badly. That’s fine. It was given almost no data. # Sample Bayesian Model # load data load(sprintf(&quot;%s/data/mega-analysis/shared/N-dementia-none.RData&quot;, local_path)) # load(&quot;data/mega-analysis/shared/N-dementia-none.RData&quot;) # clean data &amp; keep only needed columns and a subset of the used variables d &lt;- d2 %&gt;% group_by(study) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% filter(row_number() %in% sample(1:nrow(.), 100, replace = F)))) %&gt;% unnest(data) # set priors &amp; model specifications Prior &lt;- c(set_prior(&quot;cauchy(0,1)&quot;, class = &quot;sd&quot;), set_prior(&quot;student_t(3, 0, 2)&quot;, class = &quot;b&quot;), set_prior(&quot;student_t(3, 0, 5)&quot;, class = &quot;Intercept&quot;)) Iter &lt;- 30; Warmup &lt;- 21; treedepth &lt;- 20 f &lt;- formula(o_value ~ p_value + age + gender + p_value*education + (p_value*education | study)) m &lt;- brm(formula = f , data = d , family = bernoulli(link = &quot;logit&quot;) , prior = Prior , iter = Iter , warmup = Warmup , cores = 12 , threads = threading(3) , backend = &quot;cmdstanr&quot; , chains = 4) save(m, file = sprintf(&quot;%s/results/bayes_sample_mod_binomial.RData&quot;, local_path)) # save(m, file = &quot;results/bayes_sample_mod_binomial.RData&quot;) load(sprintf(&quot;%s/data/mega-analysis/shared/N-braak-none.RData&quot;, local_path)) # load(&quot;data/mega-analysis/shared/N-braak-none.RData&quot;) # clean data &amp; keep only needed columns and a subset of the used variables d &lt;- d2 %&gt;% group_by(study) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% filter(row_number() %in% sample(1:nrow(.), 100, replace = T)))) %&gt;% unnest(data) # set priors &amp; model specifications Prior &lt;- c(set_prior(&quot;cauchy(0,1)&quot;, class = &quot;sd&quot;), set_prior(&quot;student_t(3, 0, 2)&quot;, class = &quot;b&quot;), set_prior(&quot;student_t(3, 0, 5)&quot;, class = &quot;Intercept&quot;)) Iter &lt;- 30; Warmup &lt;- 21; treedepth &lt;- 20 f &lt;- formula(o_value ~ p_value + age + gender + p_value*education + (p_value*education | study)) m &lt;- brm(formula = f , data = d , prior = Prior , iter = Iter , warmup = Warmup , cores = 12 , threads = threading(3) , backend = &quot;cmdstanr&quot; , chains = 4) save(m, file = sprintf(&quot;%s/results/bayes_sample_mod_continuous.RData&quot;, local_path)) # save(m, file = &quot;results/bayes_sample_mod_continuous.RData&quot;) rm(list = c(&quot;d&quot;, &quot;Prior&quot;, &quot;Iter&quot;, &quot;Warmup&quot;, &quot;treedepth&quot;, &quot;f&quot;, &quot;m&quot;)) 3.3.2.1.1 Binary load(sprintf(&quot;%s/results/bayes_sample_mod_binomial.RData&quot;, local_path)) m ## Family: bernoulli ## Links: mu = logit ## Formula: o_value ~ p_value + age + gender + p_value * education + (p_value * education | study) ## Data: d (Number of observations: 800) ## Draws: 4 chains, each with iter = 30; warmup = 21; thin = 1; ## total post-warmup draws = 36 ## ## Group-Level Effects: ## ~study (Number of levels: 8) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 1.23 0.82 0.06 2.96 1.20 16 16 ## sd(p_value) 0.20 0.14 0.01 0.46 1.12 16 16 ## sd(education) 0.09 0.08 0.00 0.21 1.02 16 16 ## sd(p_value:education) 0.01 0.01 0.00 0.05 1.22 16 16 ## cor(Intercept,p_value) 0.03 0.39 -0.67 0.76 1.14 16 16 ## cor(Intercept,education) -0.22 0.39 -0.78 0.47 1.18 16 16 ## cor(p_value,education) -0.00 0.55 -0.85 0.77 1.02 16 16 ## cor(Intercept,p_value:education) 0.02 0.44 -0.85 0.65 1.06 16 16 ## cor(p_value,p_value:education) 0.03 0.47 -0.83 0.70 1.07 16 16 ## cor(education,p_value:education) -0.13 0.48 -0.77 0.79 1.12 16 16 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept -4.69 1.21 -7.47 -3.24 1.13 16 16 ## p_value 0.23 0.14 -0.10 0.49 1.02 16 16 ## age 0.08 0.02 0.05 0.10 1.12 16 16 ## gender1 0.02 0.29 -0.49 0.43 1.13 16 16 ## education 0.06 0.11 -0.10 0.30 1.05 16 16 ## p_value:education -0.02 0.02 -0.06 0.01 1.02 16 16 ## ## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). 3.3.2.1.2 Continuous load(sprintf(&quot;%s/results/bayes_sample_mod_continuous.RData&quot;, local_path)) 3.3.2.2 Run the Models # done &lt;- tibble(Covariate = c(&quot;fully&quot;, &quot;shared&quot;, &quot;butOne&quot;, &quot;unadjusted&quot;, &quot;standard&quot;, &quot;standarddx&quot;, &quot;shareddx&quot;), # file = map(Covariate, ~list.files(sprintf(&quot;%s/results/models/%s&quot;, local_path, .)))) %&gt;% # unnest(file) %&gt;% # separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;), sep = &quot;_&quot;) %&gt;% # mutate(Moderator = str_remove_all(Moderator, &quot;.RData&quot;) # , done = &quot;done&quot;) %&gt;% # filter(!is.na(Moderator)) # plan(multisession(workers = 4L)) nested_ipd_mega &lt;- crossing( Trait = traits$short_name , Outcome = outcomes$short_name , Moderator = c(&quot;education&quot;, &quot;age&quot;, &quot;gender&quot;, &quot;cognition&quot;, &quot;dementia&quot;) , Covariate = c(&quot;fully&quot;, &quot;shared&quot;, &quot;butOne&quot;, &quot;standard&quot;, &quot;unadjusted&quot;, &quot;standarddx&quot;, &quot;shareddx&quot;) ) %&gt;% full_join( crossing( Trait = traits$short_name , Outcome = outcomes$short_name , Moderator = &quot;none&quot; , Covariate = c(&quot;fully&quot;, &quot;shared&quot;, &quot;butOne&quot;, &quot;standard&quot;, &quot;unadjusted&quot;, &quot;standarddx&quot;, &quot;shareddx&quot;) ) ) %&gt;% full_join(done) %&gt;% filter(is.na(done)) %&gt;% # mutate(run = future_pmap( mutate(run = pmap( list(Trait, Outcome, Moderator, Covariate) , possibly(ipd_mega_mod_fun, NA_real_) # , .options = furrr_options( # globals = c(&quot;traits&quot;, &quot;moders&quot;, &quot;covars&quot;, &quot;outcomes&quot; # , &quot;hetero_fun&quot; # , &quot;rx_pred_fun&quot; # , &quot;std_eff_fun&quot; # , &quot;fx_pred_fun&quot; # , &quot;local_path&quot;) # , packages = c(&quot;broom&quot;, &quot;broom.mixed&quot;, &quot;tidyverse&quot;, &quot;brms&quot;) # ) # , .progress = T )) # nested_ipd_mega %&gt;% # mutate(Covariate = factor(Covariate) # , Covariate = relevel(Covariate, &quot;shared&quot;) # # , Moderator = factor(Moderator, levels = moders$short_name) # , Moderator = relevel(factor(Moderator), &quot;dementia&quot;) # ) %&gt;% # arrange(Covariate, Outcome, Moderator, Trait) %&gt;% # filter(Covariate != &quot;fully&quot;) %&gt;% # select(Trait, Outcome, Moderator, Covariate) %&gt;% # write.table(. # , file = sprintf(&quot;%s/scripts/cluster/args/args.txt&quot;, local_path) # , row.names = F) 3.4 Compile Results Once all the models are run, we are ready to compile all their results. By saving the fixed and study-level effects results previously, we are able to simply load those results and ignore the models. However, because we also saved the models, we can also recall and extract information from them if and when needed. I cannot share the models because the data are stored inside them. Instead, I share posterior samples and will share models with the data slot removed upon request (please email Emorie Beck). We mostly don’t need the models here. The only thing I’ll pull from them are exact sample sizes. loadRData &lt;- function(fileName, cov, obj, folder){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/results/%s/%s/%s&quot;, local_path, folder, cov, fileName) load(path) get(ls()[grepl(obj, ls())]) } n_fun &lt;- function(fileName, type){ m &lt;- loadRData(fileName, type, &quot;^m&quot;, &quot;models&quot;) d &lt;- m$data n &lt;- d %&gt;% group_by(study) %&gt;% tally() %&gt;% ungroup() return(n) } ## load in &quot;fixed&quot; effects ## first get file names nested_mega &lt;- tibble(Covariate = c(&quot;fully&quot;, &quot;shared&quot;, &quot;standard&quot;, &quot;butOne&quot;, &quot;unadjusted&quot;, &quot;standarddx&quot;, &quot;shareddx&quot;)) %&gt;% mutate(file = map(Covariate, ~list.files(sprintf(&quot;%s/results/summary/%s&quot;, local_path, .)))) %&gt;% unnest(file) %&gt;% separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;), sep = &quot;_&quot;, remove = F) %&gt;% ## read in the files mutate(Moderator = str_remove(Moderator, &quot;.RData&quot;), fx = map2(file, Covariate, ~loadRData(.x, .y, &quot;fx&quot;, &quot;summary&quot;)), rx = map2(file, Covariate, possibly(~loadRData(.x, .y, &quot;rx&quot;, &quot;summary&quot;), NA_real_)), n = map2(file, Covariate, n_fun)) %&gt;% select(-file) %&gt;% filter(!is.na(rx)) 3.4.1 Tables Next, we want to format the study results in APA table format. In this case, we are interested in the fixed and study-specific effects of personality predicting cognitive ability when there were no moderators, and the personality x moderator interaction when there was a moderator. We’ll anticipate a need to present both just fixed effects as well as fixed and study-specific effects by creating tables for each. First, let’s format the data. nested_mega_tab &lt;- ### fixed effects nested_mega %&gt;% select(-rx, -n) %&gt;% unnest(fx) %&gt;% # unnesting # keep key terms filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;) | (Moderator != &quot;none&quot; &amp; grepl(&quot;p_value:&quot;, term)) &amp; !grepl(&quot;cor&quot;, term) &amp; !grepl(&quot;sd&quot;, term)) %&gt;% mutate(study = &quot;Overall&quot;) %&gt;% ### study specific effects full_join( nested_mega %&gt;% select(-fx, -n) %&gt;% unnest(rx) %&gt;% # unnesting rename(term = names) %&gt;% filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;) | (Moderator != &quot;none&quot; &amp; grepl(&quot;p_value:&quot;, term))) ) %&gt;% left_join( outcomes %&gt;% select(Outcome = short_name, link) ) %&gt;% # reformatting: mark significance, prettify Trait, covariate, and moderator names mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;), Trait = factor(Trait, traits$short_name), Outcome = factor(Outcome, outcomes$short_name, outcomes$long_name), Moderator = factor(Moderator, moders$short_name, moders$long_name), Covariate = factor(Covariate, covars$short_name, str_wrap(covars$long_name, 15)), term = str_remove_all(term, &quot;p_value:&quot;), term = factor(term, moders$short_term, moders$long_term)) %&gt;% mutate_at(vars(estimate, conf.low, conf.high), ~ifelse(link == &quot;factor&quot;, exp(.), .)) %&gt;% # prettify the number format mutate_at(vars(estimate, conf.low, conf.high), ~ifelse(abs(.) &lt; .0014, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))) %&gt;% # combine the effects, bold significance, factor and label study-specfic effects mutate(est = sprintf(&quot;%s&lt;br&gt;[%s, %s]&quot;, estimate, conf.low, conf.high), est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;&lt;strong&gt;%s&lt;/strong&gt;&quot;, est), est), study = mapvalues(study, c(&quot;RADC-MAP&quot;, &quot;ADRC&quot;), c(&quot;Rush-MAP&quot;, &quot;WUSM-MAP&quot;)), study = factor(study, levels = c(studies_long, &quot;Overall&quot;), labels = c(studies_long, &quot;Overall&quot;))) %&gt;% # reshaping: remove extra columns, arrange by key variables, and make wide select(Outcome, Trait, Moderator, Covariate, study, term, est) %&gt;% arrange(Outcome, Trait, Moderator, Covariate, study, term, est) %&gt;% pivot_wider(names_from = &quot;Outcome&quot;, values_from = &quot;est&quot;) nested_mega_tab ## # A tibble: 1,521 × 16 ## Trait Moderator Covariate study term Incident …¹ Braak…² CERAD Lewy …³ Gross…⁴ Gross…⁵ Cereb…⁶ Cereb…⁷ Arter…⁸ Hippo…⁹ TDP-4…˟ ## &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 E None Unadjusted ROS Personality 0.95&lt;br&gt;[0… 0.04&lt;b… -0.0… 1.04&lt;b… &lt;stron… 0.95&lt;b… -0.00&lt;… 0.01&lt;b… -0.01&lt;… 0.96&lt;b… 1.01&lt;b… ## 2 E None Unadjusted Rush-MAP Personality 0.95&lt;br&gt;[0… 0.02&lt;b… &lt;str… 0.99&lt;b… 0.95&lt;b… 0.98&lt;b… -0.02&lt;… 0.01&lt;b… -0.01&lt;… 0.99&lt;b… 1.04&lt;b… ## 3 E None Unadjusted EAS Personality 0.93&lt;br&gt;[0… 0.001&lt;… &lt;NA&gt; 0.99&lt;b… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 0.99&lt;b… &lt;NA&gt; ## 4 E None Unadjusted WUSM-MAP Personality &lt;strong&gt;0.… &lt;stron… -0.0… 1.04&lt;b… &lt;NA&gt; 0.96&lt;b… 0.01&lt;b… -0.01&lt;… -0.01&lt;… 0.92&lt;b… 0.94&lt;b… ## 5 E None Unadjusted SATSA Personality 0.93&lt;br&gt;[0… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 6 E None Unadjusted HRS Personality &lt;strong&gt;0.… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 7 E None Unadjusted LISS Personality 0.91&lt;br&gt;[0… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 8 E None Unadjusted GSOEP Personality &lt;strong&gt;0.… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 9 E None Unadjusted Overall Personality 0.93&lt;br&gt;[0… -0.01&lt;… -0.0… 1.02&lt;b… 0.95&lt;b… 0.96&lt;b… -0.01&lt;… 0.02&lt;b… -0.01&lt;… 0.97&lt;b… 1.00&lt;b… ## 10 E None Fully Adjusted EAS Personality 0.83&lt;br&gt;[0… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## # … with 1,511 more rows, and abbreviated variable names ¹​`Incident Dementia Diagnosis`, ²​`Braak Stage`, ³​`Lewy Body Disease`, ## # ⁴​`Gross Cerebral Infarcts`, ⁵​`Gross Cerebral Microinfarcts`, ⁶​`Cerebral Atherosclerosis`, ⁷​`Cerebral Amyloid Angiopathy`, ## # ⁸​Arteriolosclerosis, ⁹​`Hippocampal Sclerosis`, ˟​`TDP-43` Now that we’ve formatted the values, we can group by moderators and save results as separate tables. Even though additional information could be included given that we have one outcome, we’ll stick with this split because it will make it easier for those using this tutorial who multiple traits, outcomes, covariates, and moderators. 3.4.1.1 Fixed Effects First, here’s the overall estimates and credible intervals, split by moderators. These show the estimates across all different covariate sets. ## table function ipd_tab_fun &lt;- function(d, moder){ md &lt;- mapvalues(moder, moders$long_name, moders$short_name, warn_missing = F) rs &lt;- d %&gt;% mutate(Trait = factor(Trait, traits$short_name, traits$long_name)) %&gt;% group_by(Trait) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) cs &lt;- rep(1,12) names(cs) &lt;- c(&quot; &quot;, paste0(&quot;&lt;strong&gt;&quot;, outcomes$long_name, &quot;&lt;/strong&gt;&quot;)) cln &lt;- mapvalues(colnames(d)[colnames(d) %in% outcomes$long_name], outcomes$long_name, outcomes$colnm, warn_missing = F) cln &lt;- c(&quot;Covariates&quot;, cln) # cln &lt;- if(length(unique(d$term)) == 1) c(&quot;Covariates&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 9)) else c(&quot;Covariates&quot;, &quot;Term&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 9)) al &lt;- c(&quot;r&quot;, rep(&quot;c&quot;, 11)) d &lt;- d %&gt;% select(-term) fn &lt;- paste(covars$desc, collapse = &quot; &quot;) cap &lt;- if(md == &quot;none&quot;) &quot;&lt;strong&gt;Table X&lt;/strong&gt;&lt;br&gt;&lt;em&gt;Overall Effects of Personality-Dementia Diagnosis and Neuropathology Associations&lt;/em&gt;&quot; else sprintf(&quot;&lt;strong&gt;Table X&lt;/strong&gt;&lt;br&gt;&lt;em&gt;Overall %s Moderation of Personality-Dementia Diagnosis and Neuropathology Associations&lt;/em&gt;&quot;, md) tab &lt;- d %&gt;% arrange(Trait) %&gt;% select(-Trait) %&gt;% kable(., &quot;html&quot; # kable(., &quot;latex&quot; , booktabs = T , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% add_header_above(cs, escape = F) %&gt;% footnote(fn) for (i in 1:nrow(rs)) { tab &lt;- tab %&gt;% kableExtra::group_rows(rs$Trait[i], rs$start[i], rs$end[i]) } save_kable(tab, file = sprintf(&quot;%s/results/tables/overall/%s.html&quot; , local_path, md)) return(tab) } ipd_fx_tab &lt;- nested_mega_tab %&gt;% filter(study == &quot;Overall&quot;) %&gt;% select(-study) %&gt;% group_by(Moderator) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, Moderator), ipd_tab_fun)) # save(ipd2b_reg_tab, ipd2b_res, file = sprintf(&quot;%s/manuscript/results/ipd2b_fx_tab.RData&quot;, res_path)) (ipd_fx_tab %&gt;% filter(Moderator == &quot;None&quot;))$tab[[1]] Table 3.1: Table XOverall Effects of Personality-Dementia Diagnosis and Neuropathology Associations Incident Dementia Diagnosis Braak Stage CERAD Lewy Body Disease Gross Cerebral Infarcts Gross Cerebral Microinfarcts Cerebral Atherosclerosis Cerebral Amyloid Angiopathy Arteriolosclerosis Hippocampal Sclerosis TDP-43 Covariates OR [CI] b [CI] b [CI] OR [CI] OR [CI] OR [CI] b [CI] b [CI] b [CI] OR [CI] OR [CI] Extraversion Unadjusted 0.93[0.87, 1.00] -0.01[-0.14, 0.13] -0.03[-0.11, 0.05] 1.02[0.90, 1.15] 0.95[0.79, 1.26] 0.96[0.84, 1.14] -0.01[-0.08, 0.05] 0.02[-0.05, 0.15] -0.01[-0.08, 0.05] 0.97[0.83, 1.11] 1.00[0.82, 1.17] Fully Adjusted 1.00[0.58, 1.86] Shared Covariates Adjusted 0.97[0.93, 1.02] -0.000[-0.13, 0.14] -0.04[-0.10, 0.05] 1.01[0.88, 1.12] 0.95[0.76, 1.34] 0.97[0.83, 1.13] 0.00[-0.06, 0.08] 0.02[-0.04, 0.07] -0.01[-0.08, 0.07] 0.97[0.83, 1.10] 1.01[0.80, 1.18] Standard Covariates Adjusted 0.97[0.93, 1.02] 1.05[0.68, 2.07] 0.98[0.80, 1.20] All But One Covariate Adjusted 0.99[0.93, 1.05] -0.01[-0.16, 0.13] -0.03[-0.14, 0.05] 1.00[0.82, 1.12] 0.97[0.72, 1.33] 0.97[0.82, 1.22] 0.00[-0.05, 0.06] 0.02[-0.07, 0.12] -0.01[-0.06, 0.03] 0.96[0.74, 1.14] 1.02[0.85, 1.22] Shared Covariates Adjusted (With Dementia Diagnosis) -0.10[-1.08, 0.78] 1.02[0.18, 7.57] 1.24[0.35, 7.66] Standard Covariates Adjusted (With Dementia Diagnosis) -0.13[-1.13, 1.39] 1.00[0.19, 6.68] 1.42[0.33, 6.43] Agreeableness Unadjusted 1.00[0.92, 1.11] 0.000[-0.15, 0.21] -0.01[-0.20, 0.21] 1.04[0.75, 1.75] 0.91[0.32, 2.14] 1.03[0.73, 1.46] -0.02[-0.36, 0.33] 0.01[-0.16, 0.19] 0.000[-0.17, 0.19] 1.00[0.68, 1.48] 0.97[0.68, 1.36] Fully Adjusted 1.04[0.73, 1.55] Shared Covariates Adjusted 0.97[0.92, 1.03] -0.02[-0.15, 0.10] -0.02[-0.30, 0.15] 0.99[0.83, 1.23] 1.08[0.40, 2.48] 1.07[0.77, 1.52] -0.02[-0.19, 0.16] 0.02[-0.21, 0.25] 0.02[-0.19, 0.30] 1.02[0.66, 1.75] 0.99[0.74, 1.44] Standard Covariates Adjusted 0.97[0.92, 1.03] 1.03[0.42, 3.44] 1.13[0.72, 1.80] All But One Covariate Adjusted 0.99[0.90, 1.10] -0.02[-0.16, 0.10] -0.06[-0.32, 0.18] 0.98[0.82, 1.23] 1.03[0.42, 2.55] 1.07[0.65, 1.58] -0.01[-0.23, 0.24] -0.01[-0.26, 0.21] 0.04[-0.16, 0.32] 1.01[0.63, 1.78] 0.98[0.65, 1.33] Shared Covariates Adjusted (With Dementia Diagnosis) 0.00[-1.00, 1.11] 7.29[0.84, 168.03] 1.20[0.32, 6.05] Standard Covariates Adjusted (With Dementia Diagnosis) -0.01[-1.02, 1.02] 7.65[0.88, 250.91] 1.43[0.39, 7.70] Conscientiousness Unadjusted 0.87[0.83, 0.93] -0.04[-0.11, 0.02] 0.03[-0.07, 0.12] 0.97[0.82, 1.14] 1.01[0.81, 1.45] 1.03[0.84, 1.29] -0.01[-0.06, 0.04] -0.01[-0.08, 0.06] -0.02[-0.09, 0.05] 1.04[0.86, 1.27] 1.00[0.76, 1.16] Fully Adjusted 0.96[0.65, 1.47] Shared Covariates Adjusted 0.88[0.85, 0.92] -0.04[-0.11, 0.02] 0.03[-0.06, 0.12] 0.95[0.67, 1.22] 1.02[0.83, 1.28] 1.06[0.84, 1.37] -0.01[-0.12, 0.05] -0.03[-0.16, 0.07] -0.02[-0.11, 0.07] 1.06[0.88, 1.30] 1.02[0.85, 1.19] Standard Covariates Adjusted 0.88[0.84, 0.91] 1.12[0.75, 2.12] 1.08[0.86, 1.42] All But One Covariate Adjusted 0.91[0.86, 0.95] -0.05[-0.12, 0.01] 0.03[-0.09, 0.12] 0.97[0.84, 1.11] 1.07[0.76, 1.46] 1.04[0.79, 1.38] -0.001[-0.06, 0.07] 0.01[-0.06, 0.12] -0.04[-0.10, 0.04] 1.06[0.85, 1.30] 1.01[0.84, 1.18] Shared Covariates Adjusted (With Dementia Diagnosis) -0.20[-1.37, 0.95] 2.14[0.42, 22.67] 2.79[0.46, 58.48] Standard Covariates Adjusted (With Dementia Diagnosis) -0.14[-1.09, 0.98] 2.43[0.44, 21.69] 2.09[0.46, 13.45] Neuroticism Unadjusted 1.11[1.05, 1.17] 0.02[-0.10, 0.11] -0.001[-0.09, 0.10] 1.00[0.86, 1.16] 0.98[0.81, 1.26] 0.99[0.86, 1.13] 0.01[-0.04, 0.06] 0.02[-0.06, 0.10] 0.01[-0.08, 0.10] 1.01[0.85, 1.16] 1.03[0.88, 1.20] Fully Adjusted 1.60[0.67, 5.76] Shared Covariates Adjusted 1.10[1.06, 1.14] 0.04[-0.09, 0.21] -0.03[-0.18, 0.07] 1.01[0.86, 1.16] 0.96[0.52, 1.35] 0.98[0.86, 1.13] 0.01[-0.05, 0.06] -0.00[-0.10, 0.07] 0.01[-0.07, 0.09] 1.02[0.87, 1.20] 1.03[0.88, 1.19] Standard Covariates Adjusted 1.10[1.05, 1.13] 1.04[0.61, 2.24] 0.97[0.81, 1.11] All But One Covariate Adjusted 1.08[1.03, 1.13] -0.18[-0.79, 0.11] -0.01[-0.12, 0.09] 1.00[0.86, 1.15] 0.97[0.70, 1.32] 0.99[0.85, 1.21] 0.01[-0.06, 0.08] 0.001[-0.07, 0.07] 0.00[-0.07, 0.08] 1.01[0.84, 1.17] 1.02[0.88, 1.18] Shared Covariates Adjusted (With Dementia Diagnosis) -0.12[-1.07, 0.80] 0.77[0.05, 10.83] 1.74[0.33, 34.37] Standard Covariates Adjusted (With Dementia Diagnosis) -0.14[-1.37, 0.77] 0.84[0.09, 10.61] 1.10[0.34, 4.99] Openness to Experience Unadjusted 0.87[0.78, 0.97] -0.04[-0.24, 0.06] -0.03[-0.20, 0.13] 1.02[0.86, 1.20] 0.94[0.47, 2.04] 0.90[0.52, 1.34] -0.03[-0.32, 0.25] -0.02[-0.21, 0.12] -0.07[-0.40, 0.18] 0.98[0.77, 1.22] 1.00[0.74, 1.35] Fully Adjusted 0.96[0.50, 2.02] Shared Covariates Adjusted 0.95[0.90, 1.02] -0.01[-0.10, 0.10] -0.08[-0.41, 0.15] 1.03[0.83, 1.32] 0.90[0.42, 2.13] 0.95[0.69, 1.53] -0.05[-0.21, 0.16] -0.03[-0.36, 0.20] -0.05[-0.40, 0.26] 1.02[0.78, 1.30] 1.02[0.78, 1.32] Standard Covariates Adjusted 0.95[0.90, 1.02] 1.05[0.35, 3.13] 0.94[0.63, 1.48] All But One Covariate Adjusted 0.97[0.86, 1.06] 0.000[-0.09, 0.08] -0.03[-0.23, 0.19] 1.03[0.86, 1.32] 1.03[0.46, 2.68] 0.96[0.68, 1.34] -0.02[-0.18, 0.15] -0.02[-0.18, 0.18] -0.03[-0.29, 0.27] 1.02[0.77, 1.32] 1.03[0.73, 1.67] Shared Covariates Adjusted (With Dementia Diagnosis) -0.11[-1.23, 0.79] 7.28[0.98, 238.12] 0.94[0.17, 5.92] Standard Covariates Adjusted (With Dementia Diagnosis) -0.22[-1.77, 0.81] 7.22[1.00, 196.99] 0.98[0.19, 7.35] Positive Affect Unadjusted 0.92[0.81, 1.05] 0.00[-0.17, 0.25] 0.00[-0.22, 0.21] 0.97[0.70, 1.28] 0.97[0.68, 1.35] 1.01[0.73, 1.37] 0.01[-0.19, 0.15] 0.03[-0.17, 0.26] -0.01[-0.21, 0.24] 1.11[0.77, 1.76] 1.19[0.78, 2.30] Fully Adjusted 1.10[0.51, 2.83] Shared Covariates Adjusted 0.93[0.88, 1.00] -0.03[-0.31, 0.17] 0.01[-0.16, 0.16] 0.89[0.61, 1.37] 1.03[0.80, 1.33] 1.04[0.76, 1.35] -0.03[-0.29, 0.09] 0.01[-0.24, 0.20] 0.07[-0.15, 0.33] 1.08[0.74, 1.64] 1.04[0.66, 1.53] Standard Covariates Adjusted 0.93[0.87, 0.99] 0.98[0.63, 1.44] All But One Covariate Adjusted 0.94[0.75, 1.12] -0.000[-0.23, 0.33] 0.00[-0.24, 0.19] 0.98[0.74, 1.34] 1.06[0.81, 1.47] 1.01[0.75, 1.29] 0.01[-0.21, 0.27] 0.02[-0.17, 0.20] -0.03[-0.28, 0.15] 1.10[0.76, 1.68] 1.02[0.69, 1.42] Negative Affect Unadjusted 1.10[1.00, 1.20] -0.05[-1.49, 0.99] -0.06[-1.13, 0.97] 0.98[0.26, 3.32] 0.94[0.26, 3.05] 1.05[0.29, 3.92] 0.00[-1.09, 1.19] -0.09[-0.91, 0.82] 0.05[-0.95, 0.97] 0.94[0.22, 3.84] 1.11[0.29, 4.16] Fully Adjusted 1.09[0.36, 4.11] Shared Covariates Adjusted 1.14[1.02, 1.26] -0.03[-1.23, 1.15] -0.14[-1.42, 1.29] 0.98[0.21, 4.67] 1.07[0.27, 4.56] 1.03[0.17, 4.73] -0.03[-1.26, 1.08] 0.19[-1.35, 1.71] -0.02[-1.30, 1.04] 0.96[0.21, 3.79] 0.95[0.27, 4.88] Standard Covariates Adjusted 1.14[1.01, 1.28] 1.01[0.28, 3.19] All But One Covariate Adjusted 1.05[0.73, 1.24] -0.10[-1.51, 1.03] -0.10[-1.31, 0.95] 1.05[0.28, 6.00] 0.81[0.14, 3.93] 1.12[0.31, 15.58] 0.04[-1.31, 1.10] -0.72[-3.13, 1.06] -0.04[-1.55, 1.33] 1.02[0.30, 4.10] 0.95[0.26, 5.63] Satisfaction with Life Unadjusted 0.92[0.80, 1.05] -0.01[-0.22, 0.18] -0.07[-0.29, 0.18] 1.04[0.77, 1.41] 0.99[0.72, 1.31] 1.06[0.72, 1.67] 0.01[-0.13, 0.13] 0.02[-0.14, 0.19] 0.000[-0.24, 0.24] 0.87[0.38, 1.71] 1.07[0.83, 1.47] Fully Adjusted 1.05[0.37, 2.25] Shared Covariates Adjusted 0.93[0.84, 1.03] 0.000[-0.33, 0.26] 0.01[-0.40, 0.53] 1.07[0.79, 1.49] 0.98[0.72, 1.36] 1.08[0.73, 1.71] -0.01[-0.23, 0.18] 0.01[-0.17, 0.23] -0.02[-0.20, 0.17] 0.91[0.34, 2.26] 1.10[0.78, 1.53] Standard Covariates Adjusted 0.92[0.83, 1.01] 1.05[0.64, 1.60] All But One Covariate Adjusted 0.94[0.75, 1.13] 0.00[-0.21, 0.23] 0.00[-0.27, 0.27] 1.06[0.68, 1.64] 0.99[0.69, 1.52] 1.09[0.76, 1.59] 0.09[-0.08, 0.29] 0.00[-0.22, 0.23] -0.00[-0.20, 0.20] 0.89[0.36, 2.31] 1.11[0.85, 1.50] Note: Unadjusted indicates no covariates were included. Fully adjusted models include age, gender, education, smoking status, alcohol use, cognitive ability, race, chronic conditions, BMI, and self-rated health. Shared covariates adjusted models Include age, gender, education, smoking status, alcohol use. Standard covariates adjusted models include age, gender, and education. All but one covariate adjusted models include age, gender, education, cognitive ability, and chronic conditions. Shared covariates with dementia adjusted models Include age, gender, education, smoking status, alcohol use, and dementia diagnosis. Standard covariates with dementia adjusted models include age, gender, education, and incident dementia diagnosis. (ipd_fx_tab %&gt;% filter(Moderator == &quot;Dementia Diagnosis&quot;))$tab[[1]] Table 3.1: Table XOverall dementia Moderation of Personality-Dementia Diagnosis and Neuropathology Associations Incident Dementia Diagnosis Braak Stage CERAD Lewy Body Disease Gross Cerebral Infarcts Gross Cerebral Microinfarcts Cerebral Atherosclerosis Cerebral Amyloid Angiopathy Arteriolosclerosis Hippocampal Sclerosis TDP-43 Covariates OR [CI] b [CI] b [CI] OR [CI] OR [CI] OR [CI] b [CI] b [CI] b [CI] OR [CI] OR [CI] Extraversion Unadjusted 0.06[-0.05, 0.17] -0.10[-0.57, 0.30] 1.03[0.87, 1.22] 1.05[0.65, 2.05] 1.10[0.90, 1.38] 0.02[-0.04, 0.09] 0.01[-0.09, 0.11] 0.01[-0.10, 0.11] 0.96[0.71, 1.32] 1.02[0.75, 1.38] Shared Covariates Adjusted 0.06[-0.08, 0.19] 0.04[-0.27, 0.35] 1.02[0.86, 1.22] 1.07[0.59, 2.17] 1.16[0.93, 1.79] 0.02[-0.04, 0.08] 0.03[-0.05, 0.12] 0.03[-0.07, 0.26] 1.03[0.73, 1.57] 1.01[0.72, 1.33] Standard Covariates Adjusted 0.07[-0.09, 0.26] 0.04[-0.28, 0.37] 1.04[0.86, 1.24] 1.04[0.61, 2.09] 1.12[0.84, 1.44] 0.02[-0.07, 0.15] 0.02[-0.08, 0.12] 0.01[-0.10, 0.13] 0.94[0.70, 1.28] 1.02[0.83, 1.32] All But One Covariate Adjusted 0.06[-0.07, 0.18] 0.04[-0.26, 0.36] 1.02[0.86, 1.23] 1.10[0.67, 2.35] 1.15[0.92, 1.49] 0.03[-0.05, 0.10] 0.03[-0.06, 0.13] -0.00[-0.30, 0.19] 1.01[0.73, 1.41] 1.01[0.76, 1.36] Agreeableness Shared Covariates Adjusted 26.79[0.07, 34607206.55] 0.06[-0.18, 0.27] -0.03[-0.65, 0.63] 1.13[0.76, 1.79] 1.09[0.34, 4.27] 0.96[0.59, 2.10] 0.01[-0.29, 0.36] 0.01[-0.39, 0.51] -0.02[-0.44, 0.40] 1.01[0.51, 2.05] 1.30[0.57, 6.23] Unadjusted 0.01[-0.28, 0.20] -0.01[-0.59, 0.55] 1.09[0.70, 1.83] 1.07[0.31, 4.83] 0.95[0.47, 2.11] -0.03[-0.80, 0.49] 0.00[-0.33, 0.31] -0.02[-0.40, 0.35] 1.09[0.59, 2.56] 1.23[0.56, 2.82] Standard Covariates Adjusted 0.04[-0.18, 0.26] -0.00[-0.59, 0.59] 1.15[0.82, 1.72] 1.14[0.28, 5.30] 0.98[0.43, 2.19] 0.03[-0.45, 0.42] 0.001[-0.44, 0.39] -0.09[-0.69, 0.32] 1.03[0.52, 2.20] 1.16[0.53, 2.58] All But One Covariate Adjusted 0.06[-0.14, 0.26] -0.04[-0.69, 0.58] 1.15[0.83, 1.67] 1.06[0.22, 5.10] 0.96[0.39, 2.14] 0.001[-0.38, 0.26] -0.01[-0.37, 0.38] -0.01[-0.43, 0.47] 0.99[0.50, 1.94] 1.17[0.56, 2.58] Conscientiousness Unadjusted 0.09[-0.04, 0.24] -0.04[-0.28, 0.19] 1.02[0.82, 1.26] 1.10[0.66, 2.22] 1.14[0.90, 1.46] 0.04[-0.03, 0.12] 0.01[-0.08, 0.11] 0.02[-0.09, 0.14] 0.90[0.63, 1.30] 1.08[0.87, 1.37] Shared Covariates Adjusted 0.11[-0.08, 0.30] -0.06[-0.28, 0.15] 1.05[0.84, 1.31] 1.10[0.66, 2.06] 1.17[0.93, 1.52] 0.04[-0.06, 0.11] 0.03[-0.07, 0.19] 0.001[-0.12, 0.10] 0.88[0.58, 1.32] 1.04[0.82, 1.31] Standard Covariates Adjusted 0.10[-0.08, 0.28] -0.04[-0.31, 0.24] 1.02[0.81, 1.29] 1.08[0.62, 2.22] 1.12[0.87, 1.46] 0.03[-0.07, 0.14] 0.03[-0.06, 0.12] 0.02[-0.10, 0.13] 0.91[0.63, 1.63] 1.05[0.82, 1.36] All But One Covariate Adjusted 0.12[-0.03, 0.26] -0.09[-0.29, 0.14] 1.06[0.84, 1.30] 1.10[0.63, 2.26] 1.16[0.82, 1.49] 0.03[-0.06, 0.14] 0.02[-0.14, 0.12] 0.00[-0.11, 0.11] 0.88[0.56, 1.33] 1.03[0.82, 1.32] Neuroticism Unadjusted -0.05[-0.20, 0.08] 0.02[-0.21, 0.26] 1.08[0.81, 1.39] 1.02[0.62, 1.99] 0.92[0.73, 1.22] -0.04[-0.13, 0.04] 0.01[-0.10, 0.14] 0.01[-0.12, 0.14] 0.92[0.66, 1.28] 0.99[0.72, 1.35] Shared Covariates Adjusted -0.08[-0.24, 0.05] 0.07[-0.13, 0.25] 1.08[0.82, 1.38] 1.04[0.63, 2.18] 0.97[0.65, 1.45] -0.03[-0.15, 0.08] -0.04[-0.19, 0.09] 0.000[-0.16, 0.17] 0.86[0.58, 1.24] 1.01[0.73, 1.35] Standard Covariates Adjusted -0.05[-0.18, 0.08] 0.02[-0.25, 0.25] 1.07[0.85, 1.34] 1.02[0.62, 2.18] 0.97[0.69, 1.56] -0.03[-0.16, 0.09] -0.00[-0.13, 0.16] -0.01[-0.19, 0.14] 0.92[0.67, 1.28] 1.00[0.76, 1.34] All But One Covariate Adjusted -0.09[-0.21, 0.04] 0.07[-0.12, 0.25] 1.10[0.85, 1.44] 1.06[0.64, 2.13] 0.91[0.55, 1.54] -0.02[-0.11, 0.09] -0.04[-0.16, 0.10] 0.01[-0.13, 0.14] 0.86[0.60, 1.23] 1.00[0.72, 1.56] Openness to Experience Unadjusted -0.01[-0.20, 0.16] 0.02[-0.69, 0.60] 1.14[0.78, 1.72] 1.03[0.24, 4.02] 1.03[0.53, 2.10] -0.01[-0.52, 0.41] -0.01[-0.37, 0.30] 0.05[-0.38, 0.61] 1.22[0.72, 2.12] 0.97[0.54, 1.86] Shared Covariates Adjusted 0.03[-0.19, 0.41] 0.05[-0.52, 0.63] 1.15[0.78, 1.67] 1.07[0.32, 3.40] 1.04[0.53, 2.04] -0.06[-0.36, 0.36] -0.01[-0.46, 0.41] 0.02[-0.39, 0.54] 1.23[0.74, 2.12] 0.98[0.47, 1.69] Standard Covariates Adjusted 0.03[-0.19, 0.36] 0.04[-0.55, 0.51] 1.29[0.82, 2.02] 1.10[0.28, 4.38] 1.08[0.57, 2.23] -0.04[-0.46, 0.42] -0.01[-0.40, 0.39] 0.000[-0.40, 0.39] 1.15[0.46, 2.09] 0.96[0.50, 1.84] All But One Covariate Adjusted 0.01[-0.16, 0.17] -0.16[-1.60, 0.57] 1.16[0.78, 1.71] 0.99[0.20, 4.63] 1.04[0.51, 2.11] -0.05[-0.39, 0.24] -0.01[-0.49, 0.47] 0.02[-0.30, 0.48] 1.30[0.75, 2.33] 0.95[0.49, 1.89] Positive Affect Unadjusted -0.00[-0.52, 0.43] -0.02[-0.44, 0.35] 0.96[0.40, 1.72] 1.28[0.56, 3.50] 0.97[0.49, 1.85] -0.01[-0.42, 0.46] -0.01[-0.37, 0.34] -0.01[-0.35, 0.34] 1.10[0.50, 2.73] 1.18[0.61, 2.77] Shared Covariates Adjusted 0.01[-0.49, 0.39] -0.04[-0.46, 0.33] 0.95[0.17, 1.93] 0.95[0.57, 1.79] 1.02[0.49, 2.09] 0.01[-0.37, 0.48] -0.05[-0.53, 0.41] 0.02[-0.32, 0.38] 1.16[0.51, 3.07] 1.15[0.61, 2.04] Standard Covariates Adjusted -0.00[-0.54, 0.47] -0.02[-0.52, 0.45] 0.96[0.47, 1.69] 0.96[0.56, 2.13] 0.94[0.45, 1.72] 0.08[-0.50, 0.74] -0.02[-0.36, 0.34] -0.001[-0.38, 0.45] 1.13[0.53, 2.92] 1.14[0.55, 2.08] All But One Covariate Adjusted -0.01[-0.50, 0.35] -0.01[-0.49, 0.56] 0.99[0.36, 1.82] 0.94[0.58, 1.71] 1.58[0.54, 6.35] -0.00[-0.41, 0.37] -0.05[-0.52, 0.34] 0.02[-0.44, 0.43] 1.13[0.53, 2.95] 1.17[0.60, 2.31] Negative Affect Unadjusted -0.09[-1.99, 1.66] -0.10[-1.73, 1.40] 1.02[0.08, 7.76] 1.16[0.22, 8.57] 1.07[0.15, 6.53] -0.01[-1.72, 1.63] -0.01[-1.75, 1.53] 0.13[-1.77, 2.22] 1.02[0.16, 10.27] 0.96[0.13, 5.85] Shared Covariates Adjusted -0.11[-2.19, 1.63] -0.05[-1.74, 1.66] 1.28[0.16, 10.72] 1.05[0.14, 7.19] 1.02[0.15, 6.20] 0.02[-1.61, 1.57] -0.01[-2.01, 1.67] 0.04[-1.67, 1.68] 0.97[0.16, 9.02] 0.90[0.16, 7.26] Standard Covariates Adjusted -0.12[-1.97, 1.63] 0.02[-1.76, 1.75] 0.97[0.11, 7.80] 1.09[0.16, 7.28] 1.08[0.17, 8.13] 0.00[-1.49, 1.71] -0.01[-1.61, 1.56] 0.00[-1.69, 1.64] 1.00[0.18, 6.32] 0.89[0.08, 5.81] All But One Covariate Adjusted -0.11[-2.25, 1.67] -0.06[-2.04, 1.47] 1.12[0.13, 6.43] 1.13[0.21, 6.11] 1.08[0.19, 6.18] -0.13[-2.32, 1.46] -0.04[-1.79, 1.62] 0.04[-1.85, 1.89] 0.90[0.14, 5.95] 0.96[0.16, 5.10] Satisfaction with Life Unadjusted -0.04[-0.52, 0.39] -0.01[-0.52, 0.39] 1.11[0.67, 1.92] 0.83[0.42, 1.81] 0.87[0.47, 1.74] -0.01[-0.39, 0.41] -0.04[-0.48, 0.37] -0.04[-0.49, 0.36] 1.24[0.40, 3.58] 1.17[0.63, 1.95] Shared Covariates Adjusted -0.05[-0.71, 0.34] -0.02[-0.58, 0.47] 1.14[0.56, 2.09] 0.85[0.44, 1.67] 0.93[0.52, 1.91] -0.00[-0.32, 0.34] -0.03[-0.45, 0.52] 0.02[-0.44, 0.47] 1.64[0.41, 4.14] 1.13[0.56, 2.19] Standard Covariates Adjusted -0.03[-0.54, 0.40] -0.00[-0.51, 0.39] 1.12[0.56, 2.61] 0.82[0.40, 1.56] 0.86[0.45, 1.58] 0.02[-0.33, 0.34] -0.03[-0.55, 0.55] -0.03[-0.52, 0.42] 1.02[0.10, 4.23] 1.15[0.60, 2.02] All But One Covariate Adjusted -0.02[-0.46, 0.47] -0.01[-0.65, 0.49] 1.14[0.55, 2.05] 0.83[0.41, 1.52] 0.91[0.43, 1.76] -0.00[-0.42, 0.35] -0.06[-0.52, 0.39] -0.03[-0.51, 0.35] 1.27[0.30, 4.58] 1.14[0.62, 2.10] Note: Unadjusted indicates no covariates were included. Fully adjusted models include age, gender, education, smoking status, alcohol use, cognitive ability, race, chronic conditions, BMI, and self-rated health. Shared covariates adjusted models Include age, gender, education, smoking status, alcohol use. Standard covariates adjusted models include age, gender, and education. All but one covariate adjusted models include age, gender, education, cognitive ability, and chronic conditions. Shared covariates with dementia adjusted models Include age, gender, education, smoking status, alcohol use, and dementia diagnosis. Standard covariates with dementia adjusted models include age, gender, education, and incident dementia diagnosis. These show the estimates, split by covariate sets across moderators, traits, and outcomes. ipd_tab_fun2 &lt;- function(d, cov){ # long outcome name covar &lt;- mapvalues(cov, str_wrap(covars$long_name, 15), covars$short_name, warn_missing = F) # getting row numbers for later grouping rs &lt;- d %&gt;% group_by(Moderator) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) # number and name of columns for span columns cs &lt;- rep(1,12) names(cs) &lt;- c(&quot; &quot;, outcomes$long_name) cln &lt;- mapvalues(colnames(d)[colnames(d) %in% outcomes$long_name], outcomes$long_name, outcomes$colnm, warn_missing = F) cln &lt;- c(&quot;Trait&quot;, cln) al &lt;- c(&quot;r&quot;, rep(&quot;c&quot;, 11)) # caption cap &lt;- sprintf(&quot;&lt;strong&gt;Table X&lt;/strong&gt;&lt;br&gt;&lt;em&gt;Fixed Effect Estimates of %s Personality-Dementia Diagnosis and Neuropathology Associations&lt;/em&gt;&quot;, cov) fn &lt;- mapvalues(cov, str_wrap(covars$long_name, 15), covars$desc, warn_missing = F) # kable the table tab &lt;- d %&gt;% mutate(Trait = factor(Trait, traits$short_name, traits$long_name)) %&gt;% select(-Moderator, -term) %&gt;% kable(., &quot;html&quot; # kable(., &quot;latex&quot; , booktabs = T , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% # kable_styling(full_width = F, font_size = 7) %&gt;% add_header_above(cs) %&gt;% footnote(fn) # for loop to add grouped sections for (i in 1:nrow(rs)){ tab &lt;- tab %&gt;% kableExtra::group_rows(rs$Moderator[i], rs$start[i], rs$end[i]) } # save the resulting html table save_kable(tab, file = sprintf(&quot;%s/results/tables/key-terms/%s.html&quot; , local_path, covar)) return(tab) # return the html table } ipd_fx_tab2 &lt;- nested_mega_tab %&gt;% filter(study == &quot;Overall&quot;) %&gt;% select(-study) %&gt;% arrange(Moderator, term) %&gt;% # filter(Covariate %in% c(&quot;unadjusted&quot;, &quot;shared&quot;)) %&gt;% group_by(Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, Covariate), ipd_tab_fun2)) ## Frequentist, no moderator (ipd_fx_tab2 %&gt;% filter(Covariate == &quot;Shared\\nCovariates\\nAdjusted\\n(With Dementia\\nDiagnosis)&quot;))$tab[[1]] Table 3.2: Table XFixed Effect Estimates of Shared Covariates Adjusted (With Dementia Diagnosis) Personality-Dementia Diagnosis and Neuropathology Associations Incident Dementia Diagnosis Braak Stage CERAD Lewy Body Disease Gross Cerebral Infarcts Gross Cerebral Microinfarcts Cerebral Atherosclerosis Cerebral Amyloid Angiopathy Arteriolosclerosis Hippocampal Sclerosis TDP-43 Trait OR [CI] b [CI] b [CI] OR [CI] OR [CI] OR [CI] b [CI] b [CI] b [CI] OR [CI] OR [CI] None Extraversion -0.10[-1.08, 0.78] 1.02[0.18, 7.57] 1.24[0.35, 7.66] Agreeableness 0.00[-1.00, 1.11] 7.29[0.84, 168.03] 1.20[0.32, 6.05] Conscientiousness -0.20[-1.37, 0.95] 2.14[0.42, 22.67] 2.79[0.46, 58.48] Neuroticism -0.12[-1.07, 0.80] 0.77[0.05, 10.83] 1.74[0.33, 34.37] Openness to Experience -0.11[-1.23, 0.79] 7.28[0.98, 238.12] 0.94[0.17, 5.92] Age Extraversion -0.02[-0.25, 0.20] 1.14[0.79, 2.29] 1.00[0.75, 1.39] Agreeableness -0.02[-0.27, 0.21] 1.67[0.92, 4.50] 0.99[0.74, 1.36] Conscientiousness -0.05[-0.45, 0.45] 1.16[0.61, 2.57] 0.98[0.67, 1.48] Neuroticism -0.01[-0.26, 0.21] 1.20[0.80, 2.26] 1.09[0.82, 1.50] Openness to Experience -0.01[-0.34, 0.22] 1.62[0.93, 6.71] 0.91[0.58, 1.28] Gender Extraversion -0.30[-1.96, 1.16] 1.20[0.10, 24.36] 2.17[0.35, 19.69] Agreeableness -0.21[-1.45, 1.80] 1.25[0.09, 28.52] 0.83[0.15, 7.28] Conscientiousness -0.26[-2.28, 1.41] 0.36[0.01, 20.53] 0.97[0.15, 8.07] Neuroticism -0.09[-1.95, 1.15] 0.61[0.02, 19.45] 3.42[0.38, 63.30] Openness to Experience -0.03[-2.43, 1.38] 1.27[0.11, 33.82] 0.43[0.03, 9.28] Education Extraversion -0.09[-0.87, 0.62] 1.19[0.17, 8.28] 1.11[0.47, 3.21] Agreeableness -0.05[-0.69, 0.58] 1.85[0.42, 14.00] 1.17[0.54, 3.20] Conscientiousness -0.11[-1.26, 0.79] 1.56[0.08, 226.50] 1.11[0.38, 5.00] Neuroticism -0.13[-0.67, 0.60] 1.74[0.38, 10.14] 1.33[0.62, 3.34] Openness to Experience -0.03[-0.57, 0.46] 1.37[0.43, 4.82] 1.41[0.64, 3.67] Cognition Extraversion -0.08[-0.60, 0.41] 1.28[0.45, 4.11] 0.75[0.25, 1.89] Agreeableness 0.01[-0.64, 0.56] 2.83[0.70, 19.50] 1.87[0.70, 6.67] Conscientiousness 0.20[-0.63, 1.27] 4.70[1.03, 105.76] 1.49[0.50, 4.87] Neuroticism -0.21[-0.75, 0.38] 1.01[0.22, 3.96] 0.62[0.16, 1.70] Openness to Experience -0.07[-0.65, 0.50] 3.03[0.75, 18.66] 1.94[0.72, 10.04] Note: Shared covariates with dementia adjusted models Include age, gender, education, smoking status, alcohol use, and dementia diagnosis. 3.4.1.2 Study-Specific Effects Next, we’ll look at these estimates for each sample. ## table function ipd_rx_tab_fun &lt;- function(d, moder, cov){ covar &lt;- mapvalues(cov, str_wrap(covars$long_name, 15), covars$short_name, warn_missing = F) md &lt;- mapvalues(moder, moders$long_name, moders$short_name, warn_missing = F) rs &lt;- d %&gt;% mutate(Trait = factor(Trait, traits$short_name, traits$long_name)) %&gt;% group_by(Trait) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) cs &lt;- rep(1,12) names(cs) &lt;- c(&quot; &quot;, paste0(&quot;&lt;strong&gt;&quot;, outcomes$long_name, &quot;&lt;/strong&gt;&quot;)) cln &lt;- mapvalues(colnames(d)[colnames(d) %in% outcomes$long_name], outcomes$long_name, outcomes$colnm, warn_missing = F) cln &lt;- c(&quot;Study&quot;, cln) al &lt;- c(&quot;r&quot;, rep(&quot;c&quot;, 11)) d &lt;- d %&gt;% select(-term) cap &lt;- if(md == &quot;none&quot;) sprintf(&quot;&lt;strong&gt;Table X&lt;/strong&gt;&lt;br&gt;&lt;em&gt;%s Overall and Sample-Specific Effects of Personality-Crystallized Domain Associations&lt;/em&gt;&quot;, cov) else sprintf(&quot;&lt;strong&gt;Table X&lt;/strong&gt;&lt;br&gt;&lt;em&gt;%s Overall and Sample-Specific %s Moderation of Personality-Crystallized Domain Associations&lt;/em&gt;&quot;, cov, md) fn &lt;- mapvalues(cov, str_wrap(covars$long_name, 15), covars$desc, warn_missing = F) tab &lt;- d %&gt;% arrange(Trait) %&gt;% select(-Trait) %&gt;% kable(., &quot;html&quot; , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% add_header_above(cs, escape = F) %&gt;% footnote(fn) for (i in 1:nrow(rs)) { tab &lt;- tab %&gt;% kableExtra::group_rows(rs$Trait[i], rs$start[i], rs$end[i]) } save_kable(tab, file = sprintf(&quot;%s/results/tables/study-specific/%s_%s.html&quot; , local_path, md, covar)) return(tab) } ipd_rx_tab &lt;- nested_mega_tab %&gt;% group_by(Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, Moderator, Covariate), ipd_rx_tab_fun)) ipd_rx_tab ## # A tibble: 39 × 4 ## Moderator Covariate data tab ## &lt;fct&gt; &lt;fct&gt; &lt;list&gt; &lt;list&gt; ## 1 None &quot;Unadjusted&quot; &lt;tibble [63 × 14]&gt; &lt;kablExtr [1]&gt; ## 2 None &quot;Fully Adjusted&quot; &lt;tibble [21 × 14]&gt; &lt;kablExtr [1]&gt; ## 3 None &quot;Shared\\nCovariates\\nAdjusted&quot; &lt;tibble [63 × 14]&gt; &lt;kablExtr [1]&gt; ## 4 None &quot;Standard\\nCovariates\\nAdjusted&quot; &lt;tibble [63 × 14]&gt; &lt;kablExtr [1]&gt; ## 5 None &quot;All But One\\nCovariate\\nAdjusted&quot; &lt;tibble [55 × 14]&gt; &lt;kablExtr [1]&gt; ## 6 Age &quot;Unadjusted&quot; &lt;tibble [63 × 14]&gt; &lt;kablExtr [1]&gt; ## 7 Age &quot;Fully Adjusted&quot; &lt;tibble [16 × 14]&gt; &lt;kablExtr [1]&gt; ## 8 Age &quot;Shared\\nCovariates\\nAdjusted&quot; &lt;tibble [63 × 14]&gt; &lt;kablExtr [1]&gt; ## 9 Age &quot;Standard\\nCovariates\\nAdjusted&quot; &lt;tibble [63 × 14]&gt; &lt;kablExtr [1]&gt; ## 10 Age &quot;All But One\\nCovariate\\nAdjusted&quot; &lt;tibble [55 × 14]&gt; &lt;kablExtr [1]&gt; ## # … with 29 more rows ## Frequentist (ipd_rx_tab %&gt;% filter(Moderator == &quot;None&quot; &amp; Covariate == &quot;Shared\\nCovariates\\nAdjusted&quot;))$tab[[1]] (#tab:ipd2b study specific table)Table XShared Covariates Adjusted Overall and Sample-Specific Effects of Personality-Crystallized Domain Associations Incident Dementia Diagnosis Braak Stage CERAD Lewy Body Disease Gross Cerebral Infarcts Gross Cerebral Microinfarcts Cerebral Atherosclerosis Cerebral Amyloid Angiopathy Arteriolosclerosis Hippocampal Sclerosis TDP-43 Study OR [CI] b [CI] b [CI] OR [CI] OR [CI] OR [CI] b [CI] b [CI] b [CI] OR [CI] OR [CI] Extraversion ROS 0.98[0.93, 1.04] 0.04[-0.01, 0.10] -0.02[-0.06, 0.03] 1.03[0.95, 1.13] 0.95[0.87, 1.02] 0.97[0.89, 1.04] 0.01[-0.02, 0.04] 0.02[-0.01, 0.06] -0.01[-0.05, 0.02] 0.96[0.85, 1.08] 1.04[0.96, 1.12] Rush-MAP 0.97[0.93, 1.02] 0.04[-0.01, 0.10] -0.04[-0.08, -0.00] 1.01[0.93, 1.08] 0.95[0.88, 1.03] 0.98[0.91, 1.05] -0.01[-0.04, 0.02] 0.02[-0.02, 0.05] -0.01[-0.04, 0.03] 0.98[0.88, 1.09] 1.04[0.97, 1.12] EAS 0.97[0.91, 1.04] -0.01[-0.11, 0.10] 1.01[0.84, 1.25] 0.98[0.84, 1.17] WUSM-MAP 0.97[0.91, 1.02] -0.10[-0.18, -0.01] -0.04[-0.10, 0.01] 1.03[0.93, 1.15] 0.96[0.84, 1.07] 0.01[-0.02, 0.05] 0.01[-0.04, 0.04] -0.02[-0.06, 0.03] 0.93[0.75, 1.08] 0.98[0.87, 1.09] SATSA 0.97[0.89, 1.04] HRS 0.98[0.95, 1.02] LISS 0.98[0.90, 1.11] GSOEP 0.96[0.86, 1.01] Overall 0.97[0.93, 1.02] -0.000[-0.13, 0.14] -0.04[-0.10, 0.05] 1.01[0.88, 1.12] 0.95[0.76, 1.34] 0.97[0.83, 1.13] 0.00[-0.06, 0.08] 0.02[-0.04, 0.07] -0.01[-0.08, 0.07] 0.97[0.83, 1.10] 1.01[0.80, 1.18] Agreeableness ROS 0.95[0.87, 1.01] -0.01[-0.07, 0.06] -0.00[-0.06, 0.06] 0.97[0.86, 1.09] 1.02[0.90, 1.15] 1.03[0.89, 1.17] -0.02[-0.06, 0.01] 0.00[-0.04, 0.05] 0.02[-0.03, 0.07] 1.09[0.91, 1.34] 1.00[0.90, 1.12] EAS 0.97[0.89, 1.04] 0.00[-0.08, 0.10] 1.05[0.87, 1.38] 1.06[0.82, 1.34] WUSM-MAP 0.96[0.89, 1.01] -0.04[-0.12, 0.03] -0.03[-0.10, 0.03] 0.94[0.84, 1.05] 1.14[0.98, 1.34] -0.000[-0.04, 0.04] -0.01[-0.05, 0.04] 0.01[-0.04, 0.06] 0.82[0.51, 1.11] 0.96[0.84, 1.09] SATSA 0.99[0.93, 1.10] HRS 0.98[0.95, 1.02] LISS 0.99[0.89, 1.13] GSOEP 0.97[0.90, 1.05] Overall 0.97[0.92, 1.03] -0.02[-0.15, 0.10] -0.02[-0.30, 0.15] 0.99[0.83, 1.23] 1.08[0.40, 2.48] 1.07[0.77, 1.52] -0.02[-0.19, 0.16] 0.02[-0.21, 0.25] 0.02[-0.19, 0.30] 1.02[0.66, 1.75] 0.99[0.74, 1.44] Conscientiousness ROS 0.88[0.84, 0.93] -0.04[-0.09, 0.01] 0.05[-0.00, 0.11] 0.94[0.85, 1.03] 1.03[0.94, 1.14] 1.08[0.98, 1.19] -0.01[-0.04, 0.02] 0.02[-0.01, 0.06] -0.02[-0.06, 0.03] 1.03[0.85, 1.20] 1.05[0.96, 1.16] Rush-MAP 0.88[0.84, 0.92] -0.05[-0.10, 0.01] 0.04[-0.02, 0.10] 0.93[0.81, 1.04] 1.01[0.91, 1.13] 1.10[1.00, 1.23] 0.01[-0.03, 0.05] -0.00[-0.05, 0.04] -0.03[-0.08, 0.02] 1.07[0.90, 1.28] 1.01[0.92, 1.11] EAS 0.89[0.84, 0.95] -0.05[-0.13, 0.03] 0.92[0.72, 1.11] 1.15[0.94, 1.45] WUSM-MAP 0.89[0.85, 0.93] -0.04[-0.09, 0.02] -0.001[-0.08, 0.06] 1.05[0.94, 1.17] 0.95[0.84, 1.09] -0.00[-0.04, 0.04] 0.01[-0.03, 0.05] -0.02[-0.07, 0.02] 0.99[0.76, 1.20] 0.99[0.87, 1.09] SATSA 0.88[0.84, 0.93] HRS 0.88[0.85, 0.91] LISS 0.88[0.80, 0.95] GSOEP 0.88[0.83, 0.94] Overall 0.88[0.85, 0.92] -0.04[-0.11, 0.02] 0.03[-0.06, 0.12] 0.95[0.67, 1.22] 1.02[0.83, 1.28] 1.06[0.84, 1.37] -0.01[-0.12, 0.05] -0.03[-0.16, 0.07] -0.02[-0.11, 0.07] 1.06[0.88, 1.30] 1.02[0.85, 1.19] Neuroticism ROS 1.10[1.05, 1.15] 0.01[-0.05, 0.06] -0.02[-0.07, 0.03] 1.01[0.91, 1.10] 0.99[0.91, 1.08] 0.99[0.91, 1.07] 0.02[-0.01, 0.05] -0.01[-0.06, 0.03] 0.01[-0.03, 0.04] 1.04[0.92, 1.17] 1.00[0.90, 1.09] Rush-MAP 1.11[1.06, 1.17] 0.03[-0.02, 0.10] -0.03[-0.08, 0.02] 1.06[0.96, 1.20] 0.95[0.86, 1.04] 0.98[0.89, 1.07] 0.00[-0.03, 0.04] 0.02[-0.02, 0.06] -0.01[-0.05, 0.03] 1.05[0.92, 1.20] 1.04[0.96, 1.15] EAS 1.09[1.01, 1.15] -0.02[-0.11, 0.08] 0.96[0.75, 1.11] 1.01[0.83, 1.18] WUSM-MAP 1.10[1.04, 1.15] 0.09[0.02, 0.16] 0.02[-0.04, 0.07] 1.02[0.91, 1.13] 0.98[0.87, 1.12] 0.02[-0.01, 0.05] 0.01[-0.03, 0.06] 0.03[-0.02, 0.08] 0.98[0.79, 1.15] 1.04[0.93, 1.18] SATSA 1.10[1.04, 1.15] HRS 1.10[1.07, 1.13] LISS 1.10[1.01, 1.18] GSOEP 1.10[1.04, 1.17] Overall 1.10[1.06, 1.14] 0.04[-0.09, 0.21] -0.03[-0.18, 0.07] 1.01[0.86, 1.16] 0.96[0.52, 1.35] 0.98[0.86, 1.13] 0.01[-0.05, 0.06] -0.00[-0.10, 0.07] 0.01[-0.07, 0.09] 1.02[0.87, 1.20] 1.03[0.88, 1.19] Openness to Experience ROS 0.93[0.85, 0.99] 0.00[-0.06, 0.08] -0.03[-0.08, 0.03] 1.09[0.96, 1.27] 1.00[0.89, 1.12] 0.91[0.80, 1.03] -0.03[-0.07, 0.01] -0.02[-0.07, 0.03] -0.07[-0.12, -0.02] 1.03[0.85, 1.23] 1.03[0.91, 1.15] EAS 0.98[0.91, 1.10] -0.01[-0.10, 0.10] 1.02[0.81, 1.26] 1.03[0.83, 1.29] WUSM-MAP 0.96[0.91, 1.03] -0.01[-0.08, 0.05] -0.02[-0.07, 0.04] 0.99[0.88, 1.10] 0.97[0.84, 1.12] -0.01[-0.05, 0.03] -0.03[-0.07, 0.02] -0.01[-0.06, 0.04] 1.03[0.82, 1.34] 1.02[0.89, 1.17] SATSA 0.94[0.86, 1.02] HRS 0.96[0.93, 1.00] LISS 0.98[0.87, 1.15] GSOEP 0.93[0.84, 1.00] Overall 0.95[0.90, 1.02] -0.01[-0.10, 0.10] -0.08[-0.41, 0.15] 1.03[0.83, 1.32] 0.90[0.42, 2.13] 0.95[0.69, 1.53] -0.05[-0.21, 0.16] -0.03[-0.36, 0.20] -0.05[-0.40, 0.26] 1.02[0.78, 1.30] 1.02[0.78, 1.32] Positive Affect ROS 0.97[0.90, 1.08] -0.000[-0.09, 0.08] 0.02[-0.05, 0.11] 1.01[0.88, 1.17] 1.02[0.87, 1.16] 1.00[0.83, 1.12] 0.01[-0.04, 0.05] 0.04[-0.03, 0.10] -0.02[-0.08, 0.04] 1.04[0.77, 1.40] 1.11[0.94, 1.74] Rush-MAP 0.94[0.91, 0.99] -0.01[-0.04, 0.02] 0.01[-0.02, 0.04] 0.97[0.91, 1.03] 1.04[0.98, 1.10] 1.05[0.99, 1.11] 0.01[-0.01, 0.03] 0.02[-0.01, 0.04] 0.000[-0.02, 0.02] 1.06[0.95, 1.20] 1.02[0.96, 1.08] SATSA 0.95[0.91, 1.02] HRS 0.93[0.90, 0.96] LISS 0.90[0.77, 1.01] GSOEP 0.89[0.81, 0.96] Overall 0.93[0.88, 1.00] -0.03[-0.31, 0.17] 0.01[-0.16, 0.16] 0.89[0.61, 1.37] 1.03[0.80, 1.33] 1.04[0.76, 1.35] -0.03[-0.29, 0.09] 0.01[-0.24, 0.20] 0.07[-0.15, 0.33] 1.08[0.74, 1.64] 1.04[0.66, 1.53] Negative Affect Rush-MAP 1.07[0.99, 1.15] 0.02[-0.03, 0.08] -0.03[-0.08, 0.02] 0.99[0.89, 1.11] 0.98[0.89, 1.08] 0.97[0.88, 1.07] 0.02[-0.02, 0.05] 0.02[-0.02, 0.06] 0.02[-0.02, 0.06] 0.95[0.78, 1.13] 1.05[0.96, 1.16] SATSA 1.09[1.02, 1.16] HRS 1.17[1.13, 1.21] LISS 1.17[0.99, 1.35] GSOEP 1.21[1.10, 1.34] Overall 1.14[1.02, 1.26] -0.03[-1.23, 1.15] -0.14[-1.42, 1.29] 0.98[0.21, 4.67] 1.07[0.27, 4.56] 1.03[0.17, 4.73] -0.03[-1.26, 1.08] 0.19[-1.35, 1.71] -0.02[-1.30, 1.04] 0.96[0.21, 3.79] 0.95[0.27, 4.88] Satisfaction with Life ROS 0.97[0.86, 1.09] 0.03[-0.06, 0.12] 0.03[-0.05, 0.13] 1.08[0.91, 1.28] 0.94[0.77, 1.07] 1.03[0.85, 1.21] 0.02[-0.03, 0.07] 0.001[-0.08, 0.07] -0.04[-0.11, 0.03] 0.50[0.05, 1.09] 1.11[0.95, 1.27] Rush-MAP 0.93[0.87, 0.99] 0.001[-0.05, 0.05] -0.02[-0.06, 0.03] 1.02[0.93, 1.14] 1.00[0.92, 1.09] 1.14[1.04, 1.26] 0.03[-0.00, 0.05] 0.02[-0.02, 0.06] 0.00[-0.03, 0.04] 0.98[0.84, 1.15] 1.12[1.03, 1.21] SATSA 0.99[0.94, 1.04] HRS 0.95[0.93, 0.98] LISS 0.86[0.72, 0.99] GSOEP 0.88[0.81, 0.95] Overall 0.93[0.84, 1.03] 0.000[-0.33, 0.26] 0.01[-0.40, 0.53] 1.07[0.79, 1.49] 0.98[0.72, 1.36] 1.08[0.73, 1.71] -0.01[-0.23, 0.18] 0.01[-0.17, 0.23] -0.02[-0.20, 0.17] 0.91[0.34, 2.26] 1.10[0.78, 1.53] Note: Shared covariates adjusted models Include age, gender, education, smoking status, alcohol use. 3.4.1.3 Heterogeneity Estimates 3.4.1.4 All Model Terms ipd_mod_tab &lt;- nested_mega %&gt;% select(-n, -rx) %&gt;% unnest(fx) %&gt;% # keep key terms # mark significance and prettify trait, outcome, and covariate names left_join( outcomes %&gt;% select(Outcome = short_name, link) ) %&gt;% mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;), Trait = factor(Trait, traits$short_name), Outcome = factor(Outcome, outcomes$short_name, outcomes$long_name), Moderator = factor(Moderator, moders$short_name, moders$long_name), Covariate = factor(Covariate, covars$short_name, str_wrap(covars$long_name, 15)) ) %&gt;% mutate_at(vars(estimate, conf.low, conf.high), ~ifelse(link == &quot;factor&quot;, exp(.), .)) %&gt;% # format values as text, combine estimates and CI&#39;s, bold significance mutate_at(vars(estimate, conf.low, conf.high), ~ifelse(abs(.) &lt; .01, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))) %&gt;% mutate(est = sprintf(&quot;%s&lt;br&gt;[%s, %s]&quot;, estimate, conf.low, conf.high), est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;&lt;strong&gt;%s&lt;/strong&gt;&quot;, est), est)) %&gt;% # mutate(est = sprintf(&quot;%s [%s, %s]&quot;, estimate, conf.low, conf.high), # est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;\\\\textbf{%s}&quot;, est), est)) %&gt;% # final reshaping, remove extra columns, arrange values, and change to wide format select(-estimate, -conf.low, -conf.high, -sig) %&gt;% arrange(Outcome, Trait, Moderator, Covariate) %&gt;% pivot_wider(names_from = &quot;Trait&quot;, values_from = &quot;est&quot;) ipd_mod_tab_fun &lt;- function(d, out, moder, cov, link){ md &lt;- mapvalues(moder, moders$long_name, moders$short_name, warn_missing = F) o &lt;- mapvalues(out, outcomes$long_name, outcomes$short_name, warn_missing = F) cv &lt;- mapvalues(cov, str_wrap(covars$long_name, 15), covars$short_name, warn_missing = F) cs &lt;- rep(1,9) names(cs) &lt;- c(&quot; &quot;, paste0(&quot;&lt;strong&gt;&quot;, traits$long_name, &quot;&lt;/strong&gt;&quot;)) # cln &lt;- if(length(unique(d$term2)) == 1) c(&quot;Covariate&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) else c(&quot; &quot;, &quot;Term&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) lnk &lt;- if(link == &quot;factor&quot;) &quot;&lt;em&gt;OR&lt;/em&gt; [CI]&quot; else &quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot; cln &lt;- c(&quot;Term&quot;, rep(lnk, 8)) al &lt;- c(&quot;r&quot;, rep(&quot;c&quot;, 8)) # caption cap &lt;- if(md == &quot;none&quot;) sprintf(&quot;All %s Model Estimates of Fixed Effect Personality-Dementia Diagnosis / Neuropathology Associations&quot;, cov) else sprintf(&quot;All %s Model Estimates of Fixed Effect %s Moderation of Personality-Crystallized Domain Associations&quot;, cov, md) fn &lt;- mapvalues(cov, str_wrap(covars$long_name, 15), covars$desc, warn_missing = F) # kable the table tab &lt;- d %&gt;% arrange(term) %&gt;% kable(., &quot;html&quot; # kable(., &quot;latex&quot; , booktabs = T , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% # kable_styling(full_width = F, font_size = 7) %&gt;% add_header_above(cs, escape = F) %&gt;% footnote(fn) # save the resulting html table save_kable(tab, file = sprintf(&quot;%s/results/tables/all-terms/%s_%s_%s.html&quot; , local_path, o, md, cv)) return(tab) # return the html table } ipd_mod_tab &lt;- ipd_mod_tab %&gt;% group_by(Outcome, Moderator, Covariate, link) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, Outcome, Moderator, Covariate, link), ipd_mod_tab_fun)) (ipd_mod_tab %&gt;% filter(Covariate == &quot;Shared\\nCovariates\\nAdjusted&quot;))$tab[[1]] Table 3.3: All Shared Covariates Adjusted Model Estimates of Fixed Effect Personality-Dementia Diagnosis / Neuropathology Associations Extraversion Agreeableness Conscientiousness Neuroticism Openness to Experience Positive Affect Negative Affect Satisfaction with Life Term OR [CI] OR [CI] OR [CI] OR [CI] OR [CI] OR [CI] OR [CI] OR [CI] (Intercept) 0.05[0.02, 0.14] 0.04[0.01, 0.17] 0.09[0.03, 0.25] 0.03[0.009, 0.07] 0.05[0.01, 0.17] 0.06[0.02, 0.18] 0.02[0.005, 0.08] 0.06[0.02, 0.16] age 1.08[1.08, 1.09] 1.08[1.08, 1.09] 1.08[1.08, 1.09] 1.08[1.08, 1.09] 1.08[1.08, 1.09] 1.08[1.08, 1.09] 1.09[1.08, 1.09] 1.09[1.08, 1.09] alcohol1 0.82[0.74, 0.91] 0.83[0.74, 0.94] 0.81[0.73, 0.91] 0.82[0.74, 0.91] 0.84[0.75, 0.94] 0.83[0.74, 0.93] 0.82[0.73, 0.92] 0.83[0.74, 0.93] cor__(Intercept).p_value 0.94[0.39, 2.52] 0.75[0.38, 2.29] 0.98[0.38, 2.61] 0.97[0.38, 2.58] 0.82[0.39, 2.40] 1.51[0.47, 2.69] 0.61[0.37, 1.69] 1.37[0.52, 2.60] education 0.95[0.94, 0.97] 0.95[0.93, 0.96] 0.95[0.94, 0.97] 0.96[0.94, 0.97] 0.95[0.93, 0.97] 0.95[0.93, 0.96] 0.96[0.94, 0.97] 0.95[0.93, 0.96] gender1 1.02[0.92, 1.12] 1.03[0.93, 1.15] 1.02[0.92, 1.13] 0.98[0.89, 1.09] 1.01[0.91, 1.14] 1.01[0.90, 1.15] 0.95[0.84, 1.08] 1.02[0.90, 1.14] p_value 0.97[0.93, 1.02] 0.97[0.92, 1.03] 0.88[0.85, 0.92] 1.10[1.06, 1.14] 0.95[0.90, 1.02] 0.93[0.88, 1.00] 1.14[1.02, 1.26] 0.93[0.84, 1.03] sd__(Intercept) 4.15[2.27, 12.70] 4.92[2.40, 19.94] 3.90[2.17, 11.42] 3.90[2.20, 10.80] 5.13[2.46, 22.04] 3.38[1.69, 11.90] 4.16[2.06, 17.37] 3.08[1.54, 11.22] sd__p_value 1.03[1.00, 1.11] 1.04[1.00, 1.14] 1.02[1.00, 1.08] 1.02[1.00, 1.08] 1.05[1.00, 1.16] 1.06[1.00, 1.19] 1.09[1.02, 1.30] 1.10[1.01, 1.28] smokes1 1.03[0.93, 1.14] 1.05[0.94, 1.18] 1.00[0.90, 1.12] 1.02[0.92, 1.13] 1.05[0.94, 1.18] 0.99[0.88, 1.11] 0.99[0.88, 1.12] 1.01[0.90, 1.13] Note: Shared covariates adjusted models Include age, gender, education, smoking status, alcohol use. 3.4.2 Figures Next, let’s make figures. These will include 4 kinds: “Forest Plots” over overall associations (and credible intervals) across traits, moderators, covariates, and outcomes Sample-Specific Forest Plots (or true forest plots) of sample-specific and overall associations across traits, moderators, outcomes, and covariates Overall Simple Slopes or figures showing the associations across levels of the moderators Sample-Specific Simple Slopes or figures showing the associations across levels of the moderators for each sample 3.4.2.1 Overall Forest fx_forest_fun &lt;- function(df, outcome, mod, cov, link){ print(paste(outcome, mod)) m &lt;- mapvalues(mod, moders$long_name, moders$short_name, warn_missing = F) d &lt;- round(max(abs(min(df$estimate)), abs(max(df$estimate))), 3) # stds &lt;- unique(df$study) lim &lt;- if(link == &quot;factor&quot;) c(.75, 1.25) else c(-1*round(2*d,2), round(2*d, 2)) brk &lt;- if(link == &quot;factor&quot;) c(.75, 1, 1.25) else { if(d &gt; .01) round(1.75*d,2) else round(1.75*d,3) }; brk &lt;- c(-1*brk, 0, brk) lim_high &lt;- if(link == &quot;factor&quot;) lim[2]*2 else lim[2]*4 lab &lt;- str_replace(brk, &quot;^0.&quot;, &quot;.&quot;)#str_remove(round(c(0-d-(d/5), 0, 0+d+(d/5)),2), &quot;^0&quot;) shapes &lt;- c(15, 16, 17, 18)[1:length(unique(df$term))] lt &lt;- rep(&quot;solid&quot;, length(unique(df$term))) titl &lt;- if(mod == &quot;None&quot;){&quot;Main Effects&quot;} else {sprintf(&quot;Personality x %s&quot;, mod)} leg &lt;- if(length(unique(df$term)) &gt; 1){&quot;bottom&quot;} else {&quot;none&quot;} trm &lt;- if(mod != &quot;None&quot;) paste(&quot;Personality x&quot;, unique(df$term[!is.na(df$term)])) else &quot;Main Effects&quot; df &lt;- df %&gt;% full_join(tibble(Trait = &quot; &quot;, estimate = NA, n = NA)) df &lt;- df %&gt;% arrange(estimate) trts &lt;- df$Trait[!df$Trait %in% c(&quot; &quot;)] labs &lt;- if(link == &quot;factor&quot;) &quot;OR [CI]&quot; else &quot;b [CI]&quot; yint &lt;- if(link == &quot;factor&quot;) 1 else 0 df &lt;- df %&gt;% mutate_at(vars(estimate, conf.low, conf.high), lst(f = ~ifelse(abs(.) &lt; .001, sprintf(&quot;%.4f&quot;, .), ifelse(abs(.) &lt; .01, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))))) %&gt;% mutate(Trait = factor(Trait, rev(c(&quot; &quot;, trts)))#Trait = factor(Trait, rev(c(&quot; &quot;, traits$short_name)), rev(c(&quot; &quot;, traits$short_name))) , lb = ifelse(conf.low &lt; lim[1], &quot;lower&quot;, &quot;no&quot;) , ub = ifelse(conf.high &gt; lim[2], &quot;upper&quot;, &quot;no&quot;) , conf.low2 = ifelse(conf.low &lt; lim[1], lim[1], conf.low) , conf.high2 = ifelse(conf.high &gt; lim[2], lim[2], conf.high) , est = ifelse(Trait != &quot; &quot;, sprintf(&quot;%s [%s, %s]&quot;, estimate_f, conf.low_f, conf.high_f), &quot;&quot;) ) %&gt;% arrange(Trait) p1 &lt;- df %&gt;% ggplot(aes(x = Trait, y = estimate)) + geom_errorbar(aes(ymin = conf.low2, ymax = conf.high2) , position = &quot;dodge&quot; , width = 0) + geom_point(aes(shape = term, size = term)) + geom_segment(data = df %&gt;% filter(lb == &quot;lower&quot;) , aes(y = conf.high2, yend = conf.low2, xend = Trait) , arrow = arrow(type = &quot;closed&quot;, length = unit(0.1, &quot;cm&quot;))) + geom_segment(data = df %&gt;% filter(ub == &quot;upper&quot;) , aes(y = conf.low2, yend = conf.high2, xend = Trait) , arrow = arrow(type = &quot;closed&quot;, length = unit(0.1, &quot;cm&quot;))) + geom_hline(aes(yintercept = yint), linetype = &quot;dashed&quot;, size = .5) + geom_vline(aes(xintercept = length(trts) + .5)) + annotate(&quot;rect&quot;, xmin = length(trts) + .6, xmax = Inf, ymin = -Inf, ymax = Inf, fill = &quot;white&quot;) + annotate(&quot;text&quot;, label = labs, x = length(trts) + .75, y = lim_high*.75, hjust = .5, vjust = 0, fontface = 2, size = 3) + annotate(&quot;text&quot;, label = trm, x = length(trts) + .75, y = 0, hjust = .5, vjust = 0, fontface = 2, size = 3) + geom_text(aes(y = lim_high*.75, label = est), size = 3.5) + scale_y_continuous(limits = c(lim[1], lim_high), breaks = brk, labels = lab) + scale_size_manual(values = c(3,2)) + scale_shape_manual(values = c(15, 16)) + labs(x = NULL , y = &quot;Estimate&quot; # , title = meth ) + coord_flip() + theme_classic() + theme(legend.position = &quot;none&quot; , axis.text = element_text(face = &quot;bold&quot;) , axis.title = element_text(face = &quot;bold&quot;) , plot.title = element_text(face = &quot;bold&quot;, hjust = .5) , axis.ticks.y = element_blank() , axis.line.y = element_blank() , axis.line.x.top = element_line(size = 1) # , panel.background = element_rect(fill = &quot;transparent&quot;, colour = NA) # , plot.background = element_rect(fill = &quot;transparent&quot;, colour = NA) ) my_theme &lt;- function(...) { theme_classic() + theme(plot.title = element_text(face = &quot;italic&quot;)) } title_theme &lt;- calc_element(&quot;plot.title&quot;, my_theme()) ttl &lt;- ggdraw() + draw_label( str_wrap(outcome, 50), fontfamily = title_theme$family, fontface = title_theme$face, size = title_theme$size-2 ) p &lt;- cowplot::plot_grid(ttl, p1, rel_heights = c(.15, .85), nrow = 2) return(p) } nested_ipd_fx_fig &lt;- nested_mega %&gt;% select(-rx, -n) %&gt;% unnest(fx) %&gt;% left_join( outcomes %&gt;% select(Outcome = short_name, link) ) %&gt;% mutate_at(vars(estimate, conf.low, conf.high), ~ifelse(link == &quot;factor&quot;, exp(.), .)) %&gt;% filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;) | (Moderator != &quot;none&quot; &amp; grepl(&quot;p_value:&quot;, term) &amp; !grepl(&quot;p_value:study&quot;, term) &amp; !(grepl(&quot;cor_&quot;, term) | grepl(&quot;sd_&quot;, term)))) %&gt;% mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;), Outcome = factor(Outcome, outcomes$short_name, outcomes$long_name), Covariate = factor(Covariate, covars$short_name, str_wrap(covars$long_name, 15)), term = str_remove_all(term, &quot;p_value:&quot;), term = str_to_title(str_remove_all(term, &quot;[0-9]&quot;)), # term = factor(term, c(covars$short_term, moders$short_term, stdyModers$short_term), # c(covars$long_term, moders$long_term, stdyModers$long_term)), Moderator = factor(Moderator, moders$short_name, moders$long_name)) %&gt;% group_by(Moderator, Covariate, Outcome, link) %&gt;% nest() %&gt;% ungroup() %&gt;% # filter(Covariate == &quot;Shared\\nCovariates\\nAdjusted&quot; &amp; Moderator == &quot;None&quot;) %&gt;% mutate(p = pmap(list(data, Outcome, Moderator, Covariate, link), fx_forest_fun)) fx_forest_comb_fun &lt;- function(d, mod, cov){ m &lt;- mapvalues(mod, moders$long_name, moders$short_name, warn_missing = F) cv &lt;- mapvalues(cov, str_wrap(covars$long_name, 15), covars$short_name, warn_missing = F) # d &lt;- d %&gt;% mutate(Outcome = factor(Outcome, outcomes$short_name, outcomes$long_name)) p1 &lt;- plot_grid(plotlist = d$p , nrow = ceiling(nrow(d)/3)) titl &lt;- if(mod == &quot;None&quot;) &quot;Personality-Dementia and Neuropathology Associations&quot; else sprintf(&quot;%s Moderators of Personality-Dementia and Neuropathology Associations&quot;, mod) titl &lt;- str_wrap(paste(cov, titl), 60) my_theme &lt;- function(...) { theme_classic() + theme(plot.title = element_text(face = &quot;bold&quot;)) } title_theme &lt;- calc_element(&quot;plot.title&quot;, my_theme()) ttl &lt;- ggdraw() + draw_label( titl, fontfamily = title_theme$family, fontface = title_theme$face, size = title_theme$size-1 ) p &lt;- cowplot::plot_grid(ttl, p1, rel_heights = c(.1, .9), nrow = 2) ht &lt;- nrow(d)/3 ggsave(file = sprintf(&quot;%s/results/figures/overall-forest/%s_%s.png&quot;, local_path, m, cv) , width = 12, height = ht*3) ggsave(file = sprintf(&quot;%s/results/figures/overall-forest/%s_%s.pdf&quot;, local_path, m, cv) , width = 12, height = ht*3) rm(p) gc() return(T) } nested_ipd_fx_fig2 &lt;- nested_ipd_fx_fig %&gt;% arrange(Moderator, Covariate, Outcome) %&gt;% group_by(Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(p = pmap(list(data, Moderator, Covariate), fx_forest_comb_fun)) knitr::include_graphics(&quot;https://github.com/emoriebeck/personality-dementia-neuropath/raw/master/results/figures/overall-forest/none_shared.png&quot;) 3.4.2.2 Study-Specific Forest ipd_rx_plot_fun &lt;- function(df, outcome, mod, cov, trait){ print(paste(outcome, mod)) trt &lt;- mapvalues(trait, traits$short_name, traits$long_name) m &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) d &lt;- round(max(abs(min(df$estimate)), abs(max(df$estimate))), 3) # stds &lt;- unique(df$study) lim &lt;- c(0-d-(d/2.5), 0+d+(d/2.5)) brk &lt;- round(c(0-d-(d/5), 0, 0+d+(d/5)),2) lab &lt;- str_remove(round(c(0-d-(d/5), 0, 0+d+(d/5)),2), &quot;^0&quot;) shapes &lt;- c(15, 16, 17, 18)[1:length(unique(df$term))] lt &lt;- rep(&quot;solid&quot;, length(unique(df$term))) titl &lt;- if(mod == &quot;none&quot;){trt} else {sprintf(&quot;%s x %s&quot;, trt, m)} leg &lt;- if(length(unique(df$term)) &gt; 1){&quot;bottom&quot;} else {&quot;none&quot;} df &lt;- df %&gt;% full_join(tibble(study = &quot; &quot;, estimate = NA, n = NA)) df &lt;- df %&gt;% arrange(estimate) stds &lt;- df$study[!df$study %in% c(&quot;Overall&quot;, &quot; &quot;)] df &lt;- df %&gt;% mutate(study = factor(study, rev(c(&quot; &quot;, stds, &quot;Overall&quot;))) # , conf.low = ifelse(conf.low &lt; lim[1], lim[1], conf.low) # , conf.high = ifelse(conf.high &gt; lim[2], lim[2], conf.high) , lb = ifelse(conf.low &lt; lim[1], &quot;lower&quot;, &quot;no&quot;) , ub = ifelse(conf.high &gt; lim[2], &quot;upper&quot;, &quot;no&quot;) , conf.low2 = ifelse(conf.low &lt; lim[1], lim[1], conf.low) , conf.high2 = ifelse(conf.high &gt; lim[2], lim[2], conf.high) , n = ifelse(study == &quot;Overall&quot;, sum(n, na.rm = T), n) # , study = factor(study, levels = str_remove_all(c(&quot;Overall&quot;, studies_long), &quot;-&quot;), labels = c(&quot;Overall&quot;, studies_long)) # Trait = factor(Trait, levels = traits$short_name, labels = traits$long_name), , type = ifelse(study == &quot;Overall&quot;, &quot;fixed&quot;, &quot;random&quot;)) p1 &lt;- df %&gt;% ggplot(aes(x = study, y = estimate)) + # geom_errorbar(data = df %&gt;% filter(ub != &quot;upper&quot;) # , aes(ymin = estimate, ymax = conf.high2) # , position = &quot;dodge&quot; # , width = .2) + # geom_errorbar(data = df %&gt;% filter(lb != &quot;lower&quot;) # , aes(ymin = conf.low2, ymax = estimate) # , position = &quot;dodge&quot; # , width = .2) + geom_point(data = df# %&gt;% filter(study != &quot;Overall&quot;) , aes(shape = term, size = n)) + # geom_point(data = df %&gt;% filter(study == &quot;Overall&quot;) # , aes(shape = term)) + geom_segment(data = df %&gt;% filter(lb != &quot;lower&quot;) , aes(y = conf.high2, yend = conf.low2, xend = study)) + geom_segment(data = df %&gt;% filter(ub != &quot;upper&quot;) , aes(y = conf.low2, yend = conf.high2, xend = study)) + geom_segment(data = df %&gt;% filter(lb == &quot;lower&quot;) , aes(y = conf.high2, yend = conf.low2, xend = study) , arrow = arrow(type = &quot;closed&quot;, length = unit(0.1, &quot;cm&quot;))) + geom_segment(data = df %&gt;% filter(ub == &quot;upper&quot;) , aes(y = conf.low2, yend = conf.high2, xend = study) , arrow = arrow(type = &quot;closed&quot;, length = unit(0.1, &quot;cm&quot;))) + geom_hline(aes(yintercept = 0), linetype = &quot;dashed&quot;, size = .5) + geom_vline(aes(xintercept = 1.5)) + geom_vline(aes(xintercept = length(stds) + 1.5)) + annotate(&quot;rect&quot;, xmin = length(stds) + 1.6, xmax = Inf, ymin = -Inf, ymax = Inf, fill = &quot;white&quot;) + scale_y_continuous(limits = lim, breaks = brk, labels = lab) + scale_size_continuous(range = c(2.5,5)) + scale_shape_manual(values = c(15, 16)) + labs(x = NULL , y = &quot;Estimate&quot; # , title = &quot; &quot; ) + coord_flip() + theme_classic() + theme(legend.position = &quot;none&quot; , axis.text = element_text(face = &quot;bold&quot;) , axis.title = element_text(face = &quot;bold&quot;) , plot.title = element_text(face = &quot;bold&quot;, hjust = .5) , axis.ticks.y = element_blank() , axis.line.y = element_blank() , axis.line.x.top = element_line(size = 1)) d2 &lt;- df %&gt;% mutate_at(vars(estimate, conf.low, conf.high) , ~ifelse(abs(.) &lt; .01, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))) %&gt;% mutate_at(vars(estimate, conf.low, conf.high), ~str_replace_all(., &quot;^0.&quot;, &quot;.&quot;)) %&gt;% mutate_at(vars(estimate, conf.low, conf.high), ~str_replace_all(., &quot;^-0.&quot;, &quot;-.&quot;)) %&gt;% mutate(est = ifelse(study != &quot; &quot;, sprintf(&quot;%s [%s, %s] &quot;, estimate, conf.low, conf.high), &quot;&quot;) , n = as.character(n) ) %&gt;% select(study, n, est) %&gt;% pivot_longer(cols = c(n, est), names_to = &quot;est&quot;, values_to = &quot;value&quot;) p2 &lt;- d2 %&gt;% ggplot(aes(x = study, y = est)) + geom_text(data = d2 %&gt;% filter(est == &quot;est&quot;), aes(label = value), hjust = .5, size = 3.5) + geom_text(data = d2 %&gt;% filter(est == &quot;n&quot;), aes(label = value), hjust = .5, size = 3.5) + annotate(&quot;text&quot;, label = &quot;b [CI]&quot;, x = length(stds) + 1.75, y = &quot;est&quot;, hjust = .5, vjust = 0) + annotate(&quot;text&quot;, label = &quot;N&quot;, x = length(stds) + 1.75, y = &quot;n&quot;, hjust = .5, vjust = 0) + geom_vline(aes(xintercept = 1.5)) + geom_vline(aes(xintercept = length(stds) + 1.5)) + coord_flip() + theme_void() + theme(plot.title = element_text(face = &quot;bold&quot;, hjust = 0) , axis.text = element_blank() , axis.ticks = element_blank() , axis.title = element_blank()) my_theme &lt;- function(...) { theme_classic() + theme(plot.title = element_text(face = &quot;italic&quot;)) } title_theme &lt;- calc_element(&quot;plot.title&quot;, my_theme()) ttl &lt;- ggdraw() + draw_label( titl, fontfamily = title_theme$family, fontface = title_theme$face, size = title_theme$size-2 ) p3 &lt;- cowplot::plot_grid(p1, p2 , rel_widths = c(.5, .5) , align = &quot;h&quot; ) # p &lt;- cowplot::plot_grid(ttl, subttl, p3, rel_heights = c(.05, .05, .9), nrow = 3) p &lt;- cowplot::plot_grid(ttl, p3, rel_heights = c(.05, .95), nrow = 2) gc() save(p , file = sprintf(&quot;%s/results/figures/study-specific-forest/rdata/%s_%s_%s_%s.RData&quot;, local_path, outcome, trait, mod, cov)) return(p) } ## fixed effects nested_reg_fp &lt;- nested_mega %&gt;% select(-rx, -n) %&gt;% unnest(fx) %&gt;% mutate(study = &quot;Overall&quot;) %&gt;% ## random effects full_join( nested_mega %&gt;% mutate(rx = map2(rx, n, ~(.x) %&gt;% full_join(.y))) %&gt;% select(-fx, -n) %&gt;% unnest(rx) %&gt;% rename(term = names) # mutate(term = ifelse(Moderator != &quot;none&quot;, paste(term, mapvalues(Moderator, moders$short_name, moders$short_term, warn_missing = F), sep = &quot;:&quot;), term)) ) %&gt;% ## filter key terms filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;)| (Moderator != &quot;none&quot; &amp; grepl(&quot;^p_value:&quot;, term) &amp; !grepl(&quot;study&quot;, term))) %&gt;% ## significance mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;) # , study = mapvalues(study, studies_long, studies_sp, warn_missing = F) ) %&gt;% ## grouping for plotting group_by(Outcome, Moderator, Covariate, Trait) %&gt;% nest() %&gt;% ungroup() %&gt;% # filter(Covariate != &quot;fully&quot; &amp; Outcome == &quot;dementia&quot;) %&gt;% mutate(p = pmap(list(data, Outcome, Moderator, Covariate, Trait), ipd_rx_plot_fun)) ipd_rx_plot_comb_fun &lt;- function(outcome, cov, mod, d){ o &lt;- mapvalues(outcome, outcomes$short_name, outcomes$long_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) m &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) titl &lt;- paste(&quot;Prospective Associations Between Personality / Subjective Well-Being\\nand&quot;, o) if(mod != &quot;none&quot;) titl &lt;- paste(m, &quot;Moderators of&quot;, titl) p1 &lt;- plot_grid( d$p[[1]], d$p[[2]] , d$p[[3]], d$p[[4]] , d$p[[5]], d$p[[6]] , d$p[[7]], d$p[[8]] , nrow = 4 , ncol = 2 , axis = &quot;tblr&quot; , align = &quot;hv&quot; ) my_theme &lt;- function(...) { theme_classic() + theme(plot.title = element_text(face = &quot;bold&quot;)) } title_theme &lt;- calc_element(&quot;plot.title&quot;, my_theme()) ttl &lt;- ggdraw() + draw_label( titl, fontfamily = title_theme$family, fontface = title_theme$face, size = title_theme$size ) my_theme &lt;- function(...) { theme_classic() + theme(plot.subtitle = element_text(hjust = 0)) } subtitle_theme &lt;- calc_element(&quot;subplot.title&quot;, my_theme()) subttl &lt;- ggdraw() + draw_label( &quot;Pooled Regression Using Random Effects&quot;, fontfamily = subtitle_theme$family, fontface = subtitle_theme$face, size = subtitle_theme$size ) p &lt;- cowplot::plot_grid(ttl, subttl, p1, rel_heights = c(.06, .03, .91), nrow = 3) ggsave(p , file = sprintf(&quot;%s/results/figures/study-specific-forest/%s_%s_%s.png&quot;, local_path, outcome, mod, cov) , width = 10, height = 10) ggsave(p , file = sprintf(&quot;%s/results/figures/study-specific-forest/%s_%s_%s.pdf&quot;, local_path, outcome, mod, cov) , width = 10, height = 10) return(T) } nested_reg_fp %&gt;% mutate(Trait = factor(Trait, traits$short_name)) %&gt;% arrange(Trait) %&gt;% select(-data) %&gt;% group_by(Outcome, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% # filter(Covariate == &quot;shared&quot; &amp; Outcome == &quot;dementia&quot;) %&gt;% mutate(p = pmap( list(Outcome, Covariate, Moderator, data) , possibly(ipd_rx_plot_comb_fun, NA_real_) )) knitr::include_graphics(&quot;https://github.com/emoriebeck/personality-dementia-neuropath/raw/master/results/figures/study-specific-forest/dementia_none_shared.png&quot;) 3.4.2.3 Overall Simple Effects loadRData &lt;- function(fileName, cov, obj, folder){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/results/%s/%s/%s&quot;, local_path, folder, cov, fileName) load(path) get(ls()[grepl(obj, ls())]) } ## load in &quot;fixed&quot; effects ## first get file names nested_mega_simp &lt;- tibble(Covariate = c(&quot;fully&quot;, &quot;shared&quot;, &quot;standard&quot;, &quot;butOne&quot;, &quot;unadjusted&quot;, &quot;shareddx&quot;, &quot;standarddx&quot;)) %&gt;% mutate(file = map(Covariate, ~list.files(sprintf(&quot;%s/results/predicted/%s&quot;, local_path, .)))) %&gt;% unnest(file) %&gt;% separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;), sep = &quot;_&quot;, remove = F) %&gt;% ## read in the files mutate(Moderator = str_remove(Moderator, &quot;.RData&quot;), pred.fx = map2(file, Covariate, ~loadRData(.x, .y, &quot;pred.fx&quot;, &quot;predicted&quot;)), pred.rx = map2(file, Covariate, ~loadRData(.x, .y, &quot;pred.rx&quot;, &quot;predicted&quot;))) %&gt;% select(-file) %&gt;% left_join( outcomes %&gt;% select(Outcome = short_name, link) ) %&gt;% mutate_at(vars(pred.fx, pred.rx), ~ifelse(link == &quot;factor&quot;, map(., ~(.) %&gt;% mutate_at(vars(pred, lower, upper), exp)), .)) nested_mega_simp ## # A tibble: 1,678 × 7 ## Covariate Outcome Trait Moderator pred.fx pred.rx link ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;chr&gt; ## 1 fully dementia A age &lt;tibble [303 × 5]&gt; &lt;tibble [606 × 6]&gt; factor ## 2 fully dementia A cognition &lt;tibble [303 × 5]&gt; &lt;tibble [606 × 6]&gt; factor ## 3 fully dementia A education &lt;tibble [303 × 5]&gt; &lt;tibble [606 × 6]&gt; factor ## 4 fully dementia A gender &lt;tibble [202 × 5]&gt; &lt;tibble [404 × 6]&gt; factor ## 5 fully dementia C education &lt;tibble [303 × 5]&gt; &lt;tibble [606 × 6]&gt; factor ## 6 fully dementia C gender &lt;tibble [202 × 5]&gt; &lt;tibble [404 × 6]&gt; factor ## 7 fully dementia E age &lt;tibble [303 × 5]&gt; &lt;tibble [606 × 6]&gt; factor ## 8 fully dementia E cognition &lt;tibble [303 × 5]&gt; &lt;tibble [606 × 6]&gt; factor ## 9 fully dementia E education &lt;tibble [303 × 5]&gt; &lt;tibble [606 × 6]&gt; factor ## 10 fully dementia E gender &lt;tibble [202 × 5]&gt; &lt;tibble [404 × 6]&gt; factor ## # … with 1,668 more rows simp_eff_fun &lt;- function(df, outcome, mod, cov, link){ print(paste(outcome, mod)) o &lt;- mapvalues(outcome, outcomes$short_name, outcomes$long_name, warn_missing = F) cv &lt;- cov# cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) m &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) dmini &lt;- round(min(df$pred),3); dmaxi = round(max(df$pred),3) d &lt;- round(max(abs(min(df$pred)), abs(max(df$pred))), 3) mini &lt;- if(link == &quot;factor&quot;) 0 else dmini - (dmaxi-dmini) maxi &lt;- dmaxi + (dmaxi-dmini) hl &lt;- if(link == &quot;factor&quot;) 1 else 0 brk &lt;- if(link == &quot;factor&quot;) c(round(mini*1.1,2), 1, round(maxi*.9,2)) else c(round(mini*1.1,2), 0, round(maxi*.9,2)) lab &lt;- if(link == &quot;factor&quot;) str_remove(c(round(mini*1.1,2), 1, round(maxi*.9,2)), &quot;^0&quot;) else str_remove(c(round(mini*1.1,2), 0, round(maxi*.9,2)), &quot;^0&quot;) # mini &lt;- if(link == &quot;factor&quot;) C1+(d+(d/5)) else 0+d+(d/5) lim &lt;- c(mini, maxi) # brk &lt;- if(link == &quot;factor&quot;) round(c(1-d-(d/10), 1, 1+d+(d/10)),2) else round(c(0-d-(d/10), 0, 0+d+(d/10)),2) # lab &lt;- if(link == &quot;factor&quot;) str_remove(c(round(1-d-(d/10),2), 1, round(1+d+(d/10),2)), &quot;^0&quot;) else{str_remove(c(round(0-d-(d/10),2), 0, round(0+d+(d/10),2)), &quot;^0&quot;)} titl &lt;- if(mod == &quot;none&quot;){o} else {sprintf(&quot;%s: Personality x %s Simple Effects&quot;, o, m)} lt &lt;- c(&quot;dotted&quot;, &quot;solid&quot;, &quot;dashed&quot;)[1:length(unique(df$mod_fac))] # if(link == &quot;factor&quot;) {mini &lt;- round(min(df$pred),2); maxi &lt;- round(max(df$pred),2)} else {mini &lt;- floor(min(df$pred)); maxi &lt;- ceiling(max(df$pred))} df %&gt;% mutate(Trait = factor(Trait, levels = traits$short_name, labels = traits$long_name), lower = ifelse(lower &lt; mini, mini, lower), upper = ifelse(upper &gt; maxi, maxi, upper)) %&gt;% ggplot(aes(x = p_value , y = pred , group = mod_fac)) + # ylim(c(mini, maxi)) + # scale_y_continuous(limits = lim#c(mini , maxi) # , breaks = round(seq(mini, maxi, length.out = 4),2) # , labels = round(seq(mini, maxi,length.out = 4), 2)) + scale_linetype_manual(values = lt) + geom_ribbon(aes(ymin = lower , ymax = upper , fill = mod_fac) , alpha = .25) + geom_hline(aes(yintercept = hl), linetype = &quot;dashed&quot;, size = .6, color = &quot;grey30&quot;) + geom_line(aes(linetype = mod_fac)) + labs(x = &quot;Personality (POMP)&quot; , y = if(link == &quot;factor&quot;) paste(o, &quot;(OR)&quot;) else paste(o, &quot;(POMP)&quot;) , title = str_wrap(titl, 40) , linetype = m , fill = m , subtitle = &quot;Pooled Regression Using Random Effects&quot;) + facet_wrap(~Trait, nrow = 3, scales = &quot;free&quot;) + theme_classic() + theme(legend.position = &quot;bottom&quot; , plot.title = element_text(face = &quot;bold&quot;, size = rel(1.2), hjust = .5) , plot.subtitle = element_text(size = rel(1.1), hjust = .5) , strip.background = element_rect(fill = &quot;black&quot;) , strip.text = element_text(face = &quot;bold&quot;, color = &quot;white&quot;) , axis.text = element_text(color = &quot;black&quot;)) ggsave(file = sprintf(&quot;%s/results/figures/overall-simple-effects/%s_%s_%s.png&quot;, local_path, outcome, mod, cov), width = 6, height = 6) } ipd_se_plot &lt;- nested_mega_simp %&gt;% select(-pred.rx) %&gt;% group_by(Outcome, Moderator, Covariate, link) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% unnest(pred.fx)), plot = pmap(list(data, Outcome, Moderator, Covariate, link), simp_eff_fun)) knitr::include_graphics(&quot;https://github.com/emoriebeck/personality-dementia-neuropath/raw/master/results/figures/overall-simple-effects/dementia_gender_shared.png&quot;) 3.4.2.4 Study-Specific Simple Effects ipd_std_se_plot_fun &lt;- function(df, outcome, trait, mod, cov, link){ fctr_vars &lt;- c(&quot;gender&quot;, &quot;smokes&quot;, &quot;alcohol&quot;, &quot;race&quot;, &quot;stroke&quot;, &quot;cancer&quot;, &quot;diabetes&quot;, &quot;heartProb&quot;, &quot;dementia&quot;) print(paste(outcome, mod)) o &lt;- mapvalues(outcome, outcomes$short_name, outcomes$long_name, warn_missing = F) trt &lt;- mapvalues(trait, traits$short_name, traits$long_name, warn_missing = F) cv &lt;- cov# cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) m &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) d &lt;- round(max(abs(min(df$pred)), abs(max(df$pred))), 3) # mini &lt;- if(d &gt; 2) .05 else 0-(d+(d/5)) # maxi &lt;- if(d &gt; 2) 2.05 else 0+d+(d/5) # lim &lt;- c(mini, maxi) # brk &lt;- if(d &gt; 2) c(0, 1, 2) else{round(c(0-d-(d/10), 0, 0+d+(d/10)),2)} # lab &lt;- if(d &gt; 2){c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;)} else{str_remove(c(round(0-d-(d/10),2), 0, round(0+d+(d/10),2)), &quot;^0&quot;)} titl &lt;- if(mod == &quot;none&quot;){sprintf(&quot;%s: %s&quot;, o, trt)} else {sprintf(&quot;%s: %s x %s Simple Effects&quot;, o, trt, m)} # colnames(df)[colnames(df) == mod] &lt;- &quot;mod_value&quot; # df &lt;- df %&gt;% unclass %&gt;% data.frame # df$mod_value &lt;- df[,mod] # df &lt;- df %&gt;% select(-all_of(mod)) %&gt;% as_tibble # # df &lt;- df %&gt;% group_by(study, p_value) %&gt;% summarize_at(vars(mod_value, pred, lower, upper), mean) %&gt;% ungroup() # if(class(df$mod_value) %in% c(&quot;factor&quot;, &quot;character&quot;)){ # df &lt;- df %&gt;% mutate(mod_fac = factor(mod_value)) # } else { # if(mod == &quot;age&quot;) df &lt;- df %&gt;% mutate(mod_fac = factor(mod_value, levels = c(-10, 0, 10), labels = c(&quot;-10 yrs&quot;, &quot;60&quot;, &quot;+10 yrs&quot;))) # else if(mod == &quot;education&quot;) df &lt;- df %&gt;% mutate(mod_fac = factor(mod_value, levels = c(-5, 0, 5), labels = c(&quot;-5 yrs&quot;, &quot;12 yrs&quot;, &quot;+5 yrs&quot;))) # else df &lt;- df %&gt;% select(p_value, study, mod_value) %&gt;% distinct() %&gt;% # group_by(study) %&gt;% mutate(mod_fac = factor(mod_value, levels = unique(mod_value), labels = c(&quot;-1 SD&quot;, &quot;M&quot;, &quot;+1 SD&quot;))) %&gt;% # left_join(df) # } std &lt;- unique(df$study) cols &lt;- (stdcolors %&gt;% filter(studies_long %in% std))$colors lt &lt;- (stdcolors %&gt;% filter(studies_long %in% std))$lt ht &lt;- length(unique(df$mod_fac)) if(link == &quot;factor&quot;) {mini &lt;- round(min(df$pred),2); maxi &lt;- round(max(df$pred),2)} else {mini &lt;- floor(min(df$pred)); maxi &lt;- ceiling(max(df$pred))} df &lt;- df %&gt;% mutate(study = factor(study, levels = stdcolors$studies_long, labels = stdcolors$studies_long), lower = ifelse(lower &lt; mini, mini, lower), upper = ifelse(upper &gt; maxi, maxi, upper), gr = ifelse(study == &quot;Overall&quot;, &quot;Overall&quot;, &quot;study&quot;)) %&gt;% group_by(study, mod_fac, p_value, gr) %&gt;% summarize_at(vars(pred, lower, upper), mean) %&gt;% ungroup() p &lt;- df %&gt;% ggplot(aes(x = p_value , y = pred , group = study)) + scale_y_continuous(limits = c(mini,maxi) , breaks = round(seq(mini, maxi, length.out = 4), 2) , labels = round(seq(mini, maxi, length.out = 4), 2)) + scale_linetype_manual(values = lt) + scale_color_manual(values = cols) + scale_fill_manual(values = cols) + scale_size_manual(values = c(2,.8)) + # geom_ribbon(data = df %&gt;% filter(study == &quot;Overall&quot;) # , aes(ymin = lower # , ymax = upper # , fill = study) # , alpha = .25) + geom_line(aes(linetype = study, color = study, size = gr)) + labs(x = &quot;Personality (POMP)&quot; , y = if(link == &quot;factor&quot;) paste(o, &quot;(OR)&quot;) else o , title = titl , linetype = &quot;Sample&quot; , color = &quot;Sample&quot; , fill = &quot;Sample&quot;) + guides(size = &quot;none&quot;, fill = &quot;none&quot;) + facet_wrap(~mod_fac, nrow = 1) + theme_classic() + theme(legend.position = &quot;bottom&quot; , plot.title = element_text(face = &quot;bold&quot;, size = rel(1.2), hjust = .5) , plot.subtitle = element_text(size = rel(1.1), hjust = .5) , strip.background = element_rect(fill = &quot;black&quot;) , strip.text = element_text(face = &quot;bold&quot;, color = &quot;white&quot;) , axis.text = element_text(color = &quot;black&quot;)) ggsave(p, file = sprintf(&quot;%s/results/figures/study-specific-simple-effects/%s_%s_%s_%s.png&quot;, local_path, outcome, trait, mod, cov), width = 3*ht, height = 5) return(p) } nested_simp_std_se &lt;- nested_mega_simp %&gt;% filter(Covariate != &quot;fully&quot;) %&gt;% mutate(pred.fx = map(pred.fx, ~(.) %&gt;% mutate(study = &quot;Overall&quot;)), comb.fx = map2(pred.fx, pred.rx, full_join)) %&gt;% select(-pred.fx, -pred.rx) %&gt;% # filter(Moderator %in% c(&quot;age&quot;, &quot;education&quot;)) %&gt;% mutate(pmap(list(comb.fx, Outcome, Trait, Moderator, Covariate, link), ipd_std_se_plot_fun)) 3.4.2.5 Significant Forest Plots &amp; Simple Effects std_eff_comb_plot_fun &lt;- function(p1, p2, cov, out, trt, mod){ print(paste(cov, out, trt, mod)) ttl &lt;- (cowplot::get_title(p2))$children ttl &lt;- str_wrap(ttl[[1]]$label, 45); print(ttl) p2 &lt;- p2 + labs(title = ttl) rw &lt;- if(length(levels(p2$data$mod_fac)) == 3) c(.35, .65) else c(.4, .6) p &lt;- plot_grid(p1, p2 , rel_widths = rw , align = &quot;v&quot; , axis = &quot;tb&quot; , ncol = 2 ) ggsave(p, file = sprintf(&quot;%s/results/figures/study-specific-combined/%s-%s-%s-%s.png&quot;, local_path, out, trt, mod, cov) , width = length(levels(p2$data$mod_fac))*3 + 3 , height = 5) ggsave(p, file = sprintf(&quot;%s/results/figures/study-specific-combined/%s-%s-%s-%s.pdf&quot;, local_path, out, trt, mod, cov) , width = length(levels(p2$data$mod_fac))*3 + 4 , height = 4) return(p) } nested_std_plots_comb &lt;- nested_reg_fp %&gt;% select(-p) %&gt;% unnest(data) %&gt;% filter(Moderator != &quot;none&quot; &amp; study != &quot;Overall&quot;) %&gt;% group_by(Covariate, Outcome, Trait, Moderator, sig) %&gt;% tally() %&gt;% group_by(Covariate, Outcome, Trait, Moderator) %&gt;% mutate(perc = n/sum(n)) %&gt;% ungroup() %&gt;% filter(sig == &quot;sig&quot; &amp; perc &gt; .3) %&gt;% select(-n,-perc) %&gt;% full_join( nested_reg_fp %&gt;% select(-p) %&gt;% unnest(data) %&gt;% filter(Moderator != &quot;none&quot; &amp; study == &quot;Overall&quot; &amp; sign(conf.low) == sign(conf.high)) %&gt;% select(Covariate:Moderator, sig) ) %&gt;% distinct() %&gt;% left_join( nested_reg_fp %&gt;% select(everything(), -data, fp=p) ) %&gt;% left_join( nested_simp_std_se %&gt;% select(everything(), -comb.fx, sep = `pmap(...)`) ) %&gt;% mutate(p = pmap(list(fp, sep, Covariate, Outcome, Trait, Moderator) , possibly(std_eff_comb_plot_fun, NA_real_))) knitr::include_graphics(&quot;https://github.com/emoriebeck/personality-dementia-neuropath/raw/master/results/figures/study-specific-simple-effects/dementia_N_cognition_shared.png&quot;) nested_std_plots_comb_panel &lt;- function(plist, cov, mod, nmod, trt_group){ p &lt;- plot_grid( plotlist = plist$p , ncol = 1 , align = &quot;h&quot; , axis = &quot;lr&quot; ) ggsave(p, file = sprintf(&quot;%s/results/figures/study-specific-combined-panels/%s-%s-%s.png&quot;, local_path, mod, cov, trt_group) , width = nmod*3+5 , height = nrow(plist)*3) ggsave(p, file = sprintf(&quot;%s/results/figures/study-specific-combined-panels/%s-%s-%s.pdf&quot;, local_path, mod, cov, trt_group) , width = nmod*3+5 , height = nrow(plist)*4) } nested_std_plots_comb %&gt;% filter(Moderator == &quot;dementia&quot;) %&gt;% mutate(nmod = map_dbl(sep, ~length(levels((.)$data$mod_fac))) , trt_group = mapvalues(Trait, traits$short_name, c(rep(&quot;big5&quot;, 5), rep(&quot;swb&quot;, 3)))) %&gt;% select(-fp, -sep) %&gt;% group_by(Covariate, Moderator, nmod, trt_group) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(p = pmap(list(data, Covariate, Moderator, nmod, trt_group), nested_std_plots_comb_panel)) nested_std_plots_comb_panel &lt;- function(plist, out, cov){ p &lt;- plot_grid( plotlist = plist$p , ncol = 1 , align = &quot;h&quot; , axis = &quot;lr&quot; ) ggsave(p, file = sprintf(&quot;%s/results/figures/study-specific-combined-panels/%s-%s.png&quot;, local_path, out, cov) , width = 3*3+6 , height = nrow(plist)*4) ggsave(p, file = sprintf(&quot;%s/results/figures/study-specific-combined-panels/%s-%s.pdf&quot;, local_path, out, cov) , width = 3*3+6 , height = nrow(plist)*4) } nested_reg_fp %&gt;% select(-p) %&gt;% unnest(data) %&gt;% filter(Moderator != &quot;none&quot; &amp; study == &quot;Overall&quot; &amp; sign(conf.low) == sign(conf.high)) %&gt;% select(Covariate:Moderator, sig) %&gt;% left_join(nested_std_plots_comb) %&gt;% arrange(Covariate, Outcome, Moderator, Trait) %&gt;% group_by(Covariate, Outcome) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(p = pmap(list(data, Outcome, Covariate), nested_std_plots_comb_panel)) knitr::include_graphics(&quot;https://github.com/emoriebeck/personality-dementia-neuropath/raw/master/results/figures/study-specific-combined-panels/dementia-shared-big5.png&quot;) knitr::include_graphics(&quot;https://github.com/emoriebeck/personality-dementia-neuropath/raw/master/results/figures/study-specific-combined-panels/dementia-shared-swb.png&quot;) hyp &lt;- c( &quot;p_value = 0&quot;, &quot;p_value + p_value:dementia1 = 0&quot; ); names(hyp) &lt;- c(&quot;Dementia = 0&quot;, &quot;Dementia = 1&quot;) # C - braak - dementia - shared load(&quot;/Volumes/Emorie/projects/dementia/prediction/results/models/shared/braak_C_dementia.RData&quot;) hypothesis(m, hyp, scope = &quot;coef&quot;, group = &quot;study&quot;) ## Hypothesis Tests for class : ## Group Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star ## 1 EAS Dementia = 0 -0.12 0.11 -0.32 0.08 NA NA ## 2 ROS Dementia = 0 -0.08 0.04 -0.15 -0.01 NA NA * ## 3 Rush-MAP Dementia = 0 -0.07 0.04 -0.15 0.00 NA NA ## 4 WUSM-MAP Dementia = 0 -0.13 0.05 -0.24 -0.03 NA NA * ## 5 EAS Dementia = 1 -0.04 0.05 -0.15 0.06 NA NA ## 6 ROS Dementia = 1 0.04 0.04 -0.04 0.12 NA NA ## 7 Rush-MAP Dementia = 1 0.02 0.05 -0.08 0.11 NA NA ## 8 WUSM-MAP Dementia = 1 0.04 0.04 -0.03 0.11 NA NA ## --- ## &#39;CI&#39;: 90%-CI for one-sided and 95%-CI for two-sided hypotheses. ## &#39;*&#39;: For one-sided hypotheses, the posterior probability exceeds 95%; ## for two-sided hypotheses, the value tested against lies outside the 95%-CI. ## Posterior probabilities of point hypotheses assume equal prior probabilities. hypothesis(m, hyp) ## Hypothesis Tests for class b: ## Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star ## 1 Dementia = 0 -0.10 0.07 -0.25 0.03 NA NA ## 2 Dementia = 1 0.01 0.08 -0.17 0.19 NA NA ## --- ## &#39;CI&#39;: 90%-CI for one-sided and 95%-CI for two-sided hypotheses. ## &#39;*&#39;: For one-sided hypotheses, the posterior probability exceeds 95%; ## for two-sided hypotheses, the value tested against lies outside the 95%-CI. ## Posterior probabilities of point hypotheses assume equal prior probabilities. # association only for individuals without dementia diag # C - vsclrMcrInfrcts - dementia - shared load(&quot;/Volumes/Emorie/projects/dementia/prediction/results/models/shared/vsclrMcrInfrcts_C_dementia.RData&quot;) hypothesis(m, hyp, scope = &quot;coef&quot;, group = &quot;study&quot;)$hypothesis %&gt;% mutate_at(vars(Estimate, CI.Lower, CI.Upper), exp) ## Group Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star ## 1 ROS Dementia = 0 0.9988061 0.06770320 0.8764605 1.143950 NA NA ## 2 Rush-MAP Dementia = 0 1.0447691 0.07200416 0.9105495 1.205530 NA NA ## 3 WUSM-MAP Dementia = 0 0.8432535 0.11765971 0.6625451 1.054259 NA NA ## 4 ROS Dementia = 1 1.1805017 0.06641137 1.0367432 1.355112 NA NA * ## 5 Rush-MAP Dementia = 1 1.2039033 0.08067321 1.0274525 1.409629 NA NA * ## 6 WUSM-MAP Dementia = 1 0.9797134 0.07422464 0.8476623 1.137349 NA NA hypothesis(m, hyp)$hypothesis %&gt;% mutate_at(vars(Estimate, CI.Lower, CI.Upper), exp) ## Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star ## 1 Dementia = 0 0.9754047 0.1729477 0.6870286 1.407625 NA NA ## 2 Dementia = 1 1.1438618 0.1839683 0.7751785 1.750536 NA NA # association only for individuals with dementia, such that C is risk for more pathology # N - vsclrMcrInfrcts - dementia - shared load(&quot;/Volumes/Emorie/projects/dementia/prediction/results/models/shared/vsclrMcrInfrcts_N_dementia.RData&quot;) hypothesis(m, hyp, scope = &quot;coef&quot;, group = &quot;study&quot;)$hypothesis %&gt;% mutate_at(vars(Estimate, CI.Lower, CI.Upper), exp) ## Group Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star ## 1 ROS Dementia = 0 1.0437675 0.05968691 0.9314426 1.1754425 NA NA ## 2 Rush-MAP Dementia = 0 1.0291555 0.06132083 0.9127782 1.1558555 NA NA ## 3 WUSM-MAP Dementia = 0 0.8443448 0.29233588 0.4643047 1.2229480 NA NA ## 4 ROS Dementia = 1 0.9040711 0.06041423 0.8014478 1.0129172 NA NA ## 5 Rush-MAP Dementia = 1 0.8294030 0.08189033 0.7090058 0.9682649 NA NA * ## 6 WUSM-MAP Dementia = 1 0.9789460 0.07911353 0.8446348 1.1450185 NA NA hypothesis(m, hyp)$hypothesis %&gt;% mutate_at(vars(Estimate, CI.Lower, CI.Upper), exp) ## Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star ## 1 Dementia = 0 0.9313774 0.2071516 0.6188457 1.273098 NA NA ## 2 Dementia = 1 0.9042091 0.1792381 0.6206919 1.363077 NA NA # association for indidvuals with dementia, usch that N is a protective factor against pathology # SWL - hipSclerosis - dementia - shared load(&quot;/Volumes/Emorie/projects/dementia/prediction/results/models/shared/hipSclerosis_SWL_dementia.RData&quot;) hypothesis(m, hyp, scope = &quot;coef&quot;, group = &quot;study&quot;)$hypothesis %&gt;% mutate_at(vars(Estimate, CI.Lower, CI.Upper), exp) ## Group Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star ## 1 ROS Dementia = 0 0.3873057437 1.2022471 9.461066e-03 0.9688038 NA NA * ## 2 Rush-MAP Dementia = 0 0.7703913938 0.1259654 5.871807e-01 1.0084614 NA NA ## 3 ROS Dementia = 1 0.0004545209 11.1017394 2.322757e-12 1.1098083 NA NA ## 4 Rush-MAP Dementia = 1 1.1578001156 0.1153198 9.317357e-01 1.3396036 NA NA hypothesis(m, hyp)$hypothesis %&gt;% mutate_at(vars(Estimate, CI.Lower, CI.Upper), exp) ## Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star ## 1 Dementia = 0 0.759799 0.4889561 0.2648956 2.026910 NA NA ## 2 Dementia = 1 1.244944 0.7665643 0.2256517 4.189413 NA NA # association for indidvuals without dementia, SWL protective against pathology # PA - tdp43 - dementia - shared load(&quot;/Volumes/Emorie/projects/dementia/prediction/results/models/shared/tdp43_PA_dementia.RData&quot;) hypothesis(m, hyp, scope = &quot;coef&quot;, group = &quot;study&quot;)$hypothesis %&gt;% mutate_at(vars(Estimate, CI.Lower, CI.Upper), exp) ## Group Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star ## 1 ROS Dementia = 0 1.0416263 0.15719939 0.8478363 1.580044 NA NA ## 2 Rush-MAP Dementia = 0 0.9614492 0.03858223 0.8939941 1.040813 NA NA ## 3 ROS Dementia = 1 1.2277700 0.18994277 0.9423959 1.965850 NA NA ## 4 Rush-MAP Dementia = 1 1.1038449 0.04651578 1.0060705 1.211011 NA NA * hypothesis(m, hyp)$hypothesis %&gt;% mutate_at(vars(Estimate, CI.Lower, CI.Upper), exp) ## Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star ## 1 Dementia = 0 0.9969027 0.2129140 0.6742554 1.671963 NA NA ## 2 Dementia = 1 1.1441791 0.3380502 0.5720831 2.377481 NA NA # association for indidvuals with dementia, SWL risk for pathology # SWL - vsclrInfrcts - dementia - shared load(&quot;/Volumes/Emorie/projects/dementia/prediction/results/models/shared/vsclrInfrcts_SWL_dementia.RData&quot;) hypothesis(m, hyp, scope = &quot;coef&quot;, group = &quot;study&quot;)$hypothesis %&gt;% mutate_at(vars(Estimate, CI.Lower, CI.Upper), exp) ## Group Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star ## 1 ROS Dementia = 0 0.9288913 0.14003998 0.6823330 1.169168 NA NA ## 2 Rush-MAP Dementia = 0 1.0803984 0.06045682 0.9603480 1.217140 NA NA ## 3 ROS Dementia = 1 0.7829734 0.17091983 0.5244175 1.041787 NA NA ## 4 Rush-MAP Dementia = 1 0.8976146 0.06612901 0.7898269 1.024365 NA NA hypothesis(m, hyp)$hypothesis %&gt;% mutate_at(vars(Estimate, CI.Lower, CI.Upper), exp) ## Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star ## 1 Dementia = 0 1.0323883 0.2540358 0.5857555 1.843218 NA NA ## 2 Dementia = 1 0.8802098 0.3689337 0.3921431 1.934083 NA NA # association for indidvuals with dementia, SWL risk for pathology "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
