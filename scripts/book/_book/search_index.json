[["index.html", "Personality Predictors of Dementia Diagnosis and Neuropathic Burden: A Mega-Analysis Chapter 1 Workspace 1.1 Packages 1.2 Directory Path 1.3 Codebook 1.4 Tables", " Personality Predictors of Dementia Diagnosis and Neuropathic Burden: A Mega-Analysis Emorie D. Beck University of California, Davis Tomiko Yoneda Feinberg School of Medicine Daniel K. Mroczek Feinberg School of Medicine, Northwestern University Eileen K. Graham Feinberg School of Medicine 27 July 2023 Abstract “INTRODUCTION: The extent to which the Big Five personality traits and subjective well-being (SWB) are discriminatory predictors of clinical manifestation of dementia versus dementia-related neuropathology is unclear.” “METHODS: Using data from eight independent studies (Ntotal=44,531; baseline Mage= years, % female), Bayesian multilevel models tested whether traits and SWB differentially predicted neuropsychological and neuropathological characteristics of dementia.” “RESULTS: Adjusting for sociodemographic and health covariates, synthesized and individual study results indicate that high neuroticism, low conscientiousness, and high negative affect were associated with increased risk of long-term dementia diagnosis.” “DISCUSSION: This multi-study project provides robust, conceptually replicated evidence that psychosocial factors are strong predictors of dementia diagnosis, but differentially associated with neuropathology at autopsy as a function of premorbid dementia diagnoses in some samples. These results suggest the possible importance of brain maintenance or test performance, while also highlighting the need for ongoing data collection efforts to disentangle these complex relationships.” Chapter 1 Workspace In this section, we’ll set up everything we need to clean data in the next section. This includes: Loading in all packages Loading in the codebook Setting up data frames for personality traits / well-being, outcomes, covariates, and moderators, so that we can more easily rename their short-hand names to production ready ones later Loading in and rendering html tables of some descriptives, measures, etc. 1.1 Packages First, let’s load in the packages. Note the descriptions for each commented next to them. library(knitr) # knit documents library(kableExtra) # formatted tables library(readxl) # read excel files library(haven) # read spss files library(broom.mixed) # summaries of models library(rstan) # bayes underpinnings library(tidybayes) # pretty bayes draws and plots library(cowplot) # piece plots together library(plyr) # data wrangling library(tidyverse) # data wrangling library(brms) # bayesian models library(furrr) # parallel purrr mapping library(psych) # psychometrics 1.2 Directory Path We have three different directories: 1. data_path stores the raw that that cannot be shared per data use agreements 2. res_path includes the GitHub link where shareable objects can be found 3. local_path is mostly used to save files as they render, or in some limited cases of objects that hold raw data, to access those objects that can’t be shared data_path &lt;- &quot;/Volumes/Emorie/data&quot; # res_path &lt;- &quot;/Volumes/Emorie/projects/dementia/prediction&quot; res_path &lt;- &quot;https://github.com/emoriebeck/personality-dementia-neuropath/raw/master&quot; local_path &lt;- &quot;/Volumes/Emorie/projects/dementia/prediction&quot; 1.3 Codebook Each study has a separate codebook indexing covariate, moderator, personality, and outcome variables. Moreover, these codebooks contain information about the original scale of the variable, any recoding of the variable (including binarizing outcomes, changing the scale, and removing missing data), reverse coding of scale variables, categories, etc. # list of all codebook sheets url &lt;- &quot;https://github.com/emoriebeck/personality-dementia-neuropath/raw/master/codebooks/master_codebook_09.04.20.xlsx?raw=true&quot; destfile &lt;- &quot;master_codebook_09.04.20.xlsx&quot; # destfile &lt;- sprintf(&quot;%s/codebooks/%s&quot;, local_path, destfile) curl::curl_download(url, destfile) sheets &lt;- excel_sheets(destfile) # function for reading in sheets read_fun &lt;- function(x){ read_xlsx(destfile, sheet = x) } # read in sheets and index source codebook &lt;- tibble( study = sheets, codebook = map(study, read_fun) ) ## short and long versions of names of all categories for later use studies &lt;- c(&quot;ROS&quot;, &quot;RADC-MAP&quot;, &quot;EAS&quot;, &quot;ADRC&quot; , &quot;SATSA&quot;, &quot;HRS&quot;, &quot;LISS&quot;, &quot;GSOEP&quot;) studies_long &lt;- c(&quot;ROS&quot;, &quot;Rush-MAP&quot;, &quot;EAS&quot;, &quot;WUSM-MAP&quot;, &quot;SATSA&quot;, &quot;HRS&quot;, &quot;LISS&quot;, &quot;GSOEP&quot;) stdcolors &lt;- tibble( studies = c(&quot;Overall&quot;, studies) , studies_long = c(&quot;Overall&quot;, studies_long) , std_text = str_remove_all(studies, &quot;[-]&quot;) , colors = c(&quot;black&quot;, &quot;#332288&quot;, &quot;#88ccee&quot;, &quot;#44aa99&quot;, &quot;#117733&quot;, &quot;#999933&quot;, #&quot;#ddcc77&quot;, &quot;#cc6677&quot;, &quot;#332288&quot;, &quot;#88ccee&quot;, &quot;#44aa99&quot;)#, &quot;#117733&quot;, &quot;#999933&quot;, &quot;#ddcc77&quot;) , lt = c(rep(&quot;solid&quot;, 6), rep(&quot;dotted&quot;, 3))) traits &lt;- codebook$codebook[[2]] %&gt;% filter(category == &quot;pers&quot;) %&gt;% select(long_name = Construct, short_name = name); traits ## # A tibble: 8 × 2 ## long_name short_name ## &lt;chr&gt; &lt;chr&gt; ## 1 Extraversion E ## 2 Agreeableness A ## 3 Conscientiousness C ## 4 Neuroticism N ## 5 Openness to Experience O ## 6 Positive Affect PA ## 7 Negative Affect NA ## 8 Satisfaction with Life SWL outcomes &lt;- codebook$codebook[[2]] %&gt;% filter(category == &quot;out&quot;) %&gt;% select(long_name = Construct, short_name = name, link, colnm); outcomes ## # A tibble: 11 × 4 ## long_name short_name link colnm ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Incident Dementia Diagnosis dementia factor OR [CI] ## 2 Braak Stage braak continuous b [CI] ## 3 CERAD cerad continuous b [CI] ## 4 Lewy Body Disease lewyBodyDis factor OR [CI] ## 5 Gross Cerebral Infarcts vsclrInfrcts factor OR [CI] ## 6 Gross Cerebral Microinfarcts vsclrMcrInfrcts factor OR [CI] ## 7 Cerebral Atherosclerosis atherosclerosis continuous b [CI] ## 8 Cerebral Amyloid Angiopathy angiopathy continuous b [CI] ## 9 Arteriolosclerosis arteriolosclerosis continuous b [CI] ## 10 Hippocampal Sclerosis hipSclerosis factor OR [CI] ## 11 TDP-43 tdp43 factor OR [CI] moders &lt;- codebook$codebook[[2]] %&gt;% filter(category == &quot;mod&quot;) %&gt;% select(long_name = Construct, short_name = name, short_term = old_term, long_term = new_term); moders ## # A tibble: 6 × 4 ## long_name short_name short_term long_term ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 None none p_value Personality ## 2 Age age age Age ## 3 Gender gender gender1 Gender (Male v Female) ## 4 Education education education Education (Years) ## 5 Cognition cognition cognition Cognition ## 6 Dementia Diagnosis dementia dementia Dementia Diagnosis (No v Yes) covars &lt;- codebook$codebook[[2]] %&gt;% filter(category == &quot;covariates&quot;) %&gt;% select(long_name = Construct, short_name = name, desc = new_term); covars ## # A tibble: 8 × 3 ## long_name short_name desc ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Unadjusted unadjusted Unadjusted indicates no covariates were… ## 2 Fully Adjusted fully Fully adjusted models include age, gend… ## 3 Shared Covariates Adjusted shared Shared covariates adjusted models Inclu… ## 4 Standard Covariates Adjusted standard Standard covariates adjusted models inc… ## 5 All But One Covariate Adjusted butOne All but one covariate adjusted models i… ## 6 Shared Covariates Adjusted (With Dementia Diagnosis) shareddx Shared covariates with dementia adjuste… ## 7 Standard Covariates Adjusted (With Dementia Diagnosis) standarddx Standard covariates with dementia adjus… ## 8 Shared Covariates Adjusted (With Prediction Interval) sharedint Shared covariates with prediction inter… # used personality waves url &lt;- &quot;https://github.com/emoriebeck/personality-dementia-neuropath/raw/master/codebooks/tables.xlsx?raw=true&quot; destfile &lt;- &quot;tables.xlsx&quot; # destfile &lt;- sprintf(&quot;%s/codebooks/%s&quot;, local_path, destfile) curl::curl_download(url, destfile) p_waves &lt;- read_xlsx(destfile, sheet = &quot;Table 2&quot;) 1.4 Tables 1.4.1 Table S1 Below, I create Table S1, which includes information the personality and well-being scales used in each study: p_tab &lt;- p_waves %&gt;% select(Study, everything(), -p_item, -Used) %&gt;% filter(Study != &quot;BLSA&quot;) %&gt;% mutate(Measure = factor(Measure, traits$long_name)) %&gt;% arrange(Study, Measure) rs &lt;- p_tab %&gt;% group_by(Study) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) p_tab &lt;- p_tab %&gt;% select(-Study) %&gt;% kable(. , &quot;html&quot; , caption = &quot;&lt;strong&gt;Table S1&lt;/strong&gt;&lt;br&gt;&lt;em&gt;Personality Trait and Subjective Well-Being Measurement Inventories, Scales, and Assessments Across Samples&lt;/em&gt;&quot; , escape = F , col.names = paste0(&quot;&lt;strong&gt;&quot;, colnames(p_tab)[-1], &quot;&lt;/strong&gt;&quot;) , align = c(&quot;r&quot;, &quot;l&quot;, &quot;l&quot;, &quot;c&quot;) ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) for (i in 1:nrow(rs)){ p_tab &lt;- p_tab %&gt;% kableExtra::group_rows(rs$Study[i], rs$start[i], rs$end[i]) } p_tab Table 1.1: Table S1Personality Trait and Subjective Well-Being Measurement Inventories, Scales, and Assessments Across Samples Measure Source Scale Used (Available) EAS Extraversion 24 items from the IPIP NEO 1 “strongly disagree” to 5 “strongly agree” 2004 (Annual Follow-ups) Agreeableness 24 items from the IPIP NEO 1 “strongly disagree” to 5 “strongly agree” 2004 (Annual Follow-ups) Conscientiousness 24 items from the IPIP NEO 1 “strongly disagree” to 5 “strongly agree” 2004 (Annual Follow-ups) Neuroticism 24 items from the IPIP NEO 1 “strongly disagree” to 5 “strongly agree” 2004 (Annual Follow-ups) Openness to Experience 24 items from the IPIP NEO 1 “strongly disagree” to 5 “strongly agree” 2004 (Annual Follow-ups) Positive Affect — — — Negative Affect — — — Satisfaction with Life — — — GSOEP Extraversion 3 items from the 15 item BFI-S (John, Naumann, &amp; Soto, 2008, and Lang, Lüdtke, &amp; Asendorpf, 2001) 1 “does not apply at all” to 7 ” applies perfectly” 2005 (2005, 2009, 2013, 2017) Agreeableness 3 items from the 15 item BFI-S (John, Naumann, &amp; Soto, 2008, and Lang, Lüdtke, &amp; Asendorpf, 2001) 1 “does not apply at all” to 7 ” applies perfectly” 2005 (2005, 2009, 2013, 2017) Conscientiousness 3 items from the 15 item BFI-S (John, Naumann, &amp; Soto, 2008, and Lang, Lüdtke, &amp; Asendorpf, 2001) 1 “does not apply at all” to 7 ” applies perfectly” 2005 (2005, 2009, 2013, 2017) Neuroticism 3 items from the 15 item BFI-S (John, Naumann, &amp; Soto, 2008, and Lang, Lüdtke, &amp; Asendorpf, 2001) 1 “does not apply at all” to 7 ” applies perfectly” 2005 (2005, 2009, 2013, 2017) Openness to Experience 3 items from the 15 item BFI-S (John, Naumann, &amp; Soto, 2008, and Lang, Lüdtke, &amp; Asendorpf, 2001) 1 “does not apply at all” to 7 ” applies perfectly” 2005 (2005, 2009, 2013, 2017) Positive Affect 1 item (“Frequency of being happy in the last 4 weeks”) 1 “very seldom” to 5 “very often” 2007 (2007-2017) Negative Affect 3 items (angry, sad, worried) 1 “very seldom” to 5 “very often” 2007 (2007-2017) Satisfaction with Life SWLS (Diener, Emmons, Larsen, &amp; Griffin, 1985) 0 “low” to 10 “high” 2005 (1984-2017) HRS Extraversion 5 adjectives from a 25 adjective checklist (Lachman &amp; Weaver, 1997) **1 “a lot” to 4 “not at all” 2006/8 (2006/8, 2010/12, 2014/16) Agreeableness 5 adjectives from a 25 adjective checklist (Lachman &amp; Weaver, 1997) **1 “a lot” to 4 “not at all” 2006/8 (2006/8, 2010/12, 2014/16) Conscientiousness 5 adjectives from a 25 adjective checklist (Lachman &amp; Weaver, 1997) **1 “a lot” to 4 “not at all” 2006/8 (2006/8, 2010/12, 2014/16) Neuroticism 5 adjectives from a 25 adjective checklist (Lachman &amp; Weaver, 1997) **1 “a lot” to 4 “not at all” 2006/8 (2006/8, 2010/12, 2014/16) Openness to Experience 5 adjectives from a 25 adjective checklist (Lachman &amp; Weaver, 1997) **1 “a lot” to 4 “not at all” 2006/8 (2006/8, 2010/12, 2014/16) Positive Affect PANAS-X (Watson &amp; Clark, 1994) *1 “very much” to 5 “not at all” 2006-2016 Negative Affect PANAS-X (Watson &amp; Clark, 1994) *1 “very much” to 5 “not at all” 2006-2016 Satisfaction with Life SWLS (Diener, Emmons, Larsen, &amp; Griffin, 1985) 1 “strongly disagree” to 7 “strongly agree” 2006/8 (2006/8, 2010/12, 2014/16) LISS Extraversion 10 items from the 50 item IPIP-50 (Goldberg, 1992) 1 “very inaccurate” to 5 “very accurate” 2008 (2008-2018) Agreeableness 10 items from the 50 item IPIP-50 (Goldberg, 1992) 1 “very inaccurate” to 5 “very accurate” 2008 (2008-2018) Conscientiousness 10 items from the 50 item IPIP-50 (Goldberg, 1992) 1 “very inaccurate” to 5 “very accurate” 2008 (2008-2018) Neuroticism 10 items from the 50 item IPIP-50 (Goldberg, 1992) 1 “very inaccurate” to 5 “very accurate” 2008 (2008-2018) Openness to Experience 10 items from the 50 item IPIP-50 (Goldberg, 1992) 1 “very inaccurate” to 5 “very accurate” 2008 (2008-2018) Positive Affect 10 items (e.g. “interested”) 1 “not at all” to 7 “extremely” 2008 (2008-2018) Negative Affect 10 items (e.g. “distressed”) 1 “not at all” to 7 “extremely” 2008 (2008-2018) Satisfaction with Life SWLS (Diener, Emmons, Larsen, &amp; Griffin, 1985) 1 “strongly disagree” to 7 “strongly agree” 2008 (2008-2018) RUSH-MAP Extraversion 6 items from the NEO Five Factor Inventory 1 “strongly disagree” to 5 “strongly agree” Baseline (Baseline) Agreeableness — — — Conscientiousness 12 items from the NEO Five-Factor Inventory (NEO-FFI; Costa &amp; McCrae, 1992) 1 “strongly disagree” to 5 “strongly agree” Baseline (Baseline) Neuroticism 12 items from the NEO Five-Factor Inventory (NEO-FFI; Costa &amp; McCrae, 1992) 1 “strongly disagree” to 5 “strongly agree” Baseline (Baseline) Openness to Experience — — — Positive Affect 1 item “Overall, how happy are you?” *1 “Very happy” to 4 “Not happy at all” Baseline (Annual Clinical Followups) Negative Affect PANAS-X (Watson &amp; Clark, 1994) 1 “Very slightly or not at al” to 5 “Extremely” Baseline (Annual Clinical Followups) Satisfaction with Life SWLS (Diener, Emmons, Larsen, &amp; Griffin, 1985) *1 “Strongly agree” to 7 “Strongly Disagree” Baseline (Annual Clinical Followups) RUSH-ROS Extraversion 6 items from the NEO Five Factor Inventory 1 “strongly disagree” to 5 “strongly agree” Baseline (Baseline) Agreeableness 12 items from the NEO Five-Factor Inventory (NEO-FFI; Costa &amp; McCrae, 1992) 1 “strongly disagree” to 5 “strongly agree” Baseline (Baseline) Conscientiousness 12 items from the NEO Five-Factor Inventory (NEO-FFI; Costa &amp; McCrae, 1992) 1 “strongly disagree” to 5 “strongly agree” Baseline (Baseline) Neuroticism 12 items from the NEO Five-Factor Inventory (NEO-FFI; Costa &amp; McCrae, 1992) 1 “strongly disagree” to 5 “strongly agree” Baseline (Baseline) Openness to Experience 12 items from the NEO Five-Factor Inventory (NEO-FFI; Costa &amp; McCrae, 1992) 1 “strongly disagree” to 5 “strongly agree” Baseline (Baseline) Positive Affect 1 item “Overall, how happy are you?” *1 “Very happy” to 4 “Not happy at all” Baseline (Annual Clinical Followups) Negative Affect — — — Satisfaction with Life SWLS (Diener, Emmons, Larsen, &amp; Griffin, 1985) *1 “Strongly agree” to 7 “Strongly Disagree” Baseline (Annual Clinical Followups) SATSA Extraversion 9 items from the Eysenck Personality Inventory **1 “exactly right” to 5 “not right at all” 1984 (1984, 1987, 1989, 1990, 1992, 1993, 1999, 2002, 2004, 2005, 2007) Agreeableness 10 items **1 “exactly right” to 5 “not right at all” 1984 (1984) Conscientiousness 10 items **1 “exactly right” to 5 “not right at all” 1984 (1984) Neuroticism 9 items from the Eysenck Personality Inventory **1 “exactly right” to 5 “not right at all” 1984 (1984, 1987, 1989, 1990, 1992, 1993, 1999, 2002, 2004, 2005, 2007) Openness to Experience 25 items from the NEO Personality Inventory **1 “exactly right” to 5 “not right at all” 1984 (1984) Positive Affect 5 items (e.g., “calm”, “harmonious”) **1 “exactly right” to 5 “not right at all” 1984 (1984, 1987, 1989, 1990, 1992, 1993, 1995) Positive Affect 6 items (e.g., “worried”, “tense”) **1 “exactly right” to 5 “not right at all” 1984 (1984, 1987, 1989, 1990, 1992, 1993, 1995) Satisfaction with Life 13 items **1 “exactly right” to 5 “not right at all” 1984 (1984, 1987, 1989, 1990, 1993, 2004, 2007) WUSM-MAP Extraversion 12 items from the NEO Five-Factor Inventory (NEO-FFI; Costa &amp; McCrae, 1992) 1 “strongly disagree” to 5 “strongly agree” Baseline (Clinical Follow-ups) Agreeableness 12 items from the NEO Five-Factor Inventory (NEO-FFI; Costa &amp; McCrae, 1992) 1 “strongly disagree” to 5 “strongly agree” Baseline (Clinical Follow-ups) Conscientiousness 12 items from the NEO Five-Factor Inventory (NEO-FFI; Costa &amp; McCrae, 1992) 1 “strongly disagree” to 5 “strongly agree” Baseline (Clinical Follow-ups) Neuroticism 12 items from the NEO Five-Factor Inventory (NEO-FFI; Costa &amp; McCrae, 1992) 1 “strongly disagree” to 5 “strongly agree” Baseline (Clinical Follow-ups) Openness to Experience 12 items from the NEO Five-Factor Inventory (NEO-FFI; Costa &amp; McCrae, 1992) 1 “strongly disagree” to 5 “strongly agree” Baseline (Clinical Follow-ups) Positive Affect — — — Negative Affect — — — Satisfaction with Life — — — save_kable(p_tab, file = sprintf(&quot;%s/results/tables/tab-s1.html&quot;, local_path)) 1.4.2 Table S2 Next, I create table S2, which indicates which measures were in each study, including which cognitive measures were in each sample. meas &lt;- read_xlsx(destfile, sheet = &quot;Table 1&quot;) %&gt;% select(-BLSA) rs &lt;- meas %&gt;% group_by(Category) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) meas &lt;- meas %&gt;% select(-Category) %&gt;% kable(. , &quot;html&quot; , caption = &quot;&lt;strong&gt;Table S2&lt;/strong&gt;&lt;br&gt;&lt;em&gt;List of Measures Across Samples&lt;/em&gt;&quot; , escape = F , col.names = paste0(&quot;&lt;strong&gt;&quot;, colnames(meas)[-1], &quot;&lt;/strong&gt;&quot;) , align = c(&quot;l&quot;, rep(&quot;c&quot;, 8)) ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) for (i in 1:nrow(rs)){ meas &lt;- meas %&gt;% kableExtra::group_rows(rs$Category[i], rs$start[i], rs$end[i]) } meas Table 1.2: Table S2List of Measures Across Samples Measure GSOEP HRS LISS SATSA RUSH-MAP RUSH-ROS ADRC-MAP EAS Cognitive Extraversion X X X X X X X X Agreeableness X X X X X X Conscientiousness X X X X X X X Neuroticism X X X X X X X X Openness to Experience X X X X X X X Satisfaction with Life X X X X X X X Positive Affect X X X X X Negative Affect X X X X Self-Reported Dementia X X X X X X X X Braak Stage X X X X CERAD X X X Lewy Body Disease X X X X Gross Cerebral Infarcts X X X Gross Cerebral Microinfarcts X X X Cerebral Atherosclerosis X X X Cerebral Amyloid Angiopathy X X X Covariates Arteriolosclerosis X X X Hippocampal Sclerosis X X X X Block Design X X X Digits Forward X X X X X Digits Backward X X X X X X Information X X X Digit Symbol X X X X X Cued Recall X X X Free Recall X X X X X Category Fluency X X X X X Picture Memory X Figure Logic X Vocabulary X X Boston Naming Test X X Outcomes Progressive Matrices X Serial 7’s X Trail-Making Task X X Card Rotation Age X X X X X X X X Gender X X X X X X X X Education X X X X X X X X Race X X X X Ethnicity X X X X Marital Status X X X X X X X X Personality Self-Rated Health X X X X X X Heart Problems X X X X X X X X Stroke X X X X X X X X Diabetes X X X X X X X X Cancer X X X X X X X X Respiratory Problems X X X X X X X X Smoking X X X X X X X Alcohol X X X X X X X save_kable(meas, file = sprintf(&quot;%s/results/tables/tab-s2.html&quot;, local_path)) 1.4.3 Table S3 Next, I create table S3, which indicates previous uses of the samples, their findings, and the distinction between them and the present study. uses &lt;- read_xlsx(destfile, sheet = &quot;Table S3&quot;) meas &lt;- uses %&gt;% kable(. , &quot;html&quot; , caption = &quot;&lt;strong&gt;Table S3&lt;/strong&gt;&lt;br&gt;&lt;em&gt;List of Prior Publications Examining Personality-Dementia or Neuropathology Associations&lt;/em&gt;&quot; , escape = F , col.names = paste0(&quot;&lt;strong&gt;&quot;, colnames(uses), &quot;&lt;/strong&gt;&quot;) , align = c(&quot;l&quot;, rep(&quot;c&quot;, 7), &quot;l&quot;, &quot;l&quot;) ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) meas Table 1.3: Table S3List of Prior Publications Examining Personality-Dementia or Neuropathology Associations Paper Year Ref # Sample(s) N Data Measures Outcomes Findings Comparison with Current Study Terracciano et al.  2014 5 BLSA (IPD) N = 1671 IPD + meta-analysis E, A, C, N, O Cognitive Status N -&gt; higher risk C -&gt; lower risk BLSA not used in the present sample. Meta-analyzed results from Rush-MAP and ROS, but included much smaller sample (we used an additional 10-15 years of data). Wilson et al.  2006 50 Rush-MAP N = 648 IPD N Cognitive Status N -&gt; higher risk Additional waves of data (~15 years of additional follow-ups). Used Cox Proportional Hazards Models. Only examined Neuroticism Wilson et al.  2007 6 ROS N = 997 IPD C Cognitive Status C -&gt; lower risk Additional waves of data (~15 years of additional follow-ups). Used Cox Proportional Hazards Models. Only examined Conscientiousness Wilson et al.  2015 – ROS, Rush-MAP N = 309 IPD C NFT, Lewy bodies, chronic gross cerebral infarctions, and hippocampal sclerosis,, terminal decline C -&gt; slower terminal but not preterminal decline Additional waves of data. Focus was on cognitive decline, not diagnosis. Only examined deceased participants. Additional waves of follow-up data. Terracciano et al.  2017 49 HRS N = 13,882 IPD E, A, C, N, O Cognitive Status N -&gt; higher risk C, A -&gt; lower risk Used Cox Proportional Hazards Models. Additional waves of follow-up data. Yoneda et al.  2020 52 EAS LASA N (EAS) = 785 N (LASA) = 1300 IPD E, A, C, N, O Cognitive Status N increases -&gt; higher risk We additionally include neuropathology data from EAS. Examined associations between personality and change and cognitive status, not baseline levels. Duchek et al.  2020 34 WUSM-MAP N = 436 IPD N, C In vivo neuropathology Clinical Dementia Ratings C -&gt; lower early dementia risk Focused on in vivo neuropathology, rather than neuropathology at autopsy. Only examined taransitions to early stage dementia. Only investigated N and C. Additional waves of follow-up data. Graham et al.  2021a 51 ROS Rush-MAP N (ROS) = 783 N (MAP) = 857 IPD E, A (ROS), C, O (ROS), N Cognitive Resilience (residual of global cognitive function / decline regressed on pathology) N-&gt; worse resilience Focused on association between personality traits and asymmetry between neuropathology and cognitive function / decline. Did not account for dementia diagnoses. Additional waves of follow-up data. Aschwanden et al.  2020 – ELSA HILDA N (ELSA) = 6,887 N (HILDA) = 2,778 Meta-analysis E, A, C, N, O Cognitive Status from cognitive tests C -&gt; lower dementia risk (ELSA only) Used Cox Proportional Hazards Models Different cognitive status indicator that allowed us to use more of the sample. Additional waves of follow-up data. Aschwanden et al.  2021 19 Rush-MAP ROS WUSM-MAP ELSA HILDA N (Rush-MAP) = 648 N (ROS) = 904 N (WUSM-MAP) = 436 N (ELSA) = 6887 N (HILDA) = 2778 IPD E, A, C, N, O Cognitive Status N -&gt; higher risk C -&gt; lower risk Used Cox Proportional Hazards Models. Only meta-analyzed existing previous data that, in many cases, had many fewer waves of follow-up. Covariates determined by previous publications. Graham et al.  2021b 22 EAS MAP ROS SATSA N (EAS) = 737 N (Rush-MAP) = 1233 N (ROS) = 1466 N (SATSA) = 707 IPD E, A, C, N, O Cognitive Status O -&gt; post-dementia decline Additional waves of data for EAS, Rush-MAP, and ROS. Focus was on personality predictors of cognitive decline (slope) and cognitive decline following dementia diagnosis. No reported associations between personality traits and cognitive status. save_kable(meas, file = sprintf(&quot;%s/results/tables/tab-s3.html&quot;, local_path)) "],["cleaning.html", "Chapter 2 Data Cleaning 2.1 Health and Retirement Study (HRS) 2.2 RUSH Memory and and Aging Project (RUSH-MAP) 2.3 RUSH Religious Orders Study (ROS) 2.4 Swedish Adoption Twin Study of Aging (SATSA) 2.5 ADRC Memory and Aging Project (ADRC-MAP) 2.6 Einstein Aging Study 2.7 German Socioeconomic Panel Study (GSOEP) 2.8 The Longitudinal Studies for the Social sciences (LISS)", " Chapter 2 Data Cleaning In this section, we will clean the data for each study. Raw data cannot be shared directly, but for each study, we include instrucitons on how to access the data. Mode &lt;- function(x) { ux &lt;- unique(x) ux &lt;- ux[!is.na(ux)] ux[which.max(tabulate(match(x, ux)))] } pomp &lt;- function(x) (x - min(x, na.rm = T))/(max(x, na.rm = T) - min(x, na.rm = T))*10 2.1 Health and Retirement Study (HRS) The Health and Retirement Study [HRS; (juster1995overview?)] is an ongoing longitudinal study of households in the United States. These data are available at https://hrs.isr.umich.edu by creating a free account. Participants were recruited from more than 35,000 individuals from the financial households of individuals born between 1931 and 1941 in the US. Data have been collected biannually since 1992. The latest data release includes data up to 2016. On average, 10,000 individuals are sampled each wave More information on the HRS can be found at https://hrs.isr.umich.edu/documentation/survey-design, but, in short, the HRS is a nationally representative sample of adults over 50 in the US. It is critical to note that the HRS samples households of the original cohort and follows individuals and their spouses or partners until their death. Sample size varies by year, ranging from approximately 7,500 (2014) to 15,500 (1992). (https://hrs.isr.umich.edu/sites/default/files/biblio/ResponseRates_2017.pdf). This provides 99% power to detect a zero-order correlation effect size of ~.04, two-tailed at alpha .05. 2.1.1 Load Data hrs_read_fun &lt;- function(year) { read_da &lt;- function(da, dct, Year){ print(paste(da, dct, year, sep = &quot; &quot;)) data.file &lt;- sprintf(&quot;%s/hrs/%s/%s&quot;, data_path, Year, da) # Set path to the dictionary file &quot;*.DCT&quot; dict.file &lt;- sprintf(&quot;%s/hrs/%s/%s&quot;, data_path, Year, dct) # Read the dictionary file df.dict &lt;- read.table(dict.file, skip = 1, fill = TRUE, stringsAsFactors = FALSE) # Set column names for dictionary dataframe colnames(df.dict) &lt;- c(&quot;col.num&quot;,&quot;col.type&quot;,&quot;col.name&quot;,&quot;col.width&quot;,&quot;col.lbl&quot;) # Remove last row which only contains a closing } row &lt;- which(df.dict$col.name == &quot;HHID&quot;) df.dict &lt;- df.dict[-nrow(df.dict),] if(row == 2){df.dict &lt;- df.dict[-1,]} # Extract numeric value from column width field df.dict$col.width &lt;- as.integer(sapply(df.dict$col.width, gsub, pattern = &quot;[^0-9\\\\.]&quot;, replacement = &quot;&quot;)) # Convert column types to format to be used with read_fwf function df.dict$col.type &lt;- sapply(df.dict$col.type, function(x) ifelse(x %in% c(&quot;int&quot;,&quot;byte&quot;,&quot;long&quot;), &quot;i&quot;, ifelse(x == &quot;float&quot;, &quot;n&quot;, ifelse(x == &quot;double&quot;, &quot;d&quot;, &quot;c&quot;)))) # Read the data file into a dataframe df &lt;- read_fwf(file = data.file, fwf_widths(widths = df.dict$col.width, col_names = df.dict$col.name), col_types = paste(df.dict$col.type, collapse = &quot;&quot;)) # Add column labels to headers attributes(df)$variable.labels &lt;- df.dict$col.lbl old.names &lt;- (hrs_codebook %&gt;% filter(year == Year))$orig_itemname if(any(c(&quot;PN&quot;, &quot;HHID&quot;) %in% colnames(df)) &amp; any(old.names %in% colnames(df))){ # if(any(c(&quot;PN&quot;, &quot;HHID&quot;) %in% colnames(df))){ df &lt;- df %&gt;% mutate(hhidpn = 1000*as.numeric(HHID) + as.numeric(PN)) %&gt;% select(one_of(c(&quot;PN&quot;, &quot;HHID&quot;)), one_of(old.names)) %&gt;% distinct() # gather(key = item, value = value, -hhidpn) } else {df &lt;- NA} return(df) } # Set path to the data file &quot;*.DA&quot; files &lt;- list.files(sprintf(&quot;%s/hrs/%s&quot;, data_path, year)) df2 &lt;- tibble( da = files[grepl(&quot;.da&quot;, files) | grepl(&quot;.DA&quot;, files)], dct = files[grepl(&quot;.dct&quot;, files) | grepl(&quot;.DCT&quot;, files)] ) %&gt;% mutate(data = map2(da, dct, possibly(~read_da(.x, .y, year), NA_real_))) %&gt;% filter(!is.na(data)) %&gt;% select(-da, -dct) if(nrow(df2) != 0){df2$data %&gt;% reduce(full_join) %&gt;% distinct()} else {NA} } hrs_codebook &lt;- (codebook %&gt;% filter(study == &quot;HRS&quot;))$codebook[[1]] %&gt;% mutate(orig_itemname = str_to_upper(orig_itemname)) %&gt;% mutate_at(vars(orig_itemname, name, itemname), ~str_remove_all(., &quot;[[:space:]]&quot;)) hrs_codebook ## # A tibble: 702 × 17 ## study dataset category name itemname wave waveletter year orig_itemname description scale reverse_code ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 hrs Rand cogniti… cogn… digitsB… 3 &lt;NA&gt; 1996 R3BWC20 BACKWARDS … &quot;0.I… no ## 2 hrs Rand cogniti… cogn… digitsB… 4 &lt;NA&gt; 1998 R4BWC20 BACKWARDS … &quot;0.I… no ## 3 hrs Rand cogniti… cogn… digitsB… 5 &lt;NA&gt; 2000 R5BWC20 BACKWARDS … &quot;0.I… no ## 4 hrs Rand cogniti… cogn… digitsB… 6 &lt;NA&gt; 2002 R6BWC20 BACKWARDS … &quot;0.I… no ## 5 hrs Rand cogniti… cogn… digitsB… 7 &lt;NA&gt; 2004 R7BWC20 BACKWARDS … &quot;0.I… no ## 6 hrs Rand cogniti… cogn… digitsB… 8 &lt;NA&gt; 2006 R8BWC20 BACKWARDS … &quot;0.I… no ## 7 hrs Rand cogniti… cogn… digitsB… 9 &lt;NA&gt; 2008 R9BWC20 BACKWARDS … &quot;0.I… no ## 8 hrs Rand cogniti… cogn… digitsB… 10 &lt;NA&gt; 2010 R10BWC20 BACKWARDS … &quot;0.I… no ## 9 hrs Rand cogniti… cogn… digitsB… 11 &lt;NA&gt; 2012 R11BWC20 BACKWARDS … &quot;0.I… no ## 10 hrs Rand cogniti… cogn… digitsB… 12 &lt;NA&gt; 2014 R12BWC20 BACKWARDS … &quot;0.I… no ## # ℹ 692 more rows ## # ℹ 5 more variables: recode &lt;chr&gt;, mini &lt;dbl&gt;, maxi &lt;dbl&gt;, comp_rule &lt;chr&gt;, long_rule &lt;chr&gt; old.names &lt;- unique(hrs_codebook$orig_itemname) hrs.paq &lt;- tibble( year = sprintf(&quot;%s/hrs&quot;, data_path) %&gt;% list.files(., pattern = &quot;^[0-9]&quot;) , data = map(year, hrs_read_fun) , names = map(data, colnames) ) %&gt;% filter(!is.na(data)) old.names &lt;- unique((hrs_codebook %&gt;% filter(dataset == &quot;Rand&quot;))$orig_itemname) hrs.rand &lt;- sprintf(&quot;%s/hrs/randhrs1992_2016v1.sav&quot;, data_path) %&gt;% haven::read_sav(.) %&gt;% haven::zap_labels(.) %&gt;% select(SID = HHIDPN, one_of(old.names)) %&gt;% gather(key = orig_itemname, value = value, -SID, na.rm = T) hrs_long &lt;- hrs.paq %&gt;% mutate(data = map(data, ~(.) %&gt;% pivot_longer(cols = c(-HHID, -PN) , names_to = &quot;orig_itemname&quot; , values_to = &quot;value&quot; , values_drop_na = TRUE))) %&gt;% select(-names, -year) %&gt;% unnest(data) %&gt;% mutate(SID = 1000*as.numeric(HHID) + as.numeric(PN)) %&gt;% select(-PN, -HHID) hrs_dem &lt;- sprintf(&quot;%s/hrs/pdem_withvarnames.sas7bdat&quot;, data_path) %&gt;% haven::read_sas(.) %&gt;% select(SID = hhidpn, year = prediction_year, value = prob_dementia) %&gt;% mutate(orig_itemname = &quot;PROB_DEMENTIA&quot;) hrs.subs &lt;- unique(hrs_long$SID)[unique(hrs_long$SID) %in% unique(hrs.rand$SID)] hrs_long &lt;- hrs_long %&gt;% bind_rows(hrs.rand %&gt;% select(orig_itemname, value, SID)) %&gt;% filter(SID %in% hrs.subs) save(hrs.rand, hrs.paq, file = sprintf(&quot;%s/data/clean/hrs_raw.RData&quot;, local_path)) rm(list = c(&quot;hrs.paq&quot;, &quot;hrs.rand&quot;)) 2.1.2 Recoding &amp; Reverse Scoring hrs_waves &lt;- p_waves %&gt;% filter(Study == &quot;HRS&quot;) %&gt;% select(Used) %&gt;% distinct() # join data with recoding info hrs_recode &lt;- hrs_codebook %&gt;% filter(category %in% c(&quot;pers&quot;, &quot;outcome&quot;, &quot;covariates&quot;, &quot;cognition&quot;) &amp; orig_itemname != &quot;prob_dementia&quot;) %&gt;% select(category, name, itemname, wave, year, orig_itemname, reverse_code:long_rule) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% left_join(hrs_long))) hrs_recode &lt;- hrs_dem %&gt;% left_join( hrs_codebook %&gt;% select(category, name, itemname, orig_itemname, reverse_code:long_rule) ) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() %&gt;% bind_rows(hrs_recode) # recode recode_fun &lt;- function(rule, y, year, p_year){ x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } hrs_recode &lt;- hrs_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(year = mapvalues(year, seq(2006, 2016, 2), rep(c(2006, 2010, 2014), each = 2)), p_year = 2006) %&gt;% group_by(recode, year, p_year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(recode, data, year, p_year), recode_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(value &lt; 0 | is.nan(value) | is.infinite(value), NA, value)))) # reverse code hrs_recode &lt;- hrs_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(value = ifelse(reverse_code == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))))) fun_call &lt;- function(x, rule){ switch(rule, average = mean(x, na.rm = T), mode = Mode(x)[1], sum = sum(x, na.rm = T), skip = unique(x)[1], select = unique(x)[1], max = max(x, na.rm = T), min = min(x, na.rm = T)) } 2.1.3 Covariates # compositing within years year_comp_fun &lt;- function(df, rule){ df %&gt;% # group by person and item (collapse across age) group_by(SID, name, year, p_year, long_rule) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } # composite WITHIN years hrs_cov &lt;- hrs_recode %&gt;% filter(category == &quot;covariates&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule), &quot;skip&quot;, comp_rule)) %&gt;% group_by(comp_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, year_comp_fun)) %&gt;% unnest(data) comp_fun &lt;- function(d, rule, p_year){ d %&gt;% filter(year &lt;= p_year) %&gt;% group_by(SID, name) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% distinct() } # composite ACROSS years hrs_cov &lt;- hrs_cov %&gt;% mutate(long_rule = ifelse(is.na(long_rule), &quot;skip&quot;, long_rule)) %&gt;% group_by(p_year, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(data, long_rule, p_year), comp_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %&gt;% select(-long_rule) %&gt;% spread(name, value) %&gt;% filter(!is.na(SID)) hrs_cov ## # A tibble: 28,726 × 19 ## p_year SID alcohol BMI cancer diabetes education exercise gender heartProb height married race ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2006 3010 1 28.8 0 0 12 2.02 0 1 165. 1 0 ## 2 2006 3020 1 28.8 1 0 16 1.77 1 0 165. 1 0 ## 3 2006 10001010 0 23.5 0 0 12 1.88 0 0 183. 0 0 ## 4 2006 10003030 0 28.5 0 0 16 1.25 1 1 157. 1 0 ## 5 2006 10004010 1 27.0 1 0 16 1.75 0 0 185. 1 0 ## 6 2006 10004040 1 27.0 0 0 12 2 1 0 165. 1 0 ## 7 2006 10013010 0 28.2 0 1 12 1.57 0 1 177. 1 0 ## 8 2006 10013040 1 24.5 0 0 13 1.5 1 0 160. 1 0 ## 9 2006 10038010 1 23.3 0 0 16 1.75 0 1 177. 1 0 ## 10 2006 10038040 1 23.3 0 0 16 1.78 1 0 170. 1 0 ## # ℹ 28,716 more rows ## # ℹ 6 more variables: respDis &lt;dbl&gt;, smokes &lt;dbl&gt;, SRhealth &lt;dbl&gt;, stroke &lt;dbl&gt;, weight &lt;dbl&gt;, ## # yearBrth &lt;dbl&gt; 2.1.4 Personality Variables hrs_pers &lt;- hrs_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% filter(year == &quot;2006&quot; &amp; !is.na(value)) %&gt;% group_by(SID, p_year, year, name, itemname, comp_rule) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() # alpha&#39;s hrs_alpha &lt;- hrs_pers %&gt;% filter(!is.na(value)) %&gt;% select(name, itemname, year, SID, value) %&gt;% group_by(name, year) %&gt;% nest() %&gt;% mutate(data = map(data, ~(.) %&gt;% distinct() %&gt;% pivot_wider(names_from = itemname, values_from = value, values_fn = list(mean))), alpha = map(data, possibly(~psych::alpha((.) %&gt;% select(-SID)), NA_real_))) comp_fun &lt;- function(df, rule){ df %&gt;% group_by(SID) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } # create composites hrs_pers &lt;- hrs_pers %&gt;% group_by(name, comp_rule, year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, comp_fun)) %&gt;% unnest(data) %&gt;% select(-comp_rule) hrs_pers ## # A tibble: 116,915 × 4 ## year name SID value ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2006 A 3010 3 ## 2 2006 A 3020 3 ## 3 2006 A 10001010 4 ## 4 2006 A 10003030 3.4 ## 5 2006 A 10004010 3.4 ## 6 2006 A 10004040 3.6 ## 7 2006 A 10013010 2 ## 8 2006 A 10013040 2.6 ## 9 2006 A 10038010 3.4 ## 10 2006 A 10038040 2.6 ## # ℹ 116,905 more rows 2.1.5 Cognition Variables hrs_cog &lt;- hrs_recode %&gt;% filter(category == &quot;cognition&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% filter(year == p_year) %&gt;% filter(!is.na(value)) %&gt;% group_by(name, itemname, year) %&gt;% mutate(value = pomp(value)) %&gt;% group_by(SID, name) %&gt;% summarize(value = mean(value)) %&gt;% ungroup() %&gt;% pivot_wider(names_from = &quot;name&quot;, values_from = &quot;value&quot;) hrs_cog ## # A tibble: 16,778 × 2 ## SID cognition ## &lt;dbl&gt; &lt;dbl&gt; ## 1 3010 7.5 ## 2 3020 8.08 ## 3 10001010 8.75 ## 4 10003030 6 ## 5 10004010 7.92 ## 6 10004040 8.83 ## 7 10013010 7.25 ## 8 10013040 8.67 ## 9 10038010 8.58 ## 10 10038040 8.25 ## # ℹ 16,768 more rows 2.1.6 Outcome Variables # composite within years # compositing within years hrs_out &lt;- hrs_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% unnest(data) %&gt;% group_by(SID, name, year, p_year) %&gt;% summarize(value = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.nan(value) | is.infinite(value), NA, value), group = ifelse(year &gt; p_year, &quot;future&quot;, &quot;past&quot;)) %&gt;% filter(!is.na(value)) %&gt;% group_by(SID, p_year, year, name, group) %&gt;% mutate(value = ifelse(value &lt; .5, 0, 1) , o_year = max(year[!is.na(value)])) %&gt;% group_by(SID, p_year, name, group, o_year) %&gt;% summarize(value = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value), NA, value)) %&gt;% pivot_wider(names_from = group, values_from = value) %&gt;% group_by(SID, name, o_year) %&gt;% mutate(value = ifelse(is.na(past) | (past == 0 &amp; !is.na(future)), future, ifelse(past == 0 &amp; is.na(future), past, ifelse(past == 1, NA, NA)))) %&gt;% group_by(SID, p_year, name) %&gt;% mutate(o_year = max(o_year)) %&gt;% group_by(SID, p_year, o_year, name) %&gt;% summarize(value = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value), NA, value)) %&gt;% ungroup() hrs_out ## # A tibble: 27,187 × 5 ## SID p_year o_year name value ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 3010 2006 2010 dementia 1 ## 2 3020 2006 2014 dementia 0 ## 3 10001010 2006 2014 dementia 0 ## 4 10003030 2006 2014 dementia 0 ## 5 10004010 2006 2010 dementia 0 ## 6 10004040 2006 2014 dementia 0 ## 7 10013010 2006 2014 dementia 1 ## 8 10013040 2006 2014 dementia 0 ## 9 10038010 2006 2014 dementia 0 ## 10 10038040 2006 2014 dementia 0 ## # ℹ 27,177 more rows 2.1.7 Combine Data hrs_combined &lt;- hrs_pers %&gt;% rename(Trait = name, p_value = value, p_year = year) %&gt;% full_join(hrs_out %&gt;% select(SID, Outcome = name, o_value = value, o_year)) %&gt;% full_join(hrs_cov) %&gt;% left_join( hrs_out %&gt;% filter(name == &quot;dementia&quot;) %&gt;% pivot_wider(names_from = &quot;name&quot;, values_from = &quot;value&quot;) ) %&gt;% full_join(hrs_cog) %&gt;% filter(!is.na(p_value) &amp; !is.na(o_value)) %&gt;% mutate(age = p_year - yearBrth) hrs_combined ## # A tibble: 112,097 × 27 ## p_year Trait SID p_value Outcome o_value o_year alcohol BMI cancer diabetes education exercise ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2006 A 3010 3 dementia 1 2010 1 28.8 0 0 12 2.02 ## 2 2006 A 3020 3 dementia 0 2014 1 28.8 1 0 16 1.77 ## 3 2006 A 10001010 4 dementia 0 2014 0 23.5 0 0 12 1.88 ## 4 2006 A 10003030 3.4 dementia 0 2014 0 28.5 0 0 16 1.25 ## 5 2006 A 10004010 3.4 dementia 0 2010 1 27.0 1 0 16 1.75 ## 6 2006 A 10004040 3.6 dementia 0 2014 1 27.0 0 0 12 2 ## 7 2006 A 10013010 2 dementia 1 2014 0 28.2 0 1 12 1.57 ## 8 2006 A 10013040 2.6 dementia 0 2014 1 24.5 0 0 13 1.5 ## 9 2006 A 10038010 3.4 dementia 0 2014 1 23.3 0 0 16 1.75 ## 10 2006 A 10038040 2.6 dementia 0 2014 1 23.3 0 0 16 1.78 ## # ℹ 112,087 more rows ## # ℹ 14 more variables: gender &lt;dbl&gt;, heartProb &lt;dbl&gt;, height &lt;dbl&gt;, married &lt;dbl&gt;, race &lt;dbl&gt;, ## # respDis &lt;dbl&gt;, smokes &lt;dbl&gt;, SRhealth &lt;dbl&gt;, stroke &lt;dbl&gt;, weight &lt;dbl&gt;, yearBrth &lt;dbl&gt;, ## # dementia &lt;dbl&gt;, cognition &lt;dbl&gt;, age &lt;dbl&gt; save(hrs_cov, hrs_alpha, hrs_pers, hrs_out, hrs_combined, hrs_cog, file = sprintf(&quot;%s/data/clean/hrs_cleaned.RData&quot;, local_path)) rm(list =ls()[grepl(&quot;hrs&quot;, ls())]) 2.2 RUSH Memory and and Aging Project (RUSH-MAP) The RUSH Memory and Aging Project (RUSH-MAP) is an ongoing longitudinal study that began in 1997 (a2012overview?). These data are available, through application from https://www.radc.rush.edu/requests.htm. Participants who were 65 and older were recruited from retirement communities and subsidized senior housing facilities throughout Chicagoland and northeastern Illinois beginning in 1997. Data are collected annually, and all participants are organ donors. Additional participants are recuited each year. Additional information and documentation on the data can be found at https://www.radc.rush.edu/docs/var/variables.htm. Sample sizes vary by year, ranging from 52 (1997) to 2205 participants including 884 deceased participants with autopsy data (2019, 2020). This provides 99% power to detect a zero-order correlation effect size of ~.10, two-tailed at alpha .05. 2.2.1 Load Data (map_codebook &lt;- (codebook %&gt;% filter(study == &quot;RADC-MAP&quot;))$codebook[[1]] %&gt;% mutate(orig_itemname = str_to_lower(orig_itemname))) ## # A tibble: 44 × 15 ## study dataset category name itemname year orig_itemname description scale reverse_code recode mini ## &lt;chr&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 RADC-MAP NA cognition cogn… freeRec… long… cts_wlii word list … &lt;NA&gt; no ifels… NA ## 2 RADC-MAP NA cognition cogn… cuedRec… long… cts_wliii word list … &lt;NA&gt; no ifels… NA ## 3 RADC-MAP NA cognition cogn… digitsF… long… cts_df digits bac… &lt;NA&gt; no ifels… NA ## 4 RADC-MAP NA cognition cogn… digitsB… long… cts_db digits for… &lt;NA&gt; no ifels… NA ## 5 RADC-MAP NA cognition cogn… catFlue… long… cts_catflu category f… &lt;NA&gt; no ifels… NA ## 6 RADC-MAP NA cognition cogn… bosNami… long… cts_bname Boston nam… &lt;NA&gt; no ifels… NA ## 7 RADC-MAP NA cognition cogn… progMat long… cts_pmat progressiv… &lt;NA&gt; no ifels… NA ## 8 RADC-MAP NA cognition cogn… digitSy… long… cts_sdmt symbol dig… &lt;NA&gt; no ifels… NA ## 9 RADC-MAP NA covariat… age ageBase… base… age_bl The age at… &lt;NA&gt; no ifels… NA ## 10 RADC-MAP NA covariat… alco… alcohol base… alcohol_g_bl Grams of a… &quot;\\r\\… no ifels… NA ## # ℹ 34 more rows ## # ℹ 3 more variables: maxi &lt;dbl&gt;, comp_rule &lt;chr&gt;, long_rule &lt;chr&gt; map &lt;- sprintf(&quot;%s/rush-radc/dataset_1033_long_03-24-2021.xlsx&quot;, data_path) %&gt;% read_excel() %&gt;% full_join(sprintf(&quot;%s/rush-radc/dataset_1033_basic_03-24-2021.xlsx&quot;, data_path) %&gt;% read_excel()) %&gt;% full_join(sprintf(&quot;%s/rush-radc/dataset_1034_long_03-25-2021.xlsx&quot;, data_path) %&gt;% read_excel()) %&gt;% full_join(sprintf(&quot;%s/rush-radc/dataset_1034_basic_03-25-2021.xlsx&quot;, data_path) %&gt;% read_excel()) %&gt;% filter(study == &quot;MAP&quot;) 2.2.2 Recoding &amp; Reverse Scoring rename_fun &lt;- function(cb, var){ print(var) old.names &lt;- unique((map_codebook %&gt;% filter(name == var))$orig_itemname) df &lt;- map %&gt;% select(SID = projid, wave = fu_year, one_of(old.names)) %&gt;% gather(key = orig_itemname, value = value, -SID, -wave, na.rm = T) %&gt;% left_join(cb %&gt;% select(itemname, orig_itemname, reverse_code:long_rule)) } # join data with recoding info map_recode &lt;- map_codebook %&gt;% select(category, name, itemname, year, orig_itemname, reverse_code:long_rule) %&gt;% filter(category %in% c(&quot;pers&quot;, &quot;outcome&quot;, &quot;covariates&quot;, &quot;cognition&quot;)) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, name, rename_fun)) # recode recode_fun &lt;- function(rule, y, year){ x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } map_recode &lt;- map_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(wave = as.numeric(wave)) %&gt;% group_by(recode, wave) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(recode, data, wave), recode_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(value &lt; 0 | is.nan(value) | is.infinite(value), NA, value)))) # reverse code map_recode &lt;- map_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(value = as.numeric(value), value = ifelse(reverse_code == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))))) fun_call &lt;- function(x, rule){ switch(rule, average = mean(x, na.rm = T), mode = Mode(x)[1], sum = sum(x, na.rm = T), skip = unique(x)[1], select = unique(x)[1], max = max(x, na.rm = T), min = min(x, na.rm = T)) } 2.2.3 Covariates # composite WITHIN years map_cov &lt;- map_recode %&gt;% filter(category == &quot;covariates&quot;) %&gt;% select(-category) %&gt;% mutate(data = map(data, ~(.) %&gt;% filter(!is.na(value)) %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule), &quot;skip&quot;, comp_rule)) %&gt;% group_by(comp_rule, SID, wave, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %&gt;% unnest(data) %&gt;% filter(wave == 0) )) comp_fun &lt;- function(d, rule){ d %&gt;% group_by(SID, name) %&gt;% summarize(value = fun_call(data, rule)) %&gt;% ungroup() %&gt;% distinct() } # composite ACROSS years map_cov &lt;- map_cov %&gt;% unnest(data) %&gt;% mutate(long_rule = ifelse(is.na(long_rule), &quot;skip&quot;, long_rule)) %&gt;% group_by(long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(data, long_rule), comp_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %&gt;% select(-long_rule) %&gt;% spread(name, value) %&gt;% filter(!is.na(SID)) map_cov ## # A tibble: 2,192 × 16 ## SID age alcohol BMI cancer diabetes education exercise gender heartProb married mmse parkinsons ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 00009121 80.0 1 26.8 0 0 12 1 0 0 1 29 0 ## 2 00033027 81.0 0 32.6 0 1 14 0 0 0 1 29 0 ## 3 00045071 87.5 1 28.2 0 1 16 1 1 1 1 18 0 ## 4 00130005 89.8 0 27.8 0 0 15 1 0 1 1 29 0 ## 5 00204228 65.2 0 36.6 0 1 8 1 1 0 1 27 0 ## 6 00228190 73.5 1 23.0 1 0 22 1 0 0 1 29 0 ## 7 00246264 90.0 0 24.0 0 0 16 1 0 0 1 27 0 ## 8 00285563 84.7 0 27.0 0 0 12 1 0 0 1 28 0 ## 9 00402800 78.7 0 17.2 0 0 16 1 0 0 1 17 0 ## 10 00482428 81.4 1 NA 1 0 12 1 0 0 1 30 0 ## # ℹ 2,182 more rows ## # ℹ 3 more variables: race &lt;dbl&gt;, smokes &lt;dbl&gt;, stroke &lt;dbl&gt; 2.2.4 Personality Variables map_pers &lt;- map_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% distinct() %&gt;% group_by(SID, name) %&gt;% filter(wave == min(wave)) %&gt;% ungroup() %&gt;% select(SID, name, wave, value) map_pers ## # A tibble: 9,115 × 4 ## SID name wave value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 00009121 C 0 35 ## 2 00045071 C 0 38 ## 3 00130005 C 0 31 ## 4 00246264 C 0 33 ## 5 00402800 C 0 24 ## 6 00582981 C 0 37 ## 7 00617643 C 0 34 ## 8 00696418 C 0 27 ## 9 00701662 C 0 31 ## 10 00709354 C 0 40 ## # ℹ 9,105 more rows 2.2.5 Outcome Variables map_out_waves &lt;- map_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% unnest(data) %&gt;% group_by(SID, name) %&gt;% summarize(o_year = max(wave)) %&gt;% ungroup() map_out &lt;- map_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% select(-category) %&gt;% unnest(data) map_dem &lt;- map_out %&gt;% filter(name == &quot;dementia&quot;) %&gt;% group_by(SID, name, wave) %&gt;% summarize(value = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.nan(value) | is.infinite(value), NA, value), group = ifelse(wave &gt; 0, &quot;future&quot;, &quot;past&quot;)) %&gt;% group_by(SID, name, group) %&gt;% summarize(value = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value), NA, value)) %&gt;% pivot_wider(names_from = group, values_from = value) %&gt;% group_by(SID, name) %&gt;% mutate(value = ifelse(is.na(past) | (past == 0 &amp; !is.na(future)), future, ifelse(past == 0 &amp; is.na(future), past, ifelse(past == 1, NA, NA)))) %&gt;% ungroup() comp_fun &lt;- function(df, rule){ df %&gt;% group_by(SID) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } # create composites map_out &lt;- map_out %&gt;% filter(wave &gt; 0 &amp; name != &quot;dementia&quot;) %&gt;% group_by(name, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, long_rule, comp_fun)) %&gt;% unnest(data) %&gt;% select(-long_rule) %&gt;% full_join(map_dem) %&gt;% left_join(map_out_waves) map_out ## # A tibble: 11,128 × 6 ## name SID value future past o_year ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ageDementia 00045071 88.5 NA NA 1 ## 2 ageDementia 00285563 90.5 NA NA 13 ## 3 ageDementia 00668310 88.6 NA NA 5 ## 4 ageDementia 01243685 89.7 NA NA 3 ## 5 ageDementia 01797756 86.4 NA NA 11 ## 6 ageDementia 02108769 90.9 NA NA 8 ## 7 ageDementia 03227207 97.8 NA NA 17 ## 8 ageDementia 03380931 85.7 NA NA 7 ## 9 ageDementia 03806878 92.4 NA NA 5 ## 10 ageDementia 04330337 101. NA NA 15 ## # ℹ 11,118 more rows 2.2.6 Cognition Variables # composite within years map_cog &lt;- map_recode %&gt;% filter(category == &quot;cognition&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% filter(wave == 0) %&gt;% filter(!is.na(value)) %&gt;% group_by(name, itemname, wave) %&gt;% mutate(value = pomp(value)) %&gt;% group_by(name, SID) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() %&gt;% pivot_wider(names_from = &quot;name&quot; , values_from = &quot;value&quot;) map_cog ## # A tibble: 2,189 × 2 ## SID cognition ## &lt;chr&gt; &lt;dbl&gt; ## 1 00009121 7.55 ## 2 00033027 6.17 ## 3 00045071 4.84 ## 4 00130005 6.59 ## 5 00204228 5.81 ## 6 00228190 7.38 ## 7 00246264 6.16 ## 8 00285563 5.79 ## 9 00402800 4.14 ## 10 00482428 6.58 ## # ℹ 2,179 more rows 2.2.7 Combine Data map_combined &lt;- map_pers %&gt;% rename(Trait = name, p_value = value, p_year = wave) %&gt;% full_join( map_out %&gt;% select(Outcome = name, SID, o_value = value, o_year) ) %&gt;% full_join(map_cov) %&gt;% left_join( map_out %&gt;% filter(name == &quot;dementia&quot;) %&gt;% mutate(value = ifelse(rowSums(cbind(future, past), na.rm = T) &gt;= 1, 1, 0)) %&gt;% select(-future, -past) %&gt;% pivot_wider(names_from = &quot;name&quot;, values_from = &quot;value&quot;) ) %&gt;% full_join(map_cog) %&gt;% filter(!is.na(p_value) &amp; !is.na(o_value)) map_combined ## # A tibble: 42,999 × 24 ## SID Trait p_year p_value Outcome o_value o_year age alcohol BMI cancer diabetes education exercise ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 00009… C 0 35 dement… 0 10 80.0 1 26.8 0 0 12 1 ## 2 00045… C 0 38 ageDem… 88.5 1 87.5 1 28.2 0 1 16 1 ## 3 00045… C 0 38 dement… 1 1 87.5 1 28.2 0 1 16 1 ## 4 00130… C 0 31 dement… 0 4 89.8 0 27.8 0 0 15 1 ## 5 00246… C 0 33 angiop… 2 8 90.0 0 24.0 0 0 16 1 ## 6 00246… C 0 33 arteri… 2 8 90.0 0 24.0 0 0 16 1 ## 7 00246… C 0 33 athero… 1 8 90.0 0 24.0 0 0 16 1 ## 8 00246… C 0 33 braak 3 8 90.0 0 24.0 0 0 16 1 ## 9 00246… C 0 33 cerad 2 8 90.0 0 24.0 0 0 16 1 ## 10 00246… C 0 33 hipScl… 0 8 90.0 0 24.0 0 0 16 1 ## # ℹ 42,989 more rows ## # ℹ 10 more variables: gender &lt;dbl&gt;, heartProb &lt;dbl&gt;, married &lt;dbl&gt;, mmse &lt;dbl&gt;, parkinsons &lt;dbl&gt;, ## # race &lt;dbl&gt;, smokes &lt;dbl&gt;, stroke &lt;dbl&gt;, dementia &lt;dbl&gt;, cognition &lt;dbl&gt; save(map_cov, map_pers, map_out, map_combined, map_cog, file = sprintf(&quot;%s/data/clean/radc-map_cleaned.RData&quot;, load_path)) rm(list =ls()[grepl(&quot;map&quot;, ls())]) 2.3 RUSH Religious Orders Study (ROS) The RUSH Religious Orders Study (ROS) is an ongoing longitudinal study that began in 1994 (a2012overview?). These data are available, through application from https://www.radc.rush.edu/requests.htm. Older (65 and above) Catholic nuns, priests, and brothers with no prior dementia diagnosis and who agreed to annual evaluations and eventual organ donation were recruited from more than 40 groups across the United States. Additional participants are recuited each year. Additional information and documentation on the data can be found at https://www.radc.rush.edu/docs/var/variables.htm. Sample sizes vary bt year from 353 participants (1994) to 1487 participants, including 797 deceased participants with autopsy data (2019, 2020). This provides 99% power to detect a zero-order correlation effect size of ~.11, two-tailed at alpha .05. (ros_codebook &lt;- (codebook %&gt;% filter(study == &quot;ROS&quot;))$codebook[[1]] %&gt;% mutate(orig_itemname = str_to_lower(orig_itemname))) ## # A tibble: 42 × 15 ## study dataset category name itemname year orig_itemname description scale reverse_code recode mini ## &lt;chr&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 ROS NA cognition cognit… freeRec… long… cts_wlii word list … &lt;NA&gt; no ifels… NA ## 2 ROS NA cognition cognit… cuedRec… long… cts_wliii word list … &lt;NA&gt; no ifels… NA ## 3 ROS NA cognition cognit… digitsF… long… cts_df digits bac… &lt;NA&gt; no ifels… NA ## 4 ROS NA cognition cognit… digitsB… long… cts_db digits for… &lt;NA&gt; no ifels… NA ## 5 ROS NA cognition cognit… catFlue… long… cts_catflu category f… &lt;NA&gt; no ifels… NA ## 6 ROS NA cognition cognit… bosNami… long… cts_bname Boston nam… &lt;NA&gt; no ifels… NA ## 7 ROS NA cognition cognit… progMat long… cts_pmat progressiv… &lt;NA&gt; no ifels… NA ## 8 ROS NA cognition cognit… digitSy… long… cts_sdmt symbol dig… &lt;NA&gt; no ifels… NA ## 9 ROS NA covariates age ageBase… base… age_bl The age at… &lt;NA&gt; no ifels… NA ## 10 ROS NA covariates alcohol alcohol base… alcohol_g_bl Grams of a… &quot;\\r\\… no ifels… NA ## # ℹ 32 more rows ## # ℹ 3 more variables: maxi &lt;dbl&gt;, comp_rule &lt;chr&gt;, long_rule &lt;chr&gt; ros &lt;- sprintf(&quot;%s/rush-radc/dataset_1033_long_03-24-2021.xlsx&quot;, data_path) %&gt;% read_excel() %&gt;% full_join(sprintf(&quot;%s/rush-radc/dataset_1033_basic_03-24-2021.xlsx&quot;, data_path) %&gt;% read_excel()) %&gt;% full_join(sprintf(&quot;%s/rush-radc/dataset_1034_long_03-25-2021.xlsx&quot;, data_path) %&gt;% read_excel()) %&gt;% full_join(sprintf(&quot;%s/rush-radc/dataset_1034_basic_03-25-2021.xlsx&quot;, data_path) %&gt;% read_excel()) %&gt;% filter(study == &quot;ROS&quot;) 2.3.1 Recoding &amp; Reverse Scoring rename_fun &lt;- function(cb, var){ print(var) old.names &lt;- unique((ros_codebook %&gt;% filter(name == var))$orig_itemname) df &lt;- ros %&gt;% select(SID = projid, wave = fu_year, one_of(old.names)) %&gt;% gather(key = orig_itemname, value = value, -SID, -wave, na.rm = T) %&gt;% left_join(cb %&gt;% select(itemname, orig_itemname, reverse_code:long_rule)) } # join data with recoding info ros_recode &lt;- ros_codebook %&gt;% select(category, name, itemname, year, orig_itemname, reverse_code:long_rule) %&gt;% filter(category %in% c(&quot;pers&quot;, &quot;outcome&quot;, &quot;covariates&quot;, &quot;cognition&quot;)) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, name, rename_fun)) # recode recode_fun &lt;- function(rule, y, year){ x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } ros_recode &lt;- ros_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(wave = as.numeric(wave)) %&gt;% group_by(recode, wave) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(recode, data, wave), recode_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(value &lt; 0 | is.nan(value) | is.infinite(value), NA, value)))) # reverse code ros_recode &lt;- ros_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(value = as.numeric(value), value = ifelse(reverse_code == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))))) fun_call &lt;- function(x, rule){ switch(rule, average = mean(x, na.rm = T), mode = Mode(x)[1], sum = sum(x, na.rm = T), skip = unique(x)[1], select = unique(x)[1], max = max(x, na.rm = T), min = min(x, na.rm = T)) } 2.3.2 Covariates # composite WITHIN years ros_cov &lt;- ros_recode %&gt;% filter(category == &quot;covariates&quot;) %&gt;% select(-category) %&gt;% mutate(data = map(data, ~(.) %&gt;% filter(!is.na(value)) %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule), &quot;skip&quot;, comp_rule)) %&gt;% group_by(comp_rule, SID, wave, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %&gt;% unnest(data) %&gt;% filter(wave == 0) )) comp_fun &lt;- function(d, rule){ d %&gt;% group_by(SID, name) %&gt;% summarize(value = fun_call(data, rule)) %&gt;% ungroup() %&gt;% distinct() } # composite ACROSS years ros_cov &lt;- ros_cov %&gt;% unnest(data) %&gt;% mutate(long_rule = ifelse(is.na(long_rule), &quot;skip&quot;, long_rule)) %&gt;% group_by(long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(data, long_rule), comp_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %&gt;% select(-long_rule) %&gt;% spread(name, value) %&gt;% filter(!is.na(SID)) ros_cov ## # A tibble: 1,485 × 14 ## SID age alcohol BMI cancer diabetes education exercise gender heartProb mmse race smokes stroke ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 000210… 80.0 0 19.9 0 0 22 1 0 1 18 0 0 0 ## 2 003377… 82.2 0 42.8 0 0 22 1 1 0 27 0 0 0 ## 3 003811… 70.3 0 29.7 0 0 20 0 0 0 30 0 0 NA ## 4 004702… 72.6 1 20.0 1 0 18 1 0 0 30 0 0 0 ## 5 007567… 87.3 0 33.2 0 1 20 0 1 0 23 1 1 0 ## 6 009850… 78.6 0 23.7 1 0 21 1 0 0 28 0 0 0 ## 7 012114… 85.2 0 25.1 0 0 12 0 1 0 24 0 1 0 ## 8 012370… 72.0 0 18.8 0 0 16 1 0 0 29 0 0 0 ## 9 016795… 65.2 1 36.4 0 0 22 1 0 0 30 0 0 0 ## 10 021057… 85.2 1 21.5 0 0 18 1 0 0 29 0 0 0 ## # ℹ 1,475 more rows 2.3.3 Personality Variables ros_pers &lt;- ros_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% distinct() %&gt;% group_by(SID, name) %&gt;% filter(wave == min(wave)) %&gt;% ungroup() %&gt;% select(SID, name, wave, value) ros_pers ## # A tibble: 7,569 × 4 ## SID name wave value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 00021073 A 0 32 ## 2 00337708 A 0 30 ## 3 00381112 A 0 36 ## 4 00470212 A 0 41 ## 5 00756793 A 0 27 ## 6 00985084 A 0 33 ## 7 01211411 A 0 27 ## 8 01237015 A 0 34 ## 9 01679543 A 0 43 ## 10 02105734 A 0 36 ## # ℹ 7,559 more rows 2.3.4 Outcome Variables ros_out_waves &lt;- ros_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% unnest(data) %&gt;% group_by(SID, name) %&gt;% summarize(o_year = max(wave)) %&gt;% ungroup() ros_out &lt;- ros_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% select(-category) %&gt;% unnest(data) ros_dem &lt;- ros_out %&gt;% filter(name == &quot;dementia&quot;) %&gt;% group_by(SID, name, wave) %&gt;% summarize(value = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.nan(value) | is.infinite(value), NA, value), group = ifelse(wave &gt; 0, &quot;future&quot;, &quot;past&quot;)) %&gt;% group_by(SID, name, group) %&gt;% summarize(value = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value), NA, value)) %&gt;% pivot_wider(names_from = group, values_from = value) %&gt;% group_by(SID, name) %&gt;% mutate(value = ifelse(is.na(past) | (past == 0 &amp; !is.na(future)), future, ifelse(past == 0 &amp; is.na(future), past, ifelse(past == 1, NA, NA)))) %&gt;% ungroup() comp_fun &lt;- function(df, rule){ df %&gt;% group_by(SID) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } # create composites ros_out &lt;- ros_out %&gt;% filter(wave &gt; 0 &amp; name != &quot;dementia&quot;) %&gt;% group_by(name, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, long_rule, comp_fun)) %&gt;% unnest(data) %&gt;% select(-long_rule) %&gt;% full_join(ros_dem) %&gt;% left_join(ros_out_waves) ros_out ## # A tibble: 9,581 × 6 ## name SID value future past o_year ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ageDementia 02495739 92.5 NA NA 13 ## 2 ageDementia 07299965 80.0 NA NA 13 ## 3 ageDementia 07660182 83.7 NA NA 4 ## 4 ageDementia 10100150 84.5 NA NA 12 ## 5 ageDementia 10100286 80.7 NA NA 18 ## 6 ageDementia 10101039 90.4 NA NA 8 ## 7 ageDementia 10101589 107. NA NA 6 ## 8 ageDementia 10101741 92.4 NA NA 12 ## 9 ageDementia 10116694 82.2 NA NA 5 ## 10 ageDementia 10200901 96.2 NA NA 23 ## # ℹ 9,571 more rows 2.3.5 Cognition Variables # composite within years ros_cog &lt;- ros_recode %&gt;% filter(category == &quot;cognition&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% filter(wave == 0) %&gt;% filter(!is.na(value)) %&gt;% group_by(name, itemname, wave) %&gt;% mutate(value = pomp(value)) %&gt;% group_by(name, SID) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() %&gt;% pivot_wider(names_from = &quot;name&quot; , values_from = &quot;value&quot;) ros_cog ## # A tibble: 1,485 × 2 ## SID cognition ## &lt;chr&gt; &lt;dbl&gt; ## 1 00021073 4.19 ## 2 00337708 5.89 ## 3 00381112 7.02 ## 4 00470212 6.68 ## 5 00756793 4.35 ## 6 00985084 6.83 ## 7 01211411 3.83 ## 8 01237015 5.64 ## 9 01679543 7.23 ## 10 02105734 6.64 ## # ℹ 1,475 more rows 2.3.6 Combine Data ros_combined &lt;- ros_pers %&gt;% rename(Trait = name, p_value = value, p_year = wave) %&gt;% full_join( ros_out %&gt;% select(Outcome = name, SID, o_value = value, o_year) ) %&gt;% full_join(ros_cov) %&gt;% left_join( ros_out %&gt;% filter(name == &quot;dementia&quot;) %&gt;% mutate(value = ifelse(rowSums(cbind(future, past), na.rm = T) &gt;= 1, 1, 0)) %&gt;% select(-future, -past) %&gt;% pivot_wider(names_from = &quot;name&quot;, values_from = &quot;value&quot;) ) %&gt;% full_join(ros_cog) %&gt;% filter(!is.na(p_value) &amp; !is.na(o_value)) ros_combined ## # A tibble: 48,074 × 22 ## SID Trait p_year p_value Outcome o_value o_year age alcohol BMI cancer diabetes education exercise ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 00021… A 0 32 angiop… 3 2 80.0 0 19.9 0 0 22 1 ## 2 00021… A 0 32 arteri… 0 2 80.0 0 19.9 0 0 22 1 ## 3 00021… A 0 32 athero… 2 2 80.0 0 19.9 0 0 22 1 ## 4 00021… A 0 32 braak 6 2 80.0 0 19.9 0 0 22 1 ## 5 00021… A 0 32 cerad 1 2 80.0 0 19.9 0 0 22 1 ## 6 00021… A 0 32 hipScl… 0 2 80.0 0 19.9 0 0 22 1 ## 7 00021… A 0 32 lewyBo… 0 2 80.0 0 19.9 0 0 22 1 ## 8 00021… A 0 32 vsclrI… 0 2 80.0 0 19.9 0 0 22 1 ## 9 00021… A 0 32 vsclrM… 1 2 80.0 0 19.9 0 0 22 1 ## 10 00021… A 0 32 tdp43 1 2 80.0 0 19.9 0 0 22 1 ## # ℹ 48,064 more rows ## # ℹ 8 more variables: gender &lt;dbl&gt;, heartProb &lt;dbl&gt;, mmse &lt;dbl&gt;, race &lt;dbl&gt;, smokes &lt;dbl&gt;, stroke &lt;dbl&gt;, ## # dementia &lt;dbl&gt;, cognition &lt;dbl&gt; save(ros_cov, ros_pers, ros_out, ros_combined, ros_cog, file = sprintf(&quot;%s/data/clean/ros_cleaned.RData&quot;, load_path)) rm(list =ls()[grepl(&quot;ros&quot;, ls())]) 2.4 Swedish Adoption Twin Study of Aging (SATSA) The Swedish Adoption Twin Study of Aging (SATSA) is a longitudinal study of twin pairs from the Swedish Twin Registry that began in 1984. Data are available through the ICPSR database at https://www.icpsr.umich.edu/web/ICPSR/studies/3843. All twin-pairs on the Swedish Twin Registry who were separated at an early age were invited to be a part of the study in 1984. A control sample of twins reared together were also included. Additional waves of all participants were collected in 1987, 1990, 1993, 2004, 2007, 2010, 2012, and 2014. More information, including codebooks, scales, and variable search functions can be found at https://www.maelstrom-research.org/mica/individual-study/satsa/#. Sample sizes vary by wave, ranging from 2018 participants at baseline (1984) to 379 participants (IPT7). Given that the target measures were collected at baseline, this provides 99% power to detect a zero-order correlation effect size of ~.10, two-tailed at alpha .05. 2.4.1 Load Data satsa_read_fun &lt;- function(x){ prob_vars &lt;- c(&quot;FHEART&quot;, &quot;FPARKIN&quot;, &quot;FSTROKE&quot;) y &lt;- sprintf(&quot;%s/satsa/%s&quot;, data_path, x) %&gt;% haven::read_sav(.) %&gt;% select(SID = TWINNR, one_of(old.names)) %&gt;% as_tibble() %&gt;% haven::zap_labels(.) if(any(prob_vars %in% colnames(y))){ y &lt;- y %&gt;% mutate_at(vars(one_of(prob_vars)), ~as.numeric(as.character(.))) } return(y) } satsa_codebook &lt;- (codebook %&gt;% filter(study == &quot;SATSA&quot;))$codebook[[1]] %&gt;% mutate_at(vars(orig_itemname), str_to_upper) satsa_codebook ## # A tibble: 840 × 17 ## study dataset category name itemname wave_letter year item_stem orig_itemname description scale ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 satsa SATSA_IPT1 cognition cognition blockDe… &lt;NA&gt; 1985 &lt;NA&gt; IBLOC_R1 Block Desi… inte… ## 2 satsa SATSA_IPT2 cognition cognition blockDe… &lt;NA&gt; 1989 &lt;NA&gt; IBLOC_R2 Block Desi… inte… ## 3 satsa SATSA_IPT3 cognition cognition blockDe… &lt;NA&gt; 1992 &lt;NA&gt; IBLOC_R3 Block Desi… inte… ## 4 satsa SATSA_IPT4 cognition cognition blockDe… &lt;NA&gt; 1995 &lt;NA&gt; IBLOC_R4 Block Desi… inte… ## 5 satsa SATSA_IPT5 cognition cognition blockDe… &lt;NA&gt; 1999 &lt;NA&gt; IBLOC_R5 Block Desi… inte… ## 6 satsa SATSA_IPT6 cognition cognition blockDe… &lt;NA&gt; 2002 &lt;NA&gt; IBLOC_R6 Block Desi… inte… ## 7 satsa SATSA_IPT7 cognition cognition blockDe… &lt;NA&gt; 2005 &lt;NA&gt; IBLOC_R7 Block Desi… inte… ## 8 satsa SATSA_IPT1 cognition cognition digitSp… &lt;NA&gt; 1985 &lt;NA&gt; IDGSP_R1 Digit Span… inte… ## 9 satsa SATSA_IPT2 cognition cognition digitSp… &lt;NA&gt; 1989 &lt;NA&gt; IDGSP_R2 Digit Span… inte… ## 10 satsa SATSA_IPT3 cognition cognition digitSp… &lt;NA&gt; 1992 &lt;NA&gt; IDGSP_R3 Digit Span… inte… ## # ℹ 830 more rows ## # ℹ 6 more variables: reverse_code &lt;chr&gt;, recode &lt;chr&gt;, mini &lt;dbl&gt;, maxi &lt;dbl&gt;, comp_rule &lt;chr&gt;, ## # long_rule &lt;chr&gt; old.names &lt;- unique(satsa_codebook$orig_itemname) %&gt;% str_to_upper datasets &lt;- sprintf(&quot;%s/satsa&quot;, data_path) %&gt;% list.files(., pattern = &quot;.sav&quot;) satsa &lt;- tibble(datasets = datasets) %&gt;% mutate(data = map(datasets, satsa_read_fun), ncol = map_dbl(data, ncol)) %&gt;% filter(ncol != 0) satsa &lt;- reduce(satsa$data, full_join) satsa &lt;- satsa %&gt;% mutate_if(is.factor, ~as.numeric(sub(&quot;^\\\\(0*([0-9]+)\\\\).+$&quot;, &quot;\\\\1&quot;, .))) satsa_long &lt;- satsa %&gt;% pivot_longer( names_to = &quot;orig_itemname&quot; , values_to = &quot;value&quot; , cols = -SID # , values_drop_na = T ) save(satsa, file = sprintf(&quot;%s/data/clean/satsa_raw.RData&quot;, load_path)) rm(satsa) 2.4.2 Recoding &amp; Reverse Scoring satsa_waves &lt;- p_waves %&gt;% filter(Study == &quot;SATSA&quot;) %&gt;% select(Used) %&gt;% distinct() # join data with recoding info satsa_recode &lt;- satsa_codebook %&gt;% select(category, name, itemname, year, orig_itemname, reverse_code:long_rule) %&gt;% filter(category %in% c(&quot;pers&quot;, &quot;outcome&quot;, &quot;covariates&quot;, &quot;cognition&quot;)) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% left_join(satsa_long))) # recode recode_fun &lt;- function(rule, y, year){ x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } satsa_recode &lt;- satsa_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% group_by(recode, year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(recode, data, year), recode_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(value &lt; 0 | is.nan(value) | is.infinite(value), NA, value)) %&gt;% filter(!is.na(value)))) # reverse code satsa_recode &lt;- satsa_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(value = ifelse(reverse_code == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))))) fun_call &lt;- function(x, rule){ switch(rule, average = mean(x, na.rm = T), mode = Mode(x)[1], sum = sum(x, na.rm = T), skip = unique(x)[1], select = unique(x)[1], max = max(x, na.rm = T), min = min(x, na.rm = T)) } 2.4.3 Covariates load(sprintf(&quot;%s/data/clean/satsa_cleaned.RData&quot;, local_path)) satsa_cov &lt;- satsa_recode %&gt;% filter(category == &quot;covariates&quot;) # bring in year or birth for cleaning yrBrth &lt;- satsa_cov %&gt;% filter(name == &quot;yearBrth&quot;) %&gt;% unnest(data) %&gt;% group_by(SID) %&gt;% summarize(yearBrth = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(yearBrth = ifelse(is.infinite(yearBrth), NA, yearBrth)) # compositing within years year_comp_fun &lt;- function(df, rule){ df %&gt;% # group by person and item (collapse across age) group_by(SID, name, year, long_rule) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } satsa_waves &lt;- p_waves %&gt;% filter(Study == &quot;SATSA&quot;) %&gt;% select(Used) %&gt;% distinct() satsa_cov &lt;- satsa_cov %&gt;% unnest(data) %&gt;% filter(year &lt;= max(satsa_waves$Used) + 1) %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule) | comp_rule == &quot;none&quot;, &quot;skip&quot;, comp_rule)) %&gt;% group_by(comp_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, year_comp_fun)) %&gt;% unnest(data) comp_fun &lt;- function(d, rule){ d %&gt;% group_by(SID) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() } satsa_cov &lt;- satsa_cov %&gt;% group_by(name, long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, long_rule, comp_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %&gt;% select(-long_rule) %&gt;% pivot_wider(names_from = name, values_from = value, values_fn = list(value = max)) %&gt;% mutate(BMI = weight/((height/100)^2)) satsa_cov ## # A tibble: 3,840 × 18 ## SID smokes alcohol cancer diabetes heartProb married parkinsons respProb stroke gender education mmse ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 181 0 NA NA NA NA NA NA NA NA 0 NA NA ## 2 182 0 NA NA NA NA NA NA NA NA 0 NA NA ## 3 1101 0 NA NA NA NA NA NA NA NA 0 NA NA ## 4 1102 0 NA NA NA NA NA NA NA NA 0 NA NA ## 5 1121 0 NA NA NA NA NA NA NA NA 1 NA NA ## 6 1122 0 NA NA NA NA NA NA NA NA 1 NA NA ## 7 1151 0 NA NA NA NA NA NA NA NA 1 NA NA ## 8 1152 0 NA NA NA NA NA NA NA NA 1 NA NA ## 9 1211 0 NA NA NA NA NA NA NA NA 1 NA NA ## 10 1212 0 NA NA NA NA NA NA NA NA 1 NA NA ## # ℹ 3,830 more rows ## # ℹ 5 more variables: yearBrth &lt;dbl&gt;, SRhealth &lt;dbl&gt;, height &lt;dbl&gt;, weight &lt;dbl&gt;, BMI &lt;dbl&gt; 2.4.4 Personality Variables satsa_pers &lt;- satsa_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% unnest(data) %&gt;% left_join(p_waves %&gt;% filter(Study == &quot;SATSA&quot;) %&gt;% select(name = p_item, Used)) %&gt;% filter(year %in% Used &amp; !is.na(value)) %&gt;% distinct() # alpha&#39;s satsa_alpha &lt;- satsa_pers %&gt;% select(name, itemname, year, SID, value) %&gt;% group_by(name, year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% spread(itemname, value)), alpha = map(data, possibly(~psych::alpha((.) %&gt;% select(-SID)), NA_real_))) # create composites satsa_pers &lt;- satsa_pers %&gt;% group_by(SID, name, year) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() satsa_pers ## # A tibble: 14,109 × 4 ## SID name year value ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1292 A 1984 4 ## 2 1292 C 1984 4 ## 3 1292 E 1984 3.67 ## 4 1292 N 1984 4.33 ## 5 1292 O 1984 3.5 ## 6 1292 SWL 1984 2.54 ## 7 1701 C 1984 5 ## 8 1701 E 1984 3.89 ## 9 1701 N 1984 4 ## 10 1701 O 1984 1 ## # ℹ 14,099 more rows 2.4.5 Outcome Variables satsa_out &lt;- satsa_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% unnest(data) %&gt;% distinct() %&gt;% full_join(crossing(p_year = satsa_waves$Used, name = unique((.)$name))) satsa_out_waves &lt;- satsa_out %&gt;% group_by(SID, name) %&gt;% summarize(o_year = max(year[!is.na(value)])) %&gt;% ungroup() satsa_waves &lt;- p_waves %&gt;% filter(Study == &quot;SATSA&quot;) %&gt;% select(Used) %&gt;% distinct() satsa_out &lt;- satsa_out %&gt;% filter(year &gt; p_year) %&gt;% group_by(SID, name, year, p_year) %&gt;% summarize(value = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.nan(value)|is.infinite(value), NA, value)) %&gt;% group_by(SID, p_year, name) %&gt;% summarize(value = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value), NA, value)) %&gt;% left_join(satsa_out_waves) satsa_out ## # A tibble: 3,840 × 5 ## SID p_year name value o_year ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 181 1984 dementia 0 2005 ## 2 182 1984 dementia 0 2005 ## 3 1101 1984 dementia 0 2005 ## 4 1102 1984 dementia 0 2005 ## 5 1121 1984 dementia 0 2005 ## 6 1122 1984 dementia 0 2005 ## 7 1151 1984 dementia 0 2005 ## 8 1152 1984 dementia 0 2005 ## 9 1211 1984 dementia 0 2005 ## 10 1212 1984 dementia 0 2005 ## # ℹ 3,830 more rows 2.4.6 Cognition Variables # composite within years satsa_cog &lt;- satsa_recode %&gt;% filter(category == &quot;cognition&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% filter(year == 1985) %&gt;% filter(!is.na(value)) %&gt;% group_by(name, itemname, year) %&gt;% mutate(value = pomp(value)) %&gt;% group_by(name, SID) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() %&gt;% pivot_wider(names_from = &quot;name&quot; , values_from = &quot;value&quot;) 2.4.7 Combine Data satsa_combined &lt;- satsa_pers %&gt;% rename(Trait = name, p_value = value, p_year = year) %&gt;% full_join(satsa_out %&gt;% rename(Outcome = name, o_value = value)) %&gt;% full_join(satsa_cov) %&gt;% left_join( satsa_out %&gt;% filter(name == &quot;dementia&quot;) %&gt;% pivot_wider(names_from = &quot;name&quot;, values_from = &quot;value&quot;) ) %&gt;% full_join(satsa_cog) %&gt;% filter(!is.na(p_value) &amp; !is.na(o_value)) %&gt;% mutate(age = p_year - yearBrth , o_year = 2005) satsa_combined ## # A tibble: 14,109 × 27 ## SID Trait p_year p_value Outcome o_value o_year smokes alcohol cancer diabetes heartProb married ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1292 A 1984 4 dementia 0 2005 0 0 1 0 1 1 ## 2 1292 C 1984 4 dementia 0 2005 0 0 1 0 1 1 ## 3 1292 E 1984 3.67 dementia 0 2005 0 0 1 0 1 1 ## 4 1292 N 1984 4.33 dementia 0 2005 0 0 1 0 1 1 ## 5 1292 O 1984 3.5 dementia 0 2005 0 0 1 0 1 1 ## 6 1292 SWL 1984 2.54 dementia 0 2005 0 0 1 0 1 1 ## 7 1701 C 1984 5 dementia 0 2005 0 0 0 0 1 NA ## 8 1701 E 1984 3.89 dementia 0 2005 0 0 0 0 1 NA ## 9 1701 N 1984 4 dementia 0 2005 0 0 0 0 1 NA ## 10 1701 O 1984 1 dementia 0 2005 0 0 0 0 1 NA ## # ℹ 14,099 more rows ## # ℹ 14 more variables: parkinsons &lt;dbl&gt;, respProb &lt;dbl&gt;, stroke &lt;dbl&gt;, gender &lt;dbl&gt;, education &lt;dbl&gt;, ## # mmse &lt;dbl&gt;, yearBrth &lt;dbl&gt;, SRhealth &lt;dbl&gt;, height &lt;dbl&gt;, weight &lt;dbl&gt;, BMI &lt;dbl&gt;, dementia &lt;dbl&gt;, ## # cognition &lt;dbl&gt;, age &lt;dbl&gt; save(satsa_cov, satsa_alpha, satsa_pers, satsa_out, satsa_combined, satsa_cog, file = sprintf(&quot;%s/data/clean/satsa_cleaned.RData&quot;, load_path)) rm(list =ls()[grepl(&quot;satsa&quot;, ls())]) 2.5 ADRC Memory and Aging Project (ADRC-MAP) The Alzheimer Disease Research Center Memory and Aging Project (ADRC-MAP) is an ongoing longitudinal study of memory and Alzheimer’s Disease that began in 1979. Data are available on a study-by-study basis through application from https://knightadrc.wustl.edu/Research/ResourceRequest.htm. Participants were recruited from the Charles and Joanne F. Knight Alzheimer’s Disease Research Center at Washington University in St. Louis as part of an ongoing study of disease progression. The current study uses a subset of approximately 1200 of these participants who completed personality surveys as part of a substudy (see Duchek et al., 2019). More information on the study can be found at https://knightadrc.wustl.edu/Research/PDFs/Clinical%20Core%20list%20of%20measures.pdf. Sample sizes vary over time, from approximately 400 to 1200. This provides 99% power to detect a zero-order correlation effect size of ~.15, two-tailed at alpha .05. 2.5.1 Load Data (adrc_codebook &lt;- (codebook %&gt;% filter(study == &quot;ADRC&quot;))$codebook[[1]]) ## # A tibble: 106 × 15 ## study dataset category name itemname year orig_itemname description scale reverse_code recode mini ## &lt;chr&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 ADRC NA cognition cogniti… waisBlc… long… PSY021 &quot;WAIS BLOC… Rang… no ifels… NA ## 2 ADRC NA cognition cogniti… waisInfo long… PSY019 &quot;WAIS INFO… Rang… no ifels… NA ## 3 ADRC NA cognition cogniti… waisRDi… long… DIGSYM &quot;WAIS-R DI… Rang… no ifels… NA ## 4 ADRC NA cognition cogniti… digFrwd… long… DIGFORCT &quot;NUMBER SP… Rang… no ifels… NA ## 5 ADRC NA cognition cogniti… digBckw… long… DIGBACCT &quot;NUMBER SP… Rang… no ifels… NA ## 6 ADRC NA cognition cogniti… trailMa… long… TRAILA &quot;The score… Rang… no ifels… NA ## 7 ADRC NA cognition cogniti… trailMa… long… TRAILB &quot;The score… Rang… no ifels… NA ## 8 ADRC NA cognition cogniti… cuedRec… long… SRT1C &quot;Free &amp; Cu… Rang… no ifels… NA ## 9 ADRC NA cognition cogniti… cuedRec… long… SRT2C &quot;Free &amp; Cu… Rang… no ifels… NA ## 10 ADRC NA cognition cogniti… cuedRec… long… SRT3C &quot;Free &amp; Cu… Rang… no ifels… NA ## # ℹ 96 more rows ## # ℹ 3 more variables: maxi &lt;dbl&gt;, comp_rule &lt;chr&gt;, long_rule &lt;chr&gt; adrc_read_fun &lt;- function(file){ print(file) d &lt;- sprintf(&quot;%s/adrc-map/%s&quot;, data_path, file) %&gt;% read_excel(.) %&gt;% select(SID = id, one_of(c(&quot;TESTDATE&quot;, old.names)), contains(&quot;NEO Date&quot;)) if(&quot;TESTDATE&quot; %in% colnames(d)){ if(any(class(d$TESTDATE) != &quot;numeric&quot;)){d$TESTDATE &lt;- lubridate::year(d$TESTDATE)}} d } old.names &lt;- unique(adrc_codebook$orig_itemname) adrc &lt;- tibble(file = list.files(sprintf(&quot;%s/adrc-map&quot;, data_path), pattern = &quot;.xlsx&quot;)) %&gt;% filter(!grepl(&quot;NEO&quot;, file)) %&gt;% mutate(data = map(file, adrc_read_fun)) %&gt;% filter(map_dbl(data, ncol) &gt; 1) waves &lt;- adrc %&gt;% mutate(data = map(data, ~(.) %&gt;% select(SID, one_of(&quot;TESTDATE&quot;)))) %&gt;% select(-file) %&gt;% unnest(data) %&gt;% filter(complete.cases(.)) %&gt;% # mutate(year = lubridate::year(TESTDATE)) %&gt;% distinct() %&gt;% arrange(SID, TESTDATE) %&gt;% group_by(SID) %&gt;% mutate(frstyear = min(TESTDATE)) %&gt;% ungroup() %&gt;% mutate(year = TESTDATE, wave = year - frstyear + 1) adrc_long &lt;- reduce(adrc$data, full_join) %&gt;% distinct() %&gt;% select(SID, year = TESTDATE, everything()) %&gt;% mutate(BIRTH = lubridate::year(BIRTH)) %&gt;% pivot_longer(cols = c(-SID, -year) , names_to = &quot;orig_itemname&quot; , values_to = &quot;value&quot;) # load personality data separately old.names &lt;- (adrc_codebook %&gt;% filter(category == &quot;pers&quot;))$orig_itemname adrc_pers &lt;- sprintf(&quot;%s/adrc-map/NEO - Raw Scores_FINAL.xlsx&quot;, data_path) %&gt;% read_xlsx() %&gt;% select(SID = id, date = `NEO Date 1`, one_of(old.names)) %&gt;% mutate(date = ifelse(grepl(&quot;[//]&quot;, date), as.numeric(as.Date(date, format = &quot;%m/%d/%Y&quot;)), date), date = as.Date(as.numeric(date), origin=&quot;1899-12-30&quot;)) %&gt;% filter(!is.na(date)) # get waves for participants adrc_pers_waves &lt;- adrc_pers %&gt;% select(SID, p_year = date) %&gt;% distinct() %&gt;% mutate(p_year = lubridate::year(p_year)) 2.5.2 Recode &amp; Reverse-Scoring adrc_recode &lt;- adrc_codebook %&gt;% filter(category %in% c(&quot;covariates&quot;, &quot;outcome&quot;, &quot;cognition&quot;) &amp; !is.na(orig_itemname)) %&gt;% select(category, name, itemname, orig_itemname, reverse_code:long_rule) %&gt;% right_join(adrc_long) %&gt;% left_join(adrc_pers_waves) # recode recode_fun &lt;- function(rule, y, year){ # print(rule) x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } adrc_recode &lt;- adrc_recode %&gt;% group_by(recode, year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(recode, data, year), recode_fun)) %&gt;% unnest(data) # reverse code adrc_recode &lt;- adrc_recode %&gt;% mutate(value = ifelse(reverse_code == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() fun_call &lt;- function(x, rule){ switch(rule, average = mean(x, na.rm = T), mode = Mode(x)[1], sum = sum(x, na.rm = T), skip = unique(x)[1], select = unique(x)[1], max = max(x, na.rm = T), min = min(x, na.rm = T)) } 2.5.3 Covariates load(sprintf(&quot;%s/data/clean/adrc_cleaned.RData&quot;, local_path)) # compositing within years year_comp_fun &lt;- function(df, rule){ df %&gt;% # group by person and item (collapse across age) group_by(SID, name, year, p_year, long_rule) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } adrc_cov &lt;- adrc_recode %&gt;% filter(category == &quot;covariates&quot;) %&gt;% unnest(data) %&gt;% filter(year &lt;= p_year) %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule) | comp_rule == &quot;none&quot;, &quot;skip&quot;, comp_rule)) %&gt;% group_by(comp_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, year_comp_fun)) %&gt;% unnest(data) %&gt;% select(-comp_rule) comp_fun &lt;- function(d, rule){ d %&gt;% group_by(SID, name) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() } adrc_cov &lt;- adrc_cov %&gt;% filter(!is.na(value) &amp; !is.na(name)) %&gt;% group_by(long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, long_rule, comp_fun)) %&gt;% unnest(data) %&gt;% select(-long_rule) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %&gt;% pivot_wider(names_from = name, values_from = value, values_fn = list(value = max)) %&gt;% right_join(adrc_pers_waves) %&gt;% mutate(age = p_year - yearBrth) adrc_cov ## # A tibble: 1,162 × 15 ## SID gender yearBrth alcohol cancer diabetes education heartProb married race smokes stroke weight ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1070 0 1918 1 1 0 17 1 1 0 0 0 187 ## 2 1088 0 1916 1 1 0 16 1 1 0 0 0 217 ## 3 1380 1 1913 1 1 0 16 1 0 0 0 0 129 ## 4 10018 0 1929 0 0 0 14 1 1 0 1 0 156 ## 5 10034 0 1930 0 1 0 16 0 1 0 0 0 193 ## 6 10037 1 1923 1 1 0 13 1 1 0 1 0 179 ## 7 10038 0 1927 1 0 0 18 0 1 0 0 0 205 ## 8 10045 1 1931 1 1 0 16 0 1 0 1 0 160 ## 9 10054 1 1930 0 1 0 13 1 1 0 1 0 173 ## 10 10064 0 1928 1 1 0 20 1 1 0 1 0 199 ## # ℹ 1,152 more rows ## # ℹ 2 more variables: p_year &lt;dbl&gt;, age &lt;dbl&gt; 2.5.4 Personality Variables # bring in codebook info adrc_pers &lt;- adrc_pers %&gt;% pivot_longer(`1S1`:`1S60` , names_to = &quot;orig_itemname&quot; , values_to = &quot;value&quot; , values_drop_na = T) %&gt;% left_join(adrc_codebook %&gt;% select(name:orig_itemname, reverse_code:maxi)) recode_fun &lt;- function(rule, y){ x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } # recode adrc_pers &lt;- adrc_pers %&gt;% group_by(recode) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(recode, data, recode_fun)) %&gt;% unnest(data) # reverse code adrc_pers &lt;- adrc_pers %&gt;% mutate(value = ifelse(tolower(reverse_code) == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))) # alpha&#39;s adrc_alpha &lt;- adrc_pers %&gt;% select(name, itemname, date, SID, value) %&gt;% group_by(name) %&gt;% nest() %&gt;% mutate(data = map(data, ~(.) %&gt;% pivot_wider(names_from = itemname, values_from = value)), alpha = map(data, possibly(~psych::alpha((.) %&gt;% select(-SID, -date)), NA_real_))) # create composites adrc_pers &lt;- adrc_pers %&gt;% group_by(SID, name, date) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() %&gt;% left_join(adrc_pers_waves) adrc_pers ## # A tibble: 5,730 × 5 ## SID name date value p_year ## &lt;dbl&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1070 A 2003-10-28 4.08 2003 ## 2 1070 C 2003-10-28 4.83 2003 ## 3 1070 E 2003-10-28 4.08 2003 ## 4 1070 N 2003-10-28 1.08 2003 ## 5 1070 O 2003-10-28 3.17 2003 ## 6 1088 A 2005-04-18 4.5 2005 ## 7 1088 C 2005-04-18 3.42 2005 ## 8 1088 E 2005-04-18 3.08 2005 ## 9 1088 N 2005-04-18 1.25 2005 ## 10 1088 O 2005-04-18 3.08 2005 ## # ℹ 5,720 more rows 2.5.5 Outcome Variables adrc_out &lt;- adrc_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% unnest(data) adrc_out_waves &lt;- adrc_out %&gt;% select(year, SID, name) %&gt;% group_by(SID, name) %&gt;% summarize(o_year = max(year)) %&gt;% ungroup() # compositing within years year_comp_fun &lt;- function(df, rule){ df %&gt;% # group by person and item (collapse across age) group_by(SID, name, year, long_rule, p_year) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } adrc_out &lt;- adrc_out %&gt;% filter(!is.na(value)) %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule) | comp_rule == &quot;none&quot;, &quot;skip&quot;, comp_rule)) %&gt;% group_by(comp_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, year_comp_fun)) %&gt;% unnest(data) comp_fun &lt;- function(d, rule){ d %&gt;% group_by(SID, name) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() } adrc_out &lt;- adrc_out %&gt;% filter(name == &quot;dementia&quot;) %&gt;% mutate(group = ifelse(year &lt;= p_year, &quot;past&quot;, &quot;future&quot;)) %&gt;% group_by(SID, name, group, p_year) %&gt;% summarize(value = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value), NA, value)) %&gt;% pivot_wider(names_from = group, values_from = value) %&gt;% group_by(SID, name) %&gt;% mutate(value = ifelse(is.na(past) | (past == 0 &amp; !is.na(future)), future, ifelse(past == 0 &amp; is.na(future), past, ifelse(past == 1, NA, NA)))) %&gt;% ungroup() %&gt;% full_join( adrc_out %&gt;% filter(name != &quot;dementia&quot; &amp; !is.na(value) &amp; year &gt;= p_year) %&gt;% group_by(long_rule, p_year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, long_rule, comp_fun)) %&gt;% select(-long_rule) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) ) %&gt;% left_join(adrc_out_waves) adrc_out ## # A tibble: 2,575 × 8 ## SID name p_year future past `NA` value o_year ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1070 dementia 2003 1 0 NA 1 2019 ## 2 1088 dementia 2005 1 1 NA NA 2015 ## 3 1380 dementia 2003 1 0 NA 1 2013 ## 4 10018 dementia 2005 0 0 NA 0 2018 ## 5 10034 dementia 2004 0 0 NA 0 2020 ## 6 10037 dementia 2006 1 0 NA 1 2019 ## 7 10038 dementia 2003 1 0 NA 1 2016 ## 8 10045 dementia 2003 1 1 NA NA 2018 ## 9 10054 dementia 2008 0 0 NA 0 2012 ## 10 10064 dementia 2003 1 0 NA 1 2018 ## # ℹ 2,565 more rows 2.5.6 Cognition Variables # composite within years adrc_cog &lt;- adrc_recode %&gt;% filter(category == &quot;cognition&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% filter(!is.na(p_year)) %&gt;% filter(!is.na(value)) %&gt;% group_by(name, itemname, year) %&gt;% mutate(value = pomp(value)) %&gt;% group_by(SID, name, itemname) %&gt;% filter(year %in% (p_year - 1):(p_year + 1)) %&gt;% group_by(name, SID) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() %&gt;% pivot_wider(names_from = &quot;name&quot; , values_from = &quot;value&quot;) adrc_cog ## # A tibble: 1,023 × 2 ## SID cognition ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1070 4.62 ## 2 1088 3.40 ## 3 1380 2.36 ## 4 10018 5.59 ## 5 10034 5.30 ## 6 10037 4.64 ## 7 10038 6.60 ## 8 10045 8.52 ## 9 10054 2.41 ## 10 10064 7.36 ## # ℹ 1,013 more rows 2.5.7 Combine Data adrc_combined &lt;- adrc_pers %&gt;% select(SID, Trait = name, p_value = value, p_year) %&gt;% full_join( adrc_out %&gt;% select(SID, o_year, Outcome = name, o_value = value) ) %&gt;% filter(!is.na(o_value) &amp; !is.na(p_value)) %&gt;% distinct() %&gt;% left_join(adrc_cov) %&gt;% left_join( adrc_out %&gt;% filter(name == &quot;dementia&quot;) %&gt;% mutate(value = ifelse(rowSums(cbind(future, past), na.rm = T) &gt;= 1, 1, 0)) %&gt;% select(-future, -past) %&gt;% pivot_wider(names_from = &quot;name&quot;, values_from = &quot;value&quot;) ) %&gt;% left_join(adrc_cog) %&gt;% left_join(adrc_out_waves %&gt;% select(SID, Outcome = name, o_year)) adrc_combined ## # A tibble: 11,145 × 23 ## SID Trait p_value p_year o_year Outcome o_value gender yearBrth alcohol cancer diabetes education ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1070 A 4.08 2003 2019 dementia 1 0 1918 1 1 0 17 ## 2 1070 C 4.83 2003 2019 dementia 1 0 1918 1 1 0 17 ## 3 1070 E 4.08 2003 2019 dementia 1 0 1918 1 1 0 17 ## 4 1070 N 1.08 2003 2019 dementia 1 0 1918 1 1 0 17 ## 5 1070 O 3.17 2003 2019 dementia 1 0 1918 1 1 0 17 ## 6 1088 A 4.5 2005 2015 angiopathy 0 0 1916 1 1 0 16 ## 7 1088 A 4.5 2005 2015 arterioloscl… 1 0 1916 1 1 0 16 ## 8 1088 A 4.5 2005 2015 atherosclero… 2 0 1916 1 1 0 16 ## 9 1088 A 4.5 2005 2015 braak 3 0 1916 1 1 0 16 ## 10 1088 A 4.5 2005 2015 hipSclerosis 0 0 1916 1 1 0 16 ## # ℹ 11,135 more rows ## # ℹ 10 more variables: heartProb &lt;dbl&gt;, married &lt;dbl&gt;, race &lt;dbl&gt;, smokes &lt;dbl&gt;, stroke &lt;dbl&gt;, ## # weight &lt;dbl&gt;, age &lt;dbl&gt;, `NA` &lt;dbl&gt;, dementia &lt;dbl&gt;, cognition &lt;dbl&gt; save(adrc_cov, adrc_alpha, adrc_pers, adrc_out, adrc_combined, adrc_cog, file = sprintf(&quot;%s/data/clean/adrc_cleaned.RData&quot;, load_path)) rm(list =ls()[grepl(&quot;adrc&quot;, ls())]) 2.6 Einstein Aging Study The Einstein Aging Study (EAS) is an ongoing longitudinal study of the aging brain. The EAS began in 1980 and has enrolled more than 2,600 participants since then. Data are available through application at http://www.einstein.yu.edu/departments/neurology/clinical-research-program/eas/data-sharing.aspx. Since 1993, the EAS has systematically recruited a representative aging sample in the Bronx, New York, As of 2017, 2,600 participants were enrolled in the study. As of 2010, approximately 200 of the enrolled participants had autopsy data. More information on the study can be found at http://www.einstein.yu.edu/departments/neurology/clinical-research-program/EAS/. Sample sizes vary over time, with ranges across waves not publically available. However, we suspect approximately 2,000 participants to have basic personality and dementia diagnoses, with between 150 and 300 participants having full autopsy data collected after personality was introduced into the study. This yields 99% power to detect a zero-order correlation effect size of .10 and .24, respectively, two-tailed at alpha .05. 2.6.1 Load Data (eas_codebook &lt;- (codebook %&gt;% filter(study == &quot;EAS&quot;))$codebook[[1]]) ## # A tibble: 78 × 15 ## study dataset category name itemname year orig_itemname description scale reverse_code recode mini ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 EAS behavior cognition cogni… waisBlk… long… Blockraw &quot;WAIS III:… &quot;int… &lt;NA&gt; ifels… NA ## 2 EAS behavior cognition cogni… trailma… long… Tr-A1 &quot;Other Wor… &quot;int… &lt;NA&gt; ifels… NA ## 3 EAS behavior cognition cogni… trailma… long… Tr-B1 &quot;Other Wor… &quot;int… &lt;NA&gt; ifels… NA ## 4 EAS behavior cognition cogni… digitSym long… Symraw &quot;Digit Sym… &quot;int… &lt;NA&gt; ifels… NA ## 5 EAS behavior cognition cogni… recall long… TotRecall &quot;total Rec… &quot;int… &lt;NA&gt; ifels… NA ## 6 EAS behavior cognition cogni… SPN long… Spnraw &quot;Digit Spa… &quot;int… &lt;NA&gt; ifels… NA ## 7 EAS behavior cognition cogni… CAT long… CAT &lt;NA&gt; &quot;int… &lt;NA&gt; ifels… NA ## 8 EAS behavior cognition cogni… FAS long… FAS &lt;NA&gt; &quot;int… &lt;NA&gt; ifels… NA ## 9 EAS behavior covariates alcoh… alcohol… base… SAB262 &quot;What was … &quot;1=N… no ifels… NA ## 10 EAS behavior covariates alcoh… alcohol… base… SAB263 &quot;What was … &quot;1=N… no ifels… NA ## # ℹ 68 more rows ## # ℹ 3 more variables: maxi &lt;dbl&gt;, comp_rule &lt;chr&gt;, long_rule &lt;chr&gt; old.names1 &lt;- unique((eas_codebook %&gt;% filter(dataset == &quot;behavior&quot;))$orig_itemname) old.names2 &lt;- unique((eas_codebook %&gt;% filter(dataset == &quot;neuropath&quot;))$orig_itemname) old.names3 &lt;- unique((eas_codebook %&gt;% filter(dataset == &quot;activity&quot;))$orig_itemname) eas &lt;- sprintf(&quot;%s/eas/Behavior_with_Master_Data_2021_10_25.xlsx&quot;, data_path) %&gt;% read_excel(., sheet = 1) %&gt;% mutate(year = lubridate::year(BehaviorDate)) %&gt;% select(SID = Id, wave = Wave, year, one_of(old.names1)) %&gt;% full_join( sprintf(&quot;%s/eas/Neuropath_and_Behavior_Data_2021_09_26 (3).xlsx&quot;, data_path) %&gt;% read_excel(.) %&gt;% select(SID = `Clin#`, year = DOD, wave = Wave, one_of(old.names2)) %&gt;% mutate(comb_dx = ifelse(c(&quot;VaD&quot;, &quot;AD&quot;, &quot;AGD&quot;) %in% Dx1 | c(&quot;VaD&quot;, &quot;AD&quot;, &quot;AGD&quot;) %in% Dx2 | c(&quot;VaD&quot;, &quot;AD&quot;, &quot;AGD&quot;) %in% Dx3 | grepl(&quot;VaD&quot;, `OTHER Dx`) | grepl(&quot;AD&quot;, `OTHER Dx`) | grepl(&quot;AGD&quot;, `OTHER Dx`), 1, 0) , year = lubridate::year(year)) %&gt;% select(-(Dx1:`OTHER Dx`)) ) %&gt;% full_join( sprintf(&quot;%s/eas/Northwestern_supp_Physical_Activities_2021_10_25-1.xlsx&quot;, data_path) %&gt;% read_excel(.) %&gt;% select(SID = Id, wave = Wave, one_of(old.names3)) ) %&gt;% mutate(Gender = ifelse(Gender == &quot;F&quot;, 1, ifelse(Gender == &quot;M&quot;, 0, NA))) eas_waves &lt;- eas %&gt;% select(SID, wave, year) %&gt;% distinct() eas_long &lt;- eas %&gt;% pivot_longer(values_to = &quot;value&quot; , names_to = &quot;orig_itemname&quot; , cols = c(-SID, -wave, -year)) 2.6.2 Recode &amp; Reverse-Scoring eas_recode &lt;- eas_codebook %&gt;% filter(category %in% c(&quot;covariates&quot;, &quot;outcome&quot;, &quot;cognition&quot;, &quot;pers&quot;) &amp; !is.na(orig_itemname)) %&gt;% select(category, name, itemname, orig_itemname, reverse_code:long_rule) %&gt;% right_join(eas_long) # recode recode_fun &lt;- function(rule, y, year){ print(rule) x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } eas_recode &lt;- eas_recode %&gt;% group_by(recode, year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(recode, data, year), recode_fun)) %&gt;% unnest(data) # reverse code eas_recode &lt;- eas_recode %&gt;% mutate(value = ifelse(reverse_code == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() fun_call &lt;- function(x, rule){ switch(rule, average = mean(x, na.rm = T), mode = Mode(x)[1], sum = sum(x, na.rm = T), skip = unique(x)[1], select = unique(x)[1], max = max(x, na.rm = T), min = min(x, na.rm = T)) } eas_p_waves &lt;- eas_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% unnest(data) %&gt;% filter(!is.na(value)) %&gt;% group_by(SID) %&gt;% filter(year == min(year)) %&gt;% ungroup() %&gt;% select(SID, p_year = year) %&gt;% distinct() 2.6.3 Covariates # compositing within years year_comp_fun &lt;- function(df, rule){ df %&gt;% # group by person and item (collapse across age) group_by(SID, name, year, p_year, long_rule) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } eas_cov &lt;- eas_recode %&gt;% filter(category == &quot;covariates&quot;) %&gt;% unnest(data) %&gt;% left_join(eas_p_waves) %&gt;% filter(year &lt;= p_year) %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule) | comp_rule == &quot;none&quot;, &quot;skip&quot;, comp_rule)) %&gt;% group_by(comp_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, year_comp_fun)) %&gt;% unnest(data) %&gt;% select(-comp_rule) comp_fun &lt;- function(d, rule){ d %&gt;% group_by(SID, name) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() } eas_cov &lt;- eas_cov %&gt;% filter(!is.na(value) &amp; !is.na(name)) %&gt;% group_by(long_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, long_rule, comp_fun)) %&gt;% unnest(data) %&gt;% select(-long_rule) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %&gt;% pivot_wider(names_from = name, values_from = value, values_fn = list(value = max)) %&gt;% right_join(eas_p_waves) eas_cov ## # A tibble: 799 × 17 ## SID alcohol cancer diabetes heartProb hypertension married race smokes stroke exercise BMI age ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 6075 0 0 0 0 0 1 0 0 0 NA 21.1 73.4 ## 2 8024 1 0 0 0 0 1 0 1 0 NA 28.8 94.8 ## 3 8027 1 0 0 0 0 1 0 0 0 NA 20.4 93.0 ## 4 8265 1 1 1 0 1 1 0 1 0 NA 28.5 77.3 ## 5 8291 0 0 0 0 0 1 0 0 0 NA 24 81.7 ## 6 8296 1 0 0 0 0 1 0 0 0 NA 23 88.9 ## 7 8310 1 0 1 0 0 1 0 1 0 NA 29.4 86.0 ## 8 8313 1 0 0 0 0 1 1 1 0 NA NA 87.3 ## 9 8375 1 1 0 0 NA 1 0 0 0 NA 26.3 87.2 ## 10 8512 1 0 0 0 1 1 1 1 0 NA NA 78.9 ## # ℹ 789 more rows ## # ℹ 4 more variables: education &lt;dbl&gt;, SRhealth &lt;dbl&gt;, gender &lt;dbl&gt;, p_year &lt;dbl&gt; 2.6.4 Personality Variables # bring in codebook info eas_pers &lt;- eas_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% unnest(data) %&gt;% left_join(eas_p_waves) %&gt;% filter(year == p_year) # create composites eas_pers &lt;- eas_pers %&gt;% group_by(SID, name, p_year) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() eas_pers ## # A tibble: 3,995 × 4 ## SID name p_year value ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 6075 A 2016 3.6 ## 2 6075 C 2016 3.4 ## 3 6075 E 2016 2.5 ## 4 6075 N 2016 2.8 ## 5 6075 O 2016 3.1 ## 6 8024 A 2006 3.7 ## 7 8024 C 2006 4.1 ## 8 8024 E 2006 2.7 ## 9 8024 N 2006 2.7 ## 10 8024 O 2006 2.9 ## # ℹ 3,985 more rows 2.6.5 Outcome Variables eas_out &lt;- eas_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% unnest(data) eas_out_waves &lt;- eas_out %&gt;% filter(!is.na(value)) %&gt;% select(year, SID, name) %&gt;% group_by(SID, name) %&gt;% summarize(o_year = max(year)) %&gt;% ungroup() # compositing within years year_comp_fun &lt;- function(df, rule){ df %&gt;% # group by person and item (collapse across age) group_by(SID, name, year, long_rule, p_year) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } eas_out &lt;- eas_out %&gt;% left_join(eas_p_waves) %&gt;% filter(!is.na(value)) %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule) | comp_rule == &quot;none&quot;, &quot;skip&quot;, comp_rule)) %&gt;% group_by(comp_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, year_comp_fun)) %&gt;% unnest(data) eas_out &lt;- eas_out %&gt;% filter(name == &quot;dementia&quot;) %&gt;% mutate(group = ifelse(year &lt;= p_year, &quot;past&quot;, &quot;future&quot;)) %&gt;% group_by(SID, name, group, p_year) %&gt;% summarize(value = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value), NA, value)) %&gt;% pivot_wider(names_from = group, values_from = value) %&gt;% group_by(SID, name) %&gt;% mutate(value = ifelse(is.na(past) | (past == 0 &amp; !is.na(future)), future, ifelse(past == 0 &amp; is.na(future), past, ifelse(past == 1, NA, NA)))) %&gt;% ungroup() %&gt;% full_join(eas_out %&gt;% filter(name != &quot;dementia&quot;) %&gt;% group_by(SID, name, long_rule, p_year) %&gt;% summarize(value = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% select(-long_rule) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) ) %&gt;% left_join(eas_out_waves) %&gt;% filter(!is.na(value)) eas_out ## # A tibble: 878 × 8 ## SID name p_year past future `NA` value o_year ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 8024 dementia 2006 0 NA NA 0 2006 ## 2 8027 dementia 2009 0 1 NA 1 2017 ## 3 8265 dementia 2006 0 0 NA 0 2011 ## 4 8291 dementia 2009 0 0 NA 0 2012 ## 5 8296 dementia 2006 0 NA NA 0 2006 ## 6 8310 dementia 2007 0 NA NA 0 2007 ## 7 8313 dementia 2007 0 NA NA 0 2007 ## 8 8375 dementia 2006 0 0 NA 0 2010 ## 9 8512 dementia 2010 0 0 NA 0 2013 ## 10 8518 dementia 2011 0 NA NA 0 2011 ## # ℹ 868 more rows 2.6.6 Cognition Variables # composite within years eas_cog &lt;- eas_recode %&gt;% filter(category == &quot;cognition&quot;) %&gt;% select(-category) %&gt;% unnest(data) %&gt;% left_join(eas_p_waves) %&gt;% filter(!is.na(p_year) &amp; !is.na(value)) %&gt;% group_by(name, itemname, year) %&gt;% mutate(value = pomp(value)) %&gt;% group_by(SID, name, itemname) %&gt;% filter(year %in% (p_year - 1):(p_year + 1)) %&gt;% group_by(name, SID) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() %&gt;% pivot_wider(names_from = &quot;name&quot; , values_from = &quot;value&quot;) eas_cog ## # A tibble: 799 × 2 ## SID cognition ## &lt;dbl&gt; &lt;dbl&gt; ## 1 6075 5.78 ## 2 8024 4.83 ## 3 8027 4.55 ## 4 8265 5.60 ## 5 8291 4.64 ## 6 8296 5.20 ## 7 8310 4.16 ## 8 8313 4.37 ## 9 8375 6.10 ## 10 8512 3.62 ## # ℹ 789 more rows 2.6.7 Combine Data eas_combined &lt;- eas_pers %&gt;% select(SID, Trait = name, p_value = value, p_year) %&gt;% full_join( eas_out %&gt;% select(SID, o_year, Outcome = name, o_value = value) ) %&gt;% filter(!is.na(o_value) &amp; !is.na(p_value)) %&gt;% distinct() %&gt;% left_join( eas_out %&gt;% filter(name == &quot;dementia&quot;) %&gt;% mutate(value = ifelse(rowSums(cbind(future, past), na.rm = T) &gt;= 1, 1, 0)) %&gt;% select(-future, -past) %&gt;% pivot_wider(names_from = &quot;name&quot;, values_from = &quot;value&quot;) ) %&gt;% left_join(eas_cov) %&gt;% left_join(eas_cog) eas_combined ## # A tibble: 4,320 × 25 ## SID Trait p_value p_year o_year Outcome o_value `NA` dementia alcohol cancer diabetes heartProb ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 8024 A 3.7 2006 2006 dementia 0 NA 0 1 0 0 0 ## 2 8024 C 4.1 2006 2006 dementia 0 NA 0 1 0 0 0 ## 3 8024 E 2.7 2006 2006 dementia 0 NA 0 1 0 0 0 ## 4 8024 N 2.7 2006 2006 dementia 0 NA 0 1 0 0 0 ## 5 8024 O 2.9 2006 2006 dementia 0 NA 0 1 0 0 0 ## 6 8027 A 3.2 2009 2017 dementia 1 NA 1 1 0 0 0 ## 7 8027 A 3.2 2009 2017 braak 5.5 NA 1 1 0 0 0 ## 8 8027 A 3.2 2009 2017 hipSclerosis 0 NA 1 1 0 0 0 ## 9 8027 A 3.2 2009 2017 lewyBodyDis 1 NA 1 1 0 0 0 ## 10 8027 C 3.4 2009 2017 dementia 1 NA 1 1 0 0 0 ## # ℹ 4,310 more rows ## # ℹ 12 more variables: hypertension &lt;dbl&gt;, married &lt;dbl&gt;, race &lt;dbl&gt;, smokes &lt;dbl&gt;, stroke &lt;dbl&gt;, ## # exercise &lt;dbl&gt;, BMI &lt;dbl&gt;, age &lt;dbl&gt;, education &lt;dbl&gt;, SRhealth &lt;dbl&gt;, gender &lt;dbl&gt;, cognition &lt;dbl&gt; save(eas_cov, eas_pers, eas_out, eas_combined, eas_cog, file = sprintf(&quot;%s/data/clean/eas_cleaned.RData&quot;, load_path)) rm(list =ls()[grepl(&quot;eas&quot;, ls())]) 2.7 German Socioeconomic Panel Study (GSOEP) The German Socioeconomic Panel Study (GSOEP; Socio-Economic Panel, 2017) is an ongoing longitudinal study of German collected by the German Institute of Economic Research (DIW Berlin). The data are freely available at https://www.diw.de/soep by application. Data have been collected annually since 1984 (the latest data release includes data up to 2017). Participants have been recruited from more than 11,000 households, which are nationally representative of private German households. 20,000 individuals are sampled each year, on average. It is critical to note that the GSOEP samples households, not individuals, and the households consist of individuals living in both the “old” and “new” federal states (the former West and East Germany), foreigners, and recent immigrants to Germany. Sample size varies by year, ranging from approximately 10,000 (1989) to 31,000 (2013). This provides 99% power to detect a zero-order correlation effect size of ~.06, two-tailed at alpha &lt; .05. 2.7.1 Load Data gsoep_read_fun &lt;- function(Year, WL){ old.names &lt;- (gsoep_codebook %&gt;% filter(year == Year | category == &quot;proc&quot;))$orig_itemname p &lt;- sprintf(&quot;%s/gsoep/%sp.sav&quot;, data_path, WL) %&gt;% haven::read_sav(.) %&gt;% full_join(sprintf(&quot;%s/gsoep/%skind.sav&quot;, data_path, WL) %&gt;% haven::read_sav(.)) %&gt;% full_join(sprintf(&quot;%s/gsoep/%spequiv.sav&quot;, data_path, WL) %&gt;% haven::read_sav(.)) %&gt;% full_join(sprintf(&quot;%s/gsoep/%spgen.sav&quot;, data_path, WL) %&gt;% haven::read_sav(.)) %&gt;% full_join(sprintf(&quot;%s/gsoep/%spkal.sav&quot;, data_path, WL) %&gt;% haven::read_sav(.)) %&gt;% select(one_of(old.names)) %&gt;% gather(key = orig_itemname, value = value, -persnr, -hhnr, na.rm = T) sprintf(&quot;%s/gsoep/%shbrutto.sav&quot;, data_path, WL) %&gt;% haven::read_sav(.) %&gt;% full_join(sprintf(&quot;%s/gsoep/%sh.sav&quot;, data_path, WL) %&gt;% haven::read_sav(.)) %&gt;% select(one_of(old.names)) %&gt;% gather(key = orig_itemname, value = value, -hhnr, na.rm = T) %&gt;% full_join(p %&gt;% select(persnr, hhnr) %&gt;% distinct()) %&gt;% full_join(p) } gsoep_codebook &lt;- (codebook %&gt;% filter(study == &quot;GSOEP&quot;))$codebook[[1]] %&gt;% mutate(orig_itemname = str_to_lower(orig_itemname)) gsoep_codebook ## # A tibble: 594 × 17 ## study dataset category name itemname wave waveletter year orig_itemname description scale reverse_code ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 gosep cognit cogniti… cogn… animals1 23 w 2006 f99z30r Symbol Dig… inte… no ## 2 gosep cognit cogniti… cogn… animals1 29 bc 2012 f99z30r Symbol Dig… inte… no ## 3 gosep cognit cogniti… cogn… animals2 23 w 2006 f99z60r Symbol Dig… inte… no ## 4 gosep cognit cogniti… cogn… animals2 29 bc 2012 f99z60r Symbol Dig… inte… no ## 5 gosep cognit cogniti… cogn… animals3 23 w 2006 f99z90r Symbol Dig… inte… no ## 6 gosep cognit cogniti… cogn… animals3 29 bc 2012 f99z90r Symbol Dig… inte… no ## 7 gosep cognit cogniti… cogn… symDig1 23 w 2006 f96t30g Symbol Dig… inte… no ## 8 gosep cognit cogniti… cogn… symDig1 29 bc 2012 f96t30g Symbol Dig… inte… no ## 9 gosep cognit cogniti… cogn… symDig2 23 w 2006 f96t60g Symbol Dig… inte… no ## 10 gosep cognit cogniti… cogn… symDig2 29 bc 2012 f96t60g Symbol Dig… inte… no ## # ℹ 584 more rows ## # ℹ 5 more variables: recode &lt;chr&gt;, mini &lt;dbl&gt;, maxi &lt;dbl&gt;, comp_rule &lt;chr&gt;, long_rule &lt;chr&gt; gsoep &lt;- gsoep_codebook %&gt;% select(wave, waveletter, year) %&gt;% filter(complete.cases(.)) %&gt;% distinct() %&gt;% arrange(year) %&gt;% filter(year != &quot;2018&quot;) %&gt;% mutate(data = map2(year, waveletter, gsoep_read_fun)) old.names &lt;- unique(gsoep_codebook$orig_itemname) gsoep_cog &lt;- sprintf(&quot;%s/gsoep/cognit.sav&quot;, data_path) %&gt;% haven::read_sav(.) %&gt;% select(persnr, hhnr, one_of(old.names)) %&gt;% haven::zap_labels(.) %&gt;% select(-hhnr) %&gt;% gather(key = orig_itemname, value = value, -persnr, na.rm = T) gsoep_long &lt;- gsoep %&gt;% unnest(data) %&gt;% select(-hhnr, -wave, -waveletter, -year) %&gt;% # filter(persnr %in% gsoep_cog_subs) %&gt;% full_join(gsoep_cog) %&gt;% rename(SID = persnr) save(gsoep, file = sprintf(&quot;%s/data/clean/gsoep_raw.RData&quot;, load_path)) rm(gsoep) 2.7.2 Recoding &amp; Reverse Scoring gsoep_waves &lt;- p_waves %&gt;% filter(Study == &quot;GSOEP&quot;) %&gt;% select(Used) %&gt;% distinct() # join data with recoding info gsoep_recode &lt;- gsoep_codebook %&gt;% filter(category %in% c(&quot;pers&quot;, &quot;outcome&quot;, &quot;covariates&quot;, &quot;cognition&quot;)) %&gt;% select(category, name, itemname, wave, year, orig_itemname, reverse_code:long_rule) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% left_join(gsoep_long))) # recode recode_fun &lt;- function(rule, y, year){ x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } gsoep_recode &lt;- gsoep_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% group_by(recode, year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(recode, data, year), recode_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(value &lt; 0 | is.nan(value) | is.infinite(value), NA, value)))) # reverse code gsoep_recode &lt;- gsoep_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(value = ifelse(reverse_code == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))))) fun_call &lt;- function(x, rule){ switch(rule, average = mean(x, na.rm = T), mode = Mode(x)[1], sum = sum(x, na.rm = T), skip = unique(x)[1], select = unique(x)[1], max = max(x, na.rm = T), min = min(x, na.rm = T)) } 2.7.3 Covariates load(sprintf(&quot;%s/data/clean/gsoep_cleaned.RData&quot;, local_path)) yrBrth &lt;- gsoep_recode %&gt;% filter(name == &quot;yearBrth&quot;) %&gt;% unnest(data) %&gt;% group_by(SID) %&gt;% summarize(yearBrth = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(yearBrth = ifelse(is.infinite(yearBrth), NA, yearBrth), yearBrth = ifelse(yearBrth &lt; 1000, yearBrth + 1000, yearBrth)) # compositing within years year_comp_fun &lt;- function(df, rule, name){ print(paste(rule, name)) df %&gt;% group_by(SID, yearBrth, year, long_rule) %&gt;% # group by person and item (collapse across age) summarize(value = fun_call(value, rule)) %&gt;% ungroup() } gsoep_waves &lt;- p_waves %&gt;% filter(Study == &quot;GSOEP&quot;) %&gt;% select(Used) %&gt;% distinct() gsoep_cov &lt;- gsoep_recode %&gt;% filter(category == &quot;covariates&quot;) %&gt;% mutate(data = ifelse(name == &quot;alcohol&quot;, map(data, ~(.) %&gt;% mutate(year = ifelse(year == 2006, 2005, year))), data)) %&gt;% mutate(data = map(data, ~(.) %&gt;% left_join(yrBrth) %&gt;% filter(year &lt;= max(gsoep_waves$Used) &amp; !is.na(value)) %&gt;% group_by(comp_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(comp_rule = ifelse(is.na(comp_rule), &quot;skip&quot;, comp_rule)))) %&gt;% filter(map(data, nrow) &gt; 0) %&gt;% unnest(data) %&gt;% mutate(data = pmap(list(data, comp_rule, name), year_comp_fun)) %&gt;% unnest(data) comp_fun &lt;- function(rule, p_year){ gsoep_cov %&gt;% filter(year &lt;= p_year &amp; long_rule == rule) %&gt;% group_by(SID, yearBrth, name) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() } gsoep_cov &lt;- crossing( p_year = gsoep_waves$Used, long_rule = unique(gsoep_cov$long_rule) ) %&gt;% mutate(data = map2(long_rule, p_year, comp_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %&gt;% select(-long_rule, -yearBrth) %&gt;% pivot_wider(names_from = name, values_from = value) %&gt;% mutate(yearBrth = ifelse(yearBrth &lt; 1000, yearBrth + 1000, yearBrth)) gsoep_cov ## # A tibble: 114,106 × 16 ## p_year SID exercise height weight cancer diabetes married stroke alcohol education smokes gender ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2005 101 1.67 NA NA 0 0 1 0 NA NA NA 0 ## 2 2005 102 1 NA NA 0 0 1 0 NA NA NA 1 ## 3 2005 103 2.67 NA NA 0 0 0 0 NA NA NA 0 ## 4 2005 201 2 157 61 0 0 0 0 1 11 0 1 ## 5 2005 202 3 NA NA 0 0 0 0 NA NA NA 1 ## 6 2005 203 4 177 77 0 0 0 0 1 NA 0 0 ## 7 2005 301 1 NA NA 0 0 1 0 NA NA NA 0 ## 8 2005 302 1 NA NA 0 0 1 0 NA NA NA 1 ## 9 2005 401 1 NA NA 0 0 0 0 NA NA NA 0 ## 10 2005 501 1 NA NA 0 0 0 0 NA NA NA 1 ## # ℹ 114,096 more rows ## # ℹ 3 more variables: yearBrth &lt;dbl&gt;, age &lt;dbl&gt;, SRhealth &lt;dbl&gt; 2.7.4 Personality Variables gsoep_pers &lt;- gsoep_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% unnest(data) %&gt;% filter(year %in% gsoep_waves$Used) %&gt;% distinct() # alpha&#39;s gsoep_alpha &lt;- gsoep_pers %&gt;% select(name, itemname, year, SID, value) %&gt;% group_by(name, year) %&gt;% nest() %&gt;% mutate(data = map(data, ~(.) %&gt;% pivot_wider(names_from = itemname, values_from = value)), alpha = map(data, possibly(~psych::alpha((.) %&gt;% select(-persnr)), NA_real_))) comp_fun &lt;- function(df, rule){ df %&gt;% group_by(SID) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() } # create composites gsoep_pers &lt;- gsoep_pers %&gt;% group_by(name, comp_rule, year) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, comp_fun)) %&gt;% unnest(data) %&gt;% select(-comp_rule) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) gsoep_pers ## # A tibble: 191,511 × 4 ## name year SID value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 A 2005 201 7 ## 2 A 2005 203 4.67 ## 3 A 2005 602 4.33 ## 4 A 2005 901 4.67 ## 5 A 2005 1202 7 ## 6 A 2005 1501 4.67 ## 7 A 2005 1601 4 ## 8 A 2005 1602 6.67 ## 9 A 2005 1603 4.33 ## 10 A 2005 1701 7 ## # ℹ 191,501 more rows 2.7.5 Outcome Variables gsoep_pers_subs &lt;- unique(gsoep_pers$SID) gsoep_waves &lt;- p_waves %&gt;% filter(Study == &quot;GSOEP&quot;) %&gt;% select(Used) %&gt;% distinct() # composite within years # compositing within years year_comp_fun &lt;- function(df, rule){ df %&gt;% group_by(SID, name, year) %&gt;% # group by person and item (collapse across age) summarize(value = fun_call(value, rule)) %&gt;% ungroup() } gsoep_out &lt;- gsoep_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% unnest(data) %&gt;% # filter(year &lt;= max(gsoep_waves$Used)) %&gt;% group_by(comp_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(comp_rule = ifelse(comp_rule == &quot;select&quot;, &quot;skip&quot;, comp_rule), data = map2(data, comp_rule, year_comp_fun)) %&gt;% unnest(data) # composite across years comp_fun &lt;- function(p_year){ gsoep_out %&gt;% group_by(SID, name) %&gt;% summarize(value = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value), NA, value)) } gsoep_out &lt;- tibble(p_year = gsoep_waves$Used) %&gt;% mutate(data = map(p_year, comp_fun)) %&gt;% unnest(data) %&gt;% mutate(o_year = 2017) gsoep_out ## # A tibble: 109,214 × 5 ## p_year SID name value o_year ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2005 602 dementia 0 2017 ## 2 2005 604 dementia 0 2017 ## 3 2005 901 dementia 0 2017 ## 4 2005 1501 dementia 0 2017 ## 5 2005 1601 dementia 0 2017 ## 6 2005 1602 dementia 0 2017 ## 7 2005 2301 dementia 0 2017 ## 8 2005 2302 dementia 0 2017 ## 9 2005 4701 dementia 0 2017 ## 10 2005 4901 dementia 0 2017 ## # ℹ 109,204 more rows 2.7.6 Cognition Variables gsoep_cog &lt;- gsoep_recode %&gt;% filter(category == &quot;cognition&quot;) %&gt;% unnest(data) %&gt;% filter(!is.na(value)) gsoep_cog_waves &lt;- gsoep_cog %&gt;% select(itemname, SID, year) %&gt;% group_by(SID, itemname) %&gt;% summarize(o_year = max(year)) %&gt;% ungroup() gsoep_cog &lt;- gsoep_cog %&gt;% right_join(gsoep_cog_waves) %&gt;% filter(year == o_year) %&gt;% filter(!is.na(value)) %&gt;% group_by(name, itemname, year) %&gt;% mutate(value = pomp(value)) %&gt;% group_by(name, o_year, SID) %&gt;% summarize(value = mean(value)) %&gt;% ungroup() %&gt;% pivot_wider(names_from = &quot;name&quot;, values_from = &quot;value&quot;) gsoep_cog ## # A tibble: 22,445 × 3 ## o_year SID cognition ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2012 201 0 ## 2 2012 1501 3.81 ## 3 2012 5601 2.06 ## 4 2012 6002 2.46 ## 5 2012 7302 1.44 ## 6 2012 8603 3.75 ## 7 2012 9801 3.88 ## 8 2012 11301 3.45 ## 9 2012 12303 2.66 ## 10 2012 13401 1.98 ## # ℹ 22,435 more rows 2.7.7 Combine Data gsoep_combined &lt;- gsoep_pers %&gt;% rename(Trait = name, p_value = value, p_year = year) %&gt;% full_join(gsoep_out %&gt;% select(p_year, SID, Outcome = name, o_year, o_value = value)) %&gt;% full_join(gsoep_cov) %&gt;% left_join( gsoep_out %&gt;% filter(name == &quot;dementia&quot;) %&gt;% pivot_wider(names_from = &quot;name&quot;, values_from = &quot;value&quot;) ) %&gt;% full_join(gsoep_cog) %&gt;% filter(!is.na(p_value) &amp; !is.na(o_value)) %&gt;% mutate(age = p_year - yearBrth , BMI = weight/((height/100)^2)) gsoep_combined ## # A tibble: 136,465 × 24 ## Trait p_year SID p_value Outcome o_year o_value exercise height weight cancer diabetes married stroke ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 A 2005 602 4.33 dementia 2017 0 2.8 177 87 0 0 1 0 ## 2 A 2005 901 4.67 dementia 2017 0 2.8 158 47 0 0 0 0 ## 3 A 2005 1501 4.67 dementia 2017 0 1 168. 84 0 0 0 0 ## 4 A 2005 1601 4 dementia 2017 0 2.67 174. 75 0 0 1 0 ## 5 A 2005 1602 6.67 dementia 2017 0 2 160. 48 0 0 1 0 ## 6 A 2005 2301 5 dementia 2017 0 1.8 180 75 0 0 1 0 ## 7 A 2005 2302 3.33 dementia 2017 0 3 157 46.5 0 0 1 0 ## 8 A 2005 4701 6 dementia 2017 0 2.2 168 70 0 0 0 0 ## 9 A 2005 4901 5.33 dementia 2017 0 1 162. 66.5 0 0 0 0 ## 10 A 2005 5201 6.33 dementia 2017 0 1.07 183 83 0 0 1 0 ## # ℹ 136,455 more rows ## # ℹ 10 more variables: alcohol &lt;dbl&gt;, education &lt;dbl&gt;, smokes &lt;dbl&gt;, gender &lt;dbl&gt;, yearBrth &lt;dbl&gt;, ## # age &lt;dbl&gt;, SRhealth &lt;dbl&gt;, dementia &lt;dbl&gt;, cognition &lt;dbl&gt;, BMI &lt;dbl&gt; save(gsoep_cov, gsoep_alpha, gsoep_pers, gsoep_out, gsoep_combined, gsoep_cog, file = sprintf(&quot;%s/data/clean/gsoep_cleaned.RData&quot;, load_path)) rm(list =ls()[grepl(&quot;gsoep&quot;, ls())]) 2.8 The Longitudinal Studies for the Social sciences (LISS) The Longitudinal Studies for the Social sciences (LISS; Scherpenzeel, Das, Ester, &amp; Kaczmirek, 2010) is an ongoing longitudinal study of households in the Netherlands. These data are online, through application, from https://statements.centerdata.nl/liss-panel-data-statement. Participants were approximately 8,000 Dutch-speaking individuals permanently residing in the Netherlands from 5,000 households. Data have been collected annually since 2007. The latest data release includes 11 waves of data from 2008 to 2018. More documentation are available at https://www.dataarchive.lissdata.nl/study_units/view/1. Sample sizes vary by year, ranging from 5,021 (2018) to 6808 (2008). This provides 99/% power to detect a correlation effect size of ~.04, two-tailed at alpha .05. 2.8.1 Load Data liss_read_fun &lt;- function(x){ sprintf(&quot;%s/liss/%s&quot;, data_path, x) %&gt;% haven::read_sav(.) %&gt;% select(one_of(old.names)) } liss_codebook &lt;- (codebook %&gt;% filter(study == &quot;LISS&quot;))$codebook[[1]] liss_codebook ## # A tibble: 1,327 × 17 ## study dataset category name itemname wave wave_letter year orig_itemname description scale ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 liss ai07a cognition cognition BSI 1 a 2008 ai07a031 BSI problems … &quot;1\\t… ## 2 liss ai08b cognition cognition BSI 2 b 2009 ai08b031 BSI problems … &quot;1\\t… ## 3 liss ai08c cognition cognition BSI 3 c 2010 ai08c031 BSI problems … &quot;1\\t… ## 4 liss ai08d cognition cognition BSI 4 d 2011 ai08d031 BSI problems … &quot;1\\t… ## 5 liss avars_2008 covariates yearBrth YOB1 1 a 2008 gebjaar Year of Birth &quot;num… ## 6 liss avars_2009 covariates yearBrth YOB1 2 b 2009 gebjaar Year of Birth &quot;num… ## 7 liss avars_2010 covariates yearBrth YOB1 3 c 2010 gebjaar Year of Birth &quot;num… ## 8 liss avars_2011 covariates yearBrth YOB1 4 d 2011 gebjaar Year of Birth &quot;num… ## 9 liss avars_2012 covariates yearBrth YOB1 5 e 2012 gebjaar Year of Birth &quot;num… ## 10 liss avars_2013 covariates yearBrth YOB1 6 f 2013 gebjaar Year of Birth &quot;num… ## # ℹ 1,317 more rows ## # ℹ 6 more variables: reverse_code &lt;chr&gt;, recode &lt;chr&gt;, mini &lt;dbl&gt;, maxi &lt;dbl&gt;, comp_rule &lt;chr&gt;, ## # long_rule &lt;chr&gt; old.names &lt;- unique(liss_codebook$orig_itemname) %&gt;% str_to_lower datasets &lt;- sprintf(&quot;%s/liss&quot;, data_path) %&gt;% list.files() liss &lt;- tibble(datasets = datasets) %&gt;% mutate(data = map(datasets, liss_read_fun)) liss &lt;- reduce(liss$data, full_join) %&gt;% haven::zap_labels(.) save(liss, file = sprintf(&quot;%s/data/clean/liss_raw.RData&quot;, load_path)) avars &lt;- tibble(ds = datasets[grepl(&quot;avar&quot;, datasets)]) %&gt;% mutate(data = map(ds, ~sprintf(&quot;%s/liss/%s&quot;, data_path, .) %&gt;% haven::read_sav(.) %&gt;% select(one_of(old.names)) %&gt;% haven::zap_labels(.))) %&gt;% separate(ds, c(&quot;ds&quot;, &quot;year&quot;, &quot;scrap1&quot;, &quot;scrap2&quot;), sep = &quot;_&quot;) %&gt;% separate(year, c(&quot;year&quot;, &quot;month&quot;), -2) %&gt;% select(year, month, data) %&gt;% unnest(data) 2.8.2 Recoding &amp; Reverse-Scoring rename_fun &lt;- function(cb, var){ print(var) old.names &lt;- unique((liss_codebook %&gt;% filter(name == var))$orig_itemname) df &lt;- liss %&gt;% select(SID = nomem_encr, HHID = nohouse_encr, one_of(old.names)) %&gt;% gather(key = orig_itemname, value = value, -SID, -HHID, na.rm=T) if(length(old.names) &gt; 1){ df &lt;- df %&gt;% left_join(cb %&gt;% select(itemname, year, orig_itemname, reverse_code:long_rule)) } else { df &lt;- df %&gt;% left_join(cb %&gt;% select(-(itemname:year)) %&gt;% distinct()) %&gt;% mutate(year = 0) } if(var %in% c(&quot;yearBrth&quot;, &quot;gender&quot;)) df &lt;- df %&gt;% left_join(avars %&gt;% select(-category, -name)) return(df) } avars &lt;- avars %&gt;% select(SID = nomem_encr, HHID = nohouse_encr, everything()) %&gt;% group_by(SID, HHID, year) %&gt;% summarize_at(vars(gebjaar, geslacht), Mode) %&gt;% ungroup() %&gt;% pivot_longer(cols = c(&quot;gebjaar&quot;, &quot;geslacht&quot;) , names_to = &quot;orig_itemname&quot; , values_to = &quot;value&quot;) %&gt;% mutate(year = as.numeric(year)) %&gt;% left_join( liss_codebook %&gt;% select(category, name, itemname, year, orig_itemname, reverse_code:long_rule) ) # rename variables liss_recode &lt;- liss_codebook %&gt;% filter(category %in% c(&quot;covariates&quot;, &quot;pers&quot;, &quot;outcome&quot;, &quot;cognition&quot;)) %&gt;% select(category, name:wave, year:orig_itemname, reverse_code:long_rule) %&gt;% group_by(category, name) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, name, rename_fun)) recode_fun &lt;- function(rule, y){ x &lt;- y$value if(!is.na(rule)){y$value &lt;- eval(parse(text = rule))} return(y) } liss_recode &lt;- liss_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% group_by(recode) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(recode, data), recode_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(value &lt; 0 | is.nan(value) | is.infinite(value), NA, value)))) # reverse code liss_recode &lt;- liss_recode %&gt;% mutate(data = map(data, ~(.) %&gt;% mutate(value = ifelse(tolower(reverse_code) == &quot;no&quot; | is.na(reverse_code), value, reverse.code(-1, value, mini = mini, maxi = maxi))))) fun_call &lt;- function(x, rule){ switch(rule, average = mean(x, na.rm = T), mode = Mode(x)[1], sum = sum(x, na.rm = T), skip = unique(x)[1], select = unique(x)[1], max = max(x, na.rm = T), min = min(x, na.rm = T)) } 2.8.3 Covariates load(sprintf(&quot;%s/data/clean/liss_cleaned.RData&quot;, local_path)) # bring in year or birth for cleaning liss_cov &lt;- liss_recode %&gt;% filter(category == &quot;covariates&quot;) %&gt;% unnest(data) %&gt;% distinct() # compositing within years year_comp_fun &lt;- function(df, rule){ df %&gt;% # group by person and item (collapse across age) group_by(SID, HHID, long_rule, name, year) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) } liss_waves &lt;- p_waves %&gt;% filter(Study == &quot;LISS&quot;) %&gt;% select(Used) %&gt;% distinct() liss_cov &lt;- liss_cov %&gt;% filter(year &lt;= max(liss_waves$Used)) %&gt;% group_by(comp_rule) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map2(data, comp_rule, year_comp_fun)) %&gt;% unnest(data) comp_fun &lt;- function(rule, p_year){ liss_cov %&gt;% filter(year &lt;= p_year &amp; long_rule == rule) %&gt;% group_by(SID, HHID, name) %&gt;% summarize(value = fun_call(value, rule)) %&gt;% ungroup() } liss_cov &lt;- crossing( p_year = liss_waves$Used, long_rule = unique(liss_cov$long_rule) ) %&gt;% mutate(data = map2(long_rule, p_year, comp_fun)) %&gt;% unnest(data) %&gt;% mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %&gt;% select(-long_rule) %&gt;% pivot_wider(names_from = name, values_from = value, values_fn = list(value = max)) %&gt;% mutate(BMI = weight/((height/100)^2)) liss_cov ## # A tibble: 27,202 × 21 ## p_year SID HHID weight exercise alcohol cancer diabetes education ethnicity heartProb height ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2008 800033 583404 58 NA 1 0 0 12 2 0 165 ## 2 2008 800042 500277 74.5 0 1 0 0 16 NA 0 169 ## 3 2008 800045 548654 84 NA 1 0 0 NA NA 0 185 ## 4 2008 800057 580532 85 NA 1 0 0 18 NA 0 198 ## 5 2008 800076 578048 57 0 1 0 0 NA NA 0 167 ## 6 2008 800119 537783 84.5 NA 0 1 0 NA 2 0 174 ## 7 2008 800125 582101 61 NA 1 0 0 16 2 0 158 ## 8 2008 800134 549826 66 NA 1 0 0 NA NA 0 162 ## 9 2008 800158 519049 87.5 NA 1 0 0 14 NA 0 180 ## 10 2008 800170 520571 56.5 0 1 0 0 14 NA 0 160 ## # ℹ 27,192 more rows ## # ℹ 9 more variables: parkinsons &lt;dbl&gt;, respDis &lt;dbl&gt;, smokes &lt;dbl&gt;, stroke &lt;dbl&gt;, married &lt;dbl&gt;, ## # gender &lt;dbl&gt;, yearBrth &lt;dbl&gt;, SRhealth &lt;dbl&gt;, BMI &lt;dbl&gt; 2.8.4 Personality Variables liss_pers &lt;- liss_recode %&gt;% filter(category == &quot;pers&quot;) %&gt;% unnest(data) %&gt;% filter(year == liss_waves$Used) %&gt;% distinct() # alpha&#39;s liss_alpha &lt;- liss_pers %&gt;% select(name, itemname, year, SID, value) %&gt;% group_by(name, year) %&gt;% nest() %&gt;% mutate(data = map(data, ~(.) %&gt;% pivot_wider(names_from = itemname, values_from = value)), alpha = map(data, possibly(~psych::alpha((.) %&gt;% select(-SID)), NA_real_))) # create composites liss_pers &lt;- liss_pers %&gt;% group_by(SID, HHID, name, year) %&gt;% summarize(value = mean(value, na.rm = T)) %&gt;% ungroup() liss_pers ## # A tibble: 54,280 × 5 ## SID HHID name year value ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 800033 583404 A 2008 2.8 ## 2 800033 583404 C 2008 2.3 ## 3 800033 583404 E 2008 2.4 ## 4 800033 583404 N 2008 2.7 ## 5 800033 583404 NA 2008 3.3 ## 6 800033 583404 O 2008 3.4 ## 7 800033 583404 PA 2008 4.2 ## 8 800033 583404 SWL 2008 6 ## 9 800042 500277 A 2008 3.7 ## 10 800042 500277 C 2008 3.9 ## # ℹ 54,270 more rows 2.8.5 Cognition Variables liss_cog &lt;- liss_recode %&gt;% filter(category == &quot;cognition&quot;) %&gt;% unnest(data) %&gt;% filter(year == liss_waves$Used) %&gt;% filter(!is.na(value)) %&gt;% group_by(name, itemname, year) %&gt;% mutate(value = pomp(value)) %&gt;% distinct() %&gt;% group_by(name, SID) %&gt;% summarize(value = mean(value)) %&gt;% ungroup() %&gt;% pivot_wider(names_from = &quot;name&quot;, values_from = &quot;value&quot;) liss_cog ## # A tibble: 1,804 × 2 ## SID cognition ## &lt;dbl&gt; &lt;dbl&gt; ## 1 800076 2.5 ## 2 800170 0 ## 3 800186 7.5 ## 4 800231 2.5 ## 5 800326 0 ## 6 800354 2.5 ## 7 800424 7.5 ## 8 800540 5 ## 9 800601 5 ## 10 800790 5 ## # ℹ 1,794 more rows 2.8.6 Outcome Variables liss_out &lt;- liss_recode %&gt;% filter(category == &quot;outcome&quot;) %&gt;% unnest(data) %&gt;% mutate(p_year = liss_waves$Used, group = ifelse(year &gt; p_year, &quot;future&quot;, &quot;past&quot;)) %&gt;% group_by(SID, name, p_year) %&gt;% mutate(o_year = max(year[!is.na(value)])) %&gt;% group_by(SID, name, group, p_year, o_year) %&gt;% summarize(value = max(value, na.rm = T)) %&gt;% ungroup() %&gt;% mutate(value = ifelse(is.infinite(value), NA, value)) %&gt;% pivot_wider(names_from = group, values_from = value) %&gt;% group_by(SID, p_year, name, o_year) %&gt;% mutate(value = ifelse(is.na(past) | (past == 0 &amp; !is.na(future)), future, ifelse(past == 0 &amp; is.na(future), past, ifelse(past == 1, NA, NA)))) %&gt;% ungroup() %&gt;% filter(!is.na(value)) liss_out ## # A tibble: 13,452 × 7 ## SID name p_year o_year future past value ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 800009 dementia 2008 2018 0 NA 0 ## 2 800012 dementia 2008 2015 0 NA 0 ## 3 800015 dementia 2008 2018 0 NA 0 ## 4 800018 dementia 2008 2012 0 NA 0 ## 5 800033 dementia 2008 2012 0 0 0 ## 6 800042 dementia 2008 2016 0 0 0 ## 7 800045 dementia 2008 2007 NA 0 0 ## 8 800054 dementia 2008 2018 0 NA 0 ## 9 800057 dementia 2008 2018 0 0 0 ## 10 800073 dementia 2008 2018 0 NA 0 ## # ℹ 13,442 more rows 2.8.7 Combine Data liss_combined &lt;- liss_pers %&gt;% rename(Trait = name, p_value = value, p_year = year) %&gt;% full_join(liss_out %&gt;% rename(Outcome = name, o_value = value)) %&gt;% full_join(liss_cov) %&gt;% left_join( liss_out %&gt;% filter(name == &quot;dementia&quot;) %&gt;% mutate(value = ifelse(rowSums(cbind(future, past), na.rm = T) &gt;= 1, 1, 0)) %&gt;% select(-future, -past) %&gt;% pivot_wider(names_from = &quot;name&quot;, values_from = &quot;value&quot;) ) %&gt;% full_join(liss_cog) %&gt;% filter(!is.na(p_value) &amp; !is.na(o_value)) %&gt;% mutate(age = p_year - yearBrth) liss_combined ## # A tibble: 52,267 × 31 ## SID HHID Trait p_year p_value Outcome o_year future past o_value weight exercise alcohol cancer ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 800033 583404 A 2008 2.8 dementia 2012 0 0 0 58 NA 1 0 ## 2 800033 583404 C 2008 2.3 dementia 2012 0 0 0 58 NA 1 0 ## 3 800033 583404 E 2008 2.4 dementia 2012 0 0 0 58 NA 1 0 ## 4 800033 583404 N 2008 2.7 dementia 2012 0 0 0 58 NA 1 0 ## 5 800033 583404 NA 2008 3.3 dementia 2012 0 0 0 58 NA 1 0 ## 6 800033 583404 O 2008 3.4 dementia 2012 0 0 0 58 NA 1 0 ## 7 800033 583404 PA 2008 4.2 dementia 2012 0 0 0 58 NA 1 0 ## 8 800033 583404 SWL 2008 6 dementia 2012 0 0 0 58 NA 1 0 ## 9 800042 500277 A 2008 3.7 dementia 2016 0 0 0 74.5 0 1 0 ## 10 800042 500277 C 2008 3.9 dementia 2016 0 0 0 74.5 0 1 0 ## # ℹ 52,257 more rows ## # ℹ 17 more variables: diabetes &lt;dbl&gt;, education &lt;dbl&gt;, ethnicity &lt;dbl&gt;, heartProb &lt;dbl&gt;, height &lt;dbl&gt;, ## # parkinsons &lt;dbl&gt;, respDis &lt;dbl&gt;, smokes &lt;dbl&gt;, stroke &lt;dbl&gt;, married &lt;dbl&gt;, gender &lt;dbl&gt;, ## # yearBrth &lt;dbl&gt;, SRhealth &lt;dbl&gt;, BMI &lt;dbl&gt;, dementia &lt;dbl&gt;, cognition &lt;dbl&gt;, age &lt;dbl&gt; save(liss_cov, liss_alpha, liss_pers, liss_out, liss_combined, liss_cog, file = sprintf(&quot;%s/data/clean/liss_cleaned.RData&quot;, local_path)) rm(list =ls()[grepl(&quot;liss&quot;, ls())]) "],["runmodels.html", "Chapter 3 Models 3.1 Part 1: Combine Data 3.2 Part 2: Clean and Prepare Data Sets 3.3 Part 3: Models", " Chapter 3 Models In this section, we will: Combine the data across samples and create new data frames for each personality trait / well-being x covariate x outcome x moderator combination. As preregistered, we will then rescale variables in each sample to harmonize across samples Next, we will create a series of functions to: Run the model Extract sample-specific estimates from each sample Extract cross-sample heterogeneity estimates Extract fixed and and random simple slopes Run the models or export files to the computing cluster to speed up runtime. 3.1 Part 1: Combine Data First, we’ll just load in all the combined data frames for each sample and keep our core variables: loadRData &lt;- function(fileName, type){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/data/clean/%s_cleaned.RData&quot;, local_path, fileName) load(path) get(ls()[grepl(type, ls())]) } # which(apply(nested_data %&gt;% mutate(cols = map(data, colnames)) %&gt;% select(-data) %&gt;% unnest(cols) %&gt;% mutate(inc = &quot;yes&quot;) %&gt;% spread(study, inc), 1, function(x){sum(is.na(x))/7*100}) &lt; 25) nested_data &lt;- tibble( study = studies , data = map(str_to_lower(study), ~loadRData(., &quot;combined&quot;)) ) %&gt;% mutate( data = map(data, ~(.) %&gt;% ungroup() %&gt;% mutate(SID = as.character(SID)) %&gt;% select(SID, Trait, p_year, p_value, Outcome, o_year, o_value # core variables , one_of(c(&quot;age&quot;, &quot;gender&quot;, &quot;education&quot;, &quot;cognition&quot; , &quot;alcohol&quot;, &quot;smokes&quot;, &quot;BMI&quot;, &quot;race&quot;, &quot;SRhealth&quot; , &quot;stroke&quot;, &quot;cancer&quot;, &quot;diabetes&quot;, &quot;heartProb&quot;, &quot;dementia&quot;))) ) , study = mapvalues(study, studies, studies_long) ) %&gt;% unnest(data) %&gt;% # removing this outcome because there was no variance for WUSM MAP filter(!(Outcome == &quot;vsclrInfrcts&quot; &amp; study == &quot;ADRC&quot;)) nested_data ## # A tibble: 421,476 × 22 ## study SID Trait p_year p_value Outcome o_year o_value age gender education cognition alcohol smokes ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ROS 000210… A 0 32 angiop… 2 3 80.0 0 22 4.19 0 0 ## 2 ROS 000210… A 0 32 arteri… 2 0 80.0 0 22 4.19 0 0 ## 3 ROS 000210… A 0 32 athero… 2 2 80.0 0 22 4.19 0 0 ## 4 ROS 000210… A 0 32 braak 2 6 80.0 0 22 4.19 0 0 ## 5 ROS 000210… A 0 32 cerad 2 1 80.0 0 22 4.19 0 0 ## 6 ROS 000210… A 0 32 hipScl… 2 0 80.0 0 22 4.19 0 0 ## 7 ROS 000210… A 0 32 lewyBo… 2 0 80.0 0 22 4.19 0 0 ## 8 ROS 000210… A 0 32 vsclrI… 2 0 80.0 0 22 4.19 0 0 ## 9 ROS 000210… A 0 32 vsclrM… 2 1 80.0 0 22 4.19 0 0 ## 10 ROS 000210… A 0 32 tdp43 2 1 80.0 0 22 4.19 0 0 ## # ℹ 421,466 more rows ## # ℹ 8 more variables: BMI &lt;dbl&gt;, race &lt;dbl&gt;, stroke &lt;dbl&gt;, cancer &lt;dbl&gt;, diabetes &lt;dbl&gt;, heartProb &lt;dbl&gt;, ## # dementia &lt;dbl&gt;, SRhealth &lt;dbl&gt; 3.2 Part 2: Clean and Prepare Data Sets Next time to rescale or relevel variables. 3.2.1 Descriptives But first, we’ll make a table of descriptive values (M (SD) or percentage) for all variables for each sample. cln &lt;- c(&quot;Study&quot;, &quot;E&quot;, &quot;A&quot;, &quot;C&quot;, &quot;N&quot;, &quot;O&quot;, &quot;Crystallized / Knowledge&quot;, &quot;Age (Years)&quot;, &quot;Education (Years)&quot;, &quot;% Women&quot;) fctr_vars &lt;- c(&quot;dementia&quot;, &quot;hipSclerosis&quot;, &quot;lewyBodyDis&quot;, &quot;tdp43&quot;, &quot;vsclrInfrcts&quot;, &quot;vsclrMcrInfrcts&quot;, &quot;gender&quot; , &quot;smokes&quot;, &quot;alcohol&quot;, &quot;race&quot;, &quot;stroke&quot;, &quot;cancer&quot;, &quot;diabetes&quot;, &quot;heartProb&quot;) transpose_df &lt;- function(df) { t_df &lt;- data.table::transpose(df) colnames(t_df) &lt;- rownames(df) rownames(t_df) &lt;- colnames(df) t_df &lt;- t_df %&gt;% tibble::rownames_to_column(.data = .) %&gt;% tibble::as_tibble(.) %&gt;% filter(row_number() != 1) %&gt;% set_names(c(&quot;Variable&quot;, df$study)) return(t_df) } desc_tab &lt;- nested_data %&gt;% select(-p_year, -o_year, -one_of(fctr_vars)) %&gt;% group_by(study, Trait, Outcome) %&gt;% mutate_at(vars(p_value, SRhealth), ~((. - min(., na.rm = T))/(max(., na.rm = T) - min(., na.rm = T))*10)) %&gt;% mutate_at(vars(p_value, SRhealth), ~ifelse(is.infinite(.), NA, .)) %&gt;% ungroup() %&gt;% pivot_wider(names_from = Outcome, values_from = o_value, values_fn = mean) %&gt;% pivot_wider(names_from = Trait, values_from = p_value, values_fn = mean) int_followup &lt;- nested_data %&gt;% select(study, SID, Trait, Outcome, p_year, o_year) %&gt;% mutate(interval = o_year - p_year , cat = ifelse(Outcome == &quot;dementia&quot;, &quot;dem_int&quot;, &quot;neuro_int&quot;)) %&gt;% group_by(study, SID, Trait, cat) %&gt;% summarize(interval = mean(interval)) %&gt;% group_by(study, SID, cat) %&gt;% summarize(interval = mean(interval)) %&gt;% group_by(study, cat) %&gt;% summarize(int = sprintf(&quot;%.2f (%.2f)&quot;, mean(interval, na.rm = T), sd(interval, na.rm = T))) %&gt;% ungroup() %&gt;% pivot_wider(names_from = &quot;cat&quot;, values_from = &quot;int&quot;) desc_tab &lt;- desc_tab %&gt;% group_by(study) %&gt;% mutate(n = n()) %&gt;% ungroup() %&gt;% left_join( desc_tab %&gt;% select(-dementia) %&gt;% filter(!is.na(braak) | !is.na(cerad) | !is.na(tdp43)) %&gt;% group_by(study) %&gt;% summarize(n_neuro = n()) %&gt;% ungroup() ) %&gt;% select(-one_of(fctr_vars)) %&gt;% distinct() %&gt;% pivot_longer(cols = c(-study, -SID, -n, -n_neuro), values_to = &quot;value&quot;, names_to = &quot;item&quot;, values_drop_na = T) %&gt;% group_by(study, item, n, n_neuro) %&gt;% summarize(est = sprintf(&quot;%.2f (%.2f)&quot;, mean(value, na.rm = T), sd(value, na.rm = T))) %&gt;% ungroup() %&gt;% pivot_wider(names_from = item, values_from = est) %&gt;% full_join( nested_data %&gt;% group_by(Outcome, SID, study) %&gt;% filter(o_year == min(o_year)) %&gt;% ungroup() %&gt;% select(-o_year, -dementia) %&gt;% pivot_wider(names_from = Outcome, values_from = o_value, values_fn = mean) %&gt;% select(-Trait, -p_year, -p_value) %&gt;% distinct() %&gt;% select(study, SID, one_of(fctr_vars)) %&gt;% distinct() %&gt;% group_by(study) %&gt;% summarize_at(vars(-SID), ~ifelse(is.nan(mean(., na.rm = T)), &quot;&quot;, sprintf(&quot;%i (%.2f%%)&quot;, sum(., na.rm = T), mean(., na.rm = T)*100))) %&gt;% # summarize_at(vars(-SID), ~mean(., na.rm = T)*100) %&gt;% # mutate_at(vars(-study), ~ifelse(is.nan(.) | is.na(.), &quot;&quot;, sprintf(&quot;%.2f%%&quot;, .))) %&gt;% ungroup() ) %&gt;% full_join(int_followup) %&gt;% select(study, E, A, C, N, O, PA, `NA`, SWL, n, dementia, dem_int, n_neuro, neuro_int, one_of(outcomes$short_name), age, gender, education, cognition, BMI, SRhealth, smokes, alcohol, BMI, race, stroke, cancer, diabetes, heartProb) %&gt;% transpose_df() %&gt;% mutate(Variable = mapvalues(Variable, c(&quot;n&quot;, &quot;n_neuro&quot;, &quot;dem_int&quot;, &quot;neuro_int&quot;), c(&quot;Valid Dementia N&quot;, &quot;Valid Neuropathology N&quot;, &quot;Mean Dementia Follow-up (Years)&quot;, &quot;Mean Neuropathology Follow-up (Years)&quot;)) , Variable = mapvalues(Variable, c(traits$short_name, outcomes$short_name), str_wrap(c(traits$long_name, outcomes$long_name), 25))) %&gt;% select(Variable, `Rush-MAP`, ROS, `WUSM-MAP`, EAS, GSOEP, HRS, LISS, SATSA) %&gt;% kable(., &quot;html&quot; , digits = 2 # , col.names = cln , caption = &quot;&lt;strong&gt;Table 1&lt;/strong&gt;&lt;br&gt;&lt;em&gt;Descriptive Statistics of All Harmonized Measures Across Samples&quot; , align = c(&quot;l&quot;, rep(&quot;c&quot;,9))) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% kableExtra::group_rows(&quot;Big Five Personality&quot;, 1, 5) %&gt;% kableExtra::group_rows(&quot;Subjective Well-Being&quot;, 6, 8) %&gt;% kableExtra::group_rows(&quot;Dementia&quot;, 9, 11) %&gt;% kableExtra::group_rows(&quot;Dementia and Neuropathology&quot;, 12, 23) %&gt;% kableExtra::group_rows(&quot;Covariates&quot;, 24, 36) %&gt;% add_footnote(notation = &quot;none&quot;, label = &quot;&lt;em&gt;Note.&lt;/em&gt; E = Extraversion; A = Agreeableness; C = Conscientiousness; N = Neuroticism; O = Openness, PA = Positive Affect, NA = Negative Affect, SWL = Satisfaction with Life; Age, education, gender, smoking, alcohol, BMI, chronic conditions, and cognition were assessed at the first baseline personality assessment.&quot;, escape = F); desc_tab (#tab:tab 2)Table 1Descriptive Statistics of All Harmonized Measures Across Samples Variable Rush-MAP ROS WUSM-MAP EAS GSOEP HRS LISS SATSA Big Five Personality Extraversion 5.50 (1.69) 5.17 (1.65) 5.73 (1.67) 5.59 (1.75) 6.40 (1.88) 7.32 (1.86) 5.64 (1.62) 6.33 (0.74) Agreeableness 5.33 (1.40) 6.37 (1.62) 6.73 (1.87) 7.45 (1.63) 8.41 (1.60) 6.68 (1.48) 7.23 (1.17) Conscientiousness 6.25 (1.57) 6.27 (1.39) 6.31 (1.79) 6.95 (1.73) 8.21 (1.55) 7.84 (1.63) 6.34 (1.49) 7.05 (1.35) Neuroticism 3.65 (1.68) 4.59 (1.61) 3.94 (1.91) 3.56 (2.08) 4.92 (2.04) 3.52 (2.06) 3.97 (1.69) 6.53 (1.35) Openness to Experience 5.50 (1.51) 5.60 (1.59) 5.85 (2.03) 5.88 (2.01) 6.43 (1.88) 5.98 (1.34) 4.84 (1.34) Subjective Well-Being Positive Affect 8.46 (1.82) 8.20 (3.86) 6.22 (2.15) 6.55 (1.94) 5.94 (1.67) 7.47 (2.12) Negative Affect 1.06 (1.30) 3.63 (1.98) 1.93 (1.82) 1.75 (1.76) 2.14 (2.29) Satisfaction with Life 7.39 (1.78) 6.75 (2.20) 7.00 (1.76) 6.07 (2.34) 6.56 (1.46) 5.75 (2.87) Dementia Valid Dementia N 4283 3374 1478 813 31072 14167 6543 2002 Incident Dementia Diagnosis 444 (22.17%) 428 (30.77%) 232 (27.39%) 44 (5.67%) 180 (1.03%) 1130 (7.98%) 20 (0.31%) 163 (8.14%) Mean Dementia Follow-up (Years) 5.48 (4.14) 9.56 (6.61) 15.59 (22.11) 2.70 (2.92) 11.20 (0.48) 6.76 (2.26) 5.19 (4.43) 21.00 (0.00) Dementia and Neuropathology Valid Neuropathology N 1721 1525 627 37 Mean Neuropathology Follow-up (Years) 6.16 (3.62) 10.46 (6.04) 14.83 (22.50) 7.29 (3.52) Braak Stage 3.77 (1.20) 3.58 (1.25) 4.01 (1.66) 3.12 (1.06) CERAD 2.16 (1.12) 2.22 (1.13) 2.46 (0.81) Lewy Body Disease 177 (23.14%) 177 (23.44%) 58 (38.67%) 4 (11.76%) Gross Cerebral Infarcts 298 (37.91%) 271 (34.70%) 158 (100.00%) Gross Cerebral Microinfarcts 260 (33.08%) 245 (31.37%) 27 (17.09%) Cerebral Atherosclerosis 1.13 (0.77) 1.24 (0.78) 1.29 (0.76) Cerebral Amyloid Angiopathy 1.29 (0.95) 1.29 (0.97) 1.27 (0.88) Arteriolosclerosis 1.03 (0.91) 0.99 (0.96) 1.42 (0.70) Hippocampal Sclerosis 69 (9.77%) 56 (7.64%) 3 (3.66%) 4 (11.76%) TDP-43 428 (54.31%) 353 (49.79%) 27 (31.40%) Covariates age 81.12 (6.96) 76.53 (7.24) 71.37 (10.39) 79.57 (5.39) 48.51 (16.93) 68.15 (10.59) 46.54 (15.94) 59.76 (14.02) gender 532 (25.93%) 417 (28.64%) 474 (56.63%) 476 (61.34%) 9166 (52.48%) 8438 (59.56%) 3568 (54.53%) 1177 (58.79%) education 14.87 (3.15) 18.25 (3.48) 15.71 (2.95) 14.46 (3.39) 11.60 (2.52) 12.57 (3.12) 12.60 (4.19) 10.32 (1.82) cognition 6.55 (1.02) 6.43 (0.98) 3.92 (1.29) 4.98 (0.81) 7.15 (1.63) 3.08 (2.81) 5.49 (1.35) BMI 27.03 (5.02) 27.32 (5.39) 28.28 (5.09) 25.61 (4.35) 27.65 (4.42) 25.42 (7.82) 25.50 (3.80) SRhealth 3.93 (2.94) 6.75 (2.30) 6.34 (2.79) 5.39 (1.89) 2.16 (2.79) smokes 870 (42.52%) 285 (19.57%) 97 (11.58%) 423 (54.51%) 5617 (33.97%) 7935 (56.01%) 4009 (61.97%) 998 (49.85%) alcohol 596 (36.01%) 362 (27.57%) 44 (5.25%) 714 (92.01%) 9800 (58.31%) 7523 (53.10%) 5953 (92.02%) 1334 (67.89%) race 361 (17.59%) 224 (15.38%) 126 (15.05%) 343 (44.20%) 5074 (35.82%) stroke 174 (9.26%) 96 (6.95%) 17 (2.03%) 34 (4.38%) 0 (0.00%) 1410 (9.95%) 52 (0.81%) 40 (2.06%) cancer 676 (32.96%) 444 (30.49%) 56 (6.68%) 136 (17.62%) 0 (0.00%) 2500 (17.65%) 104 (1.62%) 77 (3.98%) diabetes 275 (13.41%) 193 (13.26%) 75 (8.95%) 141 (18.24%) 0 (0.00%) 3376 (23.83%) 305 (4.76%) 124 (6.38%) heartProb 249 (12.15%) 147 (10.10%) 70 (8.35%) 170 (21.91%) 4367 (30.83%) 252 (3.93%) 667 (33.91%) Note. E = Extraversion; A = Agreeableness; C = Conscientiousness; N = Neuroticism; O = Openness, PA = Positive Affect, NA = Negative Affect, SWL = Satisfaction with Life; Age, education, gender, smoking, alcohol, BMI, chronic conditions, and cognition were assessed at the first baseline personality assessment. save_kable(desc_tab, file = sprintf(&quot;%s/results/tables/tab-1-desc.html&quot;, local_path)) 3.2.2 Zero-Order Correlations r_fun &lt;- function(d){ d &lt;- d[,apply(d, 2, function(x) sum(!is.na(x)) &gt; 0)] cor(d, use = &quot;pairwise&quot;) } nested_r &lt;- nested_data %&gt;% select(study, SID, Trait, p_value) %&gt;% pivot_wider(names_from = &quot;Trait&quot;, values_from = &quot;p_value&quot;, values_fn = mean) %&gt;% left_join( nested_data %&gt;% select(study, SID, Outcome, o_value) %&gt;% pivot_wider(names_from = &quot;Outcome&quot;, values_from = &quot;o_value&quot;, values_fn = mean) ) %&gt;% left_join( nested_data %&gt;% select(study, SID, age:SRhealth, -dementia) %&gt;% distinct() ) %&gt;% select(-SID) %&gt;% group_by(study) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(r = map(data, r_fun)) 3.2.2.1 Table cor_tab_fun &lt;- function(r, study){ coln &lt;- colnames(r) colnn &lt;- paste0(1:length(coln), &quot;. &quot;, coln) r &lt;- apply(r, c(1,2), function(x) sprintf(&quot;%.2f&quot;, x)) rownames(r) &lt;- colnn; colnames(r) &lt;- 1:length(coln) r[upper.tri(r)] &lt;- NA diag(r) &lt;- &quot;--&quot; tab &lt;- r %&gt;% data.frame() %&gt;% rownames_to_column(&quot;V&quot;) %&gt;% mutate(V = sprintf(&quot;&lt;strong&gt;%s&lt;/strong&gt;&quot;, V)) %&gt;% kable(. , &quot;html&quot; , col.names = c(&quot; &quot;, sprintf(&quot;&lt;strong&gt;%i&lt;s/trong&gt;&quot;, 1:length(coln))) , align = c(&quot;l&quot;, rep(&quot;c&quot;, length(coln))) , cap = sprintf(&quot;&lt;strong&gt;Table SX&lt;/strong&gt;&lt;br&gt;&lt;em&gt;Zero-Order Correlations Among Variables for %s&lt;/em&gt;&quot;, study) , escape = F ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times&quot;) save_kable(tab, file = sprintf(&quot;%s/results/tables/zero-order-cor/%s.html&quot;, local_path, study)) return(tab) } nested_r &lt;- nested_r %&gt;% mutate(tab = map2(r, study, cor_tab_fun)) nested_r$tab[[1]] (#tab:cor tables)Table SXZero-Order Correlations Among Variables for ROS 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 1. A – 2. C 0.29 – 3. E 0.25 0.23 – 4. N -0.33 -0.31 -0.34 – 5. O 0.21 0.08 0.19 -0.15 – 6. PA -0.09 0.15 0.06 -0.10 -0.18 – 7. SWL 0.40 0.20 0.18 -0.39 0.07 0.01 – 8. angiopathy 0.02 0.02 0.03 -0.05 -0.00 0.24 0.12 – 9. arteriolosclerosis 0.03 -0.01 -0.01 0.03 -0.14 -0.34 -0.18 0.04 – 10. atherosclerosis -0.08 -0.04 0.00 0.01 -0.11 -0.14 0.04 0.06 0.30 – 11. braak 0.04 -0.01 0.06 -0.03 0.01 -0.07 0.07 0.34 0.04 0.02 – 12. cerad -0.02 0.07 -0.01 -0.00 -0.04 0.07 0.33 -0.42 -0.01 -0.02 -0.60 – 13. hipSclerosis 0.04 -0.01 -0.03 0.03 -0.03 0.13 -0.01 0.05 0.06 0.03 0.06 -0.09 – 14. lewyBodyDis -0.01 -0.06 0.06 -0.01 0.06 -0.02 0.18 -0.03 0.03 -0.03 0.09 -0.06 0.11 – 15. vsclrInfrcts -0.01 0.01 -0.07 -0.00 -0.07 -0.11 -0.22 0.03 0.21 0.26 0.02 -0.03 -0.05 -0.01 – 16. vsclrMcrInfrcts 0.00 0.00 -0.06 -0.01 -0.11 -0.28 -0.17 0.03 0.07 0.10 0.03 -0.01 -0.00 -0.07 0.24 – 17. tdp43 -0.02 0.04 -0.00 -0.03 -0.03 0.49 0.06 0.10 0.09 0.09 0.28 -0.19 0.25 0.09 0.03 0.05 – 18. dementia -0.08 -0.10 -0.04 0.06 -0.12 0.04 0.08 0.15 0.15 0.15 0.36 -0.33 0.18 0.19 0.14 0.09 0.23 – 19. ageDementia 0.00 0.15 -0.07 -0.13 -0.07 0.23 0.00 -0.00 0.07 0.11 -0.02 0.07 0.01 0.00 0.08 0.01 0.19 -0.04 – 20. age -0.04 -0.05 -0.07 0.00 -0.16 0.30 0.18 0.13 0.19 0.23 0.17 -0.13 0.05 0.01 0.16 0.01 0.19 0.18 0.57 – 21. gender -0.12 -0.15 -0.04 -0.06 -0.10 -0.18 0.04 -0.09 -0.07 -0.01 -0.18 0.16 -0.08 0.03 0.06 0.08 -0.08 -0.01 -0.07 -0.08 – 22. education 0.13 0.09 0.12 -0.17 0.32 -0.27 -0.14 0.00 -0.05 -0.05 -0.07 -0.00 -0.06 -0.04 -0.08 -0.10 -0.09 -0.11 -0.14 -0.06 0.09 – 23. cognition 0.16 0.14 0.08 -0.17 0.31 -0.22 0.03 -0.09 -0.15 -0.15 -0.15 0.12 -0.06 -0.03 -0.10 -0.07 -0.11 -0.31 0.09 -0.45 -0.10 0.29 – 24. alcohol 0.11 0.02 0.05 -0.12 0.19 -0.02 0.12 -0.00 -0.08 -0.05 -0.05 0.01 -0.06 -0.01 0.02 -0.02 0.04 -0.07 0.00 -0.12 0.13 0.15 0.20 – 25. smokes -0.03 -0.11 -0.03 -0.04 0.03 -0.08 -0.04 -0.04 -0.08 -0.04 -0.10 0.05 -0.06 -0.00 -0.01 0.02 -0.05 -0.05 -0.07 -0.07 0.38 0.10 0.03 0.17 – 26. BMI -0.03 -0.06 0.05 0.01 0.06 0.03 0.03 -0.06 -0.11 -0.06 -0.08 0.09 -0.07 -0.05 -0.03 -0.03 -0.08 -0.14 -0.07 -0.18 0.02 0.02 0.12 -0.06 0.04 – 27. race -0.14 -0.04 0.01 0.06 -0.06 0.07 0.01 0.04 -0.01 -0.07 0.04 0.01 0.01 -0.02 -0.02 0.05 0.01 0.04 -0.09 -0.12 -0.07 -0.16 -0.15 -0.13 -0.08 0.04 – 28. stroke -0.05 -0.09 -0.09 0.06 -0.05 0.01 -0.14 -0.05 0.10 0.09 -0.04 -0.02 -0.08 -0.08 0.15 0.10 -0.00 0.02 -0.06 0.10 0.03 -0.00 -0.11 -0.04 0.00 -0.04 0.01 – 29. cancer -0.06 0.00 0.01 0.00 0.06 0.00 -0.09 -0.00 -0.05 -0.02 -0.06 0.02 0.04 -0.01 -0.02 -0.08 0.03 -0.06 0.05 0.05 -0.02 0.03 0.06 0.01 0.00 -0.02 -0.03 0.04 – 30. diabetes -0.02 -0.07 0.04 0.01 0.01 0.09 -0.11 -0.02 0.02 -0.06 -0.01 -0.06 0.02 0.02 0.02 0.01 -0.08 -0.04 -0.11 -0.02 0.06 -0.00 -0.07 -0.08 0.02 0.23 0.12 0.02 0.03 – 31. heartProb -0.06 -0.04 0.02 0.03 -0.02 -0.19 -0.07 -0.04 0.06 0.01 -0.05 0.05 -0.02 0.02 0.01 0.04 -0.04 -0.01 0.05 0.08 0.09 -0.00 -0.08 -0.02 0.00 0.05 0.01 0.01 -0.03 0.12 – 3.2.2.2 Heat Map r_reshape_fun &lt;- function(r){ coln &lt;- colnames(r) # remove lower tri and diagonal r[lower.tri(r, diag = T)] &lt;- NA r %&gt;% data.frame() %&gt;% rownames_to_column(&quot;V1&quot;) %&gt;% pivot_longer( cols = -V1 , values_to = &quot;r&quot; , names_to = &quot;V2&quot; ) %&gt;% mutate_at(vars(V1, V2), ~factor(., coln)) } r_plot_fun &lt;- function(r, study){ p &lt;- r %&gt;% ggplot(aes(x = V1, y = V2, fill = r)) + geom_raster() + geom_text(aes(label = round(r, 2))) + scale_fill_gradient2(limits = c(-1,1) , breaks = c(-1, -.5, 0, .5, 1) , low = &quot;blue&quot;, high = &quot;red&quot; , mid = &quot;white&quot;, na.value = &quot;white&quot;) + labs( x = NULL , y = NULL , fill = &quot;Zero-Order Correlation&quot; , title = &quot;Zero-Order Correlations Among Variables&quot; , subtitle = study ) + theme_classic() + theme( legend.position = &quot;bottom&quot; , axis.text = element_text(face = &quot;bold&quot;) , axis.text.x = element_text(angle = 45, hjust = 1) , plot.title = element_text(face = &quot;bold&quot;, hjust = .5) , plot.subtitle = element_text(face = &quot;italic&quot;, hjust = .5) , panel.background = element_rect(color = &quot;black&quot;, size = 1) ) ggsave(p, file = sprintf(&quot;%s/results/figures/zero-order-cor/%s.png&quot;, local_path, study), width = 14, height = 15) ggsave(p, file = sprintf(&quot;%s/results/figures/zero-order-cor/%s.pdf&quot;, local_path, study), width = 14, height = 15) return(p) } nested_r &lt;- nested_r %&gt;% mutate(r_long = map(r, r_reshape_fun) , p = map2(r_long, study, r_plot_fun)) nested_r$p[[1]] 3.2.3 POMP and Factor Levels The first thing we’ll do is get everything on the same scale. To do so, and as we preregistered, we will convert: - age to centered at 60 - education (in years) to centered at 12 years - personality characteristics and cognition to POMP - chronic conditions to 0 = no, 1 = yes - Dementia diagnosis to 0 = no, 1 = yes - Lewy Body Disease (binary; 0 = none, 1 = yes, collapsing across types) - Gross Cerebral Infarcts, Gross Cerebral Microinfarcts, Hippocampal Sclerosis (binary; 0 = No, 1 = Yes) All other indicators have scales that are already standardized across studies (e.g., BMI, Braak stage, CERAD) and will not be transformed. Now let’s: POMP personality / well-being and self-rated health Create a chronic conditions composite (sum of stroke, cancer, diabetes, heart problem) Turn binary indicators into factors Center age at 60 years and education at 12 years. nested_data &lt;- nested_data %&gt;% group_by(Trait, Outcome, study, p_year) %&gt;% mutate_at(vars(p_value, SRhealth), ~((. - min(., na.rm = T))/(max(., na.rm = T) - min(., na.rm = T))*10)) %&gt;% mutate_at(vars(p_value, SRhealth), ~ifelse(is.infinite(.), NA, .)) %&gt;% ungroup() %&gt;% mutate(CC = rowSums(cbind(stroke, cancer, diabetes, heartProb), na.rm = T)) %&gt;% mutate_at(vars(alcohol, smokes, stroke, cancer, diabetes, heartProb, gender, dementia), factor) %&gt;% mutate(age = age - 60 , education = education - 12 , interval = o_year - p_year) nested_data ## # A tibble: 421,476 × 24 ## study SID Trait p_year p_value Outcome o_year o_value age gender education cognition alcohol smokes ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; ## 1 ROS 000210… A 0 4.29 angiop… 2 3 20.0 0 10 4.19 0 0 ## 2 ROS 000210… A 0 4.29 arteri… 2 0 20.0 0 10 4.19 0 0 ## 3 ROS 000210… A 0 4.29 athero… 2 2 20.0 0 10 4.19 0 0 ## 4 ROS 000210… A 0 4.29 braak 2 6 20.0 0 10 4.19 0 0 ## 5 ROS 000210… A 0 4.29 cerad 2 1 20.0 0 10 4.19 0 0 ## 6 ROS 000210… A 0 4.29 hipScl… 2 0 20.0 0 10 4.19 0 0 ## 7 ROS 000210… A 0 4.29 lewyBo… 2 0 20.0 0 10 4.19 0 0 ## 8 ROS 000210… A 0 4.29 vsclrI… 2 0 20.0 0 10 4.19 0 0 ## 9 ROS 000210… A 0 4.29 vsclrM… 2 1 20.0 0 10 4.19 0 0 ## 10 ROS 000210… A 0 4.29 tdp43 2 1 20.0 0 10 4.19 0 0 ## # ℹ 421,466 more rows ## # ℹ 10 more variables: BMI &lt;dbl&gt;, race &lt;dbl&gt;, stroke &lt;fct&gt;, cancer &lt;fct&gt;, diabetes &lt;fct&gt;, heartProb &lt;fct&gt;, ## # dementia &lt;fct&gt;, SRhealth &lt;dbl&gt;, CC &lt;dbl&gt;, interval &lt;dbl&gt; 3.2.4 Rescale Outcomes Now that we’ve got personality and covariates scaled, we will group by personality characteristic and outcome to rescale outcomes, as needed. save_fun &lt;- function(d, trait, outcome){ if(outcome %in% c(&quot;dementia&quot;, &quot;hipSclerosis&quot;, &quot;lewyBodyDis&quot;, &quot;tdp43&quot;, &quot;vsclrInfrcts&quot;, &quot;vsclrMcrInfrcts&quot;)){ d &lt;- d %&gt;% mutate(o_value = factor(o_value)) } save(d, file = sprintf(&quot;%s/data/SCA/%s-%s.RData&quot;, local_path, trait, outcome)) return(d) } nested_data &lt;- nested_data %&gt;% group_by(Trait, Outcome) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = pmap(list(data, Trait, Outcome), save_fun)) nested_data ## # A tibble: 96 × 3 ## Trait Outcome data ## &lt;chr&gt; &lt;chr&gt; &lt;list&gt; ## 1 A angiopathy &lt;tibble [909 × 22]&gt; ## 2 A arteriolosclerosis &lt;tibble [926 × 22]&gt; ## 3 A atherosclerosis &lt;tibble [943 × 22]&gt; ## 4 A braak &lt;tibble [969 × 22]&gt; ## 5 A cerad &lt;tibble [889 × 22]&gt; ## 6 A hipSclerosis &lt;tibble [844 × 22]&gt; ## 7 A lewyBodyDis &lt;tibble [935 × 22]&gt; ## 8 A vsclrInfrcts &lt;tibble [934 × 22]&gt; ## 9 A vsclrMcrInfrcts &lt;tibble [934 × 22]&gt; ## 10 A tdp43 &lt;tibble [791 × 22]&gt; ## # ℹ 86 more rows 3.2.5 Bring in Moderators and Covariate Adjustments These full data sets will be used for sensitivity analyses and adjusted models, but we also want to set up our data for unadjusted models and moderator tests. For robusteness, we are using a few different sets of theoretically plausible covariates. The goal is to ensure that the pattern of results is not greatly impacted by the inclusion of different covariates. Not knowing the answer to this can be a threat to good science. mod_setup_fun &lt;- function(d, trait, outcome){ crossing(Covariates = c(&quot;fully&quot;, &quot;shared&quot;, &quot;standard&quot;, &quot;butOne&quot;, &quot;unadjusted&quot;, &quot;shareddx&quot;, &quot;standarddx&quot;, &quot;sharedint&quot;, &quot;int&quot;) , Moderator = c(&quot;none&quot;, &quot;education&quot;, &quot;age&quot;, &quot;gender&quot;, &quot;cognition&quot;, &quot;dementia&quot;)) %&gt;% mutate(data = list(d)) %&gt;% # filter(Covariates == &quot;sharedint&quot;) %&gt;% mutate(data = pmap(list(data, trait, outcome, Moderator, Covariates), mod_save_fun)) return(NULL) } mod_save_fun &lt;- function(d, trait, outcome, mod, cov){ covs &lt;- if(cov == &quot;unadjusted&quot;){ mod } else if (cov %in% c(&quot;shared&quot;, &quot;shareddx&quot;, &quot;sharedint&quot;)){ c(mod, &quot;age&quot;, &quot;gender&quot;, &quot;education&quot;, &quot;smokes&quot;, &quot;alcohol&quot;) } else if (cov %in% c(&quot;standard&quot;, &quot;standarddx&quot;)){ c(mod, &quot;age&quot;, &quot;gender&quot;, &quot;education&quot;) } else if(cov == &quot;butOne&quot;){ c(mod, &quot;age&quot;, &quot;gender&quot;, &quot;education&quot;, &quot;smokes&quot;, &quot;alcohol&quot;, &quot;cognition&quot;, &quot;CC&quot;) } else{ colnames(d) } if(grepl(&quot;dx&quot;, cov)) covs &lt;- c(covs, &quot;dementia&quot;) if(grepl(&quot;int&quot;, cov)) covs &lt;- c(covs, &quot;interval&quot;) d2 &lt;- d %&gt;% select(study, SID, p_year, p_value, o_year, o_value, one_of(covs), one_of(mod)) %&gt;% filter(complete.cases(.)) # d2 &lt;- if(cov == &quot;unadjusted&quot;){ # d %&gt;% select(study, SID, p_year, p_value, o_year, o_value, one_of(mod)) %&gt;% filter(complete.cases(.)) # } else if (cov == &quot;shared&quot;){ # d %&gt;% select(study, SID, p_year, p_value, o_year, o_value, one_of(mod), age, gender, education, smokes, alcohol) %&gt;% filter(complete.cases(.)) # } else if (cov == &quot;standard&quot;){ # d %&gt;% select(study, SID, p_year, p_value, o_year, o_value, one_of(mod), age, gender, education) %&gt;% filter(complete.cases(.)) # } else if (cov == &quot;butOne&quot;) { # d %&gt;% select(study, SID, p_year, p_value, o_year, o_value, one_of(mod), age, gender, education, smokes, alcohol, cognition, CC) %&gt;% filter(complete.cases(.)) # } else { # d %&gt;% filter(complete.cases(.)) # } # if(mod != &quot;none&quot;) colnames(d2)[colnames(d2) == mod] &lt;- &quot;modvalue&quot; save(d2, file = sprintf(&quot;%s/data/mega-analysis/%s/%s-%s-%s.RData&quot; , local_path, cov, trait, outcome, mod)) return(NULL) } nested_data %&gt;% # filter(Outcome != &quot;dementia&quot;) %&gt;% mutate(data = pmap(list(data, Trait, Outcome), mod_setup_fun)) Here’s one example: load(&quot;/Volumes/Emorie/projects/dementia/prediction/data/mega-analysis/shared/A-angiopathy-gender.RData&quot;) d2 ## # A tibble: 817 × 11 ## study SID p_year p_value o_year o_value gender age education smokes alcohol ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; ## 1 ROS 00021073 0 4.29 2 3 0 20.0 10 0 0 ## 2 ROS 10100312 0 6.07 13 2 1 15.3 8 0 1 ## 3 ROS 10100448 0 5 15 0 1 12.4 11 1 1 ## 4 ROS 10100574 0 5.71 9 1 1 13.7 9 0 1 ## 5 ROS 10100736 0 6.07 9 0 1 20.8 2 1 1 ## 6 ROS 10101039 0 5.71 8 1 1 23.4 7 1 1 ## 7 ROS 10101291 0 4.29 1 0 1 21.5 3 1 0 ## 8 ROS 10101327 0 3.57 2 1 1 26.9 9 1 0 ## 9 ROS 10101589 0 6.07 6 1 1 42.1 8 0 0 ## 10 ROS 10101741 0 5 12 1 1 23.3 -2 0 0 ## # ℹ 807 more rows 3.3 Part 3: Models For these first models, we’ll be testing three sets of covariates. For a full test of how covariates impact our inferences, we’ll then follow up in a later step doing a specification curve / multiverse analysis. For these first models, we will run a series of Bayesian regressions. For binary outcomes, these will be multilevel logistic regressions, while for the others, these will be “regular” multilevel linear regressions. For each of these, we will also test age, gender, and education, and cognitive functioning as moderators. 3.3.1 Functions 3.3.1.1 Model Function ipd_mega_mod_fun &lt;- function(trait, outcome, mod, cov){ print(paste(trait, outcome, mod, cov)) ## load the data load(sprintf(&quot;%s/data/mega-analysis/%s/%s-%s-%s.RData&quot;, local_path, cov, trait, outcome, mod)) ## compiled Bayesian model to speed up processing and avoid crashing if(outcome %in% c(&quot;dementia&quot;, &quot;hipSclerosis&quot;, &quot;lewyBodyDis&quot;, &quot;tdp43&quot;, &quot;vsclrInfrcts&quot;, &quot;vsclrMcrInfrcts&quot;)) load(sprintf(&quot;%s/results/bayes_sample_mod_binomial.RData&quot;, local_path)) else load(sprintf(&quot;%s/results/bayes_sample_mod_continuous.RData&quot;, local_path)) ## formula cv &lt;- c(&quot;age&quot;, &quot;gender&quot;, &quot;education&quot;, &quot;smokes&quot;, &quot;alcohol&quot;) #if (cov == &quot;shared&quot;) cv &lt;- cv if (cov == &quot;butOne&quot;) cv &lt;- c(cv, &quot;CC&quot;, &quot;cognition&quot;) if (cov == &quot;fully&quot;) cv &lt;- c(cv, &quot;CC&quot;, &quot;cognition&quot;, &quot;BMI&quot;, &quot;race&quot;, &quot;SRhealth&quot;) if (grepl(&quot;standard&quot;, cov)) cv &lt;- c(&quot;age&quot;, &quot;gender&quot;, &quot;education&quot;) if(grepl(&quot;dx&quot;, cov)) cv &lt;- c(cv, &quot;dementia&quot;) if(grepl(&quot;int&quot;, cov)) cv &lt;- c(cv, &quot;interval&quot;) rhs &lt;- &quot;p_value&quot; rhs &lt;- if(cov != &quot;unadjusted&quot;) c(rhs, cv) else rhs if(mod != &quot;none&quot;) rhs &lt;- c(rhs, paste(&quot;p_value&quot;, mod, sep = &quot;*&quot;)) re &lt;- if(mod == &quot;none&quot;) &quot;(p_value | study)&quot; else paste(paste(&quot;(p_value&quot;, mod, sep = &quot; * &quot;), &quot;| study)&quot;) rhs &lt;- paste(c(rhs, re), collapse = &quot; + &quot;) f &lt;- paste(&quot;o_value ~ &quot;, rhs, collapse = &quot;&quot;) ## run the models &amp; save m &lt;- update(m , formula = f , newdata = d2 , iter = 1000 , warmup = 500 , cores = 12 , threads = threading(3) , backend = &quot;cmdstanr&quot; , chains = 4 ) save(m, file = sprintf(&quot;%s/results/models/%s/%s_%s_%s.RData&quot; , local_path, cov, outcome, trait, mod)) ## extract model terms and confidence intervals &amp; save fx &lt;- tidy(m, conf.int = T) %&gt;% select(term, estimate, conf.low, conf.high) rx &lt;- std_eff_fun(m) save(fx, rx, file = sprintf(&quot;%s/results/summary/%s/%s_%s_%s.RData&quot; , local_path, cov, outcome, trait, mod)) ## extract heterogeneity estimates het &lt;- hetero_fun(m) save(het, file = sprintf(&quot;%s/results/heterogeneity/%s/%s_%s_%s.RData&quot; , local_path, cov, outcome, trait, mod)) if(mod != &quot;none&quot;){ # load(sprintf(&quot;%s/results/models/%s/%s_%s_%s.RData&quot;, local_path, cov, outcome, trait, mod)) pred.fx &lt;- fx_pred_fun(m, mod) pred.rx &lt;- rx_pred_fun(m, mod) save(pred.fx, pred.rx, file = sprintf(&quot;%s/results/predicted/%s/%s_%s_%s.RData&quot; , local_path, cov, outcome, trait, mod)) # rm(list = c(&quot;pred.fx&quot;, &quot;pred.rx&quot;, &quot;m&quot;)) # gc() # return(T) } ## clean up the local function environment rm(list = c(&quot;d&quot;, &quot;f&quot;, &quot;rhs&quot;, &quot;m&quot;, &quot;fx&quot;, &quot;rx&quot;, &quot;het&quot;)) gc() } 3.3.1.2 Study-Specific Effects Function As noted previously, once we run the model, we will have to use a second step to get the study-specific estimates for all studies. Unlike with dummy codes, doing so is much more straightforward. We just have to pull study-specific effects using the coef() for both Bayesian and Frequentist approaches. std_eff_fun &lt;- function(m){ coef(m, probs = c(0.025, 0.975))[[1]] %&gt;% array_tree(3) %&gt;% tibble(names = names(.), data = .) %&gt;% mutate(data = map(data, ~(.) %&gt;% data.frame %&gt;% rownames_to_column(&quot;study&quot;))) %&gt;% unnest(data) %&gt;% select(names, study, estimate = Estimate, conf.low = Q2.5, conf.high = Q97.5) } 3.3.1.3 Heterogeneity Estimates Function The Final pieces of information we need to extract from these models are estimates of the heterogeneity of effects across studies. hetero_fun &lt;- function(m){ args &lt;- list(x = m, effects = &quot;ran_pars&quot;, conf.int = T) do.call(tidy, args) %&gt;% select(group, term, estimate, conf.low, conf.high) %&gt;% separate(term, c(&quot;est&quot;, &quot;term&quot;), sep = &quot;__&quot;) %&gt;% mutate_at(vars(estimate:conf.high), ~ifelse(est == &quot;sd&quot;, .^2, .)) %&gt;% mutate(est = ifelse(est == &quot;sd&quot;, &quot;var&quot;, est)) } 3.3.1.4 Simple Effects Function 3.3.1.4.1 Fixed Effects fx_pred_fun &lt;-function(m, moder){ d &lt;- m$data d &lt;- d %&gt;% select(-o_value, -study) cols &lt;- colnames(d) mdr &lt;- if(moder == &quot;dementia&quot;) &quot;p_value&quot; else moder md_cl &lt;- class(d[,mdr]) if(any(sapply(d, class) == &quot;numeric&quot;)){ msd &lt;- d %&gt;% select_if(is.numeric) %&gt;% pivot_longer(everything() , names_to = &quot;item&quot; , values_to = &quot;value&quot;) %&gt;% group_by(item) %&gt;% summarize_at(vars(value), lst(mean, sd)) %&gt;% ungroup() } if(any(sapply(d, class) == &quot;factor&quot;)){ fct_lev &lt;- d %&gt;% select_if(is.factor) %&gt;% summarize_all(~list(levels(.))) } d &lt;- d %&gt;% select(-one_of(moder), -p_value) md_levs &lt;- if(md_cl == &quot;numeric&quot;){ if(mdr %in% c(&quot;age&quot;)) { c(-10, 0, 10) } else if (mdr %in% c(&quot;education&quot;)) { c(-5, 0, 5) } else { with(msd, c(mean[item == mdr] - sd[item == mdr], mean[item == mdr], mean[item == mdr] + sd[item == mdr])) } } else { sort(unique(fct_lev[,moder][[1]])) } md_fac &lt;- if(moder == &quot;age&quot;) c(&quot;-10 yrs&quot;, &quot;60&quot;, &quot;+10 yrs&quot;) else if (moder == &quot;education&quot;) c(&quot;-5 yrs&quot;, &quot;12 years&quot;, &quot;+5 yrs&quot;) else if(moder == &quot;gender&quot;) c(&quot;Male&quot;, &quot;Female&quot;) else c(&quot;-1 SD&quot;, &quot;M&quot;, &quot;+1 SD&quot;) if(moder != &quot;dementia&quot;){ mod_frame &lt;- expand.grid( p_value = seq(0,10,.1) , modvalue = md_levs , stringsAsFactors = F ) %&gt;% mutate(mod_fac = factor(modvalue, levels = unique(modvalue), labels = md_fac)) %&gt;% setNames(c(&quot;p_value&quot;, moder, &quot;mod_fac&quot;)) } else { mod_frame &lt;- expand.grid( p_value = with(msd, c(mean[item == &quot;p_value&quot;] - 2.5, mean[item == &quot;p_value&quot;], mean[item == &quot;p_value&quot;] + 2.5)) , dementia = c(0,1) ) %&gt;% mutate(mod_fac = factor(p_value, levels = unique(p_value), labels = c(&quot;-25%&quot;, &quot;M&quot;, &quot;+25%&quot;))) } if(ncol(d) &gt; 0){ if(any(sapply(d, class) == &quot;numeric&quot;)){ mod_frame &lt;- tibble(mod_frame, d %&gt;% select_if(is.numeric) %&gt;% summarize_all(mean)) } if(any(sapply(d, class) == &quot;factor&quot;)){ fcts &lt;- colnames(d)[sapply(d, class) == &quot;factor&quot;] for(i in 1:length(fcts)){ fct &lt;- fcts[i] mod_frame &lt;- crossing( mod_frame , levels(d[,fct]) ) %&gt;% setNames(c(colnames(mod_frame), fct)) } } } if(moder != &quot;dementia&quot;) { pred.fx &lt;- bind_cols( mod_frame, fitted(m , newdata = mod_frame , re_formula = NA) %&gt;% data.frame ) %&gt;% select(one_of(colnames(m$data)), mod_fac, pred = Estimate, lower = Q2.5, upper = Q97.5) %&gt;% group_by(p_value, mod_fac) %&gt;% summarize_at(vars(pred, lower, upper), mean) %&gt;% ungroup() } else { pred.fx &lt;- epred_draws(m, mod_frame, re_formula = NA) pred.fx &lt;- pred.fx %&gt;% ungroup() %&gt;% filter(dementia == 1) %&gt;% select(p_value, mod_fac, .epred_1 = .epred) %&gt;% bind_cols(pred.fx %&gt;% ungroup() %&gt;% filter(dementia == 0) %&gt;% select(.epred_0 = .epred) ) %&gt;% mutate(diff = .epred_1 - .epred_0) %&gt;% select(-.epred_1, -.epred_0) %&gt;% group_by(p_value, mod_fac) %&gt;% median_qi() %&gt;% select(p_value, mod_fac, pred = diff, lower = .lower, upper = .upper) } rm(list = c(&quot;m&quot;, &quot;mod_frame&quot;, &quot;d&quot;, &quot;md_levs&quot;)) gc() return(pred.fx) } 3.3.1.4.2 Study-Specific Effects rx_pred_fun &lt;- function(m, moder){ d &lt;- m$data d &lt;- d %&gt;% select(-o_value) cols &lt;- colnames(d) mdr &lt;- if(moder == &quot;dementia&quot;) &quot;p_value&quot; else moder md_cl &lt;- class(d[,mdr]) if(any(sapply(d, class) == &quot;numeric&quot;)){ msd &lt;- d %&gt;% group_by(study) %&gt;% select_if(is.numeric) %&gt;% pivot_longer(-study , names_to = &quot;item&quot; , values_to = &quot;value&quot;) %&gt;% group_by(study, item) %&gt;% summarize_at(vars(value), lst(mean, sd), na.rm = T) %&gt;% ungroup() } if(any(sapply(d, class) == &quot;factor&quot;)){ fct_lev &lt;- d %&gt;% group_by(study) %&gt;% select_if(is.factor) %&gt;% summarize_all(~list((levels(.)))) %&gt;% ungroup() } d &lt;- d %&gt;% select(-one_of(moder), -p_value) md_fac &lt;- if(moder == &quot;age&quot;) c(&quot;-10 yrs&quot;, &quot;60&quot;, &quot;+10 yrs&quot;) else if (moder == &quot;education&quot;) c(&quot;-5 yrs&quot;, &quot;12 years&quot;, &quot;+5 yrs&quot;) else if(moder == &quot;gender&quot;) c(&quot;Male&quot;, &quot;Female&quot;) else c(&quot;-1 SD&quot;, &quot;M&quot;, &quot;+1 SD&quot;) md_levs &lt;- if(!moder %in% c(&quot;cognition&quot;, &quot;dementia&quot;)){ crossing( study = unique(d$study) , modvalue = if(mdr == &quot;age&quot;) c(-10, 0, 10) else if (mdr == &quot;education&quot;) c(-5,0,5) else c(0,1) ) %&gt;% mutate(mod_fac = factor(modvalue, levels = unique(modvalue), labels = md_fac)) %&gt;% setNames(c(&quot;study&quot;, moder, &quot;mod_fac&quot;)) } else if(moder != &quot;dementia&quot;) { msd %&gt;% filter(item == moder) %&gt;% mutate(lower = mean - sd, upper = mean + sd) %&gt;% select(-sd) %&gt;% pivot_longer(cols = c(mean, lower, upper) , names_to = &quot;meas&quot; , values_to = &quot;modvalue&quot;) %&gt;% pivot_wider(names_from = &quot;item&quot;, values_from = &quot;modvalue&quot;) %&gt;% select(study, one_of(moder)) %&gt;% setNames(c(&quot;study&quot;, &quot;modvalue&quot;)) %&gt;% group_by(study) %&gt;% mutate(mod_fac = factor(modvalue, levels = sort(unique(modvalue)), labels = md_fac)) %&gt;% ungroup() %&gt;% setNames(c(&quot;study&quot;, moder, &quot;mod_fac&quot;)) } else { msd %&gt;% filter(item == mdr) %&gt;% mutate(lower = mean - 2.5, upper = mean + 2.5) %&gt;% select(-sd) %&gt;% pivot_longer(cols = c(mean, lower, upper) , names_to = &quot;meas&quot; , values_to = &quot;modvalue&quot;) %&gt;% pivot_wider(names_from = &quot;item&quot;, values_from = &quot;modvalue&quot;) %&gt;% select(study, meas, one_of(mdr)) %&gt;% setNames(c(&quot;study&quot;, &quot;meas&quot;, &quot;modvalue&quot;)) %&gt;% group_by(study) %&gt;% mutate(mod_fac = factor(meas, levels = c(&quot;lower&quot;, &quot;mean&quot;, &quot;upper&quot;), labels = c(&quot;-25%&quot;, &quot;M&quot;, &quot;+25%&quot;))) %&gt;% ungroup() %&gt;% select(-meas) %&gt;% setNames(c(&quot;study&quot;, mdr, &quot;mod_fac&quot;)) } mod_frame &lt;- if(moder != &quot;dementia&quot;){ crossing( p_value = seq(0,10,.1) , md_levs ) } else { crossing( md_levs , dementia = c(0,1) ) } if(ncol(d) &gt; 0){ if(any(sapply(d, class) == &quot;numeric&quot;)){ mod_frame &lt;- d %&gt;% group_by(study) %&gt;% select_if(is.numeric) %&gt;% summarize_all(mean, na.rm = T) %&gt;% ungroup() %&gt;% full_join(mod_frame) } if(any(sapply(d, class) == &quot;factor&quot;)){ fcts &lt;- colnames(d)[sapply(d, class) == &quot;factor&quot;] for(i in 1:length(fcts)){ fct &lt;- fcts[i] mod_frame &lt;- crossing( mod_frame , levels(d[,fct]) ) %&gt;% setNames(c(colnames(mod_frame), fct)) } } } if(moder != &quot;dementia&quot;) { pred.rx &lt;- bind_cols( mod_frame, fitted(m , newdata = mod_frame) %&gt;% data.frame ) %&gt;% select(one_of(colnames(m$data)), mod_fac, pred = Estimate, lower = Q2.5, upper = Q97.5) %&gt;% group_by(p_value, mod_fac, study) %&gt;% summarize_at(vars(pred, lower, upper), mean) %&gt;% ungroup() } else { pred.rx &lt;- epred_draws(m, mod_frame) pred.rx &lt;- pred.rx %&gt;% ungroup() %&gt;% filter(dementia == 1) %&gt;% select(study, p_value, mod_fac, .epred_1 = .epred) %&gt;% bind_cols(pred.rx %&gt;% ungroup() %&gt;% filter(dementia == 0) %&gt;% select(.epred_0 = .epred) ) %&gt;% mutate(diff = .epred_1 - .epred_0) %&gt;% select(-.epred_1, -.epred_0) %&gt;% group_by(study, p_value, mod_fac) %&gt;% median_qi() %&gt;% select(study, p_value, mod_fac, pred = diff, lower = .lower, upper = .upper) } rm(list = c(&quot;m&quot;, &quot;mod_frame&quot;, &quot;d&quot;)) gc() return(pred.rx) } 3.3.2 Run Models and Summaries 3.3.2.1 Sample Bayesian Models Before we actually run the models, we will estimate two models on smaller subsets of data. The advantage to this is that it prevents the rstan model from having to recompile the model, which speeds up runtime and prevents random crashes. It’s going to fit badly. That’s fine. It was given almost no data. # Sample Bayesian Model # load data load(sprintf(&quot;%s/data/mega-analysis/sharedint/N-dementia-none.RData&quot;, local_path)) # load(&quot;data/mega-analysis/shared/N-dementia-none.RData&quot;) # clean data &amp; keep only needed columns and a subset of the used variables d &lt;- d2 %&gt;% group_by(study) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% filter(row_number() %in% sample(1:nrow(.), 100, replace = F)))) %&gt;% unnest(data) # set priors &amp; model specifications Prior &lt;- c(set_prior(&quot;cauchy(0,1)&quot;, class = &quot;sd&quot;), set_prior(&quot;student_t(3, 0, 2)&quot;, class = &quot;b&quot;), set_prior(&quot;student_t(3, 0, 5)&quot;, class = &quot;Intercept&quot;)) Iter &lt;- 30; Warmup &lt;- 21; treedepth &lt;- 20 f &lt;- formula(o_value ~ p_value + age + gender + interval + p_value*education + (p_value*education | study)) m &lt;- brm(formula = f , data = d , family = bernoulli(link = &quot;logit&quot;) , prior = Prior , iter = Iter , warmup = Warmup , cores = 12 , threads = threading(3) , backend = &quot;cmdstanr&quot; , chains = 4) save(m, file = sprintf(&quot;%s/results/bayes_sample_mod_binomial.RData&quot;, local_path)) # save(m, file = &quot;results/bayes_sample_mod_binomial.RData&quot;) load(sprintf(&quot;%s/data/mega-analysis/sharedint/N-braak-none.RData&quot;, local_path)) # load(&quot;data/mega-analysis/shared/N-braak-none.RData&quot;) # clean data &amp; keep only needed columns and a subset of the used variables d &lt;- d2 %&gt;% group_by(study) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% filter(row_number() %in% sample(1:nrow(.), 100, replace = T)))) %&gt;% unnest(data) # set priors &amp; model specifications Prior &lt;- c(set_prior(&quot;cauchy(0,1)&quot;, class = &quot;sd&quot;), set_prior(&quot;student_t(3, 0, 2)&quot;, class = &quot;b&quot;), set_prior(&quot;student_t(3, 0, 5)&quot;, class = &quot;Intercept&quot;)) Iter &lt;- 30; Warmup &lt;- 21; treedepth &lt;- 20 f &lt;- formula(o_value ~ p_value + age + gender + interval + p_value*education + (p_value*education | study)) m &lt;- brm(formula = f , data = d , prior = Prior , iter = Iter , warmup = Warmup , cores = 12 , threads = threading(3) , backend = &quot;cmdstanr&quot; , chains = 4) save(m, file = sprintf(&quot;%s/results/bayes_sample_mod_continuous.RData&quot;, local_path)) # save(m, file = &quot;results/bayes_sample_mod_continuous.RData&quot;) rm(list = c(&quot;d&quot;, &quot;Prior&quot;, &quot;Iter&quot;, &quot;Warmup&quot;, &quot;treedepth&quot;, &quot;f&quot;, &quot;m&quot;)) 3.3.2.1.1 Binary load(sprintf(&quot;%s/results/bayes_sample_mod_binomial.RData&quot;, local_path)) m ## Family: bernoulli ## Links: mu = logit ## Formula: o_value ~ p_value + age + gender + interval + p_value * education + (p_value * education | study) ## Data: d (Number of observations: 800) ## Draws: 4 chains, each with iter = 30; warmup = 21; thin = 1; ## total post-warmup draws = 36 ## ## Group-Level Effects: ## ~study (Number of levels: 8) ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sd(Intercept) 0.63 0.46 0.05 1.46 1.41 16 16 ## sd(p_value) 0.31 0.16 0.05 0.70 0.99 16 16 ## sd(education) 0.10 0.07 0.02 0.28 1.02 16 16 ## sd(p_value:education) 0.04 0.03 0.00 0.11 1.10 16 16 ## cor(Intercept,p_value) 0.09 0.40 -0.60 0.79 0.97 16 16 ## cor(Intercept,education) 0.03 0.34 -0.59 0.60 1.25 16 16 ## cor(p_value,education) -0.21 0.43 -0.83 0.72 0.98 16 16 ## cor(Intercept,p_value:education) 0.13 0.43 -0.67 0.86 1.10 16 16 ## cor(p_value,p_value:education) 0.20 0.41 -0.66 0.76 1.23 16 16 ## cor(education,p_value:education) -0.15 0.40 -0.71 0.65 1.29 16 16 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept -5.20 0.81 -6.76 -3.93 1.08 16 16 ## p_value -0.00 0.16 -0.24 0.30 1.07 16 16 ## age 0.13 0.02 0.09 0.16 0.95 16 16 ## gender1 -0.28 0.33 -0.76 0.31 1.08 16 16 ## interval 0.16 0.03 0.12 0.22 1.07 16 16 ## education -0.04 0.13 -0.21 0.27 1.22 16 16 ## p_value:education -0.01 0.03 -0.06 0.06 1.20 16 16 ## ## Draws were sampled using sample(hmc). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). 3.3.2.1.2 Continuous load(sprintf(&quot;%s/results/bayes_sample_mod_continuous.RData&quot;, local_path)) 3.3.2.2 Run the Models done &lt;- tibble(Covariate = c(&quot;fully&quot;, &quot;shared&quot;, &quot;butOne&quot;, &quot;unadjusted&quot;, &quot;standard&quot;, &quot;standarddx&quot;, &quot;shareddx&quot;, &quot;sharedint&quot;), file = map(Covariate, ~list.files(sprintf(&quot;%s/results/models/%s&quot;, local_path, .)))) %&gt;% unnest(file) %&gt;% separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;), sep = &quot;_&quot;) %&gt;% mutate(Moderator = str_remove_all(Moderator, &quot;.RData&quot;) , done = &quot;done&quot;) %&gt;% filter(!is.na(Moderator)) # plan(multisession(workers = 4L)) nested_ipd_mega &lt;- crossing( Trait = traits$short_name , Outcome = outcomes$short_name , Moderator = c(&quot;education&quot;, &quot;age&quot;, &quot;gender&quot;, &quot;cognition&quot;, &quot;dementia&quot;) , Covariate = c(&quot;fully&quot;, &quot;shared&quot;, &quot;butOne&quot;, &quot;standard&quot;, &quot;unadjusted&quot;, &quot;standarddx&quot;, &quot;shareddx&quot;, &quot;sharedint&quot;) ) %&gt;% full_join( crossing( Trait = traits$short_name , Outcome = outcomes$short_name , Moderator = &quot;none&quot; , Covariate = c(&quot;fully&quot;, &quot;shared&quot;, &quot;butOne&quot;, &quot;standard&quot;, &quot;unadjusted&quot;, &quot;standarddx&quot;, &quot;shareddx&quot;, &quot;sharedint&quot;) # &quot;int&quot;, ) ) %&gt;% # mutate(run = future_pmap( mutate(run = pmap( list(Trait, Outcome, Moderator, Covariate) , possibly(ipd_mega_mod_fun, NA_real_) # , ipd_mega_mod_fun # , .options = furrr_options( # globals = c(&quot;traits&quot;, &quot;moders&quot;, &quot;covars&quot;, &quot;outcomes&quot; # , &quot;hetero_fun&quot; # , &quot;rx_pred_fun&quot; # , &quot;std_eff_fun&quot; # , &quot;fx_pred_fun&quot; # , &quot;local_path&quot;) # , packages = c(&quot;broom&quot;, &quot;broom.mixed&quot;, &quot;tidyverse&quot;, &quot;brms&quot;) # ) # , .progress = T )) # nested_ipd_mega %&gt;% # mutate(Covariate = factor(Covariate) # , Covariate = relevel(Covariate, &quot;shared&quot;) # # , Moderator = factor(Moderator, levels = moders$short_name) # , Moderator = relevel(factor(Moderator), &quot;dementia&quot;) # ) %&gt;% # arrange(Covariate, Outcome, Moderator, Trait) %&gt;% # filter(Covariate != &quot;fully&quot;) %&gt;% # select(Trait, Outcome, Moderator, Covariate) %&gt;% # write.table(. # , file = sprintf(&quot;%s/scripts/cluster/args/args.txt&quot;, local_path) # , row.names = F) "],["compile.html", "Chapter 4 Compile Results", " Chapter 4 Compile Results Once all the models are run, we are ready to compile all their results. By saving the fixed and study-level effects results previously, we are able to simply load those results and ignore the models. However, because we also saved the models, we can also recall and extract information from them if and when needed. I cannot share the models because the data are stored inside them. Instead, I share posterior samples and will share models with the data slot removed upon request (please email Emorie Beck). We mostly don’t need the models here. The only thing I’ll pull from them are exact sample sizes. loadRData &lt;- function(fileName, cov, obj, folder){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/results/%s/%s/%s&quot;, local_path, folder, cov, fileName) load(path) get(ls()[grepl(obj, ls())]) } n_fun &lt;- function(fileName, type){ m &lt;- loadRData(fileName, type, &quot;^m&quot;, &quot;models&quot;) d &lt;- m$data n &lt;- d %&gt;% group_by(study) %&gt;% tally() %&gt;% ungroup() return(n) } ## load in &quot;fixed&quot; effects ## first get file names nested_mega &lt;- tibble(Covariate = c(&quot;fully&quot;, &quot;shared&quot;, &quot;standard&quot;, &quot;butOne&quot;, &quot;unadjusted&quot;, &quot;standarddx&quot;, &quot;shareddx&quot;, &quot;sharedint&quot;)) %&gt;% mutate(file = map(Covariate, ~list.files(sprintf(&quot;%s/results/summary/%s&quot;, local_path, .)))) %&gt;% unnest(file) %&gt;% separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;), sep = &quot;_&quot;, remove = F) %&gt;% filter(!(Outcome == &quot;dementia&quot; &amp; Moderator == &quot;dementia.RData&quot;)) %&gt;% ## read in the files mutate(Moderator = str_remove(Moderator, &quot;.RData&quot;) , fx = map2(file, Covariate, ~loadRData(.x, .y, &quot;fx&quot;, &quot;summary&quot;)) , rx = map2(file, Covariate, possibly(~loadRData(.x, .y, &quot;rx&quot;, &quot;summary&quot;), NA_real_)) , n = map2(file, Covariate, n_fun) ) %&gt;% select(-file) %&gt;% filter(!is.na(rx)) 4.0.1 Tables Next, we want to format the study results in APA table format. In this case, we are interested in the fixed and study-specific effects of personality predicting cognitive ability when there were no moderators, and the personality x moderator interaction when there was a moderator. We’ll anticipate a need to present both just fixed effects as well as fixed and study-specific effects by creating tables for each. First, let’s format the data. tmp &lt;- ### fixed effects nested_mega %&gt;% select(-one_of(&quot;rx&quot;, &quot;n&quot;)) %&gt;% unnest(fx) %&gt;% # unnesting # keep key terms filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;) | (Moderator != &quot;none&quot; &amp; grepl(&quot;p_value:&quot;, term)) &amp; !grepl(&quot;cor&quot;, term) &amp; !grepl(&quot;sd&quot;, term)) %&gt;% mutate(study = &quot;Overall&quot;) %&gt;% ### study specific effects full_join( nested_mega %&gt;% select(-one_of(&quot;fx&quot;, &quot;n&quot;)) %&gt;% unnest(rx) %&gt;% # unnesting rename(term = names) %&gt;% filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;) | (Moderator != &quot;none&quot; &amp; grepl(&quot;p_value:&quot;, term))) ) %&gt;% left_join( outcomes %&gt;% select(Outcome = short_name, link) ) %&gt;% # reformatting: mark significance, prettify Trait, covariate, and moderator names mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;), Trait = factor(Trait, traits$short_name), Outcome = factor(Outcome, outcomes$short_name, outcomes$long_name), Moderator = factor(Moderator, moders$short_name, moders$long_name), Covariate = factor(Covariate, covars$short_name, str_wrap(covars$long_name, 15)), term = str_remove_all(term, &quot;p_value:&quot;), term = factor(term, moders$short_term, moders$long_term)) %&gt;% mutate_at(vars(estimate, conf.low, conf.high), ~ifelse(link == &quot;factor&quot;, exp(.), .)) # prettify the number format nested_mega_tab &lt;- tmp %&gt;% mutate_at(vars(estimate, conf.low, conf.high), ~ifelse(abs(.) &lt; .0014, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))) %&gt;% # combine the effects, bold significance, factor and label study-specfic effects mutate(est = sprintf(&quot;%s&lt;br&gt;[%s, %s]&quot;, estimate, conf.low, conf.high), est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;&lt;strong&gt;%s&lt;/strong&gt;&quot;, est), est), study = mapvalues(study, c(&quot;RADC-MAP&quot;, &quot;ADRC&quot;), c(&quot;Rush-MAP&quot;, &quot;WUSM-MAP&quot;)), study = factor(study, levels = c(studies_long, &quot;Overall&quot;), labels = c(studies_long, &quot;Overall&quot;))) %&gt;% # reshaping: remove extra columns, arrange by key variables, and make wide select(Outcome, Trait, Moderator, Covariate, study, term, est) %&gt;% arrange(Outcome, Trait, Moderator, Covariate, study, term, est) %&gt;% pivot_wider(names_from = &quot;Outcome&quot;, values_from = &quot;est&quot;) nested_mega_tab ## # A tibble: 1,855 × 16 ## Trait Moderator Covariate study term Incident Dementia Di…¹ `Braak Stage` CERAD `Lewy Body Disease` ## &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 E None Unadjusted ROS Pers… 0.95&lt;br&gt;[0.89, 1.01] 0.04&lt;br&gt;[-0.… -0.0… 1.04&lt;br&gt;[0.96, 1.1… ## 2 E None Unadjusted Rush… Pers… 0.95&lt;br&gt;[0.90, 1.00] 0.02&lt;br&gt;[-0.… &lt;str… 0.99&lt;br&gt;[0.91, 1.0… ## 3 E None Unadjusted EAS Pers… 0.93&lt;br&gt;[0.85, 1.04] 0.001&lt;br&gt;[-0… &lt;NA&gt; 0.99&lt;br&gt;[0.84, 1.1… ## 4 E None Unadjusted WUSM… Pers… &lt;strong&gt;0.93&lt;br&gt;[0.88… &lt;strong&gt;-0.1… -0.0… 1.04&lt;br&gt;[0.94, 1.1… ## 5 E None Unadjusted SATSA Pers… 0.93&lt;br&gt;[0.84, 1.05] &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 6 E None Unadjusted HRS Pers… &lt;strong&gt;0.95&lt;br&gt;[0.92… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 7 E None Unadjusted LISS Pers… 0.91&lt;br&gt;[0.78, 1.12] &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 8 E None Unadjusted GSOEP Pers… &lt;strong&gt;0.84&lt;br&gt;[0.77… &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 9 E None Unadjusted Over… Pers… 0.93&lt;br&gt;[0.87, 1.00] -0.01&lt;br&gt;[-0… -0.0… 1.02&lt;br&gt;[0.90, 1.1… ## 10 E None Fully Adjusted EAS Pers… 0.83&lt;br&gt;[0.59, 1.10] &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## # ℹ 1,845 more rows ## # ℹ abbreviated name: ¹​`Incident Dementia Diagnosis` ## # ℹ 7 more variables: `Gross Cerebral Infarcts` &lt;chr&gt;, `Gross Cerebral Microinfarcts` &lt;chr&gt;, ## # `Cerebral Atherosclerosis` &lt;chr&gt;, `Cerebral Amyloid Angiopathy` &lt;chr&gt;, Arteriolosclerosis &lt;chr&gt;, ## # `Hippocampal Sclerosis` &lt;chr&gt;, `TDP-43` &lt;chr&gt; Now that we’ve formatted the values, we can group by moderators and save results as separate tables. Even though additional information could be included given that we have one outcome, we’ll stick with this split because it will make it easier for those using this tutorial who multiple traits, outcomes, covariates, and moderators. 4.0.1.1 Fixed Effects First, here’s the overall estimates and credible intervals, split by moderators. These show the estimates across all different covariate sets. ## table function ipd_tab_fun &lt;- function(d, moder){ md &lt;- mapvalues(moder, moders$long_name, moders$short_name, warn_missing = F) rs &lt;- d %&gt;% mutate(Trait = factor(Trait, traits$short_name, traits$long_name)) %&gt;% group_by(Trait) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) cs &lt;- rep(1,12) names(cs) &lt;- c(&quot; &quot;, paste0(&quot;&lt;strong&gt;&quot;, outcomes$long_name, &quot;&lt;/strong&gt;&quot;)) cln &lt;- mapvalues(colnames(d)[colnames(d) %in% outcomes$long_name], outcomes$long_name, outcomes$colnm, warn_missing = F) cln &lt;- c(&quot;Covariates&quot;, cln) # cln &lt;- if(length(unique(d$term)) == 1) c(&quot;Covariates&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 9)) else c(&quot;Covariates&quot;, &quot;Term&quot;, rep(&quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot;, 9)) al &lt;- c(&quot;r&quot;, rep(&quot;c&quot;, 11)) d &lt;- d %&gt;% select(-term) fn &lt;- paste(covars$desc, collapse = &quot; &quot;) cap &lt;- if(md == &quot;none&quot;) &quot;&lt;strong&gt;Table X&lt;/strong&gt;&lt;br&gt;&lt;em&gt;Overall Effects of Personality-Dementia Diagnosis and Neuropathology Associations&lt;/em&gt;&quot; else sprintf(&quot;&lt;strong&gt;Table X&lt;/strong&gt;&lt;br&gt;&lt;em&gt;Overall %s Moderation of Personality-Dementia Diagnosis and Neuropathology Associations&lt;/em&gt;&quot;, md) tab &lt;- d %&gt;% arrange(Trait) %&gt;% select(-Trait) %&gt;% kable(., &quot;html&quot; # kable(., &quot;latex&quot; , booktabs = T , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% add_header_above(cs, escape = F) %&gt;% footnote(fn) for (i in 1:nrow(rs)) { tab &lt;- tab %&gt;% kableExtra::group_rows(rs$Trait[i], rs$start[i], rs$end[i]) } save_kable(tab, file = sprintf(&quot;%s/results/tables/overall/%s.html&quot; , local_path, md)) return(tab) } ipd_fx_tab &lt;- nested_mega_tab %&gt;% filter(study == &quot;Overall&quot;) %&gt;% select(-study) %&gt;% group_by(Moderator) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, Moderator), ipd_tab_fun)) # save(ipd2b_reg_tab, ipd2b_res, file = sprintf(&quot;%s/manuscript/results/ipd2b_fx_tab.RData&quot;, res_path)) (ipd_fx_tab %&gt;% filter(Moderator == &quot;None&quot;))$tab[[1]] Table 4.1: Table XOverall Effects of Personality-Dementia Diagnosis and Neuropathology Associations Incident Dementia Diagnosis Braak Stage CERAD Lewy Body Disease Gross Cerebral Infarcts Gross Cerebral Microinfarcts Cerebral Atherosclerosis Cerebral Amyloid Angiopathy Arteriolosclerosis Hippocampal Sclerosis TDP-43 Covariates OR [CI] b [CI] b [CI] OR [CI] OR [CI] OR [CI] b [CI] b [CI] b [CI] OR [CI] OR [CI] Extraversion Unadjusted 0.93[0.87, 1.00] -0.01[-0.14, 0.13] -0.03[-0.11, 0.05] 1.02[0.90, 1.15] 0.95[0.79, 1.26] 0.96[0.84, 1.14] -0.01[-0.08, 0.05] 0.02[-0.05, 0.15] -0.01[-0.08, 0.05] 0.97[0.83, 1.11] 1.00[0.82, 1.17] Fully Adjusted 1.00[0.58, 1.86] Shared Covariates Adjusted 0.97[0.93, 1.02] -0.000[-0.13, 0.14] -0.04[-0.10, 0.05] 1.01[0.88, 1.12] 0.95[0.76, 1.34] 0.97[0.83, 1.13] 0.00[-0.06, 0.08] 0.02[-0.04, 0.07] -0.01[-0.08, 0.07] 0.97[0.83, 1.10] 1.01[0.80, 1.18] Standard Covariates Adjusted 0.97[0.93, 1.02] 1.05[0.68, 2.07] 0.98[0.80, 1.20] All But One Covariate Adjusted 0.99[0.93, 1.05] -0.01[-0.16, 0.13] -0.03[-0.14, 0.05] 1.00[0.82, 1.12] 0.97[0.72, 1.33] 0.97[0.82, 1.22] 0.00[-0.05, 0.06] 0.02[-0.07, 0.12] -0.01[-0.06, 0.03] 0.96[0.74, 1.14] 1.02[0.85, 1.22] Shared Covariates Adjusted (With Prediction Interval) 0.95[0.92, 0.99] -0.01[-0.28, 0.15] -0.03[-0.10, 0.03] 1.01[0.91, 1.14] 1.03[0.70, 1.99] 0.96[0.83, 1.08] 0.01[-0.06, 0.09] 0.02[-0.04, 0.07] -0.01[-0.07, 0.09] 0.96[0.82, 1.16] 1.00[0.79, 1.22] Shared Covariates Adjusted (With Dementia Diagnosis) -0.10[-1.08, 0.78] 1.02[0.18, 7.57] 1.24[0.35, 7.66] Standard Covariates Adjusted (With Dementia Diagnosis) -0.13[-1.13, 1.39] 1.00[0.19, 6.68] 1.42[0.33, 6.43] Agreeableness Unadjusted 1.00[0.92, 1.11] 0.000[-0.15, 0.21] -0.01[-0.20, 0.21] 1.04[0.75, 1.75] 0.91[0.32, 2.14] 1.03[0.73, 1.46] -0.02[-0.36, 0.33] 0.01[-0.16, 0.19] 0.000[-0.17, 0.19] 1.00[0.68, 1.48] 0.97[0.68, 1.36] Fully Adjusted 1.04[0.73, 1.55] Shared Covariates Adjusted 0.97[0.92, 1.03] -0.02[-0.15, 0.10] -0.02[-0.30, 0.15] 0.99[0.83, 1.23] 1.08[0.40, 2.48] 1.07[0.77, 1.52] -0.02[-0.19, 0.16] 0.02[-0.21, 0.25] 0.02[-0.19, 0.30] 1.02[0.66, 1.75] 0.99[0.74, 1.44] Standard Covariates Adjusted 0.97[0.92, 1.03] 1.03[0.42, 3.44] 1.13[0.72, 1.80] All But One Covariate Adjusted 0.99[0.90, 1.10] -0.02[-0.16, 0.10] -0.06[-0.32, 0.18] 0.98[0.82, 1.23] 1.03[0.42, 2.55] 1.07[0.65, 1.58] -0.01[-0.23, 0.24] -0.01[-0.26, 0.21] 0.04[-0.16, 0.32] 1.01[0.63, 1.78] 0.98[0.65, 1.33] Shared Covariates Adjusted (With Prediction Interval) 0.96[0.92, 1.01] -0.02[-0.13, 0.09] -0.02[-0.29, 0.22] 0.99[0.76, 1.37] 1.15[0.42, 3.24] 1.09[0.61, 1.74] -0.01[-0.19, 0.16] 0.00[-0.32, 0.20] -0.00[-0.38, 0.17] 1.00[0.61, 1.62] 0.98[0.68, 1.50] Shared Covariates Adjusted (With Dementia Diagnosis) 0.00[-1.00, 1.11] 7.29[0.84, 168.03] 1.20[0.32, 6.05] Standard Covariates Adjusted (With Dementia Diagnosis) -0.01[-1.02, 1.02] 7.65[0.88, 250.91] 1.43[0.39, 7.70] Conscientiousness Unadjusted 0.87[0.83, 0.93] -0.04[-0.11, 0.02] 0.03[-0.07, 0.12] 0.97[0.82, 1.14] 1.01[0.81, 1.45] 1.03[0.84, 1.29] -0.01[-0.06, 0.04] -0.01[-0.08, 0.06] -0.02[-0.09, 0.05] 1.04[0.86, 1.27] 1.00[0.76, 1.16] Fully Adjusted 0.96[0.65, 1.47] Shared Covariates Adjusted 0.88[0.85, 0.92] -0.04[-0.11, 0.02] 0.03[-0.06, 0.12] 0.95[0.67, 1.22] 1.02[0.83, 1.28] 1.06[0.84, 1.37] -0.01[-0.12, 0.05] -0.03[-0.16, 0.07] -0.02[-0.11, 0.07] 1.06[0.88, 1.30] 1.02[0.85, 1.19] Standard Covariates Adjusted 0.88[0.84, 0.91] 1.12[0.75, 2.12] 1.08[0.86, 1.42] All But One Covariate Adjusted 0.91[0.86, 0.95] -0.05[-0.12, 0.01] 0.03[-0.09, 0.12] 0.97[0.84, 1.11] 1.07[0.76, 1.46] 1.04[0.79, 1.38] -0.001[-0.06, 0.07] 0.01[-0.06, 0.12] -0.04[-0.10, 0.04] 1.06[0.85, 1.30] 1.01[0.84, 1.18] Shared Covariates Adjusted (With Prediction Interval) 0.86[0.83, 0.90] -0.05[-0.14, 0.02] 0.03[-0.07, 0.14] 0.99[0.81, 1.32] 1.01[0.64, 1.92] 1.05[0.83, 1.35] 0.00[-0.05, 0.07] 0.02[-0.06, 0.13] -0.02[-0.09, 0.04] 1.05[0.85, 1.35] 1.01[0.87, 1.21] Shared Covariates Adjusted (With Dementia Diagnosis) -0.20[-1.37, 0.95] 2.14[0.42, 22.67] 2.79[0.46, 58.48] Standard Covariates Adjusted (With Dementia Diagnosis) -0.14[-1.09, 0.98] 2.43[0.44, 21.69] 2.09[0.46, 13.45] Neuroticism Unadjusted 1.11[1.05, 1.17] 0.02[-0.10, 0.11] -0.001[-0.09, 0.10] 1.00[0.86, 1.16] 0.98[0.81, 1.26] 0.99[0.86, 1.13] 0.01[-0.04, 0.06] 0.02[-0.06, 0.10] 0.01[-0.08, 0.10] 1.01[0.85, 1.16] 1.03[0.88, 1.20] Fully Adjusted 1.60[0.67, 5.76] Shared Covariates Adjusted 1.10[1.06, 1.14] 0.04[-0.09, 0.21] -0.03[-0.18, 0.07] 1.01[0.86, 1.16] 0.96[0.52, 1.35] 0.98[0.86, 1.13] 0.01[-0.05, 0.06] -0.00[-0.10, 0.07] 0.01[-0.07, 0.09] 1.02[0.87, 1.20] 1.03[0.88, 1.19] Standard Covariates Adjusted 1.10[1.05, 1.13] 1.04[0.61, 2.24] 0.97[0.81, 1.11] All But One Covariate Adjusted 1.08[1.03, 1.13] -0.18[-0.79, 0.11] -0.01[-0.12, 0.09] 1.00[0.86, 1.15] 0.97[0.70, 1.32] 0.99[0.85, 1.21] 0.01[-0.06, 0.08] 0.001[-0.07, 0.07] 0.00[-0.07, 0.08] 1.01[0.84, 1.17] 1.02[0.88, 1.18] Shared Covariates Adjusted (With Prediction Interval) 1.12[1.07, 1.16] 0.04[-0.11, 0.31] -0.01[-0.11, 0.09] 1.00[0.77, 1.16] 1.13[0.67, 2.31] 0.99[0.85, 1.13] 0.02[-0.05, 0.09] 0.01[-0.07, 0.08] 0.01[-0.07, 0.10] 1.03[0.87, 1.21] 1.03[0.88, 1.20] Shared Covariates Adjusted (With Dementia Diagnosis) -0.12[-1.07, 0.80] 0.77[0.05, 10.83] 1.74[0.33, 34.37] Standard Covariates Adjusted (With Dementia Diagnosis) -0.14[-1.37, 0.77] 0.84[0.09, 10.61] 1.10[0.34, 4.99] Openness to Experience Unadjusted 0.87[0.78, 0.97] -0.04[-0.24, 0.06] -0.03[-0.20, 0.13] 1.02[0.86, 1.20] 0.94[0.47, 2.04] 0.90[0.52, 1.34] -0.03[-0.32, 0.25] -0.02[-0.21, 0.12] -0.07[-0.40, 0.18] 0.98[0.77, 1.22] 1.00[0.74, 1.35] Fully Adjusted 0.96[0.50, 2.02] Shared Covariates Adjusted 0.95[0.90, 1.02] -0.01[-0.10, 0.10] -0.08[-0.41, 0.15] 1.03[0.83, 1.32] 0.90[0.42, 2.13] 0.95[0.69, 1.53] -0.05[-0.21, 0.16] -0.03[-0.36, 0.20] -0.05[-0.40, 0.26] 1.02[0.78, 1.30] 1.02[0.78, 1.32] Standard Covariates Adjusted 0.95[0.90, 1.02] 1.05[0.35, 3.13] 0.94[0.63, 1.48] All But One Covariate Adjusted 0.97[0.86, 1.06] 0.000[-0.09, 0.08] -0.03[-0.23, 0.19] 1.03[0.86, 1.32] 1.03[0.46, 2.68] 0.96[0.68, 1.34] -0.02[-0.18, 0.15] -0.02[-0.18, 0.18] -0.03[-0.29, 0.27] 1.02[0.77, 1.32] 1.03[0.73, 1.67] Shared Covariates Adjusted (With Prediction Interval) 0.95[0.90, 1.00] -0.02[-0.13, 0.08] -0.03[-0.21, 0.15] 1.03[0.77, 1.32] 1.09[0.37, 3.15] 0.94[0.69, 1.43] -0.03[-0.26, 0.12] -0.06[-0.19, 0.15] -0.05[-0.42, 0.25] 1.03[0.75, 1.50] 1.02[0.76, 1.39] Shared Covariates Adjusted (With Dementia Diagnosis) -0.11[-1.23, 0.79] 7.28[0.98, 238.12] 0.94[0.17, 5.92] Standard Covariates Adjusted (With Dementia Diagnosis) -0.22[-1.77, 0.81] 7.22[1.00, 196.99] 0.98[0.19, 7.35] Positive Affect Unadjusted 0.92[0.81, 1.05] 0.00[-0.17, 0.25] 0.00[-0.22, 0.21] 0.97[0.70, 1.28] 0.97[0.68, 1.35] 1.01[0.73, 1.37] 0.01[-0.19, 0.15] 0.03[-0.17, 0.26] -0.01[-0.21, 0.24] 1.11[0.77, 1.76] 1.19[0.78, 2.30] Fully Adjusted 1.10[0.51, 2.83] Shared Covariates Adjusted 0.93[0.88, 1.00] -0.03[-0.31, 0.17] 0.01[-0.16, 0.16] 0.89[0.61, 1.37] 1.03[0.80, 1.33] 1.04[0.76, 1.35] -0.03[-0.29, 0.09] 0.01[-0.24, 0.20] 0.07[-0.15, 0.33] 1.08[0.74, 1.64] 1.04[0.66, 1.53] Standard Covariates Adjusted 0.93[0.87, 0.99] 0.98[0.63, 1.44] All But One Covariate Adjusted 0.94[0.75, 1.12] -0.000[-0.23, 0.33] 0.00[-0.24, 0.19] 0.98[0.74, 1.34] 1.06[0.81, 1.47] 1.01[0.75, 1.29] 0.01[-0.21, 0.27] 0.02[-0.17, 0.20] -0.03[-0.28, 0.15] 1.10[0.76, 1.68] 1.02[0.69, 1.42] Shared Covariates Adjusted (With Prediction Interval) 0.93[0.87, 0.99] -0.05[-0.36, 0.18] 0.00[-0.26, 0.17] 1.01[0.67, 1.45] 1.07[0.80, 1.83] 1.02[0.74, 1.45] 0.01[-0.15, 0.15] 0.03[-0.12, 0.19] -0.01[-0.18, 0.18] 1.09[0.72, 1.70] 1.05[0.71, 1.54] Negative Affect Unadjusted 1.10[1.00, 1.20] -0.05[-1.49, 0.99] -0.06[-1.13, 0.97] 0.98[0.26, 3.32] 0.94[0.26, 3.05] 1.05[0.29, 3.92] 0.00[-1.09, 1.19] -0.09[-0.91, 0.82] 0.05[-0.95, 0.97] 0.94[0.22, 3.84] 1.11[0.29, 4.16] Fully Adjusted 1.09[0.36, 4.11] Shared Covariates Adjusted 1.14[1.02, 1.26] -0.03[-1.23, 1.15] -0.14[-1.42, 1.29] 0.98[0.21, 4.67] 1.07[0.27, 4.56] 1.03[0.17, 4.73] -0.03[-1.26, 1.08] 0.19[-1.35, 1.71] -0.02[-1.30, 1.04] 0.96[0.21, 3.79] 0.95[0.27, 4.88] Standard Covariates Adjusted 1.14[1.01, 1.28] 1.01[0.28, 3.19] All But One Covariate Adjusted 1.05[0.73, 1.24] -0.10[-1.51, 1.03] -0.10[-1.31, 0.95] 1.05[0.28, 6.00] 0.81[0.14, 3.93] 1.12[0.31, 15.58] 0.04[-1.31, 1.10] -0.72[-3.13, 1.06] -0.04[-1.55, 1.33] 1.02[0.30, 4.10] 0.95[0.26, 5.63] Shared Covariates Adjusted (With Prediction Interval) 1.14[1.00, 1.27] -0.11[-1.65, 1.09] -0.09[-1.26, 1.01] 1.04[0.33, 3.79] 1.02[0.26, 4.16] 1.14[0.24, 4.75] 0.00[-1.30, 1.12] -0.01[-1.28, 1.19] -0.08[-1.32, 1.09] 1.16[0.26, 8.64] 1.03[0.26, 4.26] Satisfaction with Life Unadjusted 0.92[0.80, 1.05] -0.01[-0.22, 0.18] -0.07[-0.29, 0.18] 1.04[0.77, 1.41] 0.99[0.72, 1.31] 1.06[0.72, 1.67] 0.01[-0.13, 0.13] 0.02[-0.14, 0.19] 0.000[-0.24, 0.24] 0.87[0.38, 1.71] 1.07[0.83, 1.47] Fully Adjusted 1.05[0.37, 2.25] Shared Covariates Adjusted 0.93[0.84, 1.03] 0.000[-0.33, 0.26] 0.01[-0.40, 0.53] 1.07[0.79, 1.49] 0.98[0.72, 1.36] 1.08[0.73, 1.71] -0.01[-0.23, 0.18] 0.01[-0.17, 0.23] -0.02[-0.20, 0.17] 0.91[0.34, 2.26] 1.10[0.78, 1.53] Standard Covariates Adjusted 0.92[0.83, 1.01] 1.05[0.64, 1.60] All But One Covariate Adjusted 0.94[0.75, 1.13] 0.00[-0.21, 0.23] 0.00[-0.27, 0.27] 1.06[0.68, 1.64] 0.99[0.69, 1.52] 1.09[0.76, 1.59] 0.09[-0.08, 0.29] 0.00[-0.22, 0.23] -0.00[-0.20, 0.20] 0.89[0.36, 2.31] 1.11[0.85, 1.50] Shared Covariates Adjusted (With Prediction Interval) 0.93[0.85, 1.01] 0.01[-0.29, 0.31] -0.00[-0.26, 0.23] 1.05[0.78, 1.47] 1.15[0.69, 2.22] 1.10[0.74, 2.08] 0.02[-0.20, 0.20] 0.001[-0.35, 0.35] 0.00[-0.28, 0.28] 0.79[0.40, 2.17] 1.22[0.85, 1.90] Note: Unadjusted indicates no covariates were included. Fully adjusted models include age, gender, education, smoking status, alcohol use, cognitive ability, race, chronic conditions, BMI, and self-rated health. Shared covariates adjusted models Include age, gender, education, smoking status, alcohol use. Standard covariates adjusted models include age, gender, and education. All but one covariate adjusted models include age, gender, education, cognitive ability, and chronic conditions. Shared covariates with dementia adjusted models Include age, gender, education, smoking status, alcohol use, and dementia diagnosis. Standard covariates with dementia adjusted models include age, gender, education, and incident dementia diagnosis. Shared covariates with prediction interval adjusted models Include age, gender, education, smoking status, alcohol use, and prediction interval. (ipd_fx_tab %&gt;% filter(Moderator == &quot;Dementia Diagnosis&quot;))$tab[[1]] Table 4.1: Table XOverall dementia Moderation of Personality-Dementia Diagnosis and Neuropathology Associations Incident Dementia Diagnosis Braak Stage CERAD Lewy Body Disease Gross Cerebral Infarcts Gross Cerebral Microinfarcts Cerebral Atherosclerosis Cerebral Amyloid Angiopathy Arteriolosclerosis Hippocampal Sclerosis TDP-43 Covariates OR [CI] b [CI] b [CI] OR [CI] OR [CI] OR [CI] b [CI] b [CI] b [CI] OR [CI] OR [CI] Extraversion Unadjusted 0.06[-0.05, 0.17] -0.10[-0.57, 0.30] 1.03[0.87, 1.22] 1.05[0.65, 2.05] 1.10[0.90, 1.38] 0.02[-0.04, 0.09] 0.01[-0.09, 0.11] 0.01[-0.10, 0.11] 0.96[0.71, 1.32] 1.02[0.75, 1.38] Shared Covariates Adjusted 0.06[-0.08, 0.19] 0.04[-0.27, 0.35] 1.02[0.86, 1.22] 1.07[0.59, 2.17] 1.16[0.93, 1.79] 0.02[-0.04, 0.08] 0.03[-0.05, 0.12] 0.03[-0.07, 0.26] 1.03[0.73, 1.57] 1.01[0.72, 1.33] Standard Covariates Adjusted 0.07[-0.09, 0.26] 0.04[-0.28, 0.37] 1.04[0.86, 1.24] 1.04[0.61, 2.09] 1.12[0.84, 1.44] 0.02[-0.07, 0.15] 0.02[-0.08, 0.12] 0.01[-0.10, 0.13] 0.94[0.70, 1.28] 1.02[0.83, 1.32] All But One Covariate Adjusted 0.06[-0.07, 0.18] 0.04[-0.26, 0.36] 1.02[0.86, 1.23] 1.10[0.67, 2.35] 1.15[0.92, 1.49] 0.03[-0.05, 0.10] 0.03[-0.06, 0.13] -0.00[-0.30, 0.19] 1.01[0.73, 1.41] 1.01[0.76, 1.36] Shared Covariates Adjusted (With Prediction Interval) 0.04[-0.09, 0.18] 0.04[-0.37, 0.61] 1.01[0.84, 1.23] 1.07[0.62, 2.65] 1.13[0.90, 1.40] 0.03[-0.07, 0.15] 0.04[-0.06, 0.20] 0.02[-0.07, 0.12] 1.02[0.73, 1.41] 1.01[0.74, 1.44] Agreeableness Unadjusted 0.01[-0.28, 0.20] -0.01[-0.59, 0.55] 1.09[0.70, 1.83] 1.07[0.31, 4.83] 0.95[0.47, 2.11] -0.03[-0.80, 0.49] 0.00[-0.33, 0.31] -0.02[-0.40, 0.35] 1.09[0.59, 2.56] 1.23[0.56, 2.82] Shared Covariates Adjusted 0.06[-0.18, 0.27] -0.03[-0.65, 0.63] 1.13[0.76, 1.79] 1.09[0.34, 4.27] 0.96[0.59, 2.10] 0.01[-0.29, 0.36] 0.01[-0.39, 0.51] -0.02[-0.44, 0.40] 1.01[0.51, 2.05] 1.30[0.57, 6.23] Standard Covariates Adjusted 0.04[-0.18, 0.26] -0.00[-0.59, 0.59] 1.15[0.82, 1.72] 1.14[0.28, 5.30] 0.98[0.43, 2.19] 0.03[-0.45, 0.42] 0.001[-0.44, 0.39] -0.09[-0.69, 0.32] 1.03[0.52, 2.20] 1.16[0.53, 2.58] All But One Covariate Adjusted 0.06[-0.14, 0.26] -0.04[-0.69, 0.58] 1.15[0.83, 1.67] 1.06[0.22, 5.10] 0.96[0.39, 2.14] 0.001[-0.38, 0.26] -0.01[-0.37, 0.38] -0.01[-0.43, 0.47] 0.99[0.50, 1.94] 1.17[0.56, 2.58] Shared Covariates Adjusted (With Prediction Interval) 0.05[-0.15, 0.25] -0.03[-0.63, 0.56] 1.11[0.75, 1.65] 1.08[0.30, 4.40] 1.01[0.43, 4.15] 0.05[-0.37, 0.34] -0.01[-0.50, 0.36] -0.02[-0.49, 0.43] 0.99[0.53, 2.01] 1.18[0.59, 2.54] Conscientiousness Unadjusted 0.09[-0.04, 0.24] -0.04[-0.28, 0.19] 1.02[0.82, 1.26] 1.10[0.66, 2.22] 1.14[0.90, 1.46] 0.04[-0.03, 0.12] 0.01[-0.08, 0.11] 0.02[-0.09, 0.14] 0.90[0.63, 1.30] 1.08[0.87, 1.37] Shared Covariates Adjusted 0.11[-0.08, 0.30] -0.06[-0.28, 0.15] 1.05[0.84, 1.31] 1.10[0.66, 2.06] 1.17[0.93, 1.52] 0.04[-0.06, 0.11] 0.03[-0.07, 0.19] 0.001[-0.12, 0.10] 0.88[0.58, 1.32] 1.04[0.82, 1.31] Standard Covariates Adjusted 0.10[-0.08, 0.28] -0.04[-0.31, 0.24] 1.02[0.81, 1.29] 1.08[0.62, 2.22] 1.12[0.87, 1.46] 0.03[-0.07, 0.14] 0.03[-0.06, 0.12] 0.02[-0.10, 0.13] 0.91[0.63, 1.63] 1.05[0.82, 1.36] All But One Covariate Adjusted 0.12[-0.03, 0.26] -0.09[-0.29, 0.14] 1.06[0.84, 1.30] 1.10[0.63, 2.26] 1.16[0.82, 1.49] 0.03[-0.06, 0.14] 0.02[-0.14, 0.12] 0.00[-0.11, 0.11] 0.88[0.56, 1.33] 1.03[0.82, 1.32] Shared Covariates Adjusted (With Prediction Interval) 0.10[-0.07, 0.26] -0.05[-0.29, 0.22] 1.06[0.84, 1.32] 1.09[0.65, 2.19] 1.15[0.89, 1.49] 0.03[-0.07, 0.15] 0.03[-0.06, 0.14] 0.00[-0.12, 0.12] 0.86[0.57, 1.28] 1.00[0.78, 1.31] Neuroticism Unadjusted -0.05[-0.20, 0.08] 0.02[-0.21, 0.26] 1.08[0.81, 1.39] 1.02[0.62, 1.99] 0.92[0.73, 1.22] -0.04[-0.13, 0.04] 0.01[-0.10, 0.14] 0.01[-0.12, 0.14] 0.92[0.66, 1.28] 0.99[0.72, 1.35] Shared Covariates Adjusted -0.08[-0.24, 0.05] 0.07[-0.13, 0.25] 1.08[0.82, 1.38] 1.04[0.63, 2.18] 0.97[0.65, 1.45] -0.03[-0.15, 0.08] -0.04[-0.19, 0.09] 0.000[-0.16, 0.17] 0.86[0.58, 1.24] 1.01[0.73, 1.35] Standard Covariates Adjusted -0.05[-0.18, 0.08] 0.02[-0.25, 0.25] 1.07[0.85, 1.34] 1.02[0.62, 2.18] 0.97[0.69, 1.56] -0.03[-0.16, 0.09] -0.00[-0.13, 0.16] -0.01[-0.19, 0.14] 0.92[0.67, 1.28] 1.00[0.76, 1.34] All But One Covariate Adjusted -0.09[-0.21, 0.04] 0.07[-0.12, 0.25] 1.10[0.85, 1.44] 1.06[0.64, 2.13] 0.91[0.55, 1.54] -0.02[-0.11, 0.09] -0.04[-0.16, 0.10] 0.01[-0.13, 0.14] 0.86[0.60, 1.23] 1.00[0.72, 1.56] Shared Covariates Adjusted (With Prediction Interval) -0.07[-0.21, 0.07] 0.07[-0.16, 0.32] 1.10[0.84, 1.40] 1.03[0.57, 1.89] 0.92[0.63, 1.45] -0.03[-0.14, 0.09] -0.03[-0.17, 0.12] 0.001[-0.13, 0.12] 0.87[0.62, 1.24] 1.02[0.78, 1.36] Openness to Experience Unadjusted -0.01[-0.20, 0.16] 0.02[-0.69, 0.60] 1.14[0.78, 1.72] 1.03[0.24, 4.02] 1.03[0.53, 2.10] -0.01[-0.52, 0.41] -0.01[-0.37, 0.30] 0.05[-0.38, 0.61] 1.22[0.72, 2.12] 0.97[0.54, 1.86] Shared Covariates Adjusted 0.03[-0.19, 0.41] 0.05[-0.52, 0.63] 1.15[0.78, 1.67] 1.07[0.32, 3.40] 1.04[0.53, 2.04] -0.06[-0.36, 0.36] -0.01[-0.46, 0.41] 0.02[-0.39, 0.54] 1.23[0.74, 2.12] 0.98[0.47, 1.69] Standard Covariates Adjusted 0.03[-0.19, 0.36] 0.04[-0.55, 0.51] 1.29[0.82, 2.02] 1.10[0.28, 4.38] 1.08[0.57, 2.23] -0.04[-0.46, 0.42] -0.01[-0.40, 0.39] 0.000[-0.40, 0.39] 1.15[0.46, 2.09] 0.96[0.50, 1.84] All But One Covariate Adjusted 0.01[-0.16, 0.17] -0.16[-1.60, 0.57] 1.16[0.78, 1.71] 0.99[0.20, 4.63] 1.04[0.51, 2.11] -0.05[-0.39, 0.24] -0.01[-0.49, 0.47] 0.02[-0.30, 0.48] 1.30[0.75, 2.33] 0.95[0.49, 1.89] Shared Covariates Adjusted (With Prediction Interval) 0.01[-0.19, 0.25] 0.03[-0.79, 0.74] 1.13[0.85, 1.57] 1.01[0.26, 3.79] 1.09[0.58, 2.53] -0.06[-0.46, 0.29] -0.00[-0.41, 0.48] 0.03[-0.42, 0.57] 1.24[0.76, 2.26] 0.93[0.44, 2.19] Positive Affect Unadjusted -0.00[-0.52, 0.43] -0.02[-0.44, 0.35] 0.96[0.40, 1.72] 1.28[0.56, 3.50] 0.97[0.49, 1.85] -0.01[-0.42, 0.46] -0.01[-0.37, 0.34] -0.01[-0.35, 0.34] 1.10[0.50, 2.73] 1.18[0.61, 2.77] Shared Covariates Adjusted 0.01[-0.49, 0.39] -0.04[-0.46, 0.33] 0.95[0.17, 1.93] 0.95[0.57, 1.79] 1.02[0.49, 2.09] 0.01[-0.37, 0.48] -0.05[-0.53, 0.41] 0.02[-0.32, 0.38] 1.16[0.51, 3.07] 1.15[0.61, 2.04] Standard Covariates Adjusted -0.00[-0.54, 0.47] -0.02[-0.52, 0.45] 0.96[0.47, 1.69] 0.96[0.56, 2.13] 0.94[0.45, 1.72] 0.08[-0.50, 0.74] -0.02[-0.36, 0.34] -0.001[-0.38, 0.45] 1.13[0.53, 2.92] 1.14[0.55, 2.08] All But One Covariate Adjusted -0.01[-0.50, 0.35] -0.01[-0.49, 0.56] 0.99[0.36, 1.82] 0.94[0.58, 1.71] 1.58[0.54, 6.35] -0.00[-0.41, 0.37] -0.05[-0.52, 0.34] 0.02[-0.44, 0.43] 1.13[0.53, 2.95] 1.17[0.60, 2.31] Shared Covariates Adjusted (With Prediction Interval) -0.02[-0.88, 0.46] -0.03[-0.57, 0.48] 1.12[0.67, 2.48] 0.93[0.56, 1.73] 0.85[0.44, 2.01] -0.02[-0.48, 0.39] -0.05[-0.34, 0.27] 0.02[-0.48, 0.57] 1.12[0.61, 2.85] 1.10[0.68, 1.85] Negative Affect Unadjusted -0.09[-1.99, 1.66] -0.10[-1.73, 1.40] 1.02[0.08, 7.76] 1.16[0.22, 8.57] 1.07[0.15, 6.53] -0.01[-1.72, 1.63] -0.01[-1.75, 1.53] 0.13[-1.77, 2.22] 1.02[0.16, 10.27] 0.96[0.13, 5.85] Shared Covariates Adjusted -0.11[-2.19, 1.63] -0.05[-1.74, 1.66] 1.28[0.16, 10.72] 1.05[0.14, 7.19] 1.02[0.15, 6.20] 0.02[-1.61, 1.57] -0.01[-2.01, 1.67] 0.04[-1.67, 1.68] 0.97[0.16, 9.02] 0.90[0.16, 7.26] Standard Covariates Adjusted -0.12[-1.97, 1.63] 0.02[-1.76, 1.75] 0.97[0.11, 7.80] 1.09[0.16, 7.28] 1.08[0.17, 8.13] 0.00[-1.49, 1.71] -0.01[-1.61, 1.56] 0.00[-1.69, 1.64] 1.00[0.18, 6.32] 0.89[0.08, 5.81] All But One Covariate Adjusted -0.11[-2.25, 1.67] -0.06[-2.04, 1.47] 1.12[0.13, 6.43] 1.13[0.21, 6.11] 1.08[0.19, 6.18] -0.13[-2.32, 1.46] -0.04[-1.79, 1.62] 0.04[-1.85, 1.89] 0.90[0.14, 5.95] 0.96[0.16, 5.10] Shared Covariates Adjusted (With Prediction Interval) -0.12[-2.01, 1.59] -0.31[-1.64, 1.31] 1.21[0.22, 10.72] 1.05[0.19, 6.33] 1.11[0.14, 8.85] -0.60[-2.31, 1.44] -0.02[-1.64, 1.57] -0.02[-1.88, 1.47] 0.89[0.15, 6.47] 0.98[0.16, 5.75] Satisfaction with Life Unadjusted -0.04[-0.52, 0.39] -0.01[-0.52, 0.39] 1.11[0.67, 1.92] 0.83[0.42, 1.81] 0.87[0.47, 1.74] -0.01[-0.39, 0.41] -0.04[-0.48, 0.37] -0.04[-0.49, 0.36] 1.24[0.40, 3.58] 1.17[0.63, 1.95] Shared Covariates Adjusted -0.05[-0.71, 0.34] -0.02[-0.58, 0.47] 1.14[0.56, 2.09] 0.85[0.44, 1.67] 0.93[0.52, 1.91] -0.00[-0.32, 0.34] -0.03[-0.45, 0.52] 0.02[-0.44, 0.47] 1.64[0.41, 4.14] 1.13[0.56, 2.19] Standard Covariates Adjusted -0.03[-0.54, 0.40] -0.00[-0.51, 0.39] 1.12[0.56, 2.61] 0.82[0.40, 1.56] 0.86[0.45, 1.58] 0.02[-0.33, 0.34] -0.03[-0.55, 0.55] -0.03[-0.52, 0.42] 1.02[0.10, 4.23] 1.15[0.60, 2.02] All But One Covariate Adjusted -0.02[-0.46, 0.47] -0.01[-0.65, 0.49] 1.14[0.55, 2.05] 0.83[0.41, 1.52] 0.91[0.43, 1.76] -0.00[-0.42, 0.35] -0.06[-0.52, 0.39] -0.03[-0.51, 0.35] 1.27[0.30, 4.58] 1.14[0.62, 2.10] Shared Covariates Adjusted (With Prediction Interval) -0.12[-1.39, 0.57] -0.03[-0.56, 0.39] 1.13[0.58, 2.08] 0.83[0.36, 1.73] 0.93[0.44, 2.52] -0.01[-0.44, 0.41] -0.05[-0.54, 0.45] -0.01[-0.44, 0.39] 1.26[0.25, 7.53] 1.15[0.66, 1.94] Note: Unadjusted indicates no covariates were included. Fully adjusted models include age, gender, education, smoking status, alcohol use, cognitive ability, race, chronic conditions, BMI, and self-rated health. Shared covariates adjusted models Include age, gender, education, smoking status, alcohol use. Standard covariates adjusted models include age, gender, and education. All but one covariate adjusted models include age, gender, education, cognitive ability, and chronic conditions. Shared covariates with dementia adjusted models Include age, gender, education, smoking status, alcohol use, and dementia diagnosis. Standard covariates with dementia adjusted models include age, gender, education, and incident dementia diagnosis. Shared covariates with prediction interval adjusted models Include age, gender, education, smoking status, alcohol use, and prediction interval. These show the estimates, split by covariate sets across moderators, traits, and outcomes. ipd_tab_fun2 &lt;- function(d, cov){ # long outcome name covar &lt;- mapvalues(cov, str_wrap(covars$long_name, 15), covars$short_name, warn_missing = F) # getting row numbers for later grouping rs &lt;- d %&gt;% group_by(Moderator) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) # number and name of columns for span columns cs &lt;- rep(1,12) names(cs) &lt;- c(&quot; &quot;, outcomes$long_name) cln &lt;- mapvalues(colnames(d)[colnames(d) %in% outcomes$long_name], outcomes$long_name, outcomes$colnm, warn_missing = F) cln &lt;- c(&quot;Trait&quot;, cln) al &lt;- c(&quot;r&quot;, rep(&quot;c&quot;, 11)) # caption cap &lt;- sprintf(&quot;&lt;strong&gt;Table X&lt;/strong&gt;&lt;br&gt;&lt;em&gt;Fixed Effect Estimates of %s Personality-Dementia Diagnosis and Neuropathology Associations&lt;/em&gt;&quot;, cov) fn &lt;- mapvalues(cov, str_wrap(covars$long_name, 15), covars$desc, warn_missing = F) # kable the table tab &lt;- d %&gt;% mutate(Trait = factor(Trait, traits$short_name, traits$long_name)) %&gt;% select(-Moderator, -term) %&gt;% kable(., &quot;html&quot; # kable(., &quot;latex&quot; , booktabs = T , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% # kable_styling(full_width = F, font_size = 7) %&gt;% add_header_above(cs) %&gt;% footnote(fn) # for loop to add grouped sections for (i in 1:nrow(rs)){ tab &lt;- tab %&gt;% kableExtra::group_rows(rs$Moderator[i], rs$start[i], rs$end[i]) } # save the resulting html table save_kable(tab, file = sprintf(&quot;%s/results/tables/key-terms/%s.html&quot; , local_path, covar)) return(tab) # return the html table } ipd_fx_tab2 &lt;- nested_mega_tab %&gt;% filter(study == &quot;Overall&quot;) %&gt;% select(-study) %&gt;% arrange(Moderator, term) %&gt;% # filter(Covariate %in% c(&quot;unadjusted&quot;, &quot;shared&quot;)) %&gt;% group_by(Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, Covariate), ipd_tab_fun2)) ## Frequentist, no moderator (ipd_fx_tab2 %&gt;% filter(Covariate == &quot;Shared\\nCovariates\\nAdjusted (With\\nPrediction\\nInterval)&quot;))$tab[[1]] Table 4.2: Table XFixed Effect Estimates of Shared Covariates Adjusted (With Prediction Interval) Personality-Dementia Diagnosis and Neuropathology Associations Incident Dementia Diagnosis Braak Stage CERAD Lewy Body Disease Gross Cerebral Infarcts Gross Cerebral Microinfarcts Cerebral Atherosclerosis Cerebral Amyloid Angiopathy Arteriolosclerosis Hippocampal Sclerosis TDP-43 Trait OR [CI] b [CI] b [CI] OR [CI] OR [CI] OR [CI] b [CI] b [CI] b [CI] OR [CI] OR [CI] None Extraversion 0.95[0.92, 0.99] -0.01[-0.28, 0.15] -0.03[-0.10, 0.03] 1.01[0.91, 1.14] 1.03[0.70, 1.99] 0.96[0.83, 1.08] 0.01[-0.06, 0.09] 0.02[-0.04, 0.07] -0.01[-0.07, 0.09] 0.96[0.82, 1.16] 1.00[0.79, 1.22] Agreeableness 0.96[0.92, 1.01] -0.02[-0.13, 0.09] -0.02[-0.29, 0.22] 0.99[0.76, 1.37] 1.15[0.42, 3.24] 1.09[0.61, 1.74] -0.01[-0.19, 0.16] 0.00[-0.32, 0.20] -0.00[-0.38, 0.17] 1.00[0.61, 1.62] 0.98[0.68, 1.50] Conscientiousness 0.86[0.83, 0.90] -0.05[-0.14, 0.02] 0.03[-0.07, 0.14] 0.99[0.81, 1.32] 1.01[0.64, 1.92] 1.05[0.83, 1.35] 0.00[-0.05, 0.07] 0.02[-0.06, 0.13] -0.02[-0.09, 0.04] 1.05[0.85, 1.35] 1.01[0.87, 1.21] Neuroticism 1.12[1.07, 1.16] 0.04[-0.11, 0.31] -0.01[-0.11, 0.09] 1.00[0.77, 1.16] 1.13[0.67, 2.31] 0.99[0.85, 1.13] 0.02[-0.05, 0.09] 0.01[-0.07, 0.08] 0.01[-0.07, 0.10] 1.03[0.87, 1.21] 1.03[0.88, 1.20] Openness to Experience 0.95[0.90, 1.00] -0.02[-0.13, 0.08] -0.03[-0.21, 0.15] 1.03[0.77, 1.32] 1.09[0.37, 3.15] 0.94[0.69, 1.43] -0.03[-0.26, 0.12] -0.06[-0.19, 0.15] -0.05[-0.42, 0.25] 1.03[0.75, 1.50] 1.02[0.76, 1.39] Positive Affect 0.93[0.87, 0.99] -0.05[-0.36, 0.18] 0.00[-0.26, 0.17] 1.01[0.67, 1.45] 1.07[0.80, 1.83] 1.02[0.74, 1.45] 0.01[-0.15, 0.15] 0.03[-0.12, 0.19] -0.01[-0.18, 0.18] 1.09[0.72, 1.70] 1.05[0.71, 1.54] Negative Affect 1.14[1.00, 1.27] -0.11[-1.65, 1.09] -0.09[-1.26, 1.01] 1.04[0.33, 3.79] 1.02[0.26, 4.16] 1.14[0.24, 4.75] 0.00[-1.30, 1.12] -0.01[-1.28, 1.19] -0.08[-1.32, 1.09] 1.16[0.26, 8.64] 1.03[0.26, 4.26] Satisfaction with Life 0.93[0.85, 1.01] 0.01[-0.29, 0.31] -0.00[-0.26, 0.23] 1.05[0.78, 1.47] 1.15[0.69, 2.22] 1.10[0.74, 2.08] 0.02[-0.20, 0.20] 0.001[-0.35, 0.35] 0.00[-0.28, 0.28] 0.79[0.40, 2.17] 1.22[0.85, 1.90] Age Extraversion 1.00[1.00, 1.01] 0.001[-0.01, 0.01] -0.000[-0.01, 0.01] 1.00[0.99, 1.01] 1.01[0.93, 1.09] 1.00[0.99, 1.02] -0.000[-0.00, 0.00] -0.000[-0.01, 0.01] 0.000[-0.01, 0.01] 1.01[0.99, 1.02] 0.99[0.98, 1.01] Agreeableness 1.00[1.00, 1.01] -0.00[-0.02, 0.01] -0.01[-0.06, 0.03] 1.00[0.95, 1.04] 0.95[0.79, 1.29] 1.00[0.94, 1.07] -0.00[-0.06, 0.03] -0.01[-0.04, 0.04] -0.00[-0.05, 0.04] 0.97[0.93, 1.01] 1.00[0.92, 1.07] Conscientiousness 1.01[1.00, 1.01] -0.001[-0.01, 0.01] 0.001[-0.01, 0.01] 1.00[0.99, 1.02] 1.01[0.94, 1.08] 1.00[0.99, 1.02] 0.001[-0.00, 0.01] -0.00[-0.01, 0.00] 0.000[-0.01, 0.01] 1.01[0.99, 1.03] 1.00[0.99, 1.01] Neuroticism 1.00[0.99, 1.00] 0.00[-0.01, 0.01] -0.00[-0.01, 0.01] 1.00[0.99, 1.01] 1.02[0.95, 1.08] 1.00[0.99, 1.01] 0.001[-0.01, 0.01] 0.00[-0.00, 0.01] 0.00[-0.02, 0.01] 1.00[0.98, 1.02] 1.00[0.98, 1.02] Openness to Experience 1.00[1.00, 1.01] 0.01[-0.02, 0.06] -0.01[-0.06, 0.02] 0.99[0.97, 1.02] 0.98[0.68, 1.23] 1.00[0.95, 1.06] 0.00[-0.03, 0.03] -0.00[-0.04, 0.02] -0.00[-0.04, 0.02] 1.02[0.98, 1.06] 0.99[0.93, 1.06] Positive Affect 1.00[0.99, 1.01] -0.01[-0.05, 0.03] -0.00[-0.07, 0.04] 0.99[0.92, 1.06] 1.01[0.96, 1.08] 0.99[0.92, 1.06] 0.00[-0.03, 0.04] -0.00[-0.04, 0.03] -0.00[-0.04, 0.03] 1.01[0.92, 1.12] 1.05[0.94, 1.16] Negative Affect 1.00[0.99, 1.00] -0.01[-0.68, 0.64] 0.11[-0.32, 0.41] 1.07[0.76, 1.74] 1.00[0.55, 1.69] 1.01[0.63, 1.73] -0.03[-0.38, 0.35] -0.02[-0.50, 0.35] -0.02[-0.38, 0.24] 1.07[0.70, 2.04] 0.95[0.63, 1.75] Satisfaction with Life 1.00[1.00, 1.01] -0.00[-0.04, 0.03] -0.00[-0.04, 0.04] 1.00[0.94, 1.05] 1.02[0.98, 1.06] 0.99[0.93, 1.06] 0.00[-0.02, 0.03] -0.00[-0.04, 0.05] 0.001[-0.03, 0.04] 1.04[0.92, 1.13] 0.99[0.94, 1.06] Gender Extraversion 0.95[0.89, 1.01] 0.01[-0.10, 0.11] -0.15[-0.56, 0.18] 1.08[0.75, 1.58] 1.04[0.60, 2.25] 0.95[0.70, 1.32] -0.04[-0.14, 0.05] -0.01[-0.17, 0.13] -0.07[-0.21, 0.09] 0.94[0.71, 1.24] 0.95[0.73, 1.23] Agreeableness 0.99[0.92, 1.08] 0.09[-0.16, 0.26] -0.04[-0.63, 0.54] 1.12[0.68, 1.99] 1.09[0.21, 5.54] 0.92[0.40, 2.36] -0.05[-0.59, 0.38] -0.02[-0.52, 0.43] 0.01[-0.48, 0.94] 0.85[0.49, 1.65] 0.89[0.49, 1.79] Conscientiousness 0.99[0.93, 1.07] -0.05[-0.23, 0.06] -0.02[-0.16, 0.19] 0.96[0.51, 1.24] 1.23[0.65, 2.85] 0.98[0.71, 1.31] 0.01[-0.11, 0.13] -0.000[-0.14, 0.13] -0.01[-0.19, 0.18] 1.12[0.77, 1.64] 0.91[0.71, 1.17] Neuroticism 1.01[0.94, 1.07] -0.01[-0.13, 0.10] -0.01[-0.21, 0.23] 0.92[0.65, 1.30] 0.96[0.53, 2.03] 0.95[0.73, 1.25] -0.01[-0.17, 0.14] 0.00[-0.21, 0.15] -0.24[-0.85, 0.12] 1.03[0.75, 1.41] 0.97[0.76, 1.23] Openness to Experience 1.00[0.92, 1.11] -0.03[-0.21, 0.19] -0.01[-0.55, 0.45] 1.18[0.73, 2.29] 1.07[0.31, 5.22] 0.91[0.37, 1.88] -0.03[-0.32, 0.31] 0.001[-0.34, 0.40] -0.04[-0.48, 0.54] 0.75[0.43, 1.58] 1.07[0.57, 2.04] Positive Affect 1.03[0.94, 1.13] -0.01[-0.54, 0.51] -0.001[-0.70, 0.53] 0.85[0.21, 2.65] 0.67[0.11, 3.03] 1.52[0.44, 7.49] -0.05[-0.55, 0.38] -0.02[-0.67, 0.53] -0.01[-0.48, 0.59] 0.81[0.23, 2.59] 0.67[0.19, 1.90] Negative Affect 0.92[0.73, 1.06] -0.03[-2.04, 2.54] -0.04[-2.10, 1.95] 0.94[0.12, 8.11] 0.90[0.18, 5.48] 0.75[0.08, 5.91] 0.18[-1.91, 2.35] -0.05[-2.08, 1.87] 0.06[-1.93, 1.64] 1.36[0.12, 10.75] 1.21[0.15, 9.81] Satisfaction with Life 0.98[0.91, 1.08] 0.05[-0.77, 0.68] -0.17[-1.12, 0.76] 0.94[0.26, 2.57] 0.80[0.13, 3.06] 1.49[0.38, 7.58] 0.02[-0.61, 0.52] 0.04[-0.52, 0.51] 0.06[-0.42, 0.57] 1.19[0.25, 5.23] 0.82[0.17, 2.59] Education Extraversion 1.00[0.99, 1.01] -0.01[-0.02, 0.01] 0.01[-0.01, 0.03] 0.98[0.90, 1.04] 1.01[0.91, 1.15] 1.01[0.96, 1.07] -0.001[-0.02, 0.02] -0.001[-0.02, 0.02] 0.00[-0.02, 0.02] 1.00[0.96, 1.05] 0.99[0.96, 1.03] Agreeableness 1.00[0.99, 1.01] -0.01[-0.05, 0.02] 0.01[-0.07, 0.11] 1.00[0.94, 1.06] 0.97[0.65, 1.39] 1.02[0.84, 1.24] 0.00[-0.06, 0.05] -0.01[-0.09, 0.06] -0.02[-0.08, 0.06] 0.96[0.83, 1.09] 1.01[0.90, 1.13] Conscientiousness 0.99[0.98, 1.00] 0.00[-0.01, 0.02] 0.01[-0.02, 0.03] 0.98[0.91, 1.05] 1.04[0.93, 1.29] 1.00[0.96, 1.03] -0.000[-0.02, 0.01] 0.000[-0.02, 0.02] 0.00[-0.01, 0.02] 0.98[0.93, 1.04] 0.99[0.94, 1.02] Neuroticism 1.00[0.99, 1.01] -0.01[-0.02, 0.01] -0.000[-0.02, 0.02] 1.00[0.96, 1.04] 0.99[0.88, 1.16] 0.98[0.88, 1.05] -0.00[-0.02, 0.01] -0.00[-0.02, 0.02] -0.01[-0.03, 0.01] 1.02[0.96, 1.09] 1.00[0.96, 1.04] Openness to Experience 1.00[0.99, 1.02] -0.01[-0.04, 0.02] 0.001[-0.09, 0.08] 1.00[0.95, 1.08] 0.96[0.64, 1.29] 0.93[0.66, 1.18] -0.01[-0.06, 0.05] 0.000[-0.07, 0.08] -0.001[-0.07, 0.07] 0.97[0.87, 1.12] 0.97[0.89, 1.07] Positive Affect 1.00[0.99, 1.01] -0.01[-0.10, 0.06] 0.001[-0.12, 0.10] 0.89[0.57, 1.30] 1.01[0.86, 1.20] 1.01[0.89, 1.20] 0.00[-0.08, 0.10] 0.01[-0.07, 0.11] 0.04[-0.08, 0.15] 1.00[0.83, 1.29] 1.03[0.84, 1.20] Negative Affect 1.00[0.98, 1.03] -0.09[-1.43, 1.05] -0.17[-1.48, 0.98] 1.12[0.33, 10.09] 0.98[0.30, 2.95] 1.08[0.34, 3.63] -0.02[-1.10, 0.94] -0.04[-1.07, 0.99] 0.03[-1.08, 1.31] 1.11[0.36, 4.38] 1.01[0.37, 2.95] Satisfaction with Life 1.00[0.99, 1.01] -0.00[-0.09, 0.10] -0.01[-0.14, 0.09] 0.97[0.79, 1.24] 1.00[0.84, 1.20] 1.03[0.83, 1.37] -0.000[-0.13, 0.12] 0.00[-0.16, 0.16] 0.00[-0.09, 0.09] 0.99[0.48, 1.67] 0.99[0.84, 1.17] Cognition Extraversion 1.00[0.98, 1.03] 0.00[-0.04, 0.04] 0.01[-0.04, 0.05] 0.95[0.90, 1.00] 1.01[0.82, 1.26] 0.97[0.90, 1.03] -0.01[-0.03, 0.01] -0.01[-0.05, 0.02] 0.00[-0.03, 0.03] 1.04[0.95, 1.13] 1.02[0.95, 1.10] Agreeableness 1.00[0.97, 1.05] 0.01[-0.09, 0.09] 0.02[-0.08, 0.19] 0.96[0.86, 1.08] 0.94[0.59, 1.55] 0.94[0.81, 1.09] -0.01[-0.12, 0.07] -0.00[-0.10, 0.11] -0.01[-0.12, 0.13] 1.11[0.93, 1.36] 1.06[0.84, 1.28] Conscientiousness 0.99[0.93, 1.05] -0.01[-0.04, 0.02] 0.01[-0.04, 0.05] 0.95[0.90, 1.01] 0.97[0.80, 1.18] 1.00[0.90, 1.09] -0.01[-0.05, 0.03] 0.001[-0.03, 0.03] -0.000[-0.03, 0.03] 1.04[0.93, 1.17] 0.97[0.88, 1.04] Neuroticism 1.01[0.99, 1.03] -0.01[-0.05, 0.03] 0.00[-0.05, 0.05] 1.01[0.94, 1.08] 1.01[0.84, 1.27] 0.98[0.92, 1.06] 0.02[-0.01, 0.05] -0.000[-0.05, 0.04] 0.02[-0.03, 0.08] 0.95[0.86, 1.05] 0.97[0.91, 1.05] Openness to Experience 0.99[0.96, 1.04] 0.000[-0.06, 0.06] -0.05[-0.18, 0.14] 0.97[0.82, 1.08] 0.99[0.68, 1.45] 0.97[0.83, 1.19] -0.04[-0.26, 0.05] 0.01[-0.11, 0.08] -0.01[-0.09, 0.06] 0.96[0.81, 1.15] 1.07[0.88, 1.43] Positive Affect 0.99[0.96, 1.02] -0.02[-0.16, 0.08] -0.01[-0.10, 0.07] 1.05[0.91, 1.22] 1.05[0.93, 1.21] 1.02[0.89, 1.15] 0.01[-0.08, 0.11] 0.02[-0.08, 0.11] 0.001[-0.12, 0.10] 1.10[0.88, 1.38] 1.03[0.80, 1.34] Negative Affect 1.01[0.91, 1.17] -0.03[-0.74, 0.59] -0.11[-0.88, 0.53] 1.09[0.42, 2.28] 0.99[0.41, 2.32] 1.01[0.39, 2.15] 0.03[-0.65, 0.78] -0.07[-0.86, 0.65] -0.05[-0.89, 0.72] 1.34[0.52, 5.63] 0.88[0.44, 2.31] Satisfaction with Life 1.00[0.97, 1.04] -0.03[-0.18, 0.09] 0.02[-0.10, 0.16] 1.06[0.88, 1.33] 1.04[0.88, 1.24] 1.02[0.84, 1.30] -0.000[-0.11, 0.12] 0.02[-0.09, 0.13] 0.02[-0.13, 0.16] 0.91[0.68, 1.24] 1.01[0.87, 1.20] Dementia Diagnosis Extraversion 0.04[-0.09, 0.18] 0.04[-0.37, 0.61] 1.01[0.84, 1.23] 1.07[0.62, 2.65] 1.13[0.90, 1.40] 0.03[-0.07, 0.15] 0.04[-0.06, 0.20] 0.02[-0.07, 0.12] 1.02[0.73, 1.41] 1.01[0.74, 1.44] Agreeableness 0.05[-0.15, 0.25] -0.03[-0.63, 0.56] 1.11[0.75, 1.65] 1.08[0.30, 4.40] 1.01[0.43, 4.15] 0.05[-0.37, 0.34] -0.01[-0.50, 0.36] -0.02[-0.49, 0.43] 0.99[0.53, 2.01] 1.18[0.59, 2.54] Conscientiousness 0.10[-0.07, 0.26] -0.05[-0.29, 0.22] 1.06[0.84, 1.32] 1.09[0.65, 2.19] 1.15[0.89, 1.49] 0.03[-0.07, 0.15] 0.03[-0.06, 0.14] 0.00[-0.12, 0.12] 0.86[0.57, 1.28] 1.00[0.78, 1.31] Neuroticism -0.07[-0.21, 0.07] 0.07[-0.16, 0.32] 1.10[0.84, 1.40] 1.03[0.57, 1.89] 0.92[0.63, 1.45] -0.03[-0.14, 0.09] -0.03[-0.17, 0.12] 0.001[-0.13, 0.12] 0.87[0.62, 1.24] 1.02[0.78, 1.36] Openness to Experience 0.01[-0.19, 0.25] 0.03[-0.79, 0.74] 1.13[0.85, 1.57] 1.01[0.26, 3.79] 1.09[0.58, 2.53] -0.06[-0.46, 0.29] -0.00[-0.41, 0.48] 0.03[-0.42, 0.57] 1.24[0.76, 2.26] 0.93[0.44, 2.19] Positive Affect -0.02[-0.88, 0.46] -0.03[-0.57, 0.48] 1.12[0.67, 2.48] 0.93[0.56, 1.73] 0.85[0.44, 2.01] -0.02[-0.48, 0.39] -0.05[-0.34, 0.27] 0.02[-0.48, 0.57] 1.12[0.61, 2.85] 1.10[0.68, 1.85] Negative Affect -0.12[-2.01, 1.59] -0.31[-1.64, 1.31] 1.21[0.22, 10.72] 1.05[0.19, 6.33] 1.11[0.14, 8.85] -0.60[-2.31, 1.44] -0.02[-1.64, 1.57] -0.02[-1.88, 1.47] 0.89[0.15, 6.47] 0.98[0.16, 5.75] Satisfaction with Life -0.12[-1.39, 0.57] -0.03[-0.56, 0.39] 1.13[0.58, 2.08] 0.83[0.36, 1.73] 0.93[0.44, 2.52] -0.01[-0.44, 0.41] -0.05[-0.54, 0.45] -0.01[-0.44, 0.39] 1.26[0.25, 7.53] 1.15[0.66, 1.94] Note: Shared covariates with prediction interval adjusted models Include age, gender, education, smoking status, alcohol use, and prediction interval. 4.0.1.2 Study-Specific Effects Next, we’ll look at these estimates for each sample. ## table function ipd_rx_tab_fun &lt;- function(d, moder, cov){ covar &lt;- mapvalues(cov, str_wrap(covars$long_name, 15), covars$short_name, warn_missing = F) md &lt;- mapvalues(moder, moders$long_name, moders$short_name, warn_missing = F) rs &lt;- d %&gt;% mutate(Trait = factor(Trait, traits$short_name, traits$long_name)) %&gt;% group_by(Trait) %&gt;% tally() %&gt;% mutate(end = cumsum(n), start = lag(end) + 1, start = ifelse(is.na(start), 1, start)) cs &lt;- rep(1,12) names(cs) &lt;- c(&quot; &quot;, paste0(&quot;&lt;strong&gt;&quot;, outcomes$long_name, &quot;&lt;/strong&gt;&quot;)) cln &lt;- mapvalues(colnames(d)[colnames(d) %in% outcomes$long_name], outcomes$long_name, outcomes$colnm, warn_missing = F) cln &lt;- c(&quot;Study&quot;, cln) al &lt;- c(&quot;r&quot;, rep(&quot;c&quot;, 11)) d &lt;- d %&gt;% select(-term) cap &lt;- if(md == &quot;none&quot;) sprintf(&quot;&lt;strong&gt;Table X&lt;/strong&gt;&lt;br&gt;&lt;em&gt;%s Overall and Sample-Specific Effects of Personality-Crystallized Domain Associations&lt;/em&gt;&quot;, cov) else sprintf(&quot;&lt;strong&gt;Table X&lt;/strong&gt;&lt;br&gt;&lt;em&gt;%s Overall and Sample-Specific %s Moderation of Personality-Crystallized Domain Associations&lt;/em&gt;&quot;, cov, md) fn &lt;- mapvalues(cov, str_wrap(covars$long_name, 15), covars$desc, warn_missing = F) tab &lt;- d %&gt;% arrange(Trait) %&gt;% select(-Trait) %&gt;% kable(., &quot;html&quot; , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% add_header_above(cs, escape = F) %&gt;% footnote(fn) for (i in 1:nrow(rs)) { tab &lt;- tab %&gt;% kableExtra::group_rows(rs$Trait[i], rs$start[i], rs$end[i]) } save_kable(tab, file = sprintf(&quot;%s/results/tables/study-specific/%s_%s.html&quot; , local_path, md, covar)) return(tab) } ipd_rx_tab &lt;- nested_mega_tab %&gt;% group_by(Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, Moderator, Covariate), ipd_rx_tab_fun)) ipd_rx_tab ## # A tibble: 45 × 4 ## Moderator Covariate data tab ## &lt;fct&gt; &lt;fct&gt; &lt;list&gt; &lt;list&gt; ## 1 None &quot;Unadjusted&quot; &lt;tibble [63 × 14]&gt; &lt;kablExtr [1]&gt; ## 2 None &quot;Fully Adjusted&quot; &lt;tibble [21 × 14]&gt; &lt;kablExtr [1]&gt; ## 3 None &quot;Shared\\nCovariates\\nAdjusted&quot; &lt;tibble [63 × 14]&gt; &lt;kablExtr [1]&gt; ## 4 None &quot;Standard\\nCovariates\\nAdjusted&quot; &lt;tibble [63 × 14]&gt; &lt;kablExtr [1]&gt; ## 5 None &quot;All But One\\nCovariate\\nAdjusted&quot; &lt;tibble [55 × 14]&gt; &lt;kablExtr [1]&gt; ## 6 None &quot;Shared\\nCovariates\\nAdjusted (With\\nPrediction\\nInterval)&quot; &lt;tibble [63 × 14]&gt; &lt;kablExtr [1]&gt; ## 7 Age &quot;Unadjusted&quot; &lt;tibble [63 × 14]&gt; &lt;kablExtr [1]&gt; ## 8 Age &quot;Fully Adjusted&quot; &lt;tibble [16 × 14]&gt; &lt;kablExtr [1]&gt; ## 9 Age &quot;Shared\\nCovariates\\nAdjusted&quot; &lt;tibble [63 × 14]&gt; &lt;kablExtr [1]&gt; ## 10 Age &quot;Standard\\nCovariates\\nAdjusted&quot; &lt;tibble [63 × 14]&gt; &lt;kablExtr [1]&gt; ## # ℹ 35 more rows ## Frequentist (ipd_rx_tab %&gt;% filter(Moderator == &quot;None&quot; &amp; Covariate == &quot;Shared\\nCovariates\\nAdjusted (With\\nPrediction\\nInterval)&quot;))$tab[[1]] (#tab:ipd2b study specific table)Table XShared Covariates Adjusted (With Prediction Interval) Overall and Sample-Specific Effects of Personality-Crystallized Domain Associations Incident Dementia Diagnosis Braak Stage CERAD Lewy Body Disease Gross Cerebral Infarcts Gross Cerebral Microinfarcts Cerebral Atherosclerosis Cerebral Amyloid Angiopathy Arteriolosclerosis Hippocampal Sclerosis TDP-43 Study OR [CI] b [CI] b [CI] OR [CI] OR [CI] OR [CI] b [CI] b [CI] b [CI] OR [CI] OR [CI] Extraversion ROS 0.96[0.92, 1.01] 0.05[-0.01, 0.10] -0.02[-0.06, 0.02] 1.03[0.95, 1.13] 0.93[0.85, 1.02] 0.96[0.89, 1.04] 0.01[-0.02, 0.04] 0.02[-0.01, 0.05] -0.01[-0.05, 0.02] 0.95[0.84, 1.07] 1.03[0.95, 1.12] Rush-MAP 0.95[0.91, 1.00] 0.03[-0.02, 0.08] -0.03[-0.07, 0.00] 1.00[0.92, 1.08] 0.95[0.87, 1.03] 0.97[0.90, 1.04] -0.01[-0.04, 0.02] 0.01[-0.02, 0.05] -0.01[-0.04, 0.03] 0.97[0.87, 1.08] 1.03[0.96, 1.11] EAS 0.96[0.89, 1.02] -0.01[-0.11, 0.10] 1.00[0.84, 1.15] 0.98[0.84, 1.16] WUSM-MAP 0.95[0.90, 1.00] -0.11[-0.19, -0.04] -0.03[-0.09, 0.01] 1.02[0.93, 1.13] 1.38[0.63, 8.00] 0.94[0.84, 1.06] 0.01[-0.02, 0.05] 0.01[-0.03, 0.04] -0.02[-0.06, 0.03] 0.92[0.73, 1.07] 0.98[0.87, 1.09] SATSA 0.95[0.87, 1.02] HRS 0.96[0.93, 0.99] LISS 0.96[0.88, 1.05] GSOEP 0.94[0.87, 1.00] Overall 0.95[0.92, 0.99] -0.01[-0.28, 0.15] -0.03[-0.10, 0.03] 1.01[0.91, 1.14] 1.03[0.70, 1.99] 0.96[0.83, 1.08] 0.01[-0.06, 0.09] 0.02[-0.04, 0.07] -0.01[-0.07, 0.09] 0.96[0.82, 1.16] 1.00[0.79, 1.22] Agreeableness ROS 0.95[0.89, 1.00] -0.01[-0.06, 0.06] 0.000[-0.05, 0.06] 0.97[0.86, 1.09] 1.03[0.90, 1.16] 1.04[0.92, 1.17] -0.03[-0.08, 0.01] 0.01[-0.04, 0.05] 0.02[-0.03, 0.07] 1.08[0.89, 1.32] 1.00[0.90, 1.13] EAS 0.96[0.90, 1.02] 0.01[-0.08, 0.11] 1.06[0.87, 1.41] 1.07[0.82, 1.37] WUSM-MAP 0.95[0.89, 1.00] -0.05[-0.13, 0.01] -0.03[-0.10, 0.03] 0.93[0.83, 1.04] 1.71[0.48, 25.10] 1.12[0.97, 1.32] -0.000[-0.04, 0.04] -0.00[-0.05, 0.04] 0.01[-0.04, 0.06] 0.81[0.51, 1.11] 0.95[0.83, 1.09] SATSA 0.98[0.92, 1.09] HRS 0.96[0.93, 0.99] LISS 0.97[0.90, 1.08] GSOEP 0.96[0.89, 1.03] Overall 0.96[0.92, 1.01] -0.02[-0.13, 0.09] -0.02[-0.29, 0.22] 0.99[0.76, 1.37] 1.15[0.42, 3.24] 1.09[0.61, 1.74] -0.01[-0.19, 0.16] 0.00[-0.32, 0.20] -0.00[-0.38, 0.17] 1.00[0.61, 1.62] 0.98[0.68, 1.50] Conscientiousness ROS 0.86[0.81, 0.91] -0.05[-0.10, -0.000] 0.06[0.00, 0.12] 0.93[0.83, 1.03] 1.02[0.92, 1.14] 1.07[0.96, 1.17] -0.02[-0.06, 0.02] 0.02[-0.02, 0.06] -0.02[-0.06, 0.03] 1.00[0.84, 1.18] 1.03[0.94, 1.13] Rush-MAP 0.86[0.82, 0.92] -0.05[-0.11, 0.00] 0.04[-0.01, 0.11] 0.93[0.83, 1.04] 0.99[0.88, 1.13] 1.10[0.98, 1.23] 0.02[-0.03, 0.07] 0.01[-0.04, 0.04] -0.03[-0.08, 0.02] 1.05[0.90, 1.28] 1.00[0.91, 1.11] EAS 0.87[0.82, 0.94] -0.05[-0.14, 0.02] 0.93[0.76, 1.12] 1.14[0.93, 1.49] WUSM-MAP 0.86[0.82, 0.92] -0.03[-0.09, 0.03] -0.01[-0.08, 0.06] 1.06[0.94, 1.20] 1.69[0.64, 13.03] 0.96[0.84, 1.09] -0.001[-0.03, 0.03] 0.01[-0.03, 0.05] -0.02[-0.06, 0.02] 0.97[0.75, 1.18] 0.98[0.88, 1.10] SATSA 0.86[0.81, 0.93] HRS 0.85[0.82, 0.88] LISS 0.86[0.78, 0.93] GSOEP 0.86[0.81, 0.93] Overall 0.86[0.83, 0.90] -0.05[-0.14, 0.02] 0.03[-0.07, 0.14] 0.99[0.81, 1.32] 1.01[0.64, 1.92] 1.05[0.83, 1.35] 0.00[-0.05, 0.07] 0.02[-0.06, 0.13] -0.02[-0.09, 0.04] 1.05[0.85, 1.35] 1.01[0.87, 1.21] Neuroticism ROS 1.12[1.06, 1.17] 0.01[-0.04, 0.06] -0.02[-0.06, 0.03] 1.01[0.91, 1.10] 1.00[0.91, 1.09] 1.00[0.92, 1.08] 0.02[-0.01, 0.05] -0.01[-0.05, 0.03] 0.01[-0.02, 0.05] 1.04[0.91, 1.19] 1.01[0.90, 1.10] Rush-MAP 1.12[1.07, 1.18] 0.04[-0.01, 0.10] -0.03[-0.08, 0.01] 1.06[0.96, 1.21] 0.96[0.87, 1.06] 0.98[0.90, 1.07] 0.01[-0.03, 0.04] 0.02[-0.02, 0.06] -0.00[-0.05, 0.03] 1.07[0.93, 1.23] 1.06[0.97, 1.16] EAS 1.11[1.03, 1.16] -0.02[-0.10, 0.07] 0.95[0.75, 1.12] 1.02[0.82, 1.21] WUSM-MAP 1.12[1.07, 1.18] 0.11[0.04, 0.19] 0.01[-0.04, 0.06] 1.02[0.91, 1.14] 1.57[0.64, 9.92] 0.99[0.88, 1.13] 0.02[-0.01, 0.06] 0.01[-0.03, 0.06] 0.03[-0.03, 0.08] 0.99[0.79, 1.19] 1.04[0.93, 1.18] SATSA 1.11[1.03, 1.17] HRS 1.13[1.10, 1.16] LISS 1.11[1.02, 1.19] GSOEP 1.11[1.05, 1.17] Overall 1.12[1.07, 1.16] 0.04[-0.11, 0.31] -0.01[-0.11, 0.09] 1.00[0.77, 1.16] 1.13[0.67, 2.31] 0.99[0.85, 1.13] 0.02[-0.05, 0.09] 0.01[-0.07, 0.08] 0.01[-0.07, 0.10] 1.03[0.87, 1.21] 1.03[0.88, 1.20] Openness to Experience ROS 0.93[0.85, 0.99] -0.01[-0.07, 0.06] -0.02[-0.07, 0.04] 1.08[0.95, 1.24] 0.99[0.87, 1.12] 0.91[0.80, 1.02] -0.03[-0.07, 0.01] -0.02[-0.07, 0.03] -0.07[-0.12, -0.03] 1.01[0.84, 1.23] 1.01[0.90, 1.14] EAS 0.97[0.91, 1.09] -0.02[-0.11, 0.07] 1.02[0.80, 1.26] 1.04[0.82, 1.33] WUSM-MAP 0.96[0.90, 1.03] -0.03[-0.09, 0.04] -0.01[-0.07, 0.05] 0.98[0.87, 1.10] 1.86[0.43, 36.27] 0.95[0.83, 1.10] -0.01[-0.05, 0.03] -0.03[-0.08, 0.02] -0.01[-0.06, 0.04] 1.01[0.79, 1.30] 1.00[0.88, 1.15] SATSA 0.94[0.87, 1.01] HRS 0.95[0.92, 0.98] LISS 0.96[0.87, 1.10] GSOEP 0.93[0.85, 0.99] Overall 0.95[0.90, 1.00] -0.02[-0.13, 0.08] -0.03[-0.21, 0.15] 1.03[0.77, 1.32] 1.09[0.37, 3.15] 0.94[0.69, 1.43] -0.03[-0.26, 0.12] -0.06[-0.19, 0.15] -0.05[-0.42, 0.25] 1.03[0.75, 1.50] 1.02[0.76, 1.39] Positive Affect ROS 0.96[0.90, 1.07] 0.00[-0.12, 0.09] 0.02[-0.06, 0.11] 1.01[0.81, 1.19] 1.03[0.89, 1.18] 1.00[0.82, 1.14] 0.00[-0.05, 0.05] 0.03[-0.03, 0.11] -0.02[-0.11, 0.04] 1.07[0.80, 1.52] 1.12[0.95, 1.63] Rush-MAP 0.94[0.91, 0.99] -0.01[-0.05, 0.02] 0.01[-0.02, 0.04] 0.97[0.90, 1.03] 1.04[0.98, 1.10] 1.04[0.98, 1.11] 0.01[-0.01, 0.03] 0.02[-0.01, 0.04] -0.001[-0.03, 0.02] 1.06[0.94, 1.20] 1.02[0.96, 1.08] SATSA 0.94[0.89, 1.01] HRS 0.93[0.90, 0.95] LISS 0.91[0.81, 1.01] GSOEP 0.90[0.82, 0.96] Overall 0.93[0.87, 0.99] -0.05[-0.36, 0.18] 0.00[-0.26, 0.17] 1.01[0.67, 1.45] 1.07[0.80, 1.83] 1.02[0.74, 1.45] 0.01[-0.15, 0.15] 0.03[-0.12, 0.19] -0.01[-0.18, 0.18] 1.09[0.72, 1.70] 1.05[0.71, 1.54] Negative Affect Rush-MAP 1.06[0.98, 1.15] 0.03[-0.03, 0.08] -0.03[-0.08, 0.02] 0.99[0.88, 1.11] 0.97[0.88, 1.07] 0.98[0.88, 1.08] 0.02[-0.02, 0.05] 0.02[-0.02, 0.06] 0.02[-0.02, 0.06] 0.95[0.79, 1.12] 1.05[0.96, 1.16] SATSA 1.09[1.02, 1.17] HRS 1.19[1.15, 1.23] LISS 1.15[0.97, 1.33] GSOEP 1.22[1.11, 1.35] Overall 1.14[1.00, 1.27] -0.11[-1.65, 1.09] -0.09[-1.26, 1.01] 1.04[0.33, 3.79] 1.02[0.26, 4.16] 1.14[0.24, 4.75] 0.00[-1.30, 1.12] -0.01[-1.28, 1.19] -0.08[-1.32, 1.09] 1.16[0.26, 8.64] 1.03[0.26, 4.26] Satisfaction with Life ROS 0.95[0.85, 1.07] 0.02[-0.07, 0.11] 0.03[-0.05, 0.13] 1.08[0.93, 1.28] 0.91[0.73, 1.07] 1.02[0.84, 1.20] 0.01[-0.04, 0.06] -0.00[-0.09, 0.07] -0.04[-0.12, 0.03] 0.38[0.02, 1.08] 1.11[0.95, 1.27] Rush-MAP 0.92[0.86, 0.98] -0.00[-0.05, 0.05] -0.01[-0.06, 0.03] 1.02[0.93, 1.14] 0.99[0.92, 1.10] 1.13[1.03, 1.25] 0.02[-0.01, 0.05] 0.02[-0.02, 0.06] 0.00[-0.04, 0.04] 0.99[0.83, 1.14] 1.12[1.02, 1.22] SATSA 0.98[0.93, 1.04] HRS 0.94[0.91, 0.96] LISS 0.89[0.75, 1.00] GSOEP 0.88[0.81, 0.95] Overall 0.93[0.85, 1.01] 0.01[-0.29, 0.31] -0.00[-0.26, 0.23] 1.05[0.78, 1.47] 1.15[0.69, 2.22] 1.10[0.74, 2.08] 0.02[-0.20, 0.20] 0.001[-0.35, 0.35] 0.00[-0.28, 0.28] 0.79[0.40, 2.17] 1.22[0.85, 1.90] Note: Shared covariates with prediction interval adjusted models Include age, gender, education, smoking status, alcohol use, and prediction interval. 4.0.1.3 Heterogeneity Estimates 4.0.1.4 All Model Terms ipd_mod_tab &lt;- nested_mega %&gt;% select(-one_of(c(&quot;n&quot;, &quot;rx&quot;))) %&gt;% unnest(fx) %&gt;% # keep key terms # mark significance and prettify trait, outcome, and covariate names left_join( outcomes %&gt;% select(Outcome = short_name, link) ) %&gt;% mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;), Trait = factor(Trait, traits$short_name), Outcome = factor(Outcome, outcomes$short_name, outcomes$long_name), Moderator = factor(Moderator, moders$short_name, moders$long_name), Covariate = factor(Covariate, covars$short_name, str_wrap(covars$long_name, 15)) ) %&gt;% mutate_at(vars(estimate, conf.low, conf.high), ~ifelse(link == &quot;factor&quot;, exp(.), .)) %&gt;% # format values as text, combine estimates and CI&#39;s, bold significance mutate_at(vars(estimate, conf.low, conf.high), ~ifelse(abs(.) &lt; .01, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))) %&gt;% mutate(est = sprintf(&quot;%s&lt;br&gt;[%s, %s]&quot;, estimate, conf.low, conf.high), est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;&lt;strong&gt;%s&lt;/strong&gt;&quot;, est), est)) %&gt;% # mutate(est = sprintf(&quot;%s [%s, %s]&quot;, estimate, conf.low, conf.high), # est = ifelse(sig == &quot;sig&quot;, sprintf(&quot;\\\\textbf{%s}&quot;, est), est)) %&gt;% # final reshaping, remove extra columns, arrange values, and change to wide format select(-estimate, -conf.low, -conf.high, -sig) %&gt;% arrange(Outcome, Trait, Moderator, Covariate) %&gt;% pivot_wider(names_from = &quot;Trait&quot;, values_from = &quot;est&quot;) ipd_mod_tab_fun &lt;- function(d, out, moder, cov, link){ md &lt;- mapvalues(moder, moders$long_name, moders$short_name, warn_missing = F) o &lt;- mapvalues(out, outcomes$long_name, outcomes$short_name, warn_missing = F) cv &lt;- mapvalues(cov, str_wrap(covars$long_name, 15), covars$short_name, warn_missing = F) cs &lt;- rep(1,9) names(cs) &lt;- c(&quot; &quot;, paste0(&quot;&lt;strong&gt;&quot;, traits$long_name, &quot;&lt;/strong&gt;&quot;)) # cln &lt;- if(length(unique(d$term2)) == 1) c(&quot;Covariate&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) else c(&quot; &quot;, &quot;Term&quot;, rep(&quot;\\\\textit{b} [CI]&quot;, 5)) lnk &lt;- if(link == &quot;factor&quot;) &quot;&lt;em&gt;OR&lt;/em&gt; [CI]&quot; else &quot;&lt;em&gt;b&lt;/em&gt; [CI]&quot; cln &lt;- c(&quot;Term&quot;, rep(lnk, 8)) al &lt;- c(&quot;r&quot;, rep(&quot;c&quot;, 8)) # caption cap &lt;- if(md == &quot;none&quot;) sprintf(&quot;All %s Model Estimates of Fixed Effect Personality-Dementia Diagnosis / Neuropathology Associations&quot;, cov) else sprintf(&quot;All %s Model Estimates of Fixed Effect %s Moderation of Personality-Crystallized Domain Associations&quot;, cov, md) fn &lt;- mapvalues(cov, str_wrap(covars$long_name, 15), covars$desc, warn_missing = F) # kable the table tab &lt;- d %&gt;% arrange(term) %&gt;% kable(., &quot;html&quot; # kable(., &quot;latex&quot; , booktabs = T , escape = F , col.names = cln , align = al , caption = cap ) %&gt;% kable_classic(full_width = F, html_font = &quot;Times New Roman&quot;) %&gt;% # kable_styling(full_width = F, font_size = 7) %&gt;% add_header_above(cs, escape = F) %&gt;% footnote(fn) # save the resulting html table save_kable(tab, file = sprintf(&quot;%s/results/tables/all-terms/%s_%s_%s.html&quot; , local_path, o, md, cv)) return(tab) # return the html table } ipd_mod_tab &lt;- ipd_mod_tab %&gt;% group_by(Outcome, Moderator, Covariate, link) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(tab = pmap(list(data, Outcome, Moderator, Covariate, link), ipd_mod_tab_fun)) (ipd_mod_tab %&gt;% filter(Covariate == &quot;Shared\\nCovariates\\nAdjusted (With\\nPrediction\\nInterval)&quot;))$tab[[1]] Table 4.3: All Shared Covariates Adjusted (With Prediction Interval) Model Estimates of Fixed Effect Personality-Dementia Diagnosis / Neuropathology Associations Extraversion Agreeableness Conscientiousness Neuroticism Openness to Experience Positive Affect Negative Affect Satisfaction with Life Term OR [CI] OR [CI] OR [CI] OR [CI] OR [CI] OR [CI] OR [CI] OR [CI] (Intercept) 0.01[0.004, 0.04] 0.01[0.004, 0.04] 0.03[0.01, 0.08] 0.006[0.002, 0.02] 0.01[0.004, 0.04] 0.03[0.008, 0.09] 0.007[0.002, 0.02] 0.03[0.007, 0.08] age 1.11[1.10, 1.11] 1.11[1.10, 1.11] 1.11[1.10, 1.11] 1.11[1.10, 1.12] 1.10[1.10, 1.11] 1.10[1.09, 1.10] 1.10[1.10, 1.11] 1.10[1.09, 1.10] alcohol1 0.76[0.68, 0.85] 0.76[0.68, 0.85] 0.76[0.68, 0.85] 0.76[0.68, 0.85] 0.77[0.69, 0.87] 0.79[0.70, 0.88] 0.77[0.68, 0.88] 0.79[0.71, 0.89] cor__(Intercept).p_value 1.03[0.39, 2.59] 0.76[0.38, 2.40] 0.94[0.39, 2.54] 1.08[0.40, 2.61] 0.98[0.39, 2.52] 1.33[0.44, 2.66] 0.72[0.40, 1.78] 1.06[0.42, 2.39] education 0.95[0.93, 0.96] 0.94[0.93, 0.96] 0.95[0.94, 0.97] 0.95[0.94, 0.97] 0.95[0.93, 0.96] 0.94[0.92, 0.95] 0.95[0.93, 0.96] 0.94[0.92, 0.95] gender1 1.01[0.92, 1.11] 1.03[0.92, 1.16] 1.02[0.92, 1.13] 0.97[0.87, 1.07] 1.00[0.90, 1.11] 1.01[0.89, 1.13] 0.94[0.83, 1.06] 1.01[0.89, 1.14] interval 1.13[1.12, 1.15] 1.12[1.10, 1.13] 1.13[1.12, 1.15] 1.13[1.12, 1.15] 1.12[1.10, 1.14] 1.08[1.05, 1.10] 1.10[1.07, 1.12] 1.07[1.05, 1.10] p_value 0.95[0.92, 0.99] 0.96[0.92, 1.01] 0.86[0.83, 0.90] 1.12[1.07, 1.16] 0.95[0.90, 1.00] 0.93[0.87, 0.99] 1.14[1.00, 1.27] 0.93[0.85, 1.01] sd__(Intercept) 3.88[2.15, 11.25] 4.38[2.25, 15.03] 3.57[2.05, 9.51] 3.79[2.17, 10.53] 4.18[2.24, 13.67] 3.94[1.88, 17.02] 3.88[1.96, 16.01] 3.93[1.87, 19.73] sd__p_value 1.03[1.00, 1.10] 1.03[1.00, 1.11] 1.03[1.00, 1.09] 1.02[1.00, 1.08] 1.04[1.00, 1.14] 1.05[1.00, 1.17] 1.11[1.03, 1.32] 1.08[1.01, 1.24] smokes1 1.12[1.02, 1.24] 1.12[1.00, 1.25] 1.07[0.96, 1.20] 1.11[1.00, 1.23] 1.12[1.00, 1.26] 1.03[0.92, 1.16] 1.04[0.93, 1.18] 1.05[0.94, 1.18] Note: Shared covariates with prediction interval adjusted models Include age, gender, education, smoking status, alcohol use, and prediction interval. 4.0.2 Figures Next, let’s make figures. These will include 4 kinds: “Forest Plots” over overall associations (and credible intervals) across traits, moderators, covariates, and outcomes Sample-Specific Forest Plots (or true forest plots) of sample-specific and overall associations across traits, moderators, outcomes, and covariates Overall Simple Slopes or figures showing the associations across levels of the moderators Sample-Specific Simple Slopes or figures showing the associations across levels of the moderators for each sample 4.0.2.1 Overall Forest fx_forest_fun &lt;- function(df, outcome, mod, cov, link){ print(paste(outcome, mod)) m &lt;- mapvalues(mod, moders$long_name, moders$short_name, warn_missing = F) d &lt;- round(max(abs(min(df$estimate)), abs(max(df$estimate))), 3) # stds &lt;- unique(df$study) lim &lt;- if(link == &quot;factor&quot;) c(.75, 1.25) else c(-1*round(2*d,2), round(2*d, 2)) brk &lt;- if(link == &quot;factor&quot;) c(.75, 1, 1.25) else { if(d &gt; .01) round(1.75*d,2) else round(1.75*d,3) }; brk &lt;- c(-1*brk, 0, brk) lim_high &lt;- if(link == &quot;factor&quot;) lim[2]*2 else lim[2]*4 lab &lt;- str_replace(brk, &quot;^0.&quot;, &quot;.&quot;)#str_remove(round(c(0-d-(d/5), 0, 0+d+(d/5)),2), &quot;^0&quot;) shapes &lt;- c(15, 16, 17, 18)[1:length(unique(df$term))] lt &lt;- rep(&quot;solid&quot;, length(unique(df$term))) titl &lt;- if(mod == &quot;None&quot;){&quot;Main Effects&quot;} else {sprintf(&quot;Personality x %s&quot;, mod)} leg &lt;- if(length(unique(df$term)) &gt; 1){&quot;bottom&quot;} else {&quot;none&quot;} trm &lt;- if(mod != &quot;None&quot;) paste(&quot;Personality x&quot;, unique(df$term[!is.na(df$term)])) else &quot;Main Effects&quot; df &lt;- df %&gt;% full_join(tibble(Trait = &quot; &quot;, estimate = NA, n = NA)) df &lt;- df %&gt;% arrange(estimate) trts &lt;- df$Trait[!df$Trait %in% c(&quot; &quot;)] labs &lt;- if(link == &quot;factor&quot;) &quot;OR [CI]&quot; else &quot;b [CI]&quot; yint &lt;- if(link == &quot;factor&quot;) 1 else 0 df &lt;- df %&gt;% mutate_at(vars(estimate, conf.low, conf.high), lst(f = ~ifelse(abs(.) &lt; .001, sprintf(&quot;%.4f&quot;, .), ifelse(abs(.) &lt; .01, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))))) %&gt;% mutate(Trait = factor(Trait, rev(c(&quot; &quot;, trts)))#Trait = factor(Trait, rev(c(&quot; &quot;, traits$short_name)), rev(c(&quot; &quot;, traits$short_name))) , lb = ifelse(conf.low &lt; lim[1], &quot;lower&quot;, &quot;no&quot;) , ub = ifelse(conf.high &gt; lim[2], &quot;upper&quot;, &quot;no&quot;) , conf.low2 = ifelse(conf.low &lt; lim[1], lim[1], conf.low) , conf.high2 = ifelse(conf.high &gt; lim[2], lim[2], conf.high) , est = ifelse(Trait != &quot; &quot;, sprintf(&quot;%s [%s, %s]&quot;, estimate_f, conf.low_f, conf.high_f), &quot;&quot;) ) %&gt;% arrange(Trait) p1 &lt;- df %&gt;% ggplot(aes(x = Trait, y = estimate)) + geom_errorbar(aes(ymin = conf.low2, ymax = conf.high2) , position = &quot;dodge&quot; , width = 0) + geom_point(aes(shape = term, size = term)) + geom_segment(data = df %&gt;% filter(lb == &quot;lower&quot;) , aes(y = conf.high2, yend = conf.low2, xend = Trait) , arrow = arrow(type = &quot;closed&quot;, length = unit(0.1, &quot;cm&quot;))) + geom_segment(data = df %&gt;% filter(ub == &quot;upper&quot;) , aes(y = conf.low2, yend = conf.high2, xend = Trait) , arrow = arrow(type = &quot;closed&quot;, length = unit(0.1, &quot;cm&quot;))) + geom_hline(aes(yintercept = yint), linetype = &quot;dashed&quot;, size = .5) + geom_vline(aes(xintercept = length(trts) + .5)) + annotate(&quot;rect&quot;, xmin = length(trts) + .6, xmax = Inf, ymin = -Inf, ymax = Inf, fill = &quot;white&quot;) + annotate(&quot;text&quot;, label = labs, x = length(trts) + .75, y = lim_high*.75, hjust = .5, vjust = 0, fontface = 2, size = 3) + annotate(&quot;text&quot;, label = trm, x = length(trts) + .75, y = 0, hjust = .5, vjust = 0, fontface = 2, size = 3) + geom_text(aes(y = lim_high*.75, label = est), size = 3.5) + scale_y_continuous(limits = c(lim[1], lim_high), breaks = brk, labels = lab) + scale_size_manual(values = c(3,2)) + scale_shape_manual(values = c(15, 16)) + labs(x = NULL , y = &quot;Estimate&quot; # , title = meth ) + coord_flip() + theme_classic() + theme(legend.position = &quot;none&quot; , axis.text = element_text(face = &quot;bold&quot;) , axis.title = element_text(face = &quot;bold&quot;) , plot.title = element_text(face = &quot;bold&quot;, hjust = .5) , axis.ticks.y = element_blank() , axis.line.y = element_blank() , axis.line.x.top = element_line(size = 1) # , panel.background = element_rect(fill = &quot;transparent&quot;, colour = NA) # , plot.background = element_rect(fill = &quot;transparent&quot;, colour = NA) ) my_theme &lt;- function(...) { theme_classic() + theme(plot.title = element_text(face = &quot;italic&quot;)) } title_theme &lt;- calc_element(&quot;plot.title&quot;, my_theme()) ttl &lt;- ggdraw() + draw_label( str_wrap(outcome, 50), fontfamily = title_theme$family, fontface = title_theme$face, size = title_theme$size-2 ) p &lt;- cowplot::plot_grid(ttl, p1, rel_heights = c(.15, .85), nrow = 2) return(p) } nested_ipd_fx_fig &lt;- nested_mega %&gt;% select(-rx, -n) %&gt;% unnest(fx) %&gt;% left_join( outcomes %&gt;% select(Outcome = short_name, link) ) %&gt;% mutate_at(vars(estimate, conf.low, conf.high), ~ifelse(link == &quot;factor&quot;, exp(.), .)) %&gt;% filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;) | (Moderator != &quot;none&quot; &amp; grepl(&quot;p_value:&quot;, term) &amp; !grepl(&quot;p_value:study&quot;, term) &amp; !(grepl(&quot;cor_&quot;, term) | grepl(&quot;sd_&quot;, term)))) %&gt;% mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;), Outcome = factor(Outcome, outcomes$short_name, outcomes$long_name), Covariate = factor(Covariate, covars$short_name, str_wrap(covars$long_name, 15)), term = str_remove_all(term, &quot;p_value:&quot;), term = str_to_title(str_remove_all(term, &quot;[0-9]&quot;)), # term = factor(term, c(covars$short_term, moders$short_term, stdyModers$short_term), # c(covars$long_term, moders$long_term, stdyModers$long_term)), Moderator = factor(Moderator, moders$short_name, moders$long_name)) %&gt;% group_by(Moderator, Covariate, Outcome, link) %&gt;% nest() %&gt;% ungroup() %&gt;% # filter(Covariate == &quot;Shared\\nCovariates\\nAdjusted&quot; &amp; Moderator == &quot;None&quot;) %&gt;% mutate(p = pmap(list(data, Outcome, Moderator, Covariate, link), fx_forest_fun)) fx_forest_comb_fun &lt;- function(d, mod, cov){ m &lt;- mapvalues(mod, moders$long_name, moders$short_name, warn_missing = F) cv &lt;- mapvalues(cov, str_wrap(covars$long_name, 15), covars$short_name, warn_missing = F) # d &lt;- d %&gt;% mutate(Outcome = factor(Outcome, outcomes$short_name, outcomes$long_name)) p1 &lt;- plot_grid(plotlist = d$p , nrow = ceiling(nrow(d)/3)) titl &lt;- if(mod == &quot;None&quot;) &quot;Personality-Dementia and Neuropathology Associations&quot; else sprintf(&quot;%s Moderators of Personality-Dementia and Neuropathology Associations&quot;, mod) titl &lt;- str_wrap(paste(cov, titl), 60) my_theme &lt;- function(...) { theme_classic() + theme(plot.title = element_text(face = &quot;bold&quot;)) } title_theme &lt;- calc_element(&quot;plot.title&quot;, my_theme()) ttl &lt;- ggdraw() + draw_label( titl, fontfamily = title_theme$family, fontface = title_theme$face, size = title_theme$size-1 ) p &lt;- cowplot::plot_grid(ttl, p1, rel_heights = c(.1, .9), nrow = 2) ht &lt;- nrow(d)/3 ggsave(file = sprintf(&quot;%s/results/figures/overall-forest/%s_%s.png&quot;, local_path, m, cv) , width = 12, height = ht*3) ggsave(file = sprintf(&quot;%s/results/figures/overall-forest/%s_%s.pdf&quot;, local_path, m, cv) , width = 12, height = ht*3) rm(p) gc() return(T) } nested_ipd_fx_fig2 &lt;- nested_ipd_fx_fig %&gt;% arrange(Moderator, Covariate, Outcome) %&gt;% group_by(Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(p = pmap(list(data, Moderator, Covariate), fx_forest_comb_fun)) knitr::include_graphics(&quot;https://github.com/emoriebeck/personality-dementia-neuropath/raw/master/results/figures/overall-forest/none_sharedint.png&quot;) 4.0.2.2 Study-Specific Forest ipd_rx_plot_fun &lt;- function(df, outcome, mod, cov, trait){ print(paste(outcome, mod)) trt &lt;- mapvalues(trait, traits$short_name, traits$long_name) m &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) d &lt;- round(max(abs(min(df$estimate)), abs(max(df$estimate))), 3) # stds &lt;- unique(df$study) lim &lt;- c(0-d-(d/2.5), 0+d+(d/2.5)) brk &lt;- round(c(0-d-(d/5), 0, 0+d+(d/5)),2) lab &lt;- str_remove(round(c(0-d-(d/5), 0, 0+d+(d/5)),2), &quot;^0&quot;) shapes &lt;- c(15, 16, 17, 18)[1:length(unique(df$term))] lt &lt;- rep(&quot;solid&quot;, length(unique(df$term))) titl &lt;- if(mod == &quot;none&quot;){trt} else {sprintf(&quot;%s x %s&quot;, trt, m)} leg &lt;- if(length(unique(df$term)) &gt; 1){&quot;bottom&quot;} else {&quot;none&quot;} df &lt;- df %&gt;% full_join(tibble(study = &quot; &quot;, estimate = NA, n = NA)) df &lt;- df %&gt;% arrange(estimate) stds &lt;- df$study[!df$study %in% c(&quot;Overall&quot;, &quot; &quot;)] df &lt;- df %&gt;% mutate(study = factor(study, rev(c(&quot; &quot;, stds, &quot;Overall&quot;))) # , conf.low = ifelse(conf.low &lt; lim[1], lim[1], conf.low) # , conf.high = ifelse(conf.high &gt; lim[2], lim[2], conf.high) , lb = ifelse(conf.low &lt; lim[1], &quot;lower&quot;, &quot;no&quot;) , ub = ifelse(conf.high &gt; lim[2], &quot;upper&quot;, &quot;no&quot;) , conf.low2 = ifelse(conf.low &lt; lim[1], lim[1], conf.low) , conf.high2 = ifelse(conf.high &gt; lim[2], lim[2], conf.high) , n = ifelse(study == &quot;Overall&quot;, sum(n, na.rm = T), n) # , study = factor(study, levels = str_remove_all(c(&quot;Overall&quot;, studies_long), &quot;-&quot;), labels = c(&quot;Overall&quot;, studies_long)) # Trait = factor(Trait, levels = traits$short_name, labels = traits$long_name), , type = ifelse(study == &quot;Overall&quot;, &quot;fixed&quot;, &quot;random&quot;)) p1 &lt;- df %&gt;% ggplot(aes(x = study, y = estimate)) + # geom_errorbar(data = df %&gt;% filter(ub != &quot;upper&quot;) # , aes(ymin = estimate, ymax = conf.high2) # , position = &quot;dodge&quot; # , width = .2) + # geom_errorbar(data = df %&gt;% filter(lb != &quot;lower&quot;) # , aes(ymin = conf.low2, ymax = estimate) # , position = &quot;dodge&quot; # , width = .2) + geom_point(data = df# %&gt;% filter(study != &quot;Overall&quot;) , aes(shape = term, size = n)) + # geom_point(data = df %&gt;% filter(study == &quot;Overall&quot;) # , aes(shape = term)) + geom_segment(data = df %&gt;% filter(lb != &quot;lower&quot;) , aes(y = conf.high2, yend = conf.low2, xend = study)) + geom_segment(data = df %&gt;% filter(ub != &quot;upper&quot;) , aes(y = conf.low2, yend = conf.high2, xend = study)) + geom_segment(data = df %&gt;% filter(lb == &quot;lower&quot;) , aes(y = conf.high2, yend = conf.low2, xend = study) , arrow = arrow(type = &quot;closed&quot;, length = unit(0.1, &quot;cm&quot;))) + geom_segment(data = df %&gt;% filter(ub == &quot;upper&quot;) , aes(y = conf.low2, yend = conf.high2, xend = study) , arrow = arrow(type = &quot;closed&quot;, length = unit(0.1, &quot;cm&quot;))) + geom_hline(aes(yintercept = 0), linetype = &quot;dashed&quot;, size = .5) + geom_vline(aes(xintercept = 1.5)) + geom_vline(aes(xintercept = length(stds) + 1.5)) + annotate(&quot;rect&quot;, xmin = length(stds) + 1.6, xmax = Inf, ymin = -Inf, ymax = Inf, fill = &quot;white&quot;) + scale_y_continuous(limits = lim, breaks = brk, labels = lab) + scale_size_continuous(range = c(2.5,5)) + scale_shape_manual(values = c(15, 16)) + labs(x = NULL , y = &quot;Estimate&quot; # , title = &quot; &quot; ) + coord_flip() + theme_classic() + theme(legend.position = &quot;none&quot; , axis.text = element_text(face = &quot;bold&quot;) , axis.title = element_text(face = &quot;bold&quot;) , plot.title = element_text(face = &quot;bold&quot;, hjust = .5) , axis.ticks.y = element_blank() , axis.line.y = element_blank() , axis.line.x.top = element_line(size = 1)) d2 &lt;- df %&gt;% mutate_at(vars(estimate, conf.low, conf.high) , ~ifelse(abs(.) &lt; .01, sprintf(&quot;%.3f&quot;, .), sprintf(&quot;%.2f&quot;, .))) %&gt;% mutate_at(vars(estimate, conf.low, conf.high), ~str_replace_all(., &quot;^0.&quot;, &quot;.&quot;)) %&gt;% mutate_at(vars(estimate, conf.low, conf.high), ~str_replace_all(., &quot;^-0.&quot;, &quot;-.&quot;)) %&gt;% mutate(est = ifelse(study != &quot; &quot;, sprintf(&quot;%s [%s, %s] &quot;, estimate, conf.low, conf.high), &quot;&quot;) , n = as.character(n) ) %&gt;% select(study, n, est) %&gt;% pivot_longer(cols = c(n, est), names_to = &quot;est&quot;, values_to = &quot;value&quot;) p2 &lt;- d2 %&gt;% ggplot(aes(x = study, y = est)) + geom_text(data = d2 %&gt;% filter(est == &quot;est&quot;), aes(label = value), hjust = .5, size = 3.5) + geom_text(data = d2 %&gt;% filter(est == &quot;n&quot;), aes(label = value), hjust = .5, size = 3.5) + annotate(&quot;text&quot;, label = &quot;b [CI]&quot;, x = length(stds) + 1.75, y = &quot;est&quot;, hjust = .5, vjust = 0) + annotate(&quot;text&quot;, label = &quot;N&quot;, x = length(stds) + 1.75, y = &quot;n&quot;, hjust = .5, vjust = 0) + geom_vline(aes(xintercept = 1.5)) + geom_vline(aes(xintercept = length(stds) + 1.5)) + coord_flip() + theme_void() + theme(plot.title = element_text(face = &quot;bold&quot;, hjust = 0) , axis.text = element_blank() , axis.ticks = element_blank() , axis.title = element_blank()) my_theme &lt;- function(...) { theme_classic() + theme(plot.title = element_text(face = &quot;italic&quot;)) } title_theme &lt;- calc_element(&quot;plot.title&quot;, my_theme()) ttl &lt;- ggdraw() + draw_label( titl, fontfamily = title_theme$family, fontface = title_theme$face, size = title_theme$size-2 ) p3 &lt;- cowplot::plot_grid(p1, p2 , rel_widths = c(.5, .5) , align = &quot;h&quot; ) # p &lt;- cowplot::plot_grid(ttl, subttl, p3, rel_heights = c(.05, .05, .9), nrow = 3) p &lt;- cowplot::plot_grid(ttl, p3, rel_heights = c(.05, .95), nrow = 2) gc() save(p , file = sprintf(&quot;%s/results/figures/study-specific-forest/rdata/%s_%s_%s_%s.RData&quot;, local_path, outcome, trait, mod, cov)) return(p) } ## fixed effects nested_reg_fp &lt;- nested_mega %&gt;% select(-rx, -n) %&gt;% unnest(fx) %&gt;% mutate(study = &quot;Overall&quot;) %&gt;% ## random effects full_join( nested_mega %&gt;% mutate(rx = map2(rx, n, ~(.x) %&gt;% full_join(.y))) %&gt;% select(-fx, -n) %&gt;% unnest(rx) %&gt;% rename(term = names) # mutate(term = ifelse(Moderator != &quot;none&quot;, paste(term, mapvalues(Moderator, moders$short_name, moders$short_term, warn_missing = F), sep = &quot;:&quot;), term)) ) %&gt;% ## filter key terms filter((Moderator == &quot;none&quot; &amp; term == &quot;p_value&quot;)| (Moderator != &quot;none&quot; &amp; grepl(&quot;^p_value:&quot;, term) &amp; !grepl(&quot;study&quot;, term))) %&gt;% ## significance mutate(sig = ifelse(sign(conf.low) == sign(conf.high), &quot;sig&quot;, &quot;ns&quot;) # , study = mapvalues(study, studies_long, studies_sp, warn_missing = F) ) %&gt;% ## grouping for plotting group_by(Outcome, Moderator, Covariate, Trait) %&gt;% nest() %&gt;% ungroup() %&gt;% # filter(Covariate != &quot;fully&quot; &amp; Outcome == &quot;dementia&quot;) %&gt;% mutate(p = pmap(list(data, Outcome, Moderator, Covariate, Trait), ipd_rx_plot_fun)) ipd_rx_plot_comb_fun &lt;- function(outcome, cov, mod, d){ o &lt;- mapvalues(outcome, outcomes$short_name, outcomes$long_name, warn_missing = F) cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) m &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) titl &lt;- paste(&quot;Prospective Associations Between Personality / Subjective Well-Being\\nand&quot;, o) if(mod != &quot;none&quot;) titl &lt;- paste(m, &quot;Moderators of&quot;, titl) p1 &lt;- plot_grid( d$p[[1]], d$p[[2]] , d$p[[3]], d$p[[4]] , d$p[[5]], d$p[[6]] , d$p[[7]], d$p[[8]] , nrow = 4 , ncol = 2 , axis = &quot;tblr&quot; , align = &quot;hv&quot; ) my_theme &lt;- function(...) { theme_classic() + theme(plot.title = element_text(face = &quot;bold&quot;)) } title_theme &lt;- calc_element(&quot;plot.title&quot;, my_theme()) ttl &lt;- ggdraw() + draw_label( titl, fontfamily = title_theme$family, fontface = title_theme$face, size = title_theme$size ) my_theme &lt;- function(...) { theme_classic() + theme(plot.subtitle = element_text(hjust = 0)) } subtitle_theme &lt;- calc_element(&quot;subplot.title&quot;, my_theme()) subttl &lt;- ggdraw() + draw_label( &quot;Pooled Regression Using Random Effects&quot;, fontfamily = subtitle_theme$family, fontface = subtitle_theme$face, size = subtitle_theme$size ) p &lt;- cowplot::plot_grid(ttl, subttl, p1, rel_heights = c(.06, .03, .91), nrow = 3) ggsave(p , file = sprintf(&quot;%s/results/figures/study-specific-forest/%s_%s_%s.png&quot;, local_path, outcome, mod, cov) , width = 10, height = 11) ggsave(p , file = sprintf(&quot;%s/results/figures/study-specific-forest/%s_%s_%s.pdf&quot;, local_path, outcome, mod, cov) , width = 10, height = 11) return(T) } nested_reg_fp %&gt;% mutate(Trait = factor(Trait, traits$short_name)) %&gt;% arrange(Trait) %&gt;% select(-data) %&gt;% group_by(Outcome, Moderator, Covariate) %&gt;% nest() %&gt;% ungroup() %&gt;% # filter(Covariate == &quot;shared&quot; &amp; Outcome == &quot;dementia&quot;) %&gt;% mutate(p = pmap( list(Outcome, Covariate, Moderator, data) , possibly(ipd_rx_plot_comb_fun, NA_real_) )) knitr::include_graphics(&quot;https://github.com/emoriebeck/personality-dementia-neuropath/raw/master/results/figures/study-specific-forest/dementia_none_sharedint.png&quot;) 4.0.2.3 Overall Simple Effects loadRData &lt;- function(fileName, cov, obj, folder){ #loads an RData file, and returns it path &lt;- sprintf(&quot;%s/results/%s/%s/%s&quot;, local_path, folder, cov, fileName) load(path) get(ls()[grepl(obj, ls())]) } ## load in &quot;fixed&quot; effects ## first get file names nested_mega_simp &lt;- tibble(Covariate = c(&quot;fully&quot;, &quot;shared&quot;, &quot;standard&quot;, &quot;butOne&quot;, &quot;unadjusted&quot;, &quot;shareddx&quot;, &quot;standarddx&quot;, &quot;sharedint&quot;)) %&gt;% mutate(file = map(Covariate, ~list.files(sprintf(&quot;%s/results/predicted/%s&quot;, local_path, .)))) %&gt;% unnest(file) %&gt;% separate(file, c(&quot;Outcome&quot;, &quot;Trait&quot;, &quot;Moderator&quot;), sep = &quot;_&quot;, remove = F) %&gt;% ## read in the files mutate(Moderator = str_remove(Moderator, &quot;.RData&quot;), pred.fx = map2(file, Covariate, ~loadRData(.x, .y, &quot;pred.fx&quot;, &quot;predicted&quot;)), pred.rx = map2(file, Covariate, ~loadRData(.x, .y, &quot;pred.rx&quot;, &quot;predicted&quot;))) %&gt;% select(-file) %&gt;% left_join( outcomes %&gt;% select(Outcome = short_name, link) ) %&gt;% mutate_at(vars(pred.fx, pred.rx), ~ifelse(link == &quot;factor&quot;, map(., ~(.) %&gt;% mutate_at(vars(pred, lower, upper), exp)), .)) nested_mega_simp ## # A tibble: 2,095 × 7 ## Covariate Outcome Trait Moderator pred.fx pred.rx link ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;chr&gt; ## 1 fully dementia A age &lt;tibble [303 × 5]&gt; &lt;tibble [606 × 6]&gt; factor ## 2 fully dementia A cognition &lt;tibble [303 × 5]&gt; &lt;tibble [606 × 6]&gt; factor ## 3 fully dementia A education &lt;tibble [303 × 5]&gt; &lt;tibble [606 × 6]&gt; factor ## 4 fully dementia A gender &lt;tibble [202 × 5]&gt; &lt;tibble [404 × 6]&gt; factor ## 5 fully dementia C education &lt;tibble [303 × 5]&gt; &lt;tibble [606 × 6]&gt; factor ## 6 fully dementia C gender &lt;tibble [202 × 5]&gt; &lt;tibble [404 × 6]&gt; factor ## 7 fully dementia E age &lt;tibble [303 × 5]&gt; &lt;tibble [606 × 6]&gt; factor ## 8 fully dementia E cognition &lt;tibble [303 × 5]&gt; &lt;tibble [606 × 6]&gt; factor ## 9 fully dementia E education &lt;tibble [303 × 5]&gt; &lt;tibble [606 × 6]&gt; factor ## 10 fully dementia E gender &lt;tibble [202 × 5]&gt; &lt;tibble [404 × 6]&gt; factor ## # ℹ 2,085 more rows simp_eff_fun &lt;- function(df, outcome, mod, cov, link){ print(paste(outcome, mod)) o &lt;- mapvalues(outcome, outcomes$short_name, outcomes$long_name, warn_missing = F) cv &lt;- cov# cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) m &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) dmini &lt;- round(min(df$pred),3); dmaxi = round(max(df$pred),3) d &lt;- round(max(abs(min(df$pred)), abs(max(df$pred))), 3) mini &lt;- if(link == &quot;factor&quot;) 0 else dmini - (dmaxi-dmini) maxi &lt;- dmaxi + (dmaxi-dmini) hl &lt;- if(link == &quot;factor&quot;) 1 else 0 brk &lt;- if(link == &quot;factor&quot;) c(round(mini*1.1,2), 1, round(maxi*.9,2)) else c(round(mini*1.1,2), 0, round(maxi*.9,2)) lab &lt;- if(link == &quot;factor&quot;) str_remove(c(round(mini*1.1,2), 1, round(maxi*.9,2)), &quot;^0&quot;) else str_remove(c(round(mini*1.1,2), 0, round(maxi*.9,2)), &quot;^0&quot;) # mini &lt;- if(link == &quot;factor&quot;) C1+(d+(d/5)) else 0+d+(d/5) lim &lt;- c(mini, maxi) # brk &lt;- if(link == &quot;factor&quot;) round(c(1-d-(d/10), 1, 1+d+(d/10)),2) else round(c(0-d-(d/10), 0, 0+d+(d/10)),2) # lab &lt;- if(link == &quot;factor&quot;) str_remove(c(round(1-d-(d/10),2), 1, round(1+d+(d/10),2)), &quot;^0&quot;) else{str_remove(c(round(0-d-(d/10),2), 0, round(0+d+(d/10),2)), &quot;^0&quot;)} titl &lt;- if(mod == &quot;none&quot;){o} else {sprintf(&quot;%s: Personality x %s Simple Effects&quot;, o, m)} lt &lt;- c(&quot;dotted&quot;, &quot;solid&quot;, &quot;dashed&quot;)[1:length(unique(df$mod_fac))] # if(link == &quot;factor&quot;) {mini &lt;- round(min(df$pred),2); maxi &lt;- round(max(df$pred),2)} else {mini &lt;- floor(min(df$pred)); maxi &lt;- ceiling(max(df$pred))} df %&gt;% mutate(Trait = factor(Trait, levels = traits$short_name, labels = traits$long_name), lower = ifelse(lower &lt; mini, mini, lower), upper = ifelse(upper &gt; maxi, maxi, upper)) %&gt;% ggplot(aes(x = p_value , y = pred , group = mod_fac)) + # ylim(c(mini, maxi)) + # scale_y_continuous(limits = lim#c(mini , maxi) # , breaks = round(seq(mini, maxi, length.out = 4),2) # , labels = round(seq(mini, maxi,length.out = 4), 2)) + scale_linetype_manual(values = lt) + geom_ribbon(aes(ymin = lower , ymax = upper , fill = mod_fac) , alpha = .25) + geom_hline(aes(yintercept = hl), linetype = &quot;dashed&quot;, size = .6, color = &quot;grey30&quot;) + geom_line(aes(linetype = mod_fac)) + labs(x = &quot;Personality (POMP)&quot; , y = if(link == &quot;factor&quot;) paste(o, &quot;(OR)&quot;) else paste(o, &quot;(POMP)&quot;) , title = str_wrap(titl, 40) , linetype = m , fill = m , subtitle = &quot;Pooled Regression Using Random Effects&quot;) + facet_wrap(~Trait, nrow = 3, scales = &quot;free&quot;) + theme_classic() + theme(legend.position = &quot;bottom&quot; , plot.title = element_text(face = &quot;bold&quot;, size = rel(1.2), hjust = .5) , plot.subtitle = element_text(size = rel(1.1), hjust = .5) , strip.background = element_rect(fill = &quot;black&quot;) , strip.text = element_text(face = &quot;bold&quot;, color = &quot;white&quot;) , axis.text = element_text(color = &quot;black&quot;)) ggsave(file = sprintf(&quot;%s/results/figures/overall-simple-effects/%s_%s_%s.png&quot;, local_path, outcome, mod, cov), width = 6, height = 6) } ipd_se_plot &lt;- nested_mega_simp %&gt;% filter(Moderator != &quot;dementia&quot;) %&gt;% select(-pred.rx) %&gt;% group_by(Outcome, Moderator, Covariate, link) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% unnest(pred.fx)), plot = pmap(list(data, Outcome, Moderator, Covariate, link), simp_eff_fun)) knitr::include_graphics(&quot;https://github.com/emoriebeck/personality-dementia-neuropath/raw/master/results/figures/overall-simple-effects/dementia_gender_sharedint.png&quot;) simp_eff_fun &lt;- function(df, outcome, mod, cov, link){ print(paste(outcome, mod)) o &lt;- mapvalues(outcome, outcomes$short_name, outcomes$long_name, warn_missing = F) cv &lt;- cov# cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) m &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) dmini &lt;- round(min(df$pred),3); dmaxi = round(max(df$pred),3) d &lt;- round(max(abs(min(df$pred)), abs(max(df$pred))), 3) mini &lt;- if(link == &quot;factor&quot;) 0 else dmini - (dmaxi-dmini) maxi &lt;- dmaxi + (dmaxi-dmini) hl &lt;- if(link == &quot;factor&quot;) 1 else 0 brk &lt;- if(link == &quot;factor&quot;) c(round(mini*1.1,2), 1, round(maxi*.9,2)) else c(round(mini*1.1,2), 0, round(maxi*.9,2)) lab &lt;- if(link == &quot;factor&quot;) str_remove(c(round(mini*1.1,2), 1, round(maxi*.9,2)), &quot;^0&quot;) else str_remove(c(round(mini*1.1,2), 0, round(maxi*.9,2)), &quot;^0&quot;) # mini &lt;- if(link == &quot;factor&quot;) C1+(d+(d/5)) else 0+d+(d/5) lim &lt;- c(mini, maxi) # brk &lt;- if(link == &quot;factor&quot;) round(c(1-d-(d/10), 1, 1+d+(d/10)),2) else round(c(0-d-(d/10), 0, 0+d+(d/10)),2) # lab &lt;- if(link == &quot;factor&quot;) str_remove(c(round(1-d-(d/10),2), 1, round(1+d+(d/10),2)), &quot;^0&quot;) else{str_remove(c(round(0-d-(d/10),2), 0, round(0+d+(d/10),2)), &quot;^0&quot;)} titl &lt;- if(mod == &quot;none&quot;){o} else {sprintf(&quot;%s: Personality x %s Simple Effects&quot;, o, m)} lt &lt;- c(&quot;dotted&quot;, &quot;solid&quot;, &quot;dashed&quot;)[1:length(unique(df$mod_fac))] # if(link == &quot;factor&quot;) {mini &lt;- round(min(df$pred),2); maxi &lt;- round(max(df$pred),2)} else {mini &lt;- floor(min(df$pred)); maxi &lt;- ceiling(max(df$pred))} df %&gt;% mutate(Trait = factor(Trait, levels = traits$short_name, labels = traits$long_name) , lower = ifelse(lower &lt; mini, mini, lower) , upper = ifelse(upper &gt; maxi, maxi, upper) # , dementia = factor(dementia, c(0,1), c(&quot;No&quot;, &quot;Yes&quot;)) ) %&gt;% ggplot(aes(x = pred , y = mod_fac)) + geom_errorbar(aes(xmin = lower, xmax = upper) , width = .1 , position = position_dodge(width = .9) ) + geom_point(aes(fill = Trait) , color = &quot;black&quot; , position = position_dodge(width = .9) , shape = 22 ) + xlim(c(mini, maxi)) + # scale_y_continuous(limits = lim#c(mini , maxi) # , breaks = round(seq(mini, maxi, length.out = 4),2) # , labels = round(seq(mini, maxi,length.out = 4), 2)) + # scale_linetype_manual(values = lt) + # geom_ribbon(aes(ymin = lower # , ymax = upper # , fill = mod_fac) # , alpha = .25) + # geom_hline(aes(yintercept = hl), linetype = &quot;dashed&quot;, size = .6, color = &quot;grey30&quot;) + # geom_line(aes(linetype = mod_fac)) + labs(y = &quot;Personality / SWB Rating (POMP)&quot; , x = if(link == &quot;factor&quot;) paste(o, &quot;(OR)&quot;) else paste(o, &quot;(POMP)&quot;) , title = str_wrap(titl, 40) , linetype = m , fill = m , subtitle = &quot;Pooled Regression Using Random Effects&quot;) + guides(fill = &quot;none&quot;) + facet_wrap(~Trait, nrow = 3, scales = &quot;free&quot;) + theme_classic() + theme(legend.position = &quot;bottom&quot; , plot.title = element_text(face = &quot;bold&quot;, size = rel(1.2), hjust = .5) , plot.subtitle = element_text(size = rel(1.1), hjust = .5) , strip.background = element_rect(fill = &quot;black&quot;) , strip.text = element_text(face = &quot;bold&quot;, color = &quot;white&quot;) , axis.text = element_text(color = &quot;black&quot;)) ggsave(file = sprintf(&quot;%s/results/figures/overall-simple-effects/%s_%s_%s.png&quot;, local_path, outcome, mod, cov), width = 6, height = 6) } ipd_se_plot_dx &lt;- nested_mega_simp %&gt;% filter(Moderator == &quot;dementia&quot; &amp; Outcome != Moderator) %&gt;% select(-pred.rx) %&gt;% group_by(Outcome, Moderator, Covariate, link) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(data = map(data, ~(.) %&gt;% unnest(pred.fx)), plot = pmap(list(data, Outcome, Moderator, Covariate, link), simp_eff_fun)) knitr::include_graphics(&quot;https://github.com/emoriebeck/personality-dementia-neuropath/raw/master/results/figures/overall-simple-effects/braak_dementia_sharedint.png&quot;) 4.0.2.4 Study-Specific Simple Effects ipd_std_se_plot_fun &lt;- function(df, outcome, trait, mod, cov, link){ fctr_vars &lt;- c(&quot;gender&quot;, &quot;smokes&quot;, &quot;alcohol&quot;, &quot;race&quot;, &quot;stroke&quot;, &quot;cancer&quot;, &quot;diabetes&quot;, &quot;heartProb&quot;, &quot;dementia&quot;) print(paste(outcome, mod)) o &lt;- mapvalues(outcome, outcomes$short_name, outcomes$long_name, warn_missing = F) trt &lt;- mapvalues(trait, traits$short_name, traits$long_name, warn_missing = F) cv &lt;- cov# cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) m &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) d &lt;- round(max(abs(min(df$pred)), abs(max(df$pred))), 3) titl &lt;- if(mod == &quot;none&quot;){sprintf(&quot;%s: %s&quot;, o, trt)} else {sprintf(&quot;%s: %s x %s Simple Effects&quot;, o, trt, m)} std &lt;- unique(df$study) cols &lt;- (stdcolors %&gt;% filter(studies_long %in% std))$colors lt &lt;- (stdcolors %&gt;% filter(studies_long %in% std))$lt ht &lt;- length(unique(df$mod_fac)) if(link == &quot;factor&quot;) {mini &lt;- round(min(df$pred),2); maxi &lt;- round(max(df$pred),2)} else {mini &lt;- floor(min(df$pred)); maxi &lt;- ceiling(max(df$pred))} df &lt;- df %&gt;% mutate(study = factor(study, levels = stdcolors$studies_long, labels = stdcolors$studies_long), lower = ifelse(lower &lt; mini, mini, lower), upper = ifelse(upper &gt; maxi, maxi, upper), gr = ifelse(study == &quot;Overall&quot;, &quot;Overall&quot;, &quot;study&quot;)) %&gt;% group_by(study, mod_fac, p_value, gr) %&gt;% summarize_at(vars(pred, lower, upper), mean) %&gt;% ungroup() p &lt;- df %&gt;% ggplot(aes(x = p_value , y = pred , group = study)) + scale_y_continuous(limits = c(mini,maxi) , breaks = round(seq(mini, maxi, length.out = 4), 2) , labels = round(seq(mini, maxi, length.out = 4), 2)) + scale_linetype_manual(values = lt) + scale_color_manual(values = cols) + scale_fill_manual(values = cols) + scale_size_manual(values = c(2,.8)) + geom_line(aes(linetype = study, color = study, size = gr)) + labs(x = &quot;Personality (POMP)&quot; , y = if(link == &quot;factor&quot;) paste(o, &quot;(OR)&quot;) else o , title = titl , linetype = &quot;Sample&quot; , color = &quot;Sample&quot; , fill = &quot;Sample&quot;) + guides(size = &quot;none&quot;, fill = &quot;none&quot;) + facet_wrap(~mod_fac, nrow = 1) + theme_classic() + theme(legend.position = &quot;bottom&quot; , plot.title = element_text(face = &quot;bold&quot;, size = rel(1.2), hjust = .5) , plot.subtitle = element_text(size = rel(1.1), hjust = .5) , strip.background = element_rect(fill = &quot;black&quot;) , strip.text = element_text(face = &quot;bold&quot;, color = &quot;white&quot;) , axis.text = element_text(color = &quot;black&quot;)) ggsave(p, file = sprintf(&quot;%s/results/figures/study-specific-simple-effects/%s_%s_%s_%s.png&quot;, local_path, outcome, trait, mod, cov), width = 3*ht, height = 5) return(p) } nested_simp_std_se &lt;- nested_mega_simp %&gt;% filter(Covariate != &quot;fully&quot; &amp; Moderator != &quot;dementia&quot;) %&gt;% mutate(pred.fx = map(pred.fx, ~(.) %&gt;% mutate(study = &quot;Overall&quot;)), comb.fx = map2(pred.fx, pred.rx, full_join)) %&gt;% select(-pred.fx, -pred.rx) %&gt;% # filter(Moderator %in% c(&quot;age&quot;, &quot;education&quot;)) %&gt;% mutate(pmap(list(comb.fx, Outcome, Trait, Moderator, Covariate, link), ipd_std_se_plot_fun)) knitr::include_graphics(&quot;https://github.com/emoriebeck/personality-dementia-neuropath/raw/master/results/figures/study-specific-simple-effects/dementia_C_age_sharedint.png&quot;) ipd_std_se_plot_fun &lt;- function(df, outcome, trait, mod, cov, link){ fctr_vars &lt;- c(&quot;gender&quot;, &quot;smokes&quot;, &quot;alcohol&quot;, &quot;race&quot;, &quot;stroke&quot;, &quot;cancer&quot;, &quot;diabetes&quot;, &quot;heartProb&quot;, &quot;dementia&quot;) print(paste(outcome, mod)) o &lt;- mapvalues(outcome, outcomes$short_name, outcomes$long_name, warn_missing = F) trt &lt;- mapvalues(trait, traits$short_name, traits$long_name, warn_missing = F) cv &lt;- cov# cv &lt;- mapvalues(cov, covars$short_name, covars$long_name, warn_missing = F) m &lt;- mapvalues(mod, moders$short_name, moders$long_name, warn_missing = F) d &lt;- round(max(abs(min(df$pred)), abs(max(df$pred))), 3) titl &lt;- if(mod == &quot;none&quot;){sprintf(&quot;%s: %s&quot;, o, trt)} else {sprintf(&quot;%s: %s x %s Simple Effects&quot;, o, trt, m)} std &lt;- unique(df$study) cols &lt;- (stdcolors %&gt;% filter(studies_long %in% std))$colors lt &lt;- (stdcolors %&gt;% filter(studies_long %in% std))$lt ht &lt;- length(unique(df$mod_fac)) # if(link == &quot;factor&quot;) {mini &lt;- round(min(df$pred),2); maxi &lt;- round(max(df$pred),2)} else {mini &lt;- floor(min(df$pred)); maxi &lt;- ceiling(max(df$pred))} if(link == &quot;factor&quot;) {mini &lt;- round(min(df$lower),2); maxi &lt;- round(max(df$upper),2)} else {mini &lt;- floor(min(df$lower)); maxi &lt;- ceiling(max(df$upper))} yint &lt;- if(link == &quot;factor&quot;) 1 else 0 df &lt;- df %&gt;% mutate(study = factor(study, levels = stdcolors$studies_long, labels = stdcolors$studies_long), lower = ifelse(lower &lt; mini, mini, lower), upper = ifelse(upper &gt; maxi, maxi, upper), gr = ifelse(study == &quot;Overall&quot;, &quot;Overall&quot;, &quot;study&quot;)) %&gt;% group_by(study, mod_fac, p_value, gr) %&gt;% summarize_at(vars(pred, lower, upper), mean) %&gt;% ungroup() ord &lt;- (df %&gt;% filter(mod_fac == &quot;M&quot; &amp; gr != &quot;Overall&quot;) %&gt;% arrange(desc(pred)))$study %&gt;% as.character() p &lt;- df %&gt;% # mutate(study = factor(study, c(&quot;Overall&quot;, ord))) %&gt;% ggplot(aes(y = mod_fac , x = pred , group = mod_fac)) + # scale_y_continuous(limits = c(mini,maxi) # , breaks = round(seq(mini, maxi, length.out = 4), 2) # , labels = round(seq(mini, maxi, length.out = 4), 2)) + scale_shape_manual(values = c(15, 22)) + scale_color_manual(values = cols) + # scale_fill_manual(values = cols) + scale_size_manual(values = c(4,3)) + scale_alpha_manual(values = c(1, .5)) + geom_vline(aes(xintercept = yint), linetype = &quot;dashed&quot;) + # scale_x_continuous( # limits = c(-.5, 1.5) # , breaks = c(0,1) # , labels = c(&quot;No&quot;, &quot;Yes&quot;) # ) + # geom_col( # aes(fill = study, alpha = gr) # , position = position_dodge(width = .9) # , color = &quot;black&quot; # # , alpha = .5 # ) + geom_errorbar( aes(xmin = lower, xmax = upper) , position = position_dodge(width = .9) , width = 0 , color = &quot;black&quot; ) + # geom_errorbar( # aes(ymin = lower, ymax = pred) # , position = position_dodge(width = .9) # , width = 0 # , color = &quot;white&quot; # ) + geom_point( aes(shape = gr, fill = study, size = gr) , position = position_dodge(width = .9) , color = &quot;black&quot; ) + labs(y = paste(trt, &quot;Score (%)&quot;) , x = if(link == &quot;factor&quot;) paste(&quot;Predicted Difference in&quot;, o, &quot;(OR)&quot;) else paste(&quot;Predicted Difference in&quot;, o) , title = titl) + guides(size = &quot;none&quot;, color = &quot;none&quot;, shape = &quot;none&quot;, fill = &quot;none&quot;) + facet_wrap(~study, nrow = 1) + theme_classic() + theme(legend.position = &quot;bottom&quot; , plot.title = element_text(face = &quot;bold&quot;, size = rel(1.2), hjust = .5) , plot.subtitle = element_text(size = rel(1.1), hjust = .5) , strip.background = element_rect(fill = &quot;black&quot;) , strip.text = element_text(face = &quot;bold&quot;, color = &quot;white&quot;) , axis.text = element_text(color = &quot;black&quot;) , panel.border = element_rect(color = &quot;black&quot;, fill = NA, size = 1)) ggsave(p, file = sprintf(&quot;%s/results/figures/study-specific-simple-effects/%s_%s_%s_%s.png&quot;, local_path, outcome, trait, mod, cov), width = 4*length(std), height = 5) return(p) } nested_simp_std_se_dx &lt;- nested_mega_simp %&gt;% filter(Covariate != &quot;fully&quot; &amp; Moderator == &quot;dementia&quot;) %&gt;% mutate(pred.fx = map(pred.fx, ~(.) %&gt;% mutate(study = &quot;Overall&quot;)), comb.fx = map2(pred.fx, pred.rx, full_join)) %&gt;% select(-pred.fx, -pred.rx) %&gt;% # filter(Moderator %in% c(&quot;age&quot;, &quot;education&quot;)) %&gt;% mutate(pmap(list(comb.fx, Outcome, Trait, Moderator, Covariate, link), ipd_std_se_plot_fun)) knitr::include_graphics(&quot;https://github.com/emoriebeck/personality-dementia-neuropath/raw/master/results/figures/study-specific-simple-effects/braak_C_dementia_sharedint.png&quot;) 4.0.2.5 Significant Forest Plots &amp; Simple Effects std_eff_comb_plot_fun &lt;- function(p1, p2, cov, out, trt, mod){ print(paste(cov, out, trt, mod)) ttl &lt;- (cowplot::get_title(p2))$children ttl &lt;- str_wrap(ttl[[1]]$label, 45); print(ttl) p2 &lt;- p2 + labs(title = ttl) rw &lt;- if(length(levels(p2$data$mod_fac)) == 3) c(.35, .65) else c(.4, .6) p &lt;- plot_grid(p1, p2 , rel_widths = rw , align = &quot;v&quot; , axis = &quot;tb&quot; , ncol = 2 ) ggsave(p, file = sprintf(&quot;%s/results/figures/study-specific-combined/%s-%s-%s-%s.png&quot;, local_path, out, trt, mod, cov) , width = length(levels(p2$data$mod_fac))*3 + 3 , height = 5) ggsave(p, file = sprintf(&quot;%s/results/figures/study-specific-combined/%s-%s-%s-%s.pdf&quot;, local_path, out, trt, mod, cov) , width = length(levels(p2$data$mod_fac))*3 + 4 , height = 4) return(p) } nested_std_plots_comb &lt;- nested_reg_fp %&gt;% select(-p) %&gt;% unnest(data) %&gt;% filter(!Moderator %in% c(&quot;none&quot;, &quot;dementia&quot;) &amp; study != &quot;Overall&quot;) %&gt;% group_by(Covariate, Outcome, Trait, Moderator, sig) %&gt;% tally() %&gt;% group_by(Covariate, Outcome, Trait, Moderator) %&gt;% mutate(perc = n/sum(n)) %&gt;% ungroup() %&gt;% filter(sig == &quot;sig&quot; &amp; perc &gt; .3) %&gt;% select(-n,-perc) %&gt;% full_join( nested_reg_fp %&gt;% select(-p) %&gt;% unnest(data) %&gt;% filter(!Moderator %in% c(&quot;none&quot;, &quot;dementia&quot;) &amp; study == &quot;Overall&quot; &amp; sign(conf.low) == sign(conf.high)) %&gt;% select(Covariate:Moderator, sig) ) %&gt;% distinct() %&gt;% left_join( nested_reg_fp %&gt;% select(everything(), -data, fp=p) ) %&gt;% left_join( nested_simp_std_se %&gt;% select(everything(), -comb.fx, sep = `pmap(...)`) ) %&gt;% mutate(p = pmap(list(fp, sep, Covariate, Outcome, Trait, Moderator) , possibly(std_eff_comb_plot_fun, NA_real_))) nested_std_plots_comb_dx &lt;- nested_reg_fp %&gt;% select(-p) %&gt;% unnest(data) %&gt;% filter(Moderator == &quot;dementia&quot; &amp; study != &quot;Overall&quot;) %&gt;% group_by(Covariate, Outcome, Trait, Moderator, sig) %&gt;% tally() %&gt;% group_by(Covariate, Outcome, Trait, Moderator) %&gt;% mutate(perc = n/sum(n)) %&gt;% ungroup() %&gt;% filter(sig == &quot;sig&quot; &amp; perc &gt; .3) %&gt;% select(-n,-perc) %&gt;% full_join( nested_reg_fp %&gt;% select(-p) %&gt;% unnest(data) %&gt;% filter(Moderator == &quot;dementia&quot; &amp; study == &quot;Overall&quot; &amp; sign(conf.low) == sign(conf.high)) %&gt;% select(Covariate:Moderator, sig) ) %&gt;% distinct() %&gt;% left_join( nested_reg_fp %&gt;% select(everything(), -data, fp=p) ) %&gt;% left_join( nested_simp_std_se_dx %&gt;% select(everything(), -comb.fx, sep = `pmap(...)`) ) %&gt;% mutate(p = pmap(list(fp, sep, Covariate, Outcome, Trait, Moderator) , possibly(std_eff_comb_plot_fun, NA_real_))) knitr::include_graphics(&quot;https://github.com/emoriebeck/personality-dementia-neuropath/raw/master/results/figures/study-specific-simple-effects/dementia_N_cognition_sharedint.png&quot;) nested_std_plots_comb_panel &lt;- function(plist, cov, mod, nmod, trt_group){ p &lt;- plot_grid( plotlist = plist$p , ncol = 1 , align = &quot;h&quot; , axis = &quot;lr&quot; ) ggsave(p, file = sprintf(&quot;%s/results/figures/study-specific-combined-panels/%s-%s-%s.png&quot;, local_path, mod, cov, trt_group) , width = nmod*3+5 , height = nrow(plist)*3) ggsave(p, file = sprintf(&quot;%s/results/figures/study-specific-combined-panels/%s-%s-%s.pdf&quot;, local_path, mod, cov, trt_group) , width = nmod*3+5 , height = nrow(plist)*4) } nested_std_plots_comb_dx %&gt;% filter(Moderator == &quot;dementia&quot;) %&gt;% mutate(nmod = map_dbl(sep, ~length(levels((.)$data$mod_fac))) , trt_group = mapvalues(Trait, traits$short_name, c(rep(&quot;big5&quot;, 5), rep(&quot;swb&quot;, 3)))) %&gt;% select(-fp, -sep) %&gt;% group_by(Covariate, Moderator, nmod, trt_group) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(p = pmap(list(data, Covariate, Moderator, nmod, trt_group), nested_std_plots_comb_panel)) nested_std_plots_comb_panel &lt;- function(plist, out, cov){ p &lt;- plot_grid( plotlist = plist$p , ncol = 1 , align = &quot;h&quot; , axis = &quot;lr&quot; ) ggsave(p, file = sprintf(&quot;%s/results/figures/study-specific-combined-panels/%s-%s.png&quot;, local_path, out, cov) , width = 3*3+6 , height = nrow(plist)*4) ggsave(p, file = sprintf(&quot;%s/results/figures/study-specific-combined-panels/%s-%s.pdf&quot;, local_path, out, cov) , width = 3*3+6 , height = nrow(plist)*4) } nested_reg_fp %&gt;% select(-p) %&gt;% unnest(data) %&gt;% filter(Moderator != &quot;none&quot; &amp; study == &quot;Overall&quot; &amp; sign(conf.low) == sign(conf.high)) %&gt;% select(Covariate:Moderator, sig) %&gt;% left_join(nested_std_plots_comb) %&gt;% arrange(Covariate, Outcome, Moderator, Trait) %&gt;% group_by(Covariate, Outcome) %&gt;% nest() %&gt;% ungroup() %&gt;% mutate(p = pmap(list(data, Outcome, Covariate), nested_std_plots_comb_panel)) knitr::include_graphics(&quot;https://github.com/emoriebeck/personality-dementia-neuropath/raw/master/results/figures/study-specific-combined-panels/dementia-sharedint-big5.png&quot;) knitr::include_graphics(&quot;https://github.com/emoriebeck/personality-dementia-neuropath/raw/master/results/figures/study-specific-combined-panels/dementia-sharedint.png&quot;) # C - braak - dementia - shared load(&quot;/Volumes/Emorie/projects/dementia/prediction/results/models/shared/braak_C_dementia.RData&quot;) hyp &lt;- c( &quot;p_value = 0&quot;, &quot;p_value + p_value:dementia1 = 0&quot; ); names(hyp) &lt;- c(&quot;Dementia = 0&quot;, &quot;Dementia = 1&quot;) hyp &lt;- c( &quot;dementia1 + 2.5*p_value + 2.5*p_value:dementia1 = 0&quot;, &quot;dementia1 + 5*p_value + 5*p_value:dementia1 = 0&quot;, &quot;dementia1 + 7.5*p_value + 7.5*p_value:dementia1 = 0&quot; ); names(hyp) &lt;- c(&quot;-25%&quot;, &quot;M&quot;, &quot;+25%&quot;) hypothesis(m, hyp, scope = &quot;coef&quot;, group = &quot;study&quot;)$hypothesis %&gt;% full_join( hypothesis(m, hyp)$hypothesis %&gt;% mutate(Group = &quot;Overall&quot;) ) %&gt;% mutate(Hypothesis = factor(Hypothesis, c(&quot;-25%&quot;, &quot;M&quot;, &quot;+25%&quot;))) %&gt;% arrange(Group, Hypothesis) ## Group Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star ## 1 EAS -25% 0.01488882 0.4554769 -0.83474194 0.9765685 NA NA ## 2 EAS M -0.08534036 0.4799323 -0.93023269 0.9666525 NA NA ## 3 EAS +25% -0.18556953 0.5374514 -1.15469315 0.9846866 NA NA ## 4 Overall -25% 0.28742084 0.4224154 -0.57087452 1.1065111 NA NA ## 5 Overall M 0.31428802 0.5410931 -0.83842604 1.4063249 NA NA ## 6 Overall +25% 0.34115520 0.7045705 -1.16232201 1.7692894 NA NA ## 7 ROS -25% 0.30100045 0.2579322 -0.21985532 0.7997646 NA NA ## 8 ROS M 0.39222259 0.2387495 -0.08449609 0.8575871 NA NA ## 9 ROS +25% 0.48344472 0.2558920 -0.01437826 0.9952668 NA NA ## 10 Rush-MAP -25% 0.29220652 0.2602555 -0.21477341 0.7978934 NA NA ## 11 Rush-MAP M 0.33539256 0.2444501 -0.13926983 0.8157798 NA NA ## 12 Rush-MAP +25% 0.37857860 0.2798609 -0.18550710 0.9275261 NA NA ## 13 WUSM-MAP -25% 0.61447279 0.3501419 -0.03178734 1.3488414 NA NA ## 14 WUSM-MAP M 0.70855090 0.3469458 0.07826754 1.4258705 NA NA * ## 15 WUSM-MAP +25% 0.80262902 0.3672979 0.13555049 1.5378560 NA NA * # association only for individuals without dementia diag # C - vsclrMcrInfrcts - dementia - shared load(&quot;/Volumes/Emorie/projects/dementia/prediction/results/models/shared/vsclrMcrInfrcts_C_dementia.RData&quot;) hypothesis(m, hyp, scope = &quot;coef&quot;, group = &quot;study&quot;)$hypothesis %&gt;% mutate_at(vars(Estimate, CI.Lower, CI.Upper), exp) ## Group Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star ## 1 ROS -25% 0.8915756 0.4611512 0.3565610 2.237268 NA NA ## 2 Rush-MAP -25% 0.8066729 0.4684443 0.3113866 2.031316 NA NA ## 3 WUSM-MAP -25% 0.7302583 0.6818422 0.2432074 3.798966 NA NA ## 4 ROS M 1.3499719 0.4343210 0.5796871 3.231963 NA NA ## 5 Rush-MAP M 1.2828519 0.4455106 0.5342678 3.186609 NA NA ## 6 WUSM-MAP M 0.6937837 0.7008935 0.2265149 3.633169 NA NA ## 7 ROS +25% 2.0440490 0.4687643 0.8096291 5.213544 NA NA ## 8 Rush-MAP +25% 2.0401194 0.5087942 0.7555881 5.727034 NA NA ## 9 WUSM-MAP +25% 0.6591310 0.7658073 0.1819494 3.904996 NA NA hypothesis(m, hyp)$hypothesis %&gt;% mutate_at(vars(Estimate, CI.Lower, CI.Upper), exp) ## Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star ## 1 -25% 0.895769 0.7341303 0.21332568 3.671203 NA NA ## 2 M 1.253516 1.0484006 0.15093147 12.652202 NA NA ## 3 +25% 1.754138 1.4430505 0.09036386 47.154628 NA NA # association only for individuals with dementia, such that C is risk for more pathology # N - vsclrMcrInfrcts - dementia - shared load(&quot;/Volumes/Emorie/projects/dementia/prediction/results/models/shared/vsclrMcrInfrcts_N_dementia.RData&quot;) hypothesis(m, hyp, scope = &quot;coef&quot;, group = &quot;study&quot;)$hypothesis %&gt;% mutate_at(vars(Estimate, CI.Lower, CI.Upper), exp) ## Group Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star ## 1 ROS -25% 2.4471680 0.3023402 1.3226753 4.603844 NA NA * ## 2 Rush-MAP -25% 1.7832685 0.2817748 1.0135332 3.109794 NA NA * ## 3 WUSM-MAP -25% 2.5069669 0.6096029 0.6769813 8.595932 NA NA ## 4 ROS M 1.9018237 0.3070155 1.0411631 3.465852 NA NA * ## 5 Rush-MAP M 1.1171997 0.3129798 0.6180358 2.072676 NA NA ## 6 WUSM-MAP M 2.3770887 0.6621323 0.6346968 9.414883 NA NA ## 7 ROS +25% 1.4780077 0.3777974 0.6958205 3.117623 NA NA ## 8 Rush-MAP +25% 0.6999143 0.4475947 0.2892872 1.621016 NA NA ## 9 WUSM-MAP +25% 2.2539391 0.7638452 0.5257578 11.271002 NA NA hypothesis(m, hyp)$hypothesis %&gt;% mutate_at(vars(Estimate, CI.Lower, CI.Upper), exp) ## Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star ## 1 -25% 2.155638 0.6138059 0.56145431 7.822769 NA NA ## 2 M 1.675900 0.9549461 0.20927850 14.470222 NA NA ## 3 +25% 1.302928 1.3596562 0.07122702 28.393671 NA NA # association for indidvuals with dementia, usch that N is a protective factor against pathology # SWL - hipSclerosis - dementia - shared load(&quot;/Volumes/Emorie/projects/dementia/prediction/results/models/shared/hipSclerosis_SWL_dementia.RData&quot;) hypothesis(m, hyp, scope = &quot;coef&quot;, group = &quot;study&quot;)$hypothesis %&gt;% mutate_at(vars(Estimate, CI.Lower, CI.Upper), exp) ## Group Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star ## 1 ROS -25% 4.538651e-09 28.2828020 3.575913e-30 5.047732 NA NA ## 2 Rush-MAP -25% 8.257432e-01 0.9267724 2.000186e-01 5.987976 NA NA ## 3 ROS M 1.998994e-17 56.0252894 2.940331e-59 3.643485 NA NA ## 4 Rush-MAP M 1.191047e+00 0.7937293 3.185886e-01 7.331039 NA NA ## 5 ROS +25% 8.804328e-26 83.7756345 2.417718e-88 3.634121 NA NA ## 6 Rush-MAP +25% 1.717960e+00 0.7532188 4.191172e-01 9.624497 NA NA hypothesis(m, hyp)$hypothesis %&gt;% mutate_at(vars(Estimate, CI.Lower, CI.Upper), exp) ## Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star ## 1 -25% 1.295809 1.925018 1.593292e-02 54.48063 NA NA ## 2 M 2.240864 3.671521 5.489070e-04 1199.50243 NA NA ## 3 +25% 3.875163 5.531700 1.396072e-05 37131.38049 NA NA # association for indidvuals without dementia, SWL protective against pathology # PA - tdp43 - dementia - shared load(&quot;/Volumes/Emorie/projects/dementia/prediction/results/models/shared/tdp43_PA_dementia.RData&quot;) hypothesis(m, hyp, scope = &quot;coef&quot;, group = &quot;study&quot;)$hypothesis %&gt;% mutate_at(vars(Estimate, CI.Lower, CI.Upper), exp) ## Group Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star ## 1 ROS -25% 1.467604 0.9436978 0.1891046 8.329732 NA NA ## 2 Rush-MAP -25% 1.374367 0.3791283 0.6735176 2.910392 NA NA ## 3 ROS M 2.451328 1.0160878 0.4247852 24.003485 NA NA ## 4 Rush-MAP M 1.759433 0.3452709 0.8987734 3.503260 NA NA ## 5 ROS +25% 4.094434 1.2748653 0.6069821 98.205407 NA NA ## 6 Rush-MAP +25% 2.252387 0.3489014 1.1448756 4.478002 NA NA * hypothesis(m, hyp)$hypothesis %&gt;% mutate_at(vars(Estimate, CI.Lower, CI.Upper), exp) ## Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star ## 1 -25% 1.490759 1.121642 0.17161138 17.10686 NA NA ## 2 M 2.087577 1.816012 0.06041279 106.67366 NA NA ## 3 +25% 2.923328 2.601191 0.01753368 711.82400 NA NA # association for indidvuals with dementia, SWL risk for pathology # SWL - vsclrInfrcts - dementia - shared load(&quot;/Volumes/Emorie/projects/dementia/prediction/results/models/shared/vsclrInfrcts_SWL_dementia.RData&quot;) hypothesis(m, hyp, scope = &quot;coef&quot;, group = &quot;study&quot;)$hypothesis %&gt;% mutate_at(vars(Estimate, CI.Lower, CI.Upper), exp) ## Group Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star ## 1 ROS -25% 1.1384492 0.8233407 0.19191739 5.139960 NA NA ## 2 Rush-MAP -25% 2.3972205 0.5027414 0.90584925 6.403171 NA NA ## 3 ROS M 0.6175628 0.9523147 0.07405117 3.297016 NA NA ## 4 Rush-MAP M 1.8299229 0.4528472 0.75870676 4.422587 NA NA ## 5 ROS +25% 0.3350029 1.2251884 0.02054018 2.613335 NA NA ## 6 Rush-MAP +25% 1.3968751 0.4604946 0.57312629 3.469499 NA NA hypothesis(m, hyp)$hypothesis %&gt;% mutate_at(vars(Estimate, CI.Lower, CI.Upper), exp) ## Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star ## 1 -25% 1.7669728 1.250991 0.126890890 20.73345 NA NA ## 2 M 1.2843854 1.999785 0.016166162 79.14483 NA NA ## 3 +25% 0.9336001 2.852141 0.001840744 384.31439 NA NA # association for indidvuals with dementia, SWL risk for pathology "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
