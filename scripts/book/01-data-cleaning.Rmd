---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Data Cleaning {#cleaning}

```{r mode fun}
Mode <- function(x) {
  ux <- unique(x)
  ux <- ux[!is.na(ux)]
  ux[which.max(tabulate(match(x, ux)))]
}
pomp <- function(x) (x - min(x, na.rm = T))/(max(x, na.rm = T) - min(x, na.rm = T))*10
```

## Health and Retirement Study (HRS)  
The Health and Retirement Study [HRS; @juster1995overview] is an ongoing longitudinal study of households in the United States. These data are available at https://hrs.isr.umich.edu by creating a free account.  

Participants were recruited from more than 35,000 individuals from the financial households of individuals born between 1931 and 1941 in the US. Data have been collected biannually since 1992. The latest data release includes data up to 2016. On average, 10,000 individuals are sampled each wave More information on the HRS can be found at https://hrs.isr.umich.edu/documentation/survey-design, but, in short, the HRS is a nationally representative sample of adults over 50 in the US. It is critical to note that the HRS samples households of the original cohort and follows individuals and their spouses or partners until their death.  

Sample size varies by year, ranging from approximately 7,500 (2014) to 15,500 (1992). (https://hrs.isr.umich.edu/sites/default/files/biblio/ResponseRates_2017.pdf). This provides 99% power to detect a zero-order correlation effect size of ~.04, two-tailed at alpha .05.  

### Load Data  
```{r hrs clean fun, eval = T}
hrs_read_fun <- function(year) {
  read_da <- function(da, dct, Year){
    print(paste(da, dct, year, sep = " "))
    data.file <- sprintf("%s/hrs/%s/%s", data_path, Year, da)
    # Set path to the dictionary file "*.DCT"
    dict.file <- sprintf("%s/hrs/%s/%s", data_path, Year, dct)
    # Read the dictionary file
    df.dict <- read.table(dict.file, skip = 1, fill = TRUE, stringsAsFactors = FALSE)
    # Set column names for dictionary dataframe
    colnames(df.dict) <- c("col.num","col.type","col.name","col.width","col.lbl")
    # Remove last row which only contains a closing }
    row <- which(df.dict$col.name == "HHID")
    df.dict <- df.dict[-nrow(df.dict),]
    if(row == 2){df.dict <- df.dict[-1,]}
    # Extract numeric value from column width field
    df.dict$col.width <- as.integer(sapply(df.dict$col.width, gsub, pattern = "[^0-9\\.]", replacement = ""))
    # Convert column types to format to be used with read_fwf function
    df.dict$col.type <- sapply(df.dict$col.type, function(x) ifelse(x %in% c("int","byte","long"), "i", ifelse(x == "float", "n", ifelse(x == "double", "d", "c"))))
    # Read the data file into a dataframe
    df <- read_fwf(file = data.file, fwf_widths(widths = df.dict$col.width, col_names = df.dict$col.name), col_types = paste(df.dict$col.type, collapse = ""))
    # Add column labels to headers
    attributes(df)$variable.labels <- df.dict$col.lbl
    old.names <- (hrs_codebook %>% filter(year == Year))$orig_itemname
    if(any(c("PN", "HHID") %in% colnames(df)) & any(old.names %in% colnames(df))){
    # if(any(c("PN", "HHID") %in% colnames(df))){
      df <- df %>%
      mutate(hhidpn = 1000*as.numeric(HHID) + as.numeric(PN)) %>%
      select(one_of(c("PN", "HHID")), one_of(old.names)) %>%
        distinct()
      # gather(key = item, value = value, -hhidpn)
    } else {df <- NA}
    return(df)
  }
    # Set path to the data file "*.DA"
  files <- list.files(sprintf("%s/hrs/%s", data_path, year))
  df2 <- tibble(
    da = files[grepl(".da",  files) | grepl(".DA", files)],
    dct = files[grepl(".dct", files) | grepl(".DCT", files)]
  ) %>%
    mutate(data = map2(da, dct, possibly(~read_da(.x, .y, year), NA_real_))) %>%
    filter(!is.na(data)) %>%
    select(-da, -dct) 
  if(nrow(df2) != 0){df2$data %>% reduce(full_join) %>% distinct()} else {NA}
}
```

```{r hrs codebook}
hrs_codebook <- (codebook %>% filter(study == "HRS"))$codebook[[1]] %>% 
  mutate(orig_itemname = str_to_upper(orig_itemname)) %>%
  mutate_at(vars(orig_itemname, name, itemname), ~str_remove_all(., "[[:space:]]"))
hrs_codebook
```

```{r hrs data, eval = T}
old.names <- unique(hrs_codebook$orig_itemname)
hrs.paq <- tibble(
  year = sprintf("%s/hrs", data_path) %>% list.files(., pattern = "^[0-9]")
  , data = map(year, hrs_read_fun)
  , names = map(data, colnames)
  ) %>%
  filter(!is.na(data))

old.names <- unique((hrs_codebook %>% filter(dataset == "Rand"))$orig_itemname)
hrs.rand <- sprintf("%s/hrs/randhrs1992_2016v1.sav", data_path) %>% 
  haven::read_sav(.) %>%
  haven::zap_labels(.) %>%
  select(SID = HHIDPN, one_of(old.names)) %>%
  gather(key = orig_itemname, value = value, -SID, na.rm = T)


hrs_long <- hrs.paq %>%
  mutate(data = map(data, ~(.) %>% 
      pivot_longer(cols = c(-HHID, -PN)
                   , names_to = "orig_itemname"
                   , values_to = "value"
                   , values_drop_na = TRUE))) %>%
  select(-names, -year) %>%
  unnest(data) %>%
  mutate(SID = 1000*as.numeric(HHID) + as.numeric(PN)) %>%
  select(-PN, -HHID) 

hrs_dem <- sprintf("%s/hrs/pdem_withvarnames.sas7bdat", data_path) %>%
  haven::read_sas(.) %>%
  select(SID = hhidpn, year = prediction_year, value = prob_dementia) %>%
  mutate(orig_itemname = "PROB_DEMENTIA")

hrs.subs <- unique(hrs_long$SID)[unique(hrs_long$SID) %in% unique(hrs.rand$SID)]
hrs_long <- hrs_long %>%
  bind_rows(hrs.rand %>% select(orig_itemname, value, SID)) %>%
  filter(SID %in% hrs.subs)

save(hrs.rand, hrs.paq, file = sprintf("%s/data/clean/hrs_raw.RData", wd))
rm(list = c("hrs.paq", "hrs.rand"))
```

### Recoding & Reverse Scoring  

```{r hrs recode, eval = F}
hrs_waves <- p_waves %>% filter(Study == "HRS") %>% select(Used) %>% distinct()

# join data with recoding info 
hrs_recode <- hrs_codebook %>%
  filter(category %in% c("pers", "outcome", "covariates", "cognition") & orig_itemname != "prob_dementia") %>%
  select(category, name, itemname, wave, year, orig_itemname, reverse_code:long_rule) %>%
  group_by(category, name) %>% 
  nest() %>%
  ungroup() %>%
  mutate(data = map(data, ~(.) %>% left_join(hrs_long))) 

hrs_recode <- hrs_dem %>%
  left_join(
    hrs_codebook %>% 
      select(category, name, itemname, orig_itemname, reverse_code:long_rule)
    ) %>%
  group_by(category, name) %>%
  nest() %>%
  ungroup() %>%
  bind_rows(hrs_recode)

# recode 
recode_fun <- function(rule, y, year, p_year){
  x <- y$value
  if(!is.na(rule)){y$value <- eval(parse(text = rule))}
  return(y)
}

hrs_recode <- hrs_recode %>% 
  mutate(data = map(data, ~(.) %>% 
    mutate(year = mapvalues(year, seq(2006, 2016, 2), rep(c(2006, 2010, 2014), each = 2)),
           p_year = 2006) %>%
    group_by(recode, year, p_year) %>%
    nest() %>%
    ungroup() %>%
    mutate(data = pmap(list(recode, data, year, p_year), recode_fun)) %>%
    unnest(data) %>%
    mutate(value = ifelse(value < 0 | is.nan(value) | is.infinite(value), NA, value))))


# reverse code 
hrs_recode <- hrs_recode %>%
  mutate(data = map(data, ~(.) %>%
    mutate(value = ifelse(reverse_code == "no" | is.na(reverse_code), value, 
                        reverse.code(-1, value, mini = mini, maxi = maxi)))))

fun_call <- function(x, rule){
    switch(rule,
           average = mean(x, na.rm = T),
           mode = Mode(x)[1],
           sum = sum(x, na.rm = T),
           skip = unique(x)[1],
           select = unique(x)[1],
           max = max(x, na.rm = T),
           min = min(x, na.rm = T))
  }
```

### Covariates  

```{r hrs covariates, eval = T}
# compositing within years
year_comp_fun <- function(df, rule){
  df %>%
    # group by person and item (collapse across age)
    group_by(SID, name, year, p_year, long_rule) %>% 
    summarize(value = fun_call(value, rule)) %>%
    ungroup() %>% 
    mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value))
}

# composite WITHIN years 
hrs_cov <- hrs_recode %>%
  filter(category == "covariates") %>%
  select(-category) %>%
  unnest(data) %>%
  mutate(comp_rule = ifelse(is.na(comp_rule), "skip", comp_rule)) %>%
  group_by(comp_rule) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = map2(data, comp_rule, year_comp_fun)) %>%
  unnest(data)

comp_fun <- function(d, rule, p_year){
  d %>%
    filter(year <= p_year) %>%
    group_by(SID, name) %>%
    summarize(value = fun_call(value, rule)) %>%
    ungroup() %>%
    distinct()
}

# composite ACROSS years
hrs_cov <- hrs_cov %>%
  mutate(long_rule = ifelse(is.na(long_rule), "skip", long_rule)) %>%
  group_by(p_year, long_rule) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = pmap(list(data, long_rule, p_year), comp_fun)) %>%
  unnest(data) %>%
  mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %>%
  select(-long_rule) %>%
  spread(name, value) %>%
  filter(!is.na(SID))
```

### Personality Variables  
```{r hrs personality, eval = T}
hrs_pers <- hrs_recode %>%
  filter(category == "pers") %>%
  select(-category) %>% 
  unnest(data) %>%
  filter(year == "2006" & !is.na(value)) %>%
  group_by(SID, p_year, year, name, itemname, comp_rule) %>%
  summarize(value = mean(value, na.rm = T)) %>%
  ungroup()

# alpha's
hrs_alpha <- hrs_pers %>%
  filter(!is.na(value)) %>%
  select(name, itemname, year, SID, value) %>%
  group_by(name, year) %>%
  nest() %>%
  mutate(data = map(data, ~(.) %>% distinct() %>% pivot_wider(names_from = itemname, values_from = value, values_fn = list(mean))),
         alpha = map(data, possibly(~psych::alpha((.) %>% select(-SID)), NA_real_)))

comp_fun <- function(df, rule){
  df %>%
    group_by(SID) %>%
    summarize(value = fun_call(value, rule)) %>%
    ungroup() %>%
    mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value))
}

# create composites
hrs_pers <- hrs_pers %>%
  group_by(name, comp_rule, year) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = map2(data, comp_rule, comp_fun)) %>%
  unnest(data) %>%
  select(-comp_rule)
```

### Cognition Variables  
```{r hrs cog, eval = T}
hrs_cog <- hrs_recode %>%
  filter(category == "cognition") %>%
  select(-category) %>% 
  unnest(data) %>%
  filter(year == p_year) %>%
  filter(!is.na(value)) %>%
  group_by(name, itemname, year) %>%
  mutate(value = pomp(value)) %>%
  group_by(SID, name) %>%
  summarize(value = mean(value)) %>%
  ungroup() %>%
  pivot_wider(names_from = "name", values_from = "value")
```

### Outcome Variables  
```{r hrs out, eval = T}
# composite within years 
# compositing within years
hrs_out <- hrs_recode %>%
  filter(category == "outcome") %>%
  unnest(data) %>%
  group_by(SID, name, year, p_year) %>%
  summarize(value = max(value, na.rm = T)) %>%
  ungroup() %>%
  mutate(value = ifelse(is.nan(value) | is.infinite(value), NA, value),
         group = ifelse(year > p_year, "future", "past")) %>%
  filter(!is.na(value)) %>%
  group_by(SID, p_year, year, name, group) %>%
  mutate(value = ifelse(value < .5, 0, 1)) %>%
  group_by(SID, p_year, name, group) %>%
  summarize(value = max(value, na.rm = T)) %>%
  ungroup() %>%
  mutate(value = ifelse(is.infinite(value), NA, value)) %>%
  pivot_wider(names_from = group, values_from = value) %>%
  group_by(SID, name) %>%
  mutate(value = ifelse(is.na(past) | (past == 0 & !is.na(future)), future,
                 ifelse(past == 0 & is.na(future), past, 
                 ifelse(past == 1, NA, NA)))) %>%
ungroup()
```

### Combine Data  
```{r hrs combine}
hrs_combined <- hrs_pers %>% 
  rename(Trait = name, p_value = value, p_year = year) %>%
  full_join(hrs_out %>% select(SID, Outcome = name, o_value = value)) %>%
  full_join(hrs_cov) %>%
  left_join(
    hrs_out %>%
      filter(name == "dementia") %>%
      mutate(value = ifelse(rowSums(cbind(future, past), na.rm = T) >= 1, 1, 0)) %>%
      select(-future, -past) %>%
      pivot_wider(names_from = "name", values_from = "value")
    ) %>%
  full_join(hrs_cog) %>%
  filter(!is.na(p_value) & !is.na(o_value)) %>%
  mutate(age = p_year - yearBrth
         , o_year = 2014)
```

```{r hrs save}
save(hrs_cov, hrs_alpha, hrs_pers, hrs_out, hrs_combined, hrs_cog,
     file = sprintf("%s/data/clean/hrs_cleaned.RData", wd))
```

```{r}
rm(list =ls()[grepl("hrs", ls())])
```

## RUSH Memory and and Aging Project (RUSH-MAP)  
The RUSH Memory and Aging Project (RUSH-MAP) is an ongoing longitudinal study that began in 1997 [@a2012overview]. These data are available, through application from https://www.radc.rush.edu/requests.htm.  

Participants who were 65 and older were recruited from retirement communities and subsidized senior housing facilities throughout Chicagoland and northeastern Illinois beginning in 1997. Data are collected annually, and all participants are organ donors. Additional participants are recuited each year. Additional information and documentation on the data can be found at https://www.radc.rush.edu/docs/var/variables.htm.  

Sample sizes vary by year, ranging from 52 (1997) to 2205 participants including 884 deceased participants with autopsy data (2019, 2020). This provides 99\% power to detect a zero-order correlation effect size of ~.10, two-tailed at alpha .05.  

### Load Data  

```{r map codebook}
(map_codebook <- (codebook %>% filter(study == "RADC-MAP"))$codebook[[1]] %>%
  mutate(orig_itemname = str_to_lower(orig_itemname)))
```

```{r nlsy data, eval = T}
map <- sprintf("%s/rush-radc/dataset_1033_long_03-24-2021.xlsx", data_path) %>% read_excel() %>%
  full_join(sprintf("%s/rush-radc/dataset_1033_basic_03-24-2021.xlsx", data_path) %>% read_excel()) %>%
  full_join(sprintf("%s/rush-radc/dataset_1034_long_03-25-2021.xlsx", data_path) %>% read_excel()) %>%
  full_join(sprintf("%s/rush-radc/dataset_1034_basic_03-25-2021.xlsx", data_path) %>% read_excel()) %>%
  filter(study == "MAP")
```

### Recoding & Reverse Scoring  

```{r nlsy match, eval = T}
rename_fun <- function(cb, var){
  print(var)
  old.names <- unique((map_codebook %>% filter(name == var))$orig_itemname)
  df <- map %>% 
    select(SID = projid, wave = fu_year, one_of(old.names)) %>%
    gather(key = orig_itemname, value = value, -SID, -wave, na.rm = T) %>%
    left_join(cb %>% select(itemname, orig_itemname, reverse_code:long_rule))
}

# join data with recoding info 
map_recode <- map_codebook %>%
  select(category, name, itemname, year, orig_itemname, reverse_code:long_rule) %>%
  filter(category %in% c("pers", "outcome", "covariates", "cognition")) %>%
  group_by(category, name) %>%
  nest() %>% 
  ungroup() %>%
  mutate(data = map2(data, name, rename_fun))

# recode 
recode_fun <- function(rule, y, year){
  x <- y$value
  if(!is.na(rule)){y$value <- eval(parse(text = rule))}
  return(y)
}

map_recode <- map_recode %>% 
  mutate(data = map(data, ~(.) %>% 
    mutate(wave = as.numeric(wave)) %>%
    group_by(recode, wave) %>%
    nest() %>%
    ungroup() %>%
    mutate(data = pmap(list(recode, data, wave), recode_fun)) %>%
    unnest(data) %>%
    mutate(value = ifelse(value < 0 | is.nan(value) | is.infinite(value), NA, value))))

# reverse code 
map_recode <- map_recode %>%
  mutate(data = map(data, ~(.) %>%
    mutate(value = as.numeric(value), 
           value = ifelse(reverse_code == "no" | is.na(reverse_code), value, 
                        reverse.code(-1, value, mini = mini, maxi = maxi)))))

fun_call <- function(x, rule){
    switch(rule,
           average = mean(x, na.rm = T),
           mode = Mode(x)[1],
           sum = sum(x, na.rm = T),
           skip = unique(x)[1],
           select = unique(x)[1],
           max = max(x, na.rm = T),
           min = min(x, na.rm = T))
}
```

### Covariates  

```{r map covariates, eval = T}
# composite WITHIN years 
map_cov <- map_recode %>%
  filter(category == "covariates") %>%
  select(-category) %>%
  mutate(data = map(data, ~(.) %>% 
      filter(!is.na(value)) %>%
      mutate(comp_rule = ifelse(is.na(comp_rule), "skip", comp_rule)) %>%
      group_by(comp_rule, SID, wave, long_rule) %>%
      nest() %>%
      ungroup() %>%
      mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %>%
      unnest(data) %>%
      filter(wave == 0)
      ))

comp_fun <- function(d, rule){
  d %>%
    group_by(SID, name) %>%
    summarize(value = fun_call(data, rule)) %>%
    ungroup() %>%
    distinct()
}

# composite ACROSS years
map_cov <- map_cov %>%
  unnest(data) %>%
  mutate(long_rule = ifelse(is.na(long_rule), "skip", long_rule)) %>%
  group_by(long_rule) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = pmap(list(data, long_rule), comp_fun)) %>%
  unnest(data) %>%
  mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %>%
  select(-long_rule) %>%
  spread(name, value) %>%
  filter(!is.na(SID))
```

### Personality Variables  
```{r map personality, eval = T}
map_pers <- map_recode %>%
  filter(category == "pers") %>%
  select(-category) %>% 
  unnest(data) %>% 
  distinct() %>%
  group_by(SID, name) %>%
  filter(wave == min(wave)) %>%
  ungroup() %>%
  select(SID, name, wave, value)
```

### Outcome Variables  
```{r map out, eval = T}
map_out_waves <- map_recode %>%
  filter(category == "outcome") %>%
  unnest(data) %>%
  group_by(SID, name) %>%
  summarize(o_year = max(wave)) %>%
  ungroup()

map_out <- map_recode %>%
  filter(category == "outcome") %>%
  select(-category) %>%
  unnest(data) 

map_dem <- map_out %>% 
  filter(name == "dementia") %>%
  group_by(SID, name, wave) %>%
  summarize(value = max(value, na.rm = T)) %>%
  ungroup() %>%
  mutate(value = ifelse(is.nan(value) | is.infinite(value), NA, value),
         group = ifelse(wave > 0, "future", "past")) %>%
    group_by(SID, name, group) %>%
    summarize(value = max(value, na.rm = T)) %>%
    ungroup() %>%
    mutate(value = ifelse(is.infinite(value), NA, value)) %>%
    pivot_wider(names_from = group, values_from = value) %>%
    group_by(SID, name) %>%
    mutate(value = ifelse(is.na(past) | (past == 0 & !is.na(future)), future,
                   ifelse(past == 0 & is.na(future), past, 
                   ifelse(past == 1, NA, NA)))) %>%
  ungroup()

comp_fun <- function(df, rule){
  df %>%
    group_by(SID) %>%
    summarize(value = fun_call(value, rule)) %>%
    ungroup() %>%
    mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value))
}

# create composites
map_out <- map_out %>%
  filter(wave > 0 & name != "dementia") %>%
  group_by(name, long_rule) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = map2(data, long_rule, comp_fun)) %>%
  unnest(data) %>%
  select(-long_rule) %>%
  full_join(map_dem) %>%
  left_join(map_out_waves)
```

### Cognition Variables  
```{r map cog, eval = T}
# composite within years
map_cog <- map_recode %>%
  filter(category == "cognition") %>%
  select(-category) %>%
  unnest(data) %>%
  filter(wave == 0) %>%
  filter(!is.na(value)) %>%
  group_by(name, itemname, wave) %>%
  mutate(value = pomp(value)) %>%
  group_by(name, SID) %>%
  summarize(value = mean(value, na.rm = T)) %>%
  ungroup() %>%
  pivot_wider(names_from = "name"
              , values_from = "value")
```

### Combine Data  
```{r map combine}
map_combined <- map_pers %>% 
  rename(Trait = name, p_value = value, p_year = wave) %>%
  full_join(
    map_out %>% 
      select(Outcome = name, SID, o_value = value, o_year)
    ) %>% 
  full_join(map_cov) %>%
  left_join(
    map_out %>%
      filter(name == "dementia") %>%
      mutate(value = ifelse(rowSums(cbind(future, past), na.rm = T) >= 1, 1, 0)) %>%
      select(-future, -past) %>%
      pivot_wider(names_from = "name", values_from = "value")
    ) %>%
  full_join(map_cog) %>%
  filter(!is.na(p_value) & !is.na(o_value))
```

```{r map save}
save(map_cov, map_pers, map_out, map_combined, map_cog,
     file = sprintf("%s/data/clean/radc-map_cleaned.RData", wd))
```

```{r}
rm(list =ls()[grepl("map", ls())])
```


## RUSH Religious Orders Study (ROS)  
The RUSH Religious Orders Study (ROS) is an ongoing longitudinal study that began in 1994 [@a2012overview]. These data are available, through application from https://www.radc.rush.edu/requests.htm. 

Older (65 and above) Catholic nuns, priests, and brothers with no prior dementia diagnosis and who agreed to annual evaluations and eventual organ donation were recruited from more than 40 groups across the United States. Additional participants are recuited each year. Additional information and documentation on the data can be found at https://www.radc.rush.edu/docs/var/variables.htm.  

Sample sizes vary bt year from 353 participants (1994) to 1487 participants, including 797 deceased participants with autopsy data (2019, 2020). This provides 99\% power to detect a zero-order correlation effect size of ~.11, two-tailed at alpha .05.  

```{r ros codebook}
(ros_codebook <- (codebook %>% filter(study == "ROS"))$codebook[[1]] %>%
  mutate(orig_itemname = str_to_lower(orig_itemname)))
```

```{r ros data, eval = T}
ros <- sprintf("%s/rush-radc/dataset_1033_long_03-24-2021.xlsx", data_path) %>% read_excel() %>%
  full_join(sprintf("%s/rush-radc/dataset_1033_basic_03-24-2021.xlsx", data_path) %>% read_excel()) %>%
  full_join(sprintf("%s/rush-radc/dataset_1034_long_03-25-2021.xlsx", data_path) %>% read_excel()) %>%
  full_join(sprintf("%s/rush-radc/dataset_1034_basic_03-25-2021.xlsx", data_path) %>% read_excel()) %>%
  filter(study == "ROS")
```

### Recoding & Reverse Scoring  

```{r ros match, eval = T}
rename_fun <- function(cb, var){
  print(var)
  old.names <- unique((ros_codebook %>% filter(name == var))$orig_itemname)
  df <- ros %>% 
    select(SID = projid, wave = fu_year, one_of(old.names)) %>%
    gather(key = orig_itemname, value = value, -SID, -wave, na.rm = T) %>%
    left_join(cb %>% select(itemname, orig_itemname, reverse_code:long_rule))
}

# join data with recoding info 
ros_recode <- ros_codebook %>%
  select(category, name, itemname, year, orig_itemname, reverse_code:long_rule) %>%
  filter(category %in% c("pers", "outcome", "covariates", "cognition")) %>%
  group_by(category, name) %>%
  nest() %>% 
  ungroup() %>%
  mutate(data = map2(data, name, rename_fun))

# recode 
recode_fun <- function(rule, y, year){
  x <- y$value
  if(!is.na(rule)){y$value <- eval(parse(text = rule))}
  return(y)
}

ros_recode <- ros_recode %>% 
  mutate(data = map(data, ~(.) %>% 
    mutate(wave = as.numeric(wave)) %>%
    group_by(recode, wave) %>%
    nest() %>%
    ungroup() %>%
    mutate(data = pmap(list(recode, data, wave), recode_fun)) %>%
    unnest(data) %>%
    mutate(value = ifelse(value < 0 | is.nan(value) | is.infinite(value), NA, value))))

# reverse code 
ros_recode <- ros_recode %>%
  mutate(data = map(data, ~(.) %>%
    mutate(value = as.numeric(value), 
           value = ifelse(reverse_code == "no" | is.na(reverse_code), value, 
                        reverse.code(-1, value, mini = mini, maxi = maxi)))))

fun_call <- function(x, rule){
    switch(rule,
           average = mean(x, na.rm = T),
           mode = Mode(x)[1],
           sum = sum(x, na.rm = T),
           skip = unique(x)[1],
           select = unique(x)[1],
           max = max(x, na.rm = T),
           min = min(x, na.rm = T))
}
```

### Covariates  

```{r ros covariates, eval = T}
# composite WITHIN years 
ros_cov <- ros_recode %>%
  filter(category == "covariates") %>%
  select(-category) %>%
  mutate(data = map(data, ~(.) %>% 
      filter(!is.na(value)) %>%
      mutate(comp_rule = ifelse(is.na(comp_rule), "skip", comp_rule)) %>%
      group_by(comp_rule, SID, wave, long_rule) %>%
      nest() %>%
      ungroup() %>%
      mutate(data = map2(data, comp_rule, ~fun_call((.x)$value, .y))) %>%
      unnest(data) %>%
      filter(wave == 0)
      ))

comp_fun <- function(d, rule){
  d %>%
    group_by(SID, name) %>%
    summarize(value = fun_call(data, rule)) %>%
    ungroup() %>%
    distinct()
}

# composite ACROSS years
ros_cov <- ros_cov %>%
  unnest(data) %>%
  mutate(long_rule = ifelse(is.na(long_rule), "skip", long_rule)) %>%
  group_by(long_rule) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = pmap(list(data, long_rule), comp_fun)) %>%
  unnest(data) %>%
  mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %>%
  select(-long_rule) %>%
  spread(name, value) %>%
  filter(!is.na(SID))
```

### Personality Variables  
```{r ros personality, eval = T}
ros_pers <- ros_recode %>%
  filter(category == "pers") %>%
  select(-category) %>% 
  unnest(data) %>% 
  distinct() %>%
  group_by(SID, name) %>%
  filter(wave == min(wave)) %>%
  ungroup() %>%
  select(SID, name, wave, value)
```

### Outcome Variables  
```{r ros out, eval = T}
ros_out_waves <- ros_recode %>%
  filter(category == "outcome") %>%
  unnest(data) %>%
  group_by(SID, name) %>%
  summarize(o_year = max(wave)) %>%
  ungroup()

ros_out <- ros_recode %>%
  filter(category == "outcome") %>%
  select(-category) %>%
  unnest(data) 

ros_dem <- ros_out %>% 
  filter(name == "dementia") %>%
  group_by(SID, name, wave) %>%
  summarize(value = max(value, na.rm = T)) %>%
  ungroup() %>%
  mutate(value = ifelse(is.nan(value) | is.infinite(value), NA, value),
         group = ifelse(wave > 0, "future", "past")) %>%
    group_by(SID, name, group) %>%
    summarize(value = max(value, na.rm = T)) %>%
    ungroup() %>%
    mutate(value = ifelse(is.infinite(value), NA, value)) %>%
    pivot_wider(names_from = group, values_from = value) %>%
    group_by(SID, name) %>%
    mutate(value = ifelse(is.na(past) | (past == 0 & !is.na(future)), future,
                   ifelse(past == 0 & is.na(future), past, 
                   ifelse(past == 1, NA, NA)))) %>%
  ungroup()

comp_fun <- function(df, rule){
  df %>%
    group_by(SID) %>%
    summarize(value = fun_call(value, rule)) %>%
    ungroup() %>%
    mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value))
}

# create composites
ros_out <- ros_out %>%
  filter(wave > 0 & name != "dementia") %>%
  group_by(name, long_rule) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = map2(data, long_rule, comp_fun)) %>%
  unnest(data) %>%
  select(-long_rule) %>%
  full_join(ros_dem) %>%
  left_join(ros_out_waves)
```


### Cognition Variables  
```{r ros cog, eval = T}
# composite within years
ros_cog <- ros_recode %>%
  filter(category == "cognition") %>%
  select(-category) %>%
  unnest(data) %>%
  filter(wave == 0) %>%
  filter(!is.na(value)) %>%
  group_by(name, itemname, wave) %>%
  mutate(value = pomp(value)) %>%
  group_by(name, SID) %>%
  summarize(value = mean(value, na.rm = T)) %>%
  ungroup() %>%
  pivot_wider(names_from = "name"
              , values_from = "value")
```

### Combine Data  
```{r ros combine}
ros_combined <- ros_pers %>% 
  rename(Trait = name, p_value = value, p_year = wave) %>%
  full_join(
    ros_out %>% 
      select(Outcome = name, SID, o_value = value, o_year)
    ) %>%
  full_join(ros_cov) %>%
  left_join(
    ros_out %>%
      filter(name == "dementia") %>%
      mutate(value = ifelse(rowSums(cbind(future, past), na.rm = T) >= 1, 1, 0)) %>%
      select(-future, -past) %>%
      pivot_wider(names_from = "name", values_from = "value")
    ) %>%
  full_join(ros_cog) %>%
  filter(!is.na(p_value) & !is.na(o_value))
```

```{r ros save}
save(ros_cov, ros_pers, ros_out, ros_combined, ros_cog,
     file = sprintf("%s/data/clean/ros_cleaned.RData", wd))
```

```{r}
rm(list =ls()[grepl("ros", ls())])
```

## Swedish Adoption Twin Study of Aging (SATSA)  
The Swedish Adoption Twin Study of Aging (SATSA) is a longitudinal study of twin pairs from the Swedish Twin Registry that began in 1984. Data are available through the ICPSR database at https://www.icpsr.umich.edu/web/ICPSR/studies/3843.  

All twin-pairs on the Swedish Twin Registry who were separated at an early age were invited to be a part of the study in 1984. A control sample of twins reared together were also included. Additional waves of all participants were collected in 1987, 1990, 1993, 2004, 2007, 2010, 2012, and 2014. More information, including codebooks, scales, and variable search functions can be found at https://www.maelstrom-research.org/mica/individual-study/satsa/#.

Sample sizes vary by wave, ranging from 2018 participants at baseline (1984) to 379 participants (IPT7). Given that the target measures were collected at baseline, this provides 99\% power to detect a zero-order correlation effect size of ~.10, two-tailed at alpha .05.  

### Load Data  
```{r satsa load fun} 
satsa_read_fun <- function(x){
  prob_vars <- c("FHEART", "FPARKIN", "FSTROKE")
  y <- sprintf("%s/satsa/%s", data_path, x) %>% haven::read_sav(.) %>% 
    select(SID = TWINNR, one_of(old.names)) %>%
    as_tibble() %>%
    haven::zap_labels(.)
  if(any(prob_vars %in% colnames(y))){
    y <- y %>% mutate_at(vars(one_of(prob_vars)), ~as.numeric(as.character(.)))
    }
  return(y)
}
```

```{r satsa codebook}
satsa_codebook <- (codebook %>% filter(study == "SATSA"))$codebook[[1]] %>%
  mutate_at(vars(orig_itemname), str_to_upper)
satsa_codebook
```


```{r satsa data, eval = T}
old.names <- unique(satsa_codebook$orig_itemname) %>% str_to_upper
datasets <- sprintf("%s/satsa", data_path) %>% list.files(., pattern = ".sav")
satsa <- tibble(datasets = datasets) %>%
  mutate(data = map(datasets, satsa_read_fun),
         ncol = map_dbl(data, ncol)) %>%
  filter(ncol != 0)

satsa <- reduce(satsa$data, full_join)
satsa <- satsa %>%
  mutate_if(is.factor, ~as.numeric(sub("^\\(0*([0-9]+)\\).+$", "\\1", .))) 
satsa_long <- satsa %>% 
  pivot_longer(
    names_to = "orig_itemname"
    , values_to = "value"
    , cols = -SID
    # , values_drop_na = T
    )
save(satsa, file = sprintf("%s/data/clean/satsa_raw.RData", wd))
rm(satsa)
```

### Recoding & Reverse Scoring  
```{r satsa recode}
satsa_waves <- p_waves %>% filter(Study == "SATSA") %>% select(Used) %>% distinct()

# join data with recoding info 
satsa_recode <- satsa_codebook %>%
  select(category, name, itemname, year, orig_itemname, reverse_code:long_rule) %>%
  filter(category %in% c("pers", "outcome", "covariates", "cognition")) %>%
  group_by(category, name) %>%
  nest() %>% 
  ungroup() %>%
  mutate(data = map(data, ~(.) %>% left_join(satsa_long)))

# recode 
recode_fun <- function(rule, y, year){
  x <- y$value
  if(!is.na(rule)){y$value <- eval(parse(text = rule))}
  return(y)
}

satsa_recode <- satsa_recode %>% 
  mutate(data = map(data, ~(.) %>% 
    group_by(recode, year) %>%
    nest() %>%
    ungroup() %>%
    mutate(data = pmap(list(recode, data, year), recode_fun)) %>%
    unnest(data) %>%
    mutate(value = ifelse(value < 0 | is.nan(value) | is.infinite(value), NA, value)) %>%
    filter(!is.na(value))))


# reverse code 
satsa_recode <- satsa_recode %>%
  mutate(data = map(data, ~(.) %>%
    mutate(value = ifelse(reverse_code == "no" | is.na(reverse_code), value, 
                        reverse.code(-1, value, mini = mini, maxi = maxi)))))

fun_call <- function(x, rule){
    switch(rule,
           average = mean(x, na.rm = T),
           mode = Mode(x)[1],
           sum = sum(x, na.rm = T),
           skip = unique(x)[1],
           select = unique(x)[1],
           max = max(x, na.rm = T),
           min = min(x, na.rm = T))
  }
```

### Covariates  

```{r satsa covariates, eval = T}
satsa_cov <- satsa_recode %>% filter(category == "covariates")
# bring in year or birth for cleaning
yrBrth <- satsa_cov %>% 
  filter(name == "yearBrth") %>% 
  unnest(data) %>%
  group_by(SID) %>%
  summarize(yearBrth = max(value, na.rm = T)) %>%
  ungroup() %>%
  mutate(yearBrth = ifelse(is.infinite(yearBrth), NA, yearBrth))

# compositing within years
year_comp_fun <- function(df, rule){
  df %>%
    # group by person and item (collapse across age)
    group_by(SID, name, year, long_rule) %>% 
    summarize(value = fun_call(value, rule)) %>%
    ungroup() %>% 
    mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value))
}

satsa_waves <- p_waves %>% filter(Study == "SATSA") %>% select(Used) %>% distinct()

satsa_cov <- satsa_cov %>%
  unnest(data) %>%
  filter(year <= max(satsa_waves$Used) + 1) %>%
  mutate(comp_rule = ifelse(is.na(comp_rule) | comp_rule == "none", "skip", comp_rule)) %>%
  group_by(comp_rule) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = map2(data, comp_rule, year_comp_fun)) %>%
  unnest(data)

comp_fun <- function(d, rule){
  d %>%
    group_by(SID) %>%
    summarize(value = fun_call(value, rule)) %>%
    ungroup()
}

satsa_cov <- satsa_cov %>%
  group_by(name, long_rule) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = map2(data, long_rule, comp_fun)) %>%
  unnest(data) %>%
  mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %>%
  select(-long_rule) %>%
  pivot_wider(names_from = name, values_from = value, values_fn = list(value = max))  %>%
  mutate(BMI = weight/((height/100)^2))
```

### Personality Variables  
```{r satsa pers, eval = T}
satsa_pers <- satsa_recode %>%
  filter(category == "pers") %>%
  unnest(data) %>%
  left_join(p_waves %>% filter(Study == "SATSA") %>% select(name = p_item, Used)) %>%
  filter(year %in% Used & !is.na(value)) %>%
  distinct() 

# alpha's
satsa_alpha <- satsa_pers %>%
  select(name, itemname, year, SID, value) %>%
  group_by(name, year) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = map(data, ~(.) %>% spread(itemname, value)),
         alpha = map(data, possibly(~psych::alpha((.) %>% select(-SID)), NA_real_)))

# create composites
satsa_pers <- satsa_pers %>%
  group_by(SID, name, year) %>%
  summarize(value = mean(value, na.rm = T)) %>%
  ungroup()
```

```{r satsa pers print, echo = F}
satsa_pers
```

### Outcome Variables  
```{r satsa out, eval = T}
satsa_out <- satsa_recode %>% 
  filter(category == "outcome") %>%
  unnest(data) %>%
  distinct() %>%
  full_join(crossing(p_year = satsa_waves$Used, name = unique((.)$name)))

satsa_out_waves <- satsa_out %>%
  group_by(SID, name) %>%
  summarize(o_year = max(year)) %>%
  ungroup()

satsa_waves <- p_waves %>% filter(Study == "SATSA") %>% select(Used) %>% distinct()

satsa_out <- satsa_out %>%
  filter(year > p_year) %>%
  group_by(SID, name, year, p_year) %>%
  summarize(value = max(value, na.rm = T)) %>% 
  ungroup() %>%
  mutate(value = ifelse(is.nan(value)|is.infinite(value), NA, value)) %>%
  group_by(SID, p_year, name) %>%
  summarize(value = max(value, na.rm = T)) %>%
  ungroup() %>%
  mutate(value = ifelse(is.infinite(value), NA, value),
         o_year = 2005) 
```

```{r satsa out print, echo = F}
satsa_out
```

### Cognition Variables  
```{r satsa cog, eval = T}
# composite within years
satsa_cog <- satsa_recode %>%
  filter(category == "cognition") %>%
  select(-category) %>%
  unnest(data) %>%
  filter(year == 1985) %>%
  filter(!is.na(value)) %>%
  group_by(name, itemname, year) %>%
  mutate(value = pomp(value)) %>%
  group_by(name, SID) %>%
  summarize(value = mean(value, na.rm = T)) %>%
  ungroup() %>%
  pivot_wider(names_from = "name"
              , values_from = "value")
```

### Combine Data  
```{r satsa combine}
satsa_combined <- satsa_pers %>% 
  rename(Trait = name, p_value = value, p_year = year) %>%
  full_join(satsa_out %>% rename(Outcome = name, o_value = value)) %>%
  full_join(satsa_cov) %>%
  left_join(
    satsa_out %>%
      filter(name == "dementia") %>%
      pivot_wider(names_from = "name", values_from = "value")
    ) %>%
  full_join(satsa_cog) %>%
  filter(!is.na(p_value) & !is.na(o_value)) %>%
  mutate(age = p_year - yearBrth
         , o_year = 2005)
```

```{r satsa save}
save(satsa_cov, satsa_alpha, satsa_pers, satsa_out, satsa_combined, satsa_cog,
     file = sprintf("%s/data/clean/satsa_cleaned.RData", wd))
```

```{r}
rm(list =ls()[grepl("satsa", ls())])
```

## ADRC Memory and Aging Project (ADRC-MAP)  
The Alzheimer Disease Research Center Memory and Aging Project (ADRC-MAP) is an ongoing longitudinal study of memory and Alzheimer's Disease that began in 1979. Data are available on a study-by-study basis through application from https://knightadrc.wustl.edu/Research/ResourceRequest.htm.

Participants were recruited from the Charles and Joanne F. Knight Alzheimerâ€™s Disease Research Center at Washington University in St. Louis as part of an ongoing study of disease progression. The current study uses a subset of approximately 1200 of these participants who completed personality surveys as part of a substudy (see Duchek et al., 2019). More information on the study can be found at https://knightadrc.wustl.edu/Research/PDFs/Clinical%20Core%20list%20of%20measures.pdf.

Sample sizes vary over time, from approximately 400 to 1200. This provides 99% power to detect a zero-order correlation effect size of ~.15, two-tailed at alpha .05.  

### Load Data  

```{r adrc-map codebook}
(adrc_codebook <- (codebook %>% filter(study == "ADRC"))$codebook[[1]])
```

```{r}
adrc_read_fun <- function(file){
  print(file)
  d <- sprintf("%s/adrc-map/%s", data_path, file) %>% read_excel(.) %>%
    select(SID = id, one_of(c("TESTDATE", old.names)), contains("NEO Date"))
  if("TESTDATE" %in% colnames(d)){ if(any(class(d$TESTDATE) != "numeric")){d$TESTDATE <- lubridate::year(d$TESTDATE)}}
  d
}

old.names <- unique(adrc_codebook$orig_itemname)
adrc <- tibble(file = list.files(sprintf("%s/adrc-map", data_path), pattern = ".xlsx")) %>%
  filter(!grepl("NEO", file)) %>%
  mutate(data = map(file, adrc_read_fun)) %>%
  filter(map_dbl(data, ncol) > 1)

waves <- adrc %>%
  mutate(data = map(data, ~(.) %>% select(SID, one_of("TESTDATE")))) %>%
  select(-file) %>%
  unnest(data) %>%
  filter(complete.cases(.)) %>%
  # mutate(year = lubridate::year(TESTDATE)) %>%
  distinct() %>%
  arrange(SID, TESTDATE) %>%
  group_by(SID) %>%
  mutate(frstyear = min(TESTDATE)) %>%
  ungroup() %>%
  mutate(year = TESTDATE, 
         wave = year - frstyear + 1)

adrc_long <- reduce(adrc$data, full_join) %>%
  distinct() %>%
  select(SID, year = TESTDATE, everything()) %>%
  mutate(BIRTH = lubridate::year(BIRTH)) %>%
  pivot_longer(cols = c(-SID, -year)
               , names_to = "orig_itemname"
               , values_to = "value")

# load personality data separately
old.names <- (adrc_codebook %>% filter(category == "pers"))$orig_itemname
adrc_pers <- sprintf("%s/adrc-map/NEO - Raw Scores_FINAL.xlsx", data_path) %>% 
  read_xlsx() %>%
  select(SID = id, date = `NEO Date 1`, one_of(old.names)) %>%
  mutate(date = ifelse(grepl("[//]", date), as.numeric(as.Date(date, format = "%m/%d/%Y")), date),
         date = as.Date(as.numeric(date), origin="1899-12-30")) %>%
  filter(!is.na(date))
# get waves for participants
adrc_pers_waves <- adrc_pers %>%
  select(SID, p_year = date) %>%
  distinct() %>%
  mutate(p_year = lubridate::year(p_year))
```

### Recode & Reverse-Scoring  
```{r}
adrc_recode <- adrc_codebook %>%
  filter(category %in%  c("covariates", "outcome", "cognition") & !is.na(orig_itemname)) %>%
  select(category, name, itemname, orig_itemname, reverse_code:long_rule) %>%
  right_join(adrc_long) %>%
  left_join(adrc_pers_waves)

# recode 

recode_fun <- function(rule, y, year){
  # print(rule)
  x <- y$value
  if(!is.na(rule)){y$value <- eval(parse(text = rule))}
  return(y)
}

adrc_recode <- adrc_recode %>%
  group_by(recode, year) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = pmap(list(recode, data, year), recode_fun)) %>%
  unnest(data)

# reverse code 
adrc_recode <- adrc_recode %>%
  mutate(value = ifelse(reverse_code == "no" | is.na(reverse_code), value, 
                        reverse.code(-1, value, mini = mini, maxi = maxi))) %>%
  group_by(category, name) %>%
  nest() %>% 
  ungroup()

fun_call <- function(x, rule){
    switch(rule,
           average = mean(x, na.rm = T),
           mode = Mode(x)[1],
           sum = sum(x, na.rm = T),
           skip = unique(x)[1],
           select = unique(x)[1],
           max = max(x, na.rm = T),
           min = min(x, na.rm = T))
  }
```


### Covariates  
```{r adrc cov}
# compositing within years
year_comp_fun <- function(df, rule){
  df %>%
    # group by person and item (collapse across age)
    group_by(SID, name, year, p_year, long_rule) %>% 
    summarize(value = fun_call(value, rule)) %>%
    ungroup() %>% 
    mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value))
}

adrc_cov <- adrc_recode %>%
  filter(category == "covariates") %>%
  unnest(data) %>%
  filter(year <= p_year) %>%
  mutate(comp_rule = ifelse(is.na(comp_rule) | comp_rule == "none", "skip", comp_rule)) %>%
  group_by(comp_rule) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = map2(data, comp_rule, year_comp_fun)) %>%
  unnest(data) %>%
  select(-comp_rule)

comp_fun <- function(d, rule){
  d %>%
    group_by(SID, name) %>%
    summarize(value = fun_call(value, rule)) %>%
    ungroup()
}

adrc_cov <- adrc_cov %>%
  filter(!is.na(value) & !is.na(name)) %>%
  group_by(long_rule) %>%
  nest() %>%
  ungroup() %>% 
  mutate(data = map2(data, long_rule, comp_fun)) %>%
  unnest(data) %>% 
  select(-long_rule) %>%
  mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %>%
  pivot_wider(names_from = name, values_from = value, values_fn = list(value = max)) %>%
  right_join(adrc_pers_waves) %>%
  mutate(age = p_year - yearBrth)
```

### Personality Variables  
```{r adrc pers}
# bring in codebook info
adrc_pers <- adrc_pers %>%
  pivot_longer(`1S1`:`1S60`
               , names_to = "orig_itemname"
               , values_to = "value"
               , values_drop_na = T) %>%
  left_join(adrc_codebook %>% select(name:orig_itemname, reverse_code:maxi))

recode_fun <- function(rule, y){
  x <- y$value
  if(!is.na(rule)){y$value <- eval(parse(text = rule))}
  return(y)
}

# recode 
adrc_pers <- adrc_pers %>%
  group_by(recode) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = map2(recode, data, recode_fun)) %>%
  unnest(data) 

# reverse code 
adrc_pers <- adrc_pers %>%
  mutate(value = ifelse(tolower(reverse_code) == "no" | is.na(reverse_code), value, 
                        reverse.code(-1, value, mini = mini, maxi = maxi)))

# alpha's
adrc_alpha <- adrc_pers %>%
  select(name, itemname, date, SID, value) %>%
  group_by(name) %>%
  nest() %>%
  mutate(data = map(data, ~(.) %>% pivot_wider(names_from = itemname, values_from = value)),
         alpha = map(data, possibly(~psych::alpha((.) %>% select(-SID, -date)), NA_real_)))

# create composites
adrc_pers <- adrc_pers %>%
  group_by(SID, name, date) %>%
  summarize(value = mean(value, na.rm = T))  %>%
  ungroup() %>%
  left_join(adrc_pers_waves)
```

### Outcome Variables  
```{r adrc outcome}
adrc_out <- adrc_recode %>%
  filter(category == "outcome") %>%
  unnest(data)

adrc_out_waves <- adrc_out %>%
  select(year, SID, name) %>%
  group_by(SID, name) %>%
  summarize(o_year = max(year)) %>% 
  ungroup()

# compositing within years
year_comp_fun <- function(df, rule){
  df %>%
    # group by person and item (collapse across age)
    group_by(SID, name, year, long_rule, p_year) %>% 
    summarize(value = fun_call(value, rule)) %>%
    ungroup() %>% 
    mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value))
}

adrc_out <- adrc_out %>%
  filter(!is.na(value)) %>%
  mutate(comp_rule = ifelse(is.na(comp_rule) | comp_rule == "none", "skip", comp_rule)) %>%
  group_by(comp_rule) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = map2(data, comp_rule, year_comp_fun)) %>%
  unnest(data)

comp_fun <- function(d, rule){
  d %>%
    group_by(SID, name) %>%
    summarize(value = fun_call(value, rule)) %>%
    ungroup()
}

adrc_out <- adrc_out %>%
  filter(name == "dementia") %>%
  mutate(group = ifelse(year <= p_year, "past", "future")) %>%
  group_by(SID, name, group, p_year) %>%
  summarize(value = max(value, na.rm = T)) %>%
  ungroup() %>%
  mutate(value = ifelse(is.infinite(value), NA, value)) %>%
  pivot_wider(names_from = group, values_from = value) %>%
  group_by(SID, name) %>%
  mutate(value = ifelse(is.na(past) | (past == 0 & !is.na(future)), future,
                 ifelse(past == 0 & is.na(future), past, 
                 ifelse(past == 1, NA, NA)))) %>%
  ungroup() %>%
  full_join(
    adrc_out %>%
      filter(name != "dementia" & !is.na(value) & year >= p_year) %>% 
      group_by(long_rule, p_year) %>%
      nest() %>%
      ungroup() %>% 
      mutate(data = map2(data, long_rule, comp_fun)) %>%
      select(-long_rule) %>%
      unnest(data) %>%
      mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value))
  ) %>%
  left_join(adrc_out_waves)
```

### Cognition Variables  
```{r adrc cog, eval = T}
# composite within years
adrc_cog <- adrc_recode %>%
  filter(category == "cognition") %>%
  select(-category) %>%
  unnest(data) %>%
  filter(!is.na(p_year)) %>%
  filter(!is.na(value)) %>%
  group_by(name, itemname, year) %>%
  mutate(value = pomp(value)) %>%
  group_by(SID, name, itemname) %>%
  filter(year %in% (p_year - 1):(p_year + 1)) %>%
  group_by(name, SID) %>%
  summarize(value = mean(value, na.rm = T)) %>%
  ungroup() %>%
  pivot_wider(names_from = "name"
              , values_from = "value")
```

### Combine Data  
```{r adrc combine}
adrc_combined <- adrc_pers %>% 
  select(SID, Trait = name, p_value = value, p_year) %>%
  full_join(
    adrc_out %>% 
      select(SID, o_year, Outcome = name, o_value = value)
    ) %>%
  filter(!is.na(o_value) & !is.na(p_value)) %>%
  distinct() %>%
  left_join(adrc_cov) %>%
  left_join(
    adrc_out %>%
      filter(name == "dementia") %>%
      mutate(value = ifelse(rowSums(cbind(future, past), na.rm = T) >= 1, 1, 0)) %>%
      select(-future, -past) %>%
      pivot_wider(names_from = "name", values_from = "value")
    ) %>%
  left_join(adrc_cog) %>%
  left_join(adrc_out_waves %>% select(SID, Outcome = name, o_year))
```

```{r adrc save}
save(adrc_cov, adrc_alpha, adrc_pers, adrc_out, adrc_combined, adrc_cog,
     file = sprintf("%s/data/clean/adrc_cleaned.RData", wd))
```

```{r}
rm(list =ls()[grepl("adrc", ls())])
```

## Einstein Aging Study  
The Einstein Aging Study (EAS) is an ongoing longitudinal study of the aging brain. The EAS began in 1980 and has enrolled more than 2,600 participants since then. Data are available through application at http://www.einstein.yu.edu/departments/neurology/clinical-research-program/eas/data-sharing.aspx.  

Since 1993, the EAS has systematically recruited a representative aging sample in the Bronx, New York, As of 2017, 2,600 participants were enrolled in the study. As of 2010, approximately 200 of the enrolled participants had autopsy data. More information on the study can be found at http://www.einstein.yu.edu/departments/neurology/clinical-research-program/EAS/.  

Sample sizes vary over time, with ranges across waves not publically available. However, we suspect approximately 2,000 participants to have basic personality and dementia diagnoses, with between 150 and 300 participants having full autopsy data collected after personality was introduced into the study. This yields 99\% power to detect a zero-order correlation effect size of .10 and .24, respectively, two-tailed at alpha .05.  

### Load Data  
```{r eas codebook}
(eas_codebook <- (codebook %>% filter(study == "EAS"))$codebook[[1]])
```

```{r nlsy data, eval = F}
old.names1 <- unique((eas_codebook %>% filter(dataset == "behavior"))$orig_itemname)
old.names2 <- unique((eas_codebook %>% filter(dataset == "neuropath"))$orig_itemname)
old.names3 <- unique((eas_codebook %>% filter(dataset == "activity"))$orig_itemname)
eas <- sprintf("%s/eas/Behavior_with_Master_Data_2021_10_25.xlsx", data_path) %>% 
  read_excel(., sheet = 1) %>% 
  mutate(year = lubridate::year(BehaviorDate)) %>%
  select(SID = Id, wave = Wave, year, one_of(old.names1)) %>%
  full_join(
    sprintf("%s/eas/Neuropath_and_Behavior_Data_2021_09_26 (3).xlsx", data_path) %>% 
      read_excel(.) %>% 
      select(SID = `Clin#`, year = DOD, wave = Wave, one_of(old.names2)) %>%
      mutate(comb_dx = ifelse(c("VaD", "AD", "AGD") %in% Dx1 | c("VaD", "AD", "AGD") %in% Dx2 | 
                                c("VaD", "AD", "AGD") %in% Dx3 | grepl("VaD", `OTHER Dx`) | 
                                grepl("AD", `OTHER Dx`) | grepl("AGD", `OTHER Dx`), 1, 0)
             , year = lubridate::year(year)) %>%
      select(-(Dx1:`OTHER Dx`))
  ) %>% 
  full_join(
    sprintf("%s/eas/Northwestern_supp_Physical_Activities_2021_10_25-1.xlsx", data_path) %>% 
      read_excel(.) %>% 
      select(SID = Id, wave = Wave, one_of(old.names3))
  ) %>% 
  mutate(Gender = ifelse(Gender == "F", 1, ifelse(Gender == "M", 0, NA)))

eas_waves <- eas %>% select(SID, wave, year) %>% distinct()

eas_long <- eas %>%
  pivot_longer(values_to = "value"
               , names_to = "orig_itemname"
               , cols = c(-SID, -wave, -year))
```

### Recode & Reverse-Scoring  
```{r}
eas_recode <- eas_codebook %>%
  filter(category %in%  c("covariates", "outcome", "cognition", "pers") & !is.na(orig_itemname)) %>%
  select(category, name, itemname, orig_itemname, reverse_code:long_rule) %>%
  right_join(eas_long) 

# recode 

recode_fun <- function(rule, y, year){
  print(rule)
  x <- y$value
  if(!is.na(rule)){y$value <- eval(parse(text = rule))}
  return(y)
}

eas_recode <- eas_recode %>%
  group_by(recode, year) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = pmap(list(recode, data, year), recode_fun)) %>%
  unnest(data)

# reverse code 
eas_recode <- eas_recode %>%
  mutate(value = ifelse(reverse_code == "no" | is.na(reverse_code), value, 
                        reverse.code(-1, value, mini = mini, maxi = maxi))) %>%
  group_by(category, name) %>%
  nest() %>% 
  ungroup()

fun_call <- function(x, rule){
    switch(rule,
           average = mean(x, na.rm = T),
           mode = Mode(x)[1],
           sum = sum(x, na.rm = T),
           skip = unique(x)[1],
           select = unique(x)[1],
           max = max(x, na.rm = T),
           min = min(x, na.rm = T))
}

eas_p_waves <- eas_recode %>% 
  filter(category == "pers") %>% 
  unnest(data) %>%
  filter(!is.na(value)) %>%
  group_by(SID) %>%
  filter(year == min(year)) %>%
  ungroup() %>%
  select(SID, p_year = year) %>%
  distinct()
```

### Covariates  
```{r eas cov}
# compositing within years
year_comp_fun <- function(df, rule){
  df %>%
    # group by person and item (collapse across age)
    group_by(SID, name, year, p_year, long_rule) %>% 
    summarize(value = fun_call(value, rule)) %>%
    ungroup() %>% 
    mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value))
}

eas_cov <- eas_recode %>%
  filter(category == "covariates") %>%
  unnest(data) %>%
  left_join(eas_p_waves) %>%
  filter(year <= p_year) %>%
  mutate(comp_rule = ifelse(is.na(comp_rule) | comp_rule == "none", "skip", comp_rule)) %>%
  group_by(comp_rule) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = map2(data, comp_rule, year_comp_fun)) %>%
  unnest(data) %>%
  select(-comp_rule)

comp_fun <- function(d, rule){
  d %>%
    group_by(SID, name) %>%
    summarize(value = fun_call(value, rule)) %>%
    ungroup()
}

eas_cov <- eas_cov %>%
  filter(!is.na(value) & !is.na(name)) %>%
  group_by(long_rule) %>%
  nest() %>%
  ungroup() %>% 
  mutate(data = map2(data, long_rule, comp_fun)) %>%
  unnest(data) %>% 
  select(-long_rule) %>%
  mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %>%
  pivot_wider(names_from = name, values_from = value, values_fn = list(value = max)) %>%
  right_join(eas_p_waves) 
```

### Personality Variables  
```{r eas pers}
# bring in codebook info
eas_pers <- eas_recode %>% 
  filter(category == "pers") %>%
  unnest(data) %>%
  left_join(eas_p_waves) %>% 
  filter(year == p_year)

# create composites
eas_pers <- eas_pers %>%
  group_by(SID, name, p_year) %>%
  summarize(value = mean(value, na.rm = T))  %>%
  ungroup() 
```

### Outcome Variables  
```{r eas outcome}
eas_out <- eas_recode %>%
  filter(category == "outcome") %>%
  unnest(data)

eas_out_waves <- eas_out %>%
  filter(!is.na(value)) %>%
  select(year, SID, name) %>%
  group_by(SID, name) %>%
  summarize(o_year = max(year)) %>% 
  ungroup()

# compositing within years
year_comp_fun <- function(df, rule){
  df %>%
    # group by person and item (collapse across age)
    group_by(SID, name, year, long_rule, p_year) %>% 
    summarize(value = fun_call(value, rule)) %>%
    ungroup() %>% 
    mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value))
}

eas_out <- eas_out %>%
  left_join(eas_p_waves) %>%
  filter(!is.na(value)) %>%
  mutate(comp_rule = ifelse(is.na(comp_rule) | comp_rule == "none", "skip", comp_rule)) %>%
  group_by(comp_rule) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = map2(data, comp_rule, year_comp_fun)) %>%
  unnest(data)

eas_out <- eas_out %>%
  filter(name == "dementia") %>%
  mutate(group = ifelse(year <= p_year, "past", "future")) %>%
  group_by(SID, name, group, p_year) %>%
  summarize(value = max(value, na.rm = T)) %>%
  ungroup() %>%
  mutate(value = ifelse(is.infinite(value), NA, value)) %>%
  pivot_wider(names_from = group, values_from = value) %>%
  group_by(SID, name) %>%
  mutate(value = ifelse(is.na(past) | (past == 0 & !is.na(future)), future,
                 ifelse(past == 0 & is.na(future), past, 
                 ifelse(past == 1, NA, NA)))) %>%
  ungroup() %>%
  full_join(eas_out %>%
    filter(name != "dementia") %>%
    group_by(SID, name, long_rule, p_year) %>%
    summarize(value = max(value, na.rm = T)) %>%
    ungroup() %>%
    select(-long_rule) %>%
    mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value))
  ) %>%
  left_join(eas_out_waves) %>%
  filter(!is.na(value))
```

### Cognition Variables  
```{r eas cog, eval = T}
# composite within years
eas_cog <- eas_recode %>%
  filter(category == "cognition") %>%
  select(-category) %>%
  unnest(data) %>%
  left_join(eas_p_waves) %>%
  filter(!is.na(p_year) & !is.na(value)) %>%
  group_by(name, itemname, year) %>%
  mutate(value = pomp(value)) %>%
  group_by(SID, name, itemname) %>%
  filter(year %in% (p_year - 1):(p_year + 1)) %>%
  group_by(name, SID) %>%
  summarize(value = mean(value, na.rm = T)) %>%
  ungroup() %>%
  pivot_wider(names_from = "name"
              , values_from = "value")
```

### Combine Data  
```{r eas combine}
eas_combined <- eas_pers %>% 
  select(SID, Trait = name, p_value = value, p_year) %>%
  full_join(
    eas_out %>% 
      select(SID, o_year, Outcome = name, o_value = value)
    ) %>%
  filter(!is.na(o_value) & !is.na(p_value)) %>%
  distinct() %>%
  left_join(
    eas_out %>%
      filter(name == "dementia") %>%
      mutate(value = ifelse(rowSums(cbind(future, past), na.rm = T) >= 1, 1, 0)) %>%
      select(-future, -past) %>%
      pivot_wider(names_from = "name", values_from = "value")
    ) %>%
  left_join(eas_cov) %>%
  left_join(eas_cog) 
```

```{r eas save}
save(eas_cov, eas_pers, eas_out, eas_combined, eas_cog,
     file = sprintf("%s/data/clean/eas_cleaned.RData", wd))
```

```{r}
rm(list =ls()[grepl("eas", ls())])
```

## German Socioeconomic Panel Study (GSOEP)  

The German Socioeconomic Panel Study (GSOEP; Socio-Economic Panel, 2017) is an ongoing longitudinal study of German collected by the German Institute of Economic Research (DIW Berlin). The data are freely available at https://www.diw.de/soep by application.  

Data have been collected annually since 1984 (the latest data release includes data up to 2017). Participants have been recruited from more than 11,000 households, which are nationally representative of private German households. 20,000 individuals are sampled each year, on average. It is critical to note that the GSOEP samples households, not individuals, and the households consist of individuals living in both the â€œoldâ€ and â€œnewâ€ federal states (the former West and East Germany), foreigners, and recent immigrants to Germany.  

Sample size varies by year, ranging from approximately 10,000 (1989) to 31,000 (2013). This provides 99\% power to detect a zero-order correlation effect size of ~.06, two-tailed at alpha < .05.  
 
### Load Data  
```{r gsoep clean fun, eval = T}
gsoep_read_fun <- function(Year, WL){
  old.names <- (gsoep_codebook %>% filter(year == Year | category == "proc"))$orig_itemname 
  p <- sprintf("%s/gsoep/%sp.sav", data_path, WL) %>% haven::read_sav(.) %>%
    full_join(sprintf("%s/gsoep/%skind.sav", data_path, WL) %>% haven::read_sav(.)) %>%
    full_join(sprintf("%s/gsoep/%spequiv.sav", data_path, WL) %>% haven::read_sav(.)) %>%
    full_join(sprintf("%s/gsoep/%spgen.sav", data_path, WL) %>% haven::read_sav(.)) %>%
    full_join(sprintf("%s/gsoep/%spkal.sav", data_path, WL) %>% haven::read_sav(.)) %>%
    select(one_of(old.names)) %>%
    gather(key = orig_itemname, value = value, -persnr, -hhnr, na.rm = T)
  
 sprintf("%s/gsoep/%shbrutto.sav", data_path, WL) %>% haven::read_sav(.) %>%
    full_join(sprintf("%s/gsoep/%sh.sav", data_path, WL) %>% haven::read_sav(.)) %>%
    select(one_of(old.names)) %>%
    gather(key = orig_itemname, value = value, -hhnr, na.rm = T) %>%
    full_join(p %>% select(persnr, hhnr) %>% distinct()) %>%
    full_join(p) 
}
```

```{r gsoep codebook}
gsoep_codebook <- (codebook %>% filter(study == "GSOEP"))$codebook[[1]] %>%
  mutate(orig_itemname = str_to_lower(orig_itemname))
gsoep_codebook
```

```{r gsoep data, eval = T}
gsoep <- gsoep_codebook %>% 
  select(wave, waveletter, year) %>%
  filter(complete.cases(.)) %>%
  distinct() %>%
  arrange(year) %>%
  filter(year != "2018") %>%
  mutate(data = map2(year, waveletter, gsoep_read_fun)) 

old.names <- unique(gsoep_codebook$orig_itemname)
gsoep_cog <- sprintf("%s/gsoep/cognit.sav", data_path) %>% haven::read_sav(.) %>%
  select(persnr, hhnr, one_of(old.names)) %>%
  haven::zap_labels(.) %>%
  select(-hhnr) %>%
  gather(key = orig_itemname, value = value, -persnr, na.rm = T)

gsoep_long <- gsoep %>% unnest(data) %>%
  select(-hhnr, -wave, -waveletter, -year) %>%
  # filter(persnr %in% gsoep_cog_subs) %>%
  full_join(gsoep_cog) %>%
  rename(SID = persnr)

save(gsoep, file = sprintf("%s/data/clean/gsoep_raw.RData", wd))
rm(gsoep)
```


### Recoding & Reverse Scoring  
```{r gsoep recode}
gsoep_waves <- p_waves %>% filter(Study == "GSOEP") %>% select(Used) %>% distinct()

# join data with recoding info 
gsoep_recode <- gsoep_codebook %>%
  filter(category %in% c("pers", "outcome", "covariates", "cognition")) %>%
  select(category, name, itemname, wave, year, orig_itemname, reverse_code:long_rule) %>%
  group_by(category, name) %>% 
  nest() %>%
  ungroup() %>%
  mutate(data = map(data, ~(.) %>% left_join(gsoep_long))) 

# recode 
recode_fun <- function(rule, y, year){
  x <- y$value
  if(!is.na(rule)){y$value <- eval(parse(text = rule))}
  return(y)
}

gsoep_recode <- gsoep_recode %>% 
  mutate(data = map(data, ~(.) %>% 
    group_by(recode, year) %>%
    nest() %>%
    ungroup() %>%
    mutate(data = pmap(list(recode, data, year), recode_fun)) %>%
    unnest(data) %>%
    mutate(value = ifelse(value < 0 | is.nan(value) | is.infinite(value), NA, value))))

# reverse code 
gsoep_recode <- gsoep_recode %>%
  mutate(data = map(data, ~(.) %>%
    mutate(value = ifelse(reverse_code == "no" | is.na(reverse_code), value, 
                        reverse.code(-1, value, mini = mini, maxi = maxi)))))

fun_call <- function(x, rule){
    switch(rule,
           average = mean(x, na.rm = T),
           mode = Mode(x)[1],
           sum = sum(x, na.rm = T),
           skip = unique(x)[1],
           select = unique(x)[1],
           max = max(x, na.rm = T),
           min = min(x, na.rm = T))
  }
```

### Covariates  
```{r gsoep matching, eval = T}
yrBrth <- gsoep_recode %>% 
  filter(name == "yearBrth") %>% 
  unnest(data) %>%
  group_by(SID) %>% 
  summarize(yearBrth = max(value, na.rm = T)) %>%
  ungroup() %>%
  mutate(yearBrth = ifelse(is.infinite(yearBrth), NA, yearBrth),
         yearBrth = ifelse(yearBrth < 1000, yearBrth + 1000, yearBrth)) 

# compositing within years
year_comp_fun <- function(df, rule, name){
  print(paste(rule, name))
  df %>%
    group_by(SID, yearBrth, year, long_rule) %>% # group by person and item (collapse across age)
    summarize(value = fun_call(value, rule)) %>%
    ungroup()
}

gsoep_waves <- p_waves %>% filter(Study == "GSOEP") %>% select(Used) %>% distinct()

gsoep_cov <- gsoep_recode %>%
  filter(category == "covariates") %>%
  mutate(data = ifelse(name == "alcohol", map(data, ~(.) %>% mutate(year = ifelse(year == 2006, 2005, year))), data)) %>%
  mutate(data = map(data, ~(.) %>%
    left_join(yrBrth) %>%
    filter(year <= max(gsoep_waves$Used) & !is.na(value)) %>%
    group_by(comp_rule) %>%
    nest() %>%
    ungroup() %>%
    mutate(comp_rule = ifelse(is.na(comp_rule), "skip", comp_rule)))) %>%
  filter(map(data, nrow) > 0) %>%
  unnest(data) %>%
  mutate(data = pmap(list(data, comp_rule, name), year_comp_fun)) %>%
  unnest(data)

comp_fun <- function(rule, p_year){
  gsoep_cov %>%
    filter(year <= p_year  & long_rule == rule) %>%
    group_by(SID, yearBrth, name) %>%
    summarize(value = fun_call(value, rule)) %>%
    ungroup()
}

gsoep_cov <- crossing(
  p_year = gsoep_waves$Used, 
  long_rule = unique(gsoep_cov$long_rule)
  ) %>%
  mutate(data = map2(long_rule, p_year, comp_fun)) %>%
  unnest(data) %>%
  mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %>%
  select(-long_rule, -yearBrth) %>%
  pivot_wider(names_from = name, values_from = value) %>%
  mutate(yearBrth = ifelse(yearBrth < 1000, yearBrth + 1000, yearBrth))
```

```{r}
gsoep_cov
```

### Personality Variables  
```{r gsoep pers, eval = T}
gsoep_pers <- gsoep_recode %>%
  filter(category == "pers") %>%
  unnest(data) %>%
  filter(year %in% gsoep_waves$Used) %>%
  distinct()

# alpha's
gsoep_alpha <- gsoep_pers %>%
  select(name, itemname, year, SID, value) %>%
  group_by(name, year) %>%
  nest() %>%
  mutate(data = map(data, ~(.) %>% pivot_wider(names_from = itemname, values_from = value)),
         alpha = map(data, possibly(~psych::alpha((.) %>% select(-persnr)), NA_real_)))

comp_fun <- function(df, rule){
  df %>%
    group_by(SID) %>%
    summarize(value = fun_call(value, rule)) %>%
    ungroup()
}

# create composites
gsoep_pers <- gsoep_pers %>%
  group_by(name, comp_rule, year) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = map2(data, comp_rule, comp_fun)) %>%
  unnest(data) %>% 
  select(-comp_rule) %>%
  mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value))
```

### Outcome Variables  
```{r gsoep out, eval = T}
gsoep_pers_subs <- unique(gsoep_pers$SID)
gsoep_waves <- p_waves %>% filter(Study == "GSOEP") %>% select(Used) %>% distinct()

# composite within years 
# compositing within years
year_comp_fun <- function(df, rule){
  df %>%
    group_by(SID, name, year) %>% # group by person and item (collapse across age)
    summarize(value = fun_call(value, rule)) %>%
    ungroup()
}


gsoep_out <- gsoep_recode %>%
  filter(category == "outcome") %>%
  unnest(data) %>%
  # filter(year <= max(gsoep_waves$Used)) %>%
  group_by(comp_rule) %>%
  nest() %>%
  ungroup() %>%
  mutate(comp_rule = ifelse(comp_rule == "select", "skip", comp_rule),
         data = map2(data, comp_rule, year_comp_fun)) %>%
  unnest(data)

# composite across years
comp_fun <- function(p_year){
  gsoep_out %>%
    group_by(SID, name) %>%
    summarize(value = max(value, na.rm = T)) %>%
    ungroup() %>%
    mutate(value = ifelse(is.infinite(value), NA, value)) 
}

gsoep_out <- tibble(p_year = gsoep_waves$Used) %>%
  mutate(data = map(p_year, comp_fun)) %>%
  unnest(data) %>%
  mutate(o_year = 2017)
```

### Cognition Variables  
```{r}
gsoep_cog <- gsoep_recode %>%
  filter(category == "cognition") %>%
  unnest(data) %>% 
  filter(!is.na(value))

gsoep_cog_waves <- gsoep_cog %>%
  select(itemname, SID, year) %>%
  group_by(SID, itemname) %>%
  summarize(o_year = max(year)) %>%
  ungroup()

gsoep_cog <- gsoep_cog %>%
  right_join(gsoep_cog_waves) %>%
  filter(year == o_year) %>%
  filter(!is.na(value)) %>%
  group_by(name, itemname, year) %>%
  mutate(value = pomp(value)) %>%
  group_by(name, o_year, SID) %>%
  summarize(value = mean(value)) %>%
  ungroup() %>%
  pivot_wider(names_from = "name", values_from = "value")
```

### Combine Data  
```{r gsoep combine}
gsoep_combined <- gsoep_pers %>% 
  rename(Trait = name, p_value = value, p_year = year) %>%
  full_join(gsoep_out %>% select(p_year, SID, Outcome = name, o_year, o_value = value)) %>%
  full_join(gsoep_cov) %>%
  left_join(
    gsoep_out %>%
      filter(name == "dementia") %>%
      pivot_wider(names_from = "name", values_from = "value")
    ) %>%
  full_join(gsoep_cog) %>%
  filter(!is.na(p_value) & !is.na(o_value)) %>%
  mutate(age = p_year - yearBrth
         , BMI = weight/((height/100)^2))
```

```{r gsoep save}
save(gsoep_cov, gsoep_alpha, gsoep_pers, gsoep_out, gsoep_combined, gsoep_cog,
     file = sprintf("%s/data/clean/gsoep_cleaned.RData", wd))
```

```{r}
rm(list =ls()[grepl("gsoep", ls())])
```

## The Longitudinal Studies for the Social sciences (LISS)  
The Longitudinal Studies for the Social sciences (LISS; Scherpenzeel, Das, Ester, & Kaczmirek, 2010) is an ongoing longitudinal study of households in the Netherlands. These data are online, through application, from https://statements.centerdata.nl/liss-panel-data-statement.  

Participants were approximately 8,000 Dutch-speaking individuals permanently residing in the Netherlands from 5,000 households. Data have been collected annually since 2007. The latest data release includes 11 waves of data from 2008 to 2018. More documentation are available at https://www.dataarchive.lissdata.nl/study_units/view/1.  

Sample sizes vary by year, ranging from 5,021 (2018) to 6808 (2008). This provides 99/% power to detect a correlation effect size of ~.04, two-tailed at alpha .05.  

### Load Data  
```{r liss clean fun, eval = T}
liss_read_fun <- function(x){
  sprintf("%s/liss/%s", data_path, x) %>% haven::read_sav(.) %>% select(one_of(old.names))
}
```

```{r liss codebook}
liss_codebook <- (codebook %>% filter(study == "LISS"))$codebook[[1]]
liss_codebook
```

```{r liss data, eval = T}
old.names <- unique(liss_codebook$orig_itemname) %>% str_to_lower
datasets <- sprintf("%s/liss", data_path) %>% list.files()
liss <- tibble(datasets = datasets) %>%
  mutate(data = map(datasets, liss_read_fun)) 

liss <- reduce(liss$data, full_join) %>% haven::zap_labels(.)
save(liss, file = sprintf("%s/data/clean/liss_raw.RData", wd))

avars <- tibble(ds = datasets[grepl("avar", datasets)]) %>%
  mutate(data = map(ds, ~sprintf("%s/liss/%s", data_path, .) %>% 
                      haven::read_sav(.) %>% 
                      select(one_of(old.names)) %>% 
                      haven::zap_labels(.))) %>%
  separate(ds, c("ds", "year", "scrap1", "scrap2"), sep = "_") %>%
  separate(year, c("year", "month"), -2) %>%
  select(year, month, data) %>% 
  unnest(data) 
```

### Recoding & Reverse-Scoring  
```{r liss recode, eval = T}
rename_fun <- function(cb, var){
  print(var)
  old.names <- unique((liss_codebook %>% filter(name == var))$orig_itemname)
  df <- liss %>% 
    select(SID = nomem_encr, HHID = nohouse_encr, one_of(old.names)) %>%
    gather(key = orig_itemname, value = value, 
           -SID, -HHID, na.rm=T)
  if(length(old.names) > 1){
      df <- df %>% left_join(cb %>% select(itemname, year, orig_itemname, reverse_code:long_rule))
  } else {
    df <- df %>% left_join(cb %>% select(-(itemname:year)) %>% distinct()) %>% mutate(year = 0)
  }
  if(var %in% c("yearBrth", "gender")) df <- df %>% left_join(avars %>% select(-category, -name))
  return(df)
}

avars <- avars %>%
  select(SID = nomem_encr, HHID = nohouse_encr, everything()) %>%
  group_by(SID, HHID, year) %>%
  summarize_at(vars(gebjaar, geslacht), Mode) %>%
  ungroup() %>%
  pivot_longer(cols = c("gebjaar", "geslacht")
               , names_to = "orig_itemname"
               , values_to = "value") %>%
  mutate(year = as.numeric(year)) %>%
  left_join(
    liss_codebook %>% 
      select(category, name, itemname, year, orig_itemname, reverse_code:long_rule)
    )

# rename variables   
liss_recode <- liss_codebook %>%
  filter(category %in% c("covariates", "pers", "outcome", "cognition")) %>%
  select(category, name:wave, year:orig_itemname, reverse_code:long_rule) %>%
  group_by(category, name) %>% 
  nest() %>%
  ungroup() %>%
  mutate(data = map2(data, name, rename_fun))


recode_fun <- function(rule, y){
  x <- y$value
  if(!is.na(rule)){y$value <- eval(parse(text = rule))}
  return(y)
}


liss_recode <- liss_recode %>% 
  mutate(data = map(data, ~(.) %>% 
    group_by(recode) %>%
    nest() %>%
    ungroup() %>%
    mutate(data = pmap(list(recode, data), recode_fun)) %>%
    unnest(data) %>%
    mutate(value = ifelse(value < 0 | is.nan(value) | is.infinite(value), NA, value))))


# reverse code 
liss_recode <- liss_recode %>%
  mutate(data = map(data, ~(.) %>%
          mutate(value = ifelse(tolower(reverse_code) == "no" | is.na(reverse_code), value, 
                        reverse.code(-1, value, mini = mini, maxi = maxi)))))

fun_call <- function(x, rule){
    switch(rule,
           average = mean(x, na.rm = T),
           mode = Mode(x)[1],
           sum = sum(x, na.rm = T),
           skip = unique(x)[1],
           select = unique(x)[1],
           max = max(x, na.rm = T),
           min = min(x, na.rm = T))
  }
```


### Covariates  

```{r liss matching, eval = T}
# bring in year or birth for cleaning
liss_cov <- liss_recode %>% 
  filter(category == "covariates") %>% 
  unnest(data) %>%
  distinct()

# compositing within years
year_comp_fun <- function(df, rule){
  df %>%
    # group by person and item (collapse across age)
    group_by(SID, HHID, long_rule, name, year) %>% 
    summarize(value = fun_call(value, rule)) %>%
    ungroup() %>% 
    mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value))
}

liss_waves <- p_waves %>% filter(Study == "LISS") %>% select(Used) %>% distinct()

liss_cov <- liss_cov %>%
  filter(year <= max(liss_waves$Used)) %>%
  group_by(comp_rule) %>%
  nest() %>%
  ungroup() %>%
  mutate(data = map2(data, comp_rule, year_comp_fun)) %>%
  unnest(data)

comp_fun <- function(rule, p_year){
  liss_cov %>%
    filter(year <= p_year  & long_rule == rule) %>%
    group_by(SID, HHID, name) %>%
    summarize(value = fun_call(value, rule)) %>%
    ungroup()
}

liss_cov <- crossing(
  p_year = liss_waves$Used, 
  long_rule = unique(liss_cov$long_rule)
  ) %>%
  mutate(data = map2(long_rule, p_year, comp_fun)) %>%
  unnest(data) %>%
  mutate(value = ifelse(is.infinite(value) | is.nan(value), NA, value)) %>%
  select(-long_rule) %>%
  pivot_wider(names_from = name, values_from = value, values_fn = list(value = max)) %>%
  mutate(BMI = weight/((height/100)^2))
```

### Personality Variables  
```{r liss pers, eval = T}
liss_pers <- liss_recode %>%
  filter(category == "pers") %>%
  unnest(data) %>%
  filter(year == liss_waves$Used) %>%
  distinct()

# alpha's
liss_alpha <- liss_pers %>%
  select(name, itemname, year, SID, value) %>%
  group_by(name, year) %>%
  nest() %>%
  mutate(data = map(data, ~(.) %>% pivot_wider(names_from = itemname, values_from = value)),
         alpha = map(data, possibly(~psych::alpha((.) %>% select(-SID)), NA_real_)))

# create composites
liss_pers <- liss_pers %>%
  group_by(SID, HHID, name, year) %>%
  summarize(value = mean(value, na.rm = T))  %>%
  ungroup()
```

### Cognition Variables
```{r}
liss_cog <- liss_recode %>%
  filter(category == "cognition") %>%
  unnest(data) %>%
  filter(year == liss_waves$Used) %>%
  filter(!is.na(value)) %>%
  group_by(name, itemname, year) %>%
  mutate(value = pomp(value)) %>%
  distinct() %>%
  group_by(name, SID) %>%
  summarize(value = mean(value)) %>%
  ungroup() %>%
  pivot_wider(names_from = "name", values_from = "value")
```

### Outcome Variables  
```{r liss out, eval = T}
liss_out <- liss_recode %>%
  filter(category == "outcome") %>%
  unnest(data) %>%
  mutate(p_year = liss_waves$Used, 
         group = ifelse(year > p_year, "future", "past")) %>%
  group_by(SID, name, group, p_year) %>%
  summarize(value = max(value, na.rm = T)) %>%
  ungroup() %>%
  mutate(value = ifelse(is.infinite(value), NA, value)) %>%
  pivot_wider(names_from = group, values_from = value) %>%
  group_by(SID, p_year, name) %>%
  mutate(value = ifelse(is.na(past) | (past == 0 & !is.na(future)), future,
                 ifelse(past == 0 & is.na(future), past, 
                 ifelse(past == 1, NA, NA)))) %>% 
  ungroup() %>%
  filter(!is.na(value))
```

### Combine Data  
```{r liss combine}
liss_combined <- liss_pers %>% 
  rename(Trait = name, p_value = value, p_year = year) %>%
  full_join(liss_out %>% rename(Outcome = name, o_value = value)) %>%
  full_join(liss_cov) %>%
  left_join(
    liss_out %>%
      filter(name == "dementia") %>%
      mutate(value = ifelse(rowSums(cbind(future, past), na.rm = T) >= 1, 1, 0)) %>%
      select(-future, -past) %>%
      pivot_wider(names_from = "name", values_from = "value")
    ) %>%
  full_join(liss_cog) %>%
  filter(!is.na(p_value) & !is.na(o_value)) %>%
  mutate(age = p_year - yearBrth
         , o_year = 2018)
```

```{r liss save}
save(liss_cov, liss_alpha, liss_pers, liss_out, liss_combined, liss_cog, 
     file = sprintf("%s/data/clean/liss_cleaned.RData", wd))
```

```{r}
rm(list =ls()[grepl("liss", ls())])
```